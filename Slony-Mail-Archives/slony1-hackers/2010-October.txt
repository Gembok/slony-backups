From cbbrowne at ca.afilias.info  Tue Oct  5 15:48:04 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue, 05 Oct 2010 18:48:04 -0400
Subject: [Slony1-hackers] Docs not building just now
Message-ID: <87eic4cl3v.fsf@cbbrowne.afilias-int.info>

A bunch of stuff is busted in the documentation right now; the root of
it seems to be the changes in commit
d40f0bfe8ea8fe398fc1aa89a45412a028daaa29, which restructured lots of
stuff but, I suspect, without verification that the docs were building.

I committed some changes that rectify *some* of it; there were a lot
more problems.  Still a ways to go with the documentation.

postgres at cbbrowne [06:31:21] [~/slony1-engine.master/doc/adminguide] [REL_2_0_STABLE *]
-> % make html
make: Circular HTML.index <- html dependency dropped.
LC_ALL=C /usr/bin/perl /usr/bin/collateindex.pl -f -g -i 'bookindex' -o bookindex.sgml HTML.index
Processing HTML.index...
97 entries loaded...
0 entries ignored...
Done.
openjade:slonyupgrade.sgml:51:19:E: character data is not allowed here
openjade:slonik.sgml:2:21:E: document type does not allow element "REFENTRY" here; assuming missing "ARTICLE" start-tag
openjade:slonik_ref.sgml:1:10:E: character data is not allowed here
openjade:slony.sgml:119:9:E: end tag for element "CHAPTER" which is not open
openjade:monitoring.sgml:314:9:X: reference to non-existent ID "SLONWATCHDOG"
openjade:faq.sgml:160:23:X: reference to non-existent ID "THREADPATCH"
openjade:slonyupgrade.sgml:186:38:X: reference to non-existent ID "TRIGGERS"
openjade:monitoring.sgml:95:54:X: reference to non-existent ID "BESTPRACTICES"
openjade:faq.sgml:1838:53:X: reference to non-existent ID "BESTPRACTICES"
openjade:firstdb.sgml:173:32:X: reference to non-existent ID "MKSLONCONF"
openjade:slonik_ref.sgml:2444:13:X: reference to non-existent ID "COMPLEXFAILOVER"
openjade:slonik.sgml:69:32:X: reference to non-existent ID "SLONIKREF"
openjade:slonyupgrade.sgml:172:36:X: reference to non-existent ID "SLONIKCONFDUMP"
openjade:slonyupgrade.sgml:227:36:X: reference to non-existent ID "SLONIKCONFDUMP"
openjade:slonik_ref.sgml:337:46:X: reference to non-existent ID "PLAINPATHS"
openjade:monitoring.sgml:313:39:X: reference to non-existent ID "LAUNCHCLUSTERS"
openjade:faq.sgml:855:20:X: reference to non-existent ID "GENSYNC"
openjade:firstdb.sgml:169:32:X: reference to non-existent ID "ALTPERL"
openjade:firstdb.sgml:374:25:X: reference to non-existent ID "ALTPERL"
openjade:addthings.sgml:69:53:X: reference to non-existent ID "ALTPERL"
openjade:slonik_ref.sgml:2173:41:X: reference to non-existent ID "LOCKING"
openjade:slonik_ref.sgml:2312:41:X: reference to non-existent ID "LOCKING"
openjade:slonik_ref.sgml:2522:61:X: reference to non-existent ID "LOCKING"
openjade:faq.sgml:1634:9:X: reference to non-existent ID "LOCKING"
openjade:monitoring.sgml:366:60:X: reference to non-existent ID "TESTBED"
openjade:partitioning.sgml:12:46:X: reference to non-existent ID "TESTBED"
openjade:faq.sgml:328:41:X: reference to non-existent ID "EXTRACTSCHEMA"
openjade:faq.sgml:1092:47:X: reference to non-existent ID "FAILOVER"
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'ALTPERL'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'MKSLONCONF'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'ALTPERL'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'BESTPRACTICES'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'LAUNCHCLUSTERS'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'SLONWATCHDOG'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'TESTBED'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'TESTBED'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'SLONIKCONFDUMP'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'TRIGGERS'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'SLONIKCONFDUMP'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'PLAINPATHS'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'COMPLEXFAILOVER'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'EXTRACTSCHEMA'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'GENSYNC'
openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'FAILOVER'
make: *** [html] Error 1
postgres at cbbrowne [06:44:00] [~/slony1-engine.master/doc/adminguide] [REL_2_0_STABLE *]
-> %
-- 
(format nil "~S@~S" "cbbrowne" "ca.afilias.info")
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From guillaume at lelarge.info  Wed Oct  6 00:18:28 2010
From: guillaume at lelarge.info (Guillaume Lelarge)
Date: Wed, 06 Oct 2010 09:18:28 +0200
Subject: [Slony1-hackers] Docs not building just now
In-Reply-To: <87eic4cl3v.fsf@cbbrowne.afilias-int.info>
References: <87eic4cl3v.fsf@cbbrowne.afilias-int.info>
Message-ID: <4CAC22C4.9070601@lelarge.info>

Le 06/10/2010 00:48, Christopher Browne a ?crit :
> A bunch of stuff is busted in the documentation right now; the root of
> it seems to be the changes in commit
> d40f0bfe8ea8fe398fc1aa89a45412a028daaa29, which restructured lots of
> stuff but, I suspect, without verification that the docs were building.
> 
> I committed some changes that rectify *some* of it; there were a lot
> more problems.  Still a ways to go with the documentation.
> 
> postgres at cbbrowne [06:31:21] [~/slony1-engine.master/doc/adminguide] [REL_2_0_STABLE *]
> -> % make html
> make: Circular HTML.index <- html dependency dropped.
> LC_ALL=C /usr/bin/perl /usr/bin/collateindex.pl -f -g -i 'bookindex' -o bookindex.sgml HTML.index
> Processing HTML.index...
> 97 entries loaded...
> 0 entries ignored...
> Done.
> openjade:slonyupgrade.sgml:51:19:E: character data is not allowed here

<para> While that approach has been found to be easier and safer,
nothing prevents one from carefully copying &slony1; components for
the new version into place to overwrite the old version as
the <quote>install</quote> step.  That might <emphasis>not</emphasis>
work on <trademark>Windows</trademark> if it locks library files that
are in use.</para> It is also important to make sure that any connections
to the database are restarted after the new binary is installed.

The </para> tag is badly placed. The text "It is also..." is not inside
a para tag. Can't work.

> openjade:slonik.sgml:2:21:E: document type does not allow element "REFENTRY" here; assuming missing "ARTICLE" start-tag

Don't know why but slonik is referenced two times in filelist.sgml. I
don't think that what causes you trouble here, but I don't see the point
of having it twice.

> openjade:slonik_ref.sgml:1:10:E: character data is not allowed here

<article> id="slonikref">

You should get rid of the > right after article, the id is part of it.

> openjade:slony.sgml:119:9:E: end tag for element "CHAPTER" which is not open

Actually, it's open. I think you got this error because of the previous one.

> openjade:monitoring.sgml:314:9:X: reference to non-existent ID "SLONWATCHDOG"
> openjade:faq.sgml:160:23:X: reference to non-existent ID "THREADPATCH"
> openjade:slonyupgrade.sgml:186:38:X: reference to non-existent ID "TRIGGERS"
> openjade:monitoring.sgml:95:54:X: reference to non-existent ID "BESTPRACTICES"
> openjade:faq.sgml:1838:53:X: reference to non-existent ID "BESTPRACTICES"
> openjade:firstdb.sgml:173:32:X: reference to non-existent ID "MKSLONCONF"
> openjade:slonik_ref.sgml:2444:13:X: reference to non-existent ID "COMPLEXFAILOVER"
> openjade:slonik.sgml:69:32:X: reference to non-existent ID "SLONIKREF"
> openjade:slonyupgrade.sgml:172:36:X: reference to non-existent ID "SLONIKCONFDUMP"
> openjade:slonyupgrade.sgml:227:36:X: reference to non-existent ID "SLONIKCONFDUMP"
> openjade:slonik_ref.sgml:337:46:X: reference to non-existent ID "PLAINPATHS"
> openjade:monitoring.sgml:313:39:X: reference to non-existent ID "LAUNCHCLUSTERS"
> openjade:faq.sgml:855:20:X: reference to non-existent ID "GENSYNC"
> openjade:firstdb.sgml:169:32:X: reference to non-existent ID "ALTPERL"
> openjade:firstdb.sgml:374:25:X: reference to non-existent ID "ALTPERL"
> openjade:addthings.sgml:69:53:X: reference to non-existent ID "ALTPERL"
> openjade:slonik_ref.sgml:2173:41:X: reference to non-existent ID "LOCKING"
> openjade:slonik_ref.sgml:2312:41:X: reference to non-existent ID "LOCKING"
> openjade:slonik_ref.sgml:2522:61:X: reference to non-existent ID "LOCKING"
> openjade:faq.sgml:1634:9:X: reference to non-existent ID "LOCKING"
> openjade:monitoring.sgml:366:60:X: reference to non-existent ID "TESTBED"
> openjade:partitioning.sgml:12:46:X: reference to non-existent ID "TESTBED"
> openjade:faq.sgml:328:41:X: reference to non-existent ID "EXTRACTSCHEMA"
> openjade:faq.sgml:1092:47:X: reference to non-existent ID "FAILOVER"
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'ALTPERL'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'MKSLONCONF'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'ALTPERL'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'BESTPRACTICES'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'LAUNCHCLUSTERS'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'SLONWATCHDOG'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'TESTBED'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'TESTBED'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'SLONIKCONFDUMP'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'TRIGGERS'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'SLONIKCONFDUMP'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'PLAINPATHS'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'COMPLEXFAILOVER'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'EXTRACTSCHEMA'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'GENSYNC'
> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'FAILOVER'
> make: *** [html] Error 1
> postgres at cbbrowne [06:44:00] [~/slony1-engine.master/doc/adminguide] [REL_2_0_STABLE *]
> -> %

I would have built a patch if I could have a way to build the
documentation. I don't understand why the makefile tries to create a
database to build the documentation...


-- 
Guillaume
 http://www.postgresql.fr
 http://dalibo.com

From ssinger at ca.afilias.info  Wed Oct  6 08:32:08 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Wed, 06 Oct 2010 11:32:08 -0400
Subject: [Slony1-hackers] Docs not building just now
In-Reply-To: <87eic4cl3v.fsf@cbbrowne.afilias-int.info>
References: <87eic4cl3v.fsf@cbbrowne.afilias-int.info>
Message-ID: <4CAC9678.4050707@ca.afilias.info>

On 10-10-05 06:48 PM, Christopher Browne wrote:
> A bunch of stuff is busted in the documentation right now; the root of
> it seems to be the changes in commit
> d40f0bfe8ea8fe398fc1aa89a45412a028daaa29, which restructured lots of
> stuff but, I suspect, without verification that the docs were building.
>
> I committed some changes that rectify *some* of it; there were a lot
> more problems.  Still a ways to go with the documentation.
>

Sorry about that I should have checked more carefully.

I've commited changes that get REL_2_0_STABLE and master to build the 
documentation without errors.


From ssinger at ca.afilias.info  Wed Oct  6 08:34:16 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Wed, 06 Oct 2010 11:34:16 -0400
Subject: [Slony1-hackers] Docs not building just now
In-Reply-To: <4CAC22C4.9070601@lelarge.info>
References: <87eic4cl3v.fsf@cbbrowne.afilias-int.info>
	<4CAC22C4.9070601@lelarge.info>
Message-ID: <4CAC96F8.60205@ca.afilias.info>

On 10-10-06 03:18 AM, Guillaume Lelarge wrote:

> I would have built a patch if I could have a way to build the
> documentation. I don't understand why the makefile tries to create a
> database to build the documentation...
>


The make file uses pg_autodoc to create documentation based on the 
'COMMENT' (and schema) data in the database.




From cbbrowne at ca.afilias.info  Wed Oct  6 09:34:54 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed, 06 Oct 2010 12:34:54 -0400
Subject: [Slony1-hackers] Docs not building just now
In-Reply-To: <4CAC22C4.9070601@lelarge.info> (Guillaume Lelarge's message of
	"Wed, 06 Oct 2010 09:18:28 +0200")
References: <87eic4cl3v.fsf@cbbrowne.afilias-int.info>
	<4CAC22C4.9070601@lelarge.info>
Message-ID: <874oczcma9.fsf@cbbrowne.afilias-int.info>

Guillaume Lelarge <guillaume at lelarge.info> writes:

> Le 06/10/2010 00:48, Christopher Browne a ?crit :
>> A bunch of stuff is busted in the documentation right now; the root of
>> it seems to be the changes in commit
>> d40f0bfe8ea8fe398fc1aa89a45412a028daaa29, which restructured lots of
>> stuff but, I suspect, without verification that the docs were building.
>> 
>> I committed some changes that rectify *some* of it; there were a lot
>> more problems.  Still a ways to go with the documentation.
>> 
>> postgres at cbbrowne [06:31:21] [~/slony1-engine.master/doc/adminguide] [REL_2_0_STABLE *]
>> -> % make html
>> make: Circular HTML.index <- html dependency dropped.
>> LC_ALL=C /usr/bin/perl /usr/bin/collateindex.pl -f -g -i 'bookindex' -o bookindex.sgml HTML.index
>> Processing HTML.index...
>> 97 entries loaded...
>> 0 entries ignored...
>> Done.
>> openjade:slonyupgrade.sgml:51:19:E: character data is not allowed here
>
> <para> While that approach has been found to be easier and safer,
> nothing prevents one from carefully copying &slony1; components for
> the new version into place to overwrite the old version as
> the <quote>install</quote> step.  That might <emphasis>not</emphasis>
> work on <trademark>Windows</trademark> if it locks library files that
> are in use.</para> It is also important to make sure that any connections
> to the database are restarted after the new binary is installed.
>
> The </para> tag is badly placed. The text "It is also..." is not inside
> a para tag. Can't work.

Yep, I'm plowing through the issues.  A bunch of little things.

>> openjade:slonik.sgml:2:21:E: document type does not allow element "REFENTRY" here; assuming missing "ARTICLE" start-tag
>
> Don't know why but slonik is referenced two times in filelist.sgml. I
> don't think that what causes you trouble here, but I don't see the point
> of having it twice.
>
>> openjade:slonik_ref.sgml:1:10:E: character data is not allowed here
>
> <article> id="slonikref">
>
> You should get rid of the > right after article, the id is part of it.

I think that single thing is causing a lot of the subsequent errors.

>> openjade:slony.sgml:119:9:E: end tag for element "CHAPTER" which is not open
>
> Actually, it's open. I think you got this error because of the previous one.
>
>> openjade:monitoring.sgml:314:9:X: reference to non-existent ID "SLONWATCHDOG"
>> openjade:faq.sgml:160:23:X: reference to non-existent ID "THREADPATCH"
>> openjade:slonyupgrade.sgml:186:38:X: reference to non-existent ID "TRIGGERS"
>> openjade:monitoring.sgml:95:54:X: reference to non-existent ID "BESTPRACTICES"
>> openjade:faq.sgml:1838:53:X: reference to non-existent ID "BESTPRACTICES"
>> openjade:firstdb.sgml:173:32:X: reference to non-existent ID "MKSLONCONF"
>> openjade:slonik_ref.sgml:2444:13:X: reference to non-existent ID "COMPLEXFAILOVER"
>> openjade:slonik.sgml:69:32:X: reference to non-existent ID "SLONIKREF"
>> openjade:slonyupgrade.sgml:172:36:X: reference to non-existent ID "SLONIKCONFDUMP"
>> openjade:slonyupgrade.sgml:227:36:X: reference to non-existent ID "SLONIKCONFDUMP"
>> openjade:slonik_ref.sgml:337:46:X: reference to non-existent ID "PLAINPATHS"
>> openjade:monitoring.sgml:313:39:X: reference to non-existent ID "LAUNCHCLUSTERS"
>> openjade:faq.sgml:855:20:X: reference to non-existent ID "GENSYNC"
>> openjade:firstdb.sgml:169:32:X: reference to non-existent ID "ALTPERL"
>> openjade:firstdb.sgml:374:25:X: reference to non-existent ID "ALTPERL"
>> openjade:addthings.sgml:69:53:X: reference to non-existent ID "ALTPERL"
>> openjade:slonik_ref.sgml:2173:41:X: reference to non-existent ID "LOCKING"
>> openjade:slonik_ref.sgml:2312:41:X: reference to non-existent ID "LOCKING"
>> openjade:slonik_ref.sgml:2522:61:X: reference to non-existent ID "LOCKING"
>> openjade:faq.sgml:1634:9:X: reference to non-existent ID "LOCKING"
>> openjade:monitoring.sgml:366:60:X: reference to non-existent ID "TESTBED"
>> openjade:partitioning.sgml:12:46:X: reference to non-existent ID "TESTBED"
>> openjade:faq.sgml:328:41:X: reference to non-existent ID "EXTRACTSCHEMA"
>> openjade:faq.sgml:1092:47:X: reference to non-existent ID "FAILOVER"
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'ALTPERL'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'MKSLONCONF'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'ALTPERL'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'BESTPRACTICES'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'LAUNCHCLUSTERS'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'SLONWATCHDOG'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'TESTBED'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'TESTBED'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'SLONIKCONFDUMP'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'TRIGGERS'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'SLONIKCONFDUMP'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'PLAINPATHS'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'COMPLEXFAILOVER'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'EXTRACTSCHEMA'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'GENSYNC'
>> openjade:/usr/share/sgml/docbook/stylesheet/dsssl/modular/html/dblink.dsl:203:1:E: XRef LinkEnd to missing ID 'FAILOVER'
>> make: *** [html] Error 1
>> postgres at cbbrowne [06:44:00] [~/slony1-engine.master/doc/adminguide] [REL_2_0_STABLE *]
>> -> %

> I would have built a patch if I could have a way to build the
> documentation. I don't understand why the makefile tries to create a
> database to build the documentation...

We use Rod Taylor's "PostgreSQL Autodoc" tool to include extensive docs
on the schema as part of the documentation tree.  That means that if
part of the docs references "sl_log_1", then you can follow the link to
the definition of the table.

I seem to have fought it into some degree of submission, for 2.0 and HEAD.
-- 
output = reverse("ofni.sailifa.ac" "@" "enworbbc")
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From singh.gurjeet at gmail.com  Fri Oct  8 11:14:59 2010
From: singh.gurjeet at gmail.com (Gurjeet Singh)
Date: Fri, 8 Oct 2010 14:14:59 -0400
Subject: [Slony1-hackers] Slonik uninstall node
Message-ID: <AANLkTimxgVRH9HfzWzE9OvYaDjKFELLz5_m6WQ=ZW-3T@mail.gmail.com>

Slony version 2.0.3

I have a 2 node Slony cluster and I wish to cleanup everything (manually) if
it is detected that one of the nodes has failed.

So, is just stopping the slon daemons and then executing 'uninstall node'
for the remaining node enough to clean up everything?

$ ./slon_kill

$ ( ./slonik_print_preamble && echo 'uninstall node ( id = 2 ); ' ) | slonik

I looked at slonik.c;slonik_uninstall_node() and _cluster_name.uninstallNode()
plpgsql function, all I could notice is that slonik_uninstall_node() calls
the plpgsql function and then issues 'drop schema _cluster_name cascade;'.
The plpgsql function just issues a 'lock table
_cluster_name.sl_config_lock'.

So I don't see a problem in performing the above 2 commands to clean up and
then configure replication setup from scratch.

Any objections?

Regards,
-- 
gurjeet.singh
@ EnterpriseDB - The Enterprise Postgres Company
http://www.EnterpriseDB.com

singh.gurjeet@{ gmail | yahoo }.com
Twitter/Skype: singh_gurjeet

Mail sent from my BlackLaptop device
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-hackers/attachments/20101008/09972df7/attachment.htm 

From ssinger at ca.afilias.info  Fri Oct  8 11:23:01 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 08 Oct 2010 14:23:01 -0400
Subject: [Slony1-hackers] Slonik uninstall node
In-Reply-To: <AANLkTimxgVRH9HfzWzE9OvYaDjKFELLz5_m6WQ=ZW-3T@mail.gmail.com>
References: <AANLkTimxgVRH9HfzWzE9OvYaDjKFELLz5_m6WQ=ZW-3T@mail.gmail.com>
Message-ID: <4CAF6185.7020609@ca.afilias.info>

On 10-10-08 02:14 PM, Gurjeet Singh wrote:
> Slony version 2.0.3
>
> I have a 2 node Slony cluster and I wish to cleanup everything
> (manually) if it is detected that one of the nodes has failed.
>
> So, is just stopping the slon daemons and then executing 'uninstall
> node' for the remaining node enough to clean up everything?
>
> $ ./slon_kill
>
> $ ( ./slonik_print_preamble && echo 'uninstall node ( id = 2 ); ' ) | slonik
>
> I looked at slonik.c;slonik_uninstall_node() and
> _cluster_name.uninstallNode() plpgsql function, all I could notice is
> that slonik_uninstall_node() calls the plpgsql function and then issues
> 'drop schema _cluster_name cascade;'. The plpgsql function just issues a
> 'lock table _cluster_name.sl_config_lock'.
>
> So I don't see a problem in performing the above 2 commands to clean up
> and then configure replication setup from scratch.
>
> Any objections?

This should be fine.

Doing the uinstall node on 2 will remove slony from node 2.  (assuming 
your node 1 has failed).

Also when you reinstall your cluster I wouldn't put 2.0.3 back on.  You 
would be much better off with 2.0.4 or 2.0.5.  2.0.3 had a serious 
regression bug introduced with it.







>
> Regards,
> --
> gurjeet.singh
> @ EnterpriseDB - The Enterprise Postgres Company
> http://www.EnterpriseDB.com
>
> singh.gurjeet@{ gmail | yahoo }.com
> Twitter/Skype: singh_gurjeet
>
> Mail sent from my BlackLaptop device
>
>
>
> _______________________________________________
> Slony1-hackers mailing list
> Slony1-hackers at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-hackers


From scott.marlowe at gmail.com  Fri Oct  8 15:31:21 2010
From: scott.marlowe at gmail.com (Scott Marlowe)
Date: Fri, 8 Oct 2010 16:31:21 -0600
Subject: [Slony1-hackers] [Slony1-general] Slonik uninstall node
In-Reply-To: <AANLkTimxgVRH9HfzWzE9OvYaDjKFELLz5_m6WQ=ZW-3T@mail.gmail.com>
References: <AANLkTimxgVRH9HfzWzE9OvYaDjKFELLz5_m6WQ=ZW-3T@mail.gmail.com>
Message-ID: <AANLkTinkJ7t6kiw0eL+Hde+K2qjEDWhcoHi_3UhiDObn@mail.gmail.com>

On Fri, Oct 8, 2010 at 12:14 PM, Gurjeet Singh <singh.gurjeet at gmail.com> wrote:
> Slony version 2.0.3
>
> I have a 2 node Slony cluster and I wish to cleanup everything (manually) if
> it is detected that one of the nodes has failed.
>
> So, is just stopping the slon daemons and then executing 'uninstall node'
> for the remaining node enough to clean up everything?

You can leave the daemons running and just drop node.  You might need
to reshape your cluster if the failed node was between two nodes.

From atsaloli.tech at gmail.com  Mon Oct 18 16:26:04 2010
From: atsaloli.tech at gmail.com (Aleksey Tsalolikhin)
Date: Mon, 18 Oct 2010 16:26:04 -0700
Subject: [Slony1-hackers] Documentation patch: "Best Practices": Do not dump
 the slony schemas, or else replication lag can increase during pg_dump.
In-Reply-To: <AANLkTi=mChoE+kcp=6aW=VX=DD50dP+kS9Y2dzkDCq4Z@mail.gmail.com>
References: <AANLkTi=mChoE+kcp=6aW=VX=DD50dP+kS9Y2dzkDCq4Z@mail.gmail.com>
Message-ID: <AANLkTi=T39CTSq1joWMpboRrrwkdWdaoGjtwn=jL8LGz@mail.gmail.com>

Hi.  Ran into this scenario:  replication lag increases from seconds
to minutes (or tens of minutes) while doing a pg_dump of the entire
database on the slave.  Per Steve Singer's suggestion I excluded the
slony schemas from the pg_dump and replication lag stayed within
normal paramaters.

May I offer an addition to the "Best Practices" page for both 1.2 and
2.0 documentation sets:

If you pg_dump your database from your Slony slave, avoid dumping your
Slony schemas or else pg_dump's locking will compete with Slony's own
locking which will slow down Slony replication for the duration of the
pg_dump.  Exclude the Slony schemas from pg_dump either using "-n
public" to dump the default schema only (assuming all your data is
there), or, if you use multiple schemas, use pg_dump
--exclude-schema=schemaname to specifically exclude your Slony schemas
by name.

Best,
Aleksey

From atsaloli.tech at gmail.com  Mon Oct 18 16:27:31 2010
From: atsaloli.tech at gmail.com (Aleksey Tsalolikhin)
Date: Mon, 18 Oct 2010 16:27:31 -0700
Subject: [Slony1-hackers] documentation patch for "Best Practices" page --
 sorry if it's a duplicate, not sure if my earlier msg. got through
Message-ID: <AANLkTim4nUSG_tUfoRAC+u95Rxb+8Ku7r-7X5ZEy80us@mail.gmail.com>

Hi.  Ran into this scenario:  replication lag increases from seconds
to minutes (or tens of minutes) while doing a pg_dump of the entire
database on the slave.  Per Steve Singer's suggestion I excluded the
slony schemas from the pg_dump and replication lag stayed within
normal paramaters.

May I offer an addition to the "Best Practices" page for both 1.2 and
2.0 documentation sets:

If you pg_dump your database from your Slony slave, avoid dumping your
Slony schemas or else pg_dump's locking will compete with Slony's own
locking which will slow down Slony replication for the duration of the
pg_dump.  Exclude the Slony schemas from pg_dump either using "-n
public" to dump the default schema only (assuming all your data is
there), or, if you use multiple schemas, use pg_dump
--exclude-schema=schemaname to specifically exclude your Slony schemas
by name.

Best,
Aleksey

From ssinger at ca.afilias.info  Tue Oct 19 13:12:23 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Tue, 19 Oct 2010 16:12:23 -0400
Subject: [Slony1-hackers] Documentation patch: "Best Practices": Do not
 dump the slony schemas, or else replication lag can increase during pg_dump.
In-Reply-To: <AANLkTi=T39CTSq1joWMpboRrrwkdWdaoGjtwn=jL8LGz@mail.gmail.com>
References: <AANLkTi=mChoE+kcp=6aW=VX=DD50dP+kS9Y2dzkDCq4Z@mail.gmail.com>
	<AANLkTi=T39CTSq1joWMpboRrrwkdWdaoGjtwn=jL8LGz@mail.gmail.com>
Message-ID: <4CBDFBA7.4070804@ca.afilias.info>

On 10-10-18 07:26 PM, Aleksey Tsalolikhin wrote:
> Hi.  Ran into this scenario:  replication lag increases from seconds
> to minutes (or tens of minutes) while doing a pg_dump of the entire
> database on the slave.  Per Steve Singer's suggestion I excluded the
> slony schemas from the pg_dump and replication lag stayed within
> normal paramaters.
>
> May I offer an addition to the "Best Practices" page for both 1.2 and
> 2.0 documentation sets:
>
> If you pg_dump your database from your Slony slave, avoid dumping your
> Slony schemas or else pg_dump's locking will compete with Slony's own
> locking which will slow down Slony replication for the duration of the
> pg_dump.  Exclude the Slony schemas from pg_dump either using "-n
> public" to dump the default schema only (assuming all your data is
> there), or, if you use multiple schemas, use pg_dump
> --exclude-schema=schemaname to specifically exclude your Slony schemas
> by name.
>

I've applied a somewhat edited version of this but to the "Locking 
Issues" page.  I'm trying to phase out that best practices page since it 
seems like a mash of unrelated stuff.

Thanks





> Best,
> Aleksey
> _______________________________________________
> Slony1-hackers mailing list
> Slony1-hackers at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-hackers


From yunfeng82 at gmail.com  Thu Oct 28 03:15:57 2010
From: yunfeng82 at gmail.com (Jason Chen)
Date: Thu, 28 Oct 2010 18:15:57 +0800
Subject: [Slony1-hackers] Abnormal <event pending> in sl_path just after
	configure one slave.
Message-ID: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>

Hi,

When I tried to deploy slony-2.0.4, there have a problem I met during slave
node configuration. Maser node slon process looks hang and there is *<event
pending>* in pa_conninfo of sl_path table. Below is the output of that
table.

[root at slony-r1s1-001 ~]# psql -U postgres system.db -c "select * from
_slony.sl_path"
 pa_server | pa_client |
pa_conninfo                                       | pa_connretry
-----------+-----------+-----------------------------------------------------------------------------+--------------
2 |         1 | host=192.168.11.12 dbname=system.db user=postgres
port=5432|           10
1 |         2 | <event
pending>
|           10


Here is the configuration sequence I used to setup master and slave, I used
atlperl related tools to configure slon.
*On master node:*

   1. Configure and start postgresql service
   2. Configure slon using slonik_init_cluster and
   slony_define_replication_set
   3. Start slon service

*On slave node:*

   1. Configure and start postgresql service
   2. Configure slon using slonik_store_node and slonik_subscribe_set
   3. Start slon service

The incorrect configuration in sl_path will cause master node hangs and
master will not generate any new SYNC event. However, *after about 7 hours,
*the information in sl_path becomes correct configuration and SYNC event can
be generated.

After check slony source, I was thinking the issue might happen during
subscribeSet and add some logs in backend script slony1_funcs.sql. However,
it looks like subscribeSet and enableSubscription finished successfully from
slon log. I also checked slon thread info, there is no
remoteListenThread_main and remoteWorkerThread_main thread comparing with
normal slon process in the master node.

My question are:

   1. Is there any other things we can check in the slony table or logs?
   2. Why there need to wait for 7 hours for that correct sl_path? Does
   there has anything block master node?
   3. Do you think this is a configuration issue or issue inside slony
   source code?


Thanks,
Jason
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-hackers/attachments/20101028/1f1a9122/attachment.htm 

From JanWieck at Yahoo.com  Thu Oct 28 07:27:42 2010
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Thu, 28 Oct 2010 10:27:42 -0400
Subject: [Slony1-hackers] Abnormal <event pending> in sl_path just after
 configure one slave.
In-Reply-To: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>
References: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>
Message-ID: <4CC9885E.3010507@Yahoo.com>

On 10/28/2010 6:15 AM, Jason Chen wrote:
> Hi,
>
> When I tried to deploy slony-2.0.4, there have a problem I met during
> slave node configuration. Maser node slon process looks hang and there
> is *<event pending>* in pa_conninfo of sl_path table. Below is the
> output of that table.
>
> [root at slony-r1s1-001 ~]# psql -U postgres system.db -c "select * from
> _slony.sl_path"
>   pa_server | pa_client |
> pa_conninfo                                       | pa_connretry
> -----------+-----------+-----------------------------------------------------------------------------+--------------
> 2 |         1 | host=192.168.11.12 dbname=system.db user=postgres
> port=5432|           10
> 1 |         2 | <event
> pending>
> |           10

Is the conninfo for pa_server=2 and pa_client=1 correct?

Is the port 5432 on host 192.168.11.12 actually reachable (firewall)?


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From ssinger at ca.afilias.info  Thu Oct 28 11:05:08 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Thu, 28 Oct 2010 14:05:08 -0400
Subject: [Slony1-hackers] Abnormal <event pending> in sl_path just after
 configure one slave.
In-Reply-To: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>
References: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>
Message-ID: <4CC9BB54.9010807@ca.afilias.info>

On 10-10-28 06:15 AM, Jason Chen wrote:
> Hi,
>
> When I tried to deploy slony-2.0.4, there have a problem I met during
> slave node configuration. Maser node slon process looks hang and there
> is *<event pending>* in pa_conninfo of sl_path table. Below is the
> output of that table.
>
> [root at slony-r1s1-001 ~]# psql -U postgres system.db -c "select * from
> _slony.sl_path"
>   pa_server | pa_client |
> pa_conninfo                                       | pa_connretry
> -----------+-----------+-----------------------------------------------------------------------------+--------------
> 2 |         1 | host=192.168.11.12 dbname=system.db user=postgres
> port=5432|           10
> 1 |         2 | <event
> pending>
> |           10
>
>
> Here is the configuration sequence I used to setup master and slave, I
> used atlperl related tools to configure slon.
> _*On master node:*_
>
>    1. Configure and start postgresql service
>    2. Configure slon using slonik_init_cluster and
>       slony_define_replication_set
>    3. Start slon service
>
> _*On slave node:*_
>
>    1. Configure and start postgresql service
>    2. Configure slon using slonik_store_node and slonik_subscribe_set
>    3. Start slon service
>
> The incorrect configuration in sl_path will cause master node hangs and
> master will not generate any new SYNC event. However, *after about 7
> hours, *the information in sl_path becomes correct configuration and
> SYNC event can be generated.
>
> After check slony source, I was thinking the issue might happen during
> subscribeSet and add some logs in backend script slony1_funcs.sql.
> However, it looks like subscribeSet and enableSubscription finished
> successfully from slon log. I also checked slon thread info, there is no
> remoteListenThread_main and remoteWorkerThread_main thread comparing
> with normal slon process in the master node.
>
> My question are:
>
>    1. Is there any other things we can check in the slony table or logs?
>    2. Why there need to wait for 7 hours for that correct sl_path? Does
>       there has anything block master node?

My question is what were the slons doing during those 7 hours.

If you configure your slon processes to log at the debug level they 
should print a fair amount of stuff.

You get the <event pending> entries in sl_path when you subscribe the 
set before processing the STORE_PATH message on the other node.

What maybe want to do is move define_replication_set to come after 
you've started up the slons.

Having said that even if you do things in the order you described things 
still should have worked and I don't see why it took 7 hours to update 
sl_path.  What were the slons doing during those 7 hours.



>    3. Do you think this is a configuration issue or issue inside slony
>       source code?
>
>
> Thanks,
> Jason
>
>
>
> _______________________________________________
> Slony1-hackers mailing list
> Slony1-hackers at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-hackers


From yunfeng82 at gmail.com  Thu Oct 28 18:46:11 2010
From: yunfeng82 at gmail.com (Jason Chen)
Date: Fri, 29 Oct 2010 09:46:11 +0800
Subject: [Slony1-hackers] Abnormal <event pending> in sl_path just after
 configure one slave.
In-Reply-To: <4CC9885E.3010507@Yahoo.com>
References: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>
	<4CC9885E.3010507@Yahoo.com>
Message-ID: <AANLkTikSyvOLg6DUtOEDPAoLwcZWaNb-15zMvjwNe45H@mail.gmail.com>

Hi Jan,

Thanks for your response. conninfo information is correct and also port 5432
on host 192.168.11.12 is reachable without firewall.

Best regards,
Jason

On Thu, Oct 28, 2010 at 10:27 PM, Jan Wieck <JanWieck at yahoo.com> wrote:

> On 10/28/2010 6:15 AM, Jason Chen wrote:
>
>> Hi,
>>
>> When I tried to deploy slony-2.0.4, there have a problem I met during
>> slave node configuration. Maser node slon process looks hang and there
>> is *<event pending>* in pa_conninfo of sl_path table. Below is the
>> output of that table.
>>
>> [root at slony-r1s1-001 ~]# psql -U postgres system.db -c "select * from
>> _slony.sl_path"
>>  pa_server | pa_client |
>> pa_conninfo                                       | pa_connretry
>>
>> -----------+-----------+-----------------------------------------------------------------------------+--------------
>> 2 |         1 | host=192.168.11.12 dbname=system.db user=postgres
>> port=5432|           10
>> 1 |         2 | <event
>> pending>
>> |           10
>>
>
> Is the conninfo for pa_server=2 and pa_client=1 correct?
>
> Is the port 5432 on host 192.168.11.12 actually reachable (firewall)?
>
>
> Jan
>
> --
> Anyone who trades liberty for security deserves neither
> liberty nor security. -- Benjamin Franklin
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-hackers/attachments/20101029/66363a21/attachment.htm 

From yunfeng82 at gmail.com  Thu Oct 28 20:05:17 2010
From: yunfeng82 at gmail.com (Jason Chen)
Date: Fri, 29 Oct 2010 11:05:17 +0800
Subject: [Slony1-hackers] Abnormal <event pending> in sl_path just after
 configure one slave.
In-Reply-To: <4CC9BB54.9010807@ca.afilias.info>
References: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>
	<4CC9BB54.9010807@ca.afilias.info>
Message-ID: <AANLkTimnjH5XqCX6wyAgQCcL5P51ESYsybocrNKf-TjG@mail.gmail.com>

Hi Steve,

Thanks for your response. During those 7 hours, actually I have done nothing
but just leave it there. The sl_path will be correctly updated after that
time. Another workaround to solve this issue is restart master node slon
service which will also update sl_path to the correct value in pa_conninfo.

I have turned on the highest level log on both slon and postgresql but
didn't find more useful information. In the normal case, pa_conninfo in
sl_path will be event pending only for a short time and then will be updated
correctly after master generates STORE_PATH event. However, in the error
case, looks like master will not generates STORE_PATH event.

What will be case that cause master node hangs and cannot generate
STORE_PATH event? Is there any more debug information I can check in gdb for
the slon process?

Thanks,
Jason


On Fri, Oct 29, 2010 at 2:05 AM, Steve Singer <ssinger at ca.afilias.info>wrote:

> My question is what were the slons doing during those 7 hours.
>
> If you configure your slon processes to log at the debug level they should
> print a fair amount of stuff.
>
> You get the <event pending> entries in sl_path when you subscribe the set
> before processing the STORE_PATH message on the other node.
>
> What maybe want to do is move define_replication_set to come after you've
> started up the slons.
>
> Having said that even if you do things in the order you described things
> still should have worked and I don't see why it took 7 hours to update
> sl_path.  What were the slons doing during those 7 hours.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-hackers/attachments/20101029/256ad3fc/attachment.htm 

From yunfeng82 at gmail.com  Fri Oct 29 03:15:03 2010
From: yunfeng82 at gmail.com (Jason Chen)
Date: Fri, 29 Oct 2010 18:15:03 +0800
Subject: [Slony1-hackers] Abnormal <event pending> in sl_path just after
 configure one slave.
In-Reply-To: <AANLkTimnjH5XqCX6wyAgQCcL5P51ESYsybocrNKf-TjG@mail.gmail.com>
References: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>
	<4CC9BB54.9010807@ca.afilias.info>
	<AANLkTimnjH5XqCX6wyAgQCcL5P51ESYsybocrNKf-TjG@mail.gmail.com>
Message-ID: <AANLkTin-fLZDnnOZBmRUfsZxuRf1caxoaON2oS2sZVdU@mail.gmail.com>

Hi Steve,

After more troubleshooting and several times reconfiguration whole system,
it seems the issue should be in master node configuration. However, I still
haven't figured out the root cause and reproduce step. This is not
reproduced every time.

In the normal correct case, after configure master node, there has
consistent SYNC events which will be generated. However, in the error case,
looks like master node slon has hung and there is no new SYNC events
generated.

Do you have any more insight on the potential issue which might happen
during master node configuration?

Thanks,
Jason


On Fri, Oct 29, 2010 at 11:05 AM, Jason Chen <yunfeng82 at gmail.com> wrote:

> Hi Steve,
>
> Thanks for your response. During those 7 hours, actually I have done
> nothing but just leave it there. The sl_path will be correctly updated after
> that time. Another workaround to solve this issue is restart master node
> slon service which will also update sl_path to the correct value in
> pa_conninfo.
>
> I have turned on the highest level log on both slon and postgresql but
> didn't find more useful information. In the normal case, pa_conninfo in
> sl_path will be event pending only for a short time and then will be updated
> correctly after master generates STORE_PATH event. However, in the error
> case, looks like master will not generates STORE_PATH event.
>
> What will be case that cause master node hangs and cannot generate
> STORE_PATH event? Is there any more debug information I can check in gdb for
> the slon process?
>
> Thanks,
> Jason
>
>
>
> On Fri, Oct 29, 2010 at 2:05 AM, Steve Singer <ssinger at ca.afilias.info>wrote:
>
>> My question is what were the slons doing during those 7 hours.
>>
>> If you configure your slon processes to log at the debug level they should
>> print a fair amount of stuff.
>>
>> You get the <event pending> entries in sl_path when you subscribe the set
>> before processing the STORE_PATH message on the other node.
>>
>> What maybe want to do is move define_replication_set to come after you've
>> started up the slons.
>>
>> Having said that even if you do things in the order you described things
>> still should have worked and I don't see why it took 7 hours to update
>> sl_path.  What were the slons doing during those 7 hours.
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-hackers/attachments/20101029/9157f911/attachment.htm 

From ssinger at ca.afilias.info  Fri Oct 29 05:23:39 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 29 Oct 2010 08:23:39 -0400
Subject: [Slony1-hackers] Abnormal <event pending> in sl_path just after
 configure one slave.
In-Reply-To: <AANLkTin-fLZDnnOZBmRUfsZxuRf1caxoaON2oS2sZVdU@mail.gmail.com>
References: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>	<4CC9BB54.9010807@ca.afilias.info>	<AANLkTimnjH5XqCX6wyAgQCcL5P51ESYsybocrNKf-TjG@mail.gmail.com>
	<AANLkTin-fLZDnnOZBmRUfsZxuRf1caxoaON2oS2sZVdU@mail.gmail.com>
Message-ID: <4CCABCCB.4080103@ca.afilias.info>

On 10-10-29 06:15 AM, Jason Chen wrote:
> Hi Steve,
>
> After more troubleshooting and several times reconfiguration whole
> system, it seems the issue should be in master node configuration.
> However, I still haven't figured out the root cause and reproduce step.
> This is not reproduced every time.
>
> In the normal correct case, after configure master node, there has
> consistent SYNC events which will be generated. However, in the error
> case, looks like master node slon has hung and there is no new SYNC
> events generated.
>
> Do you have any more insight on the potential issue which might happen
> during master node configuration?
>
> Thanks,
> Jason
>

If you turn up the logging level to debug , what does slon report in the 
log in cases where it doesn't work.   I must be logging some stuff even 
if it then stops/hangs.


slon using the connection settings from the service config to connect to 
its 'local' database that it generates the syncs on.  It sounds like 
slon isn't able to talk to this database.


>
> On Fri, Oct 29, 2010 at 11:05 AM, Jason Chen <yunfeng82 at gmail.com
> <mailto:yunfeng82 at gmail.com>> wrote:
>
>     Hi Steve,
>
>     Thanks for your response. During those 7 hours, actually I have done
>     nothing but just leave it there. The sl_path will be correctly
>     updated after that time. Another workaround to solve this issue is
>     restart master node slon service which will also update sl_path to
>     the correct value in pa_conninfo.
>
>     I have turned on the highest level log on both slon and postgresql
>     but didn't find more useful information. In the normal case,
>     pa_conninfo in sl_path will be event pending only for a short time
>     and then will be updated correctly after master generates STORE_PATH
>     event. However, in the error case, looks like master will not
>     generates STORE_PATH event.
>
>     What will be case that cause master node hangs and cannot generate
>     STORE_PATH event? Is there any more debug information I can check in
>     gdb for the slon process?
>
>     Thanks,
>     Jason
>
>
>
>     On Fri, Oct 29, 2010 at 2:05 AM, Steve Singer
>     <ssinger at ca.afilias.info <mailto:ssinger at ca.afilias.info>> wrote:
>
>         My question is what were the slons doing during those 7 hours.
>
>         If you configure your slon processes to log at the debug level
>         they should print a fair amount of stuff.
>
>         You get the <event pending> entries in sl_path when you
>         subscribe the set before processing the STORE_PATH message on
>         the other node.
>
>         What maybe want to do is move define_replication_set to come
>         after you've started up the slons.
>
>         Having said that even if you do things in the order you
>         described things still should have worked and I don't see why it
>         took 7 hours to update sl_path.  What were the slons doing
>         during those 7 hours.
>
>
>


From ssinger at ca.afilias.info  Fri Oct 29 07:39:56 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 29 Oct 2010 10:39:56 -0400
Subject: [Slony1-hackers] Abnormal <event pending> in sl_path just after
 configure one slave.
In-Reply-To: <AANLkTimk0Qxs6UGaB+mtsO1fnKNPDH5NZXuJb5aAG+K2@mail.gmail.com>
References: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>	<4CC9BB54.9010807@ca.afilias.info>	<AANLkTimnjH5XqCX6wyAgQCcL5P51ESYsybocrNKf-TjG@mail.gmail.com>	<AANLkTin-fLZDnnOZBmRUfsZxuRf1caxoaON2oS2sZVdU@mail.gmail.com>	<4CCABCCB.4080103@ca.afilias.info>
	<AANLkTimk0Qxs6UGaB+mtsO1fnKNPDH5NZXuJb5aAG+K2@mail.gmail.com>
Message-ID: <4CCADCBC.9030401@ca.afilias.info>

On 10-10-29 10:24 AM, Jason Chen wrote:
> Hi Steve,
>
>  >If you turn up the logging level to debug , what does slon report in
> the log in cases where it doesn't work.   I must be logging some stuff
> even if it then stops/hangs.
>
> I have attached the normal configuration and error configuration master
> node log. Can you take a look and see if there is anything abnormal?
>
>  >slon using the connection settings from the service config to connect
> to its 'local' database that it generates the syncs on.  It sounds like
> slon isn't able to talk to this database.
>
> Is there any log we can check on that since postgresql on the master
> node runs well?
>
> Please also let me know if you need other more information.
>
> Thanks,
> Jason
>

The error log stops after a few minutes.  Does slon just stop writing to 
the file?

As you can see in the normal log file,
the localListener thread sees the STORE NODE event and then the STORE 
PATH event a bit further down.

2010-10-29 15:01:38 UTCDEBUG2 localListenThread: Received event 
1,5000000179 STORE_NODE
2010-10-29 15:01:38 UTCCONFIG storeNode: no_id=2 no_comment='slave'


Once it processes that store node event it then starts the remoteWorker 
and remoteListener threads that actually do stuff

In the error case, if you query the sl_event table on the master you 
should see the STORE NODE and STORE PATH events. (this is worth 
confirming).  The question is why is the slon not getting to this 
events. What event numbers are assigned to them?

In the error case it got as far as 1,5000000081  in the normal case the 
STORE NODE event was 1,5000000180 so if the time from when you started 
slon until when you ran the storeNode is similar in both cases then you 
still have a fair number of events left to process (though processing 
100 SYNC events when no tables are replicated should be pretty fast)


From yunfeng82 at gmail.com  Fri Oct 29 08:12:52 2010
From: yunfeng82 at gmail.com (Jason Chen)
Date: Fri, 29 Oct 2010 23:12:52 +0800
Subject: [Slony1-hackers] Abnormal <event pending> in sl_path just after
 configure one slave.
In-Reply-To: <4CCADCBC.9030401@ca.afilias.info>
References: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>
	<4CC9BB54.9010807@ca.afilias.info>
	<AANLkTimnjH5XqCX6wyAgQCcL5P51ESYsybocrNKf-TjG@mail.gmail.com>
	<AANLkTin-fLZDnnOZBmRUfsZxuRf1caxoaON2oS2sZVdU@mail.gmail.com>
	<4CCABCCB.4080103@ca.afilias.info>
	<AANLkTimk0Qxs6UGaB+mtsO1fnKNPDH5NZXuJb5aAG+K2@mail.gmail.com>
	<4CCADCBC.9030401@ca.afilias.info>
Message-ID: <AANLkTimqzbG+-vCnotUueJ8tfv_1kygca-5MkZJP2LA3@mail.gmail.com>

That is correct. In the error node, the master node cannot get STORE_PATH
event and cannot start remoteListen and remoteWorker threads.

Below is the event table for the error node.
*[root at slony-r1s1-001 ~]# psql -U postgres system.db -c "select * from
_slony.sl_event where ev_seqno > 5000000078";
* ev_origin |  ev_seqno  |        ev_timestamp        | ev_snapshot |
ev_type       | ev_data1 | ev_data2 |
ev_data3
        | ev_data4 | ev_data5 | ev_data6 | ev_data7 | ev_data8
-----------+------------+----------------------------+-------------+---------------------+----------+----------+-----------------------------------------------------
--------+----------+----------+----------+----------+----------
         1 | 5000000079 | 2010-10-29 16:17:23.546814 | 888:888:    |
SYNC                |          |
|
        |          |          |          |          |
         1 | 5000000080 | 2010-10-29 09:49:06.107569 | 982:982:    |
STORE_NODE          | 2        | slave
|
        |          |          |          |          |
         1 | 5000000081 | 2010-10-29 09:49:06.107569 | 982:982:    |
ENABLE_NODE         | 2        |
|
        |          |          |          |          |
         1 | 5000000082 | 2010-10-29 09:49:06.433519 | 983:983:    |
STORE_PATH          | 2        | 1        | host=192.168.11.12
dbname=system.db user=postgres po
rt=5432 | 10       |          |          |          |
         1 | 5000000083 | 2010-10-29 09:49:10.311715 | 988:988:    |
SUBSCRIBE_SET       | 1        | 1        |
2
        | t        | f        |          |          |
         1 | 5000000084 | 2010-10-29 09:49:10.311715 | 988:988:    |
ENABLE_SUBSCRIPTION | 1        | 1        |
2
        | t        | f        |          |          |
(6 rows)

In the normal node event table, there has similar records below. Only
difference is there have a number of SYNC events generated continuously.
*[root at 140-r1s1-001 ~]# psql -U postgres system.db -c "select * from
_slony.sl_event where ev_seqno > 5000000078 order by ev_seqno";
*LOG:  duration: 5.093 ms  statement: select * from _slony.sl_event where
ev_seqno > 5000000078 order by ev_seqno
 ev_origin |  ev_seqno  |        ev_timestamp        | ev_snapshot |
ev_type       | ev_data1 | ev_data2 |
ev_data3
        | ev_data4 | ev_data5 | ev_data6 | ev_data7 | ev_data8
-----------+------------+----------------------------+-------------+---------------------+----------+----------+-----------------------------------------------------
--------+----------+----------+----------+----------+----------
         1 | 5000000082 | 2010-10-29 13:55:57.312714 | 892:892:    |
SYNC                |          |
|
        |          |          |          |          |
         1 | 5000000083 | 2010-10-29 06:32:52.628858 | 997:997:    |
STORE_NODE          | 2        | slave
|
        |          |          |          |          |
         1 | 5000000084 | 2010-10-29 06:32:52.628858 | 997:997:    |
ENABLE_NODE         | 2        |
|
        |          |          |          |          |
         1 | 5000000085 | 2010-10-29 06:32:53.07135  | 998:998:    |
STORE_PATH          | 2        | 1        | host=192.168.11.12
dbname=system.db user=postgres po
rt=5432 | 10       |          |          |          |
         1 | 5000000086 | 2010-10-29 06:32:57.676823 | 1003:1003:  |
SUBSCRIBE_SET       | 1        | 1        |
2
        | t        | f        |          |          |
         1 | 5000000087 | 2010-10-29 06:32:57.676823 | 1003:1003:  |
ENABLE_SUBSCRIPTION | 1        | 1        |
2
        | t        | f        |          |          |
         1 | 5000000088 | 2010-10-29 13:58:27.852526 | 1085:1085:  |
SYNC                |          |
|
        |          |          |          |          |
         1 | 5000000089 | 2010-10-29 13:58:37.868268 | 1087:1087:  |
SYNC                |          |
|
        |          |          |          |          |
...................
         1 | 5000000526 | 2010-10-29 15:11:31.902246 | 1987:1987:  |
SYNC                |          |
|
        |          |          |          |          |
         1 | 5000000527 | 2010-10-29 15:11:41.905465 | 1989:1989:  |
SYNC                |          |
|
        |          |          |          |          |
         1 | 5000000528 | 2010-10-29 15:11:51.912475 | 1991:1991:  |
SYNC                |          |
|
        |          |          |          |          |
         1 | 5000000529 | 2010-10-29 15:12:01.913758 | 1993:1993:  |
SYNC                |          |
|
        |          |          |          |          |
(448 rows)


On Fri, Oct 29, 2010 at 10:39 PM, Steve Singer <ssinger at ca.afilias.info>wrote:

> On 10-10-29 10:24 AM, Jason Chen wrote:
>
>> Hi Steve,
>>
>>  >If you turn up the logging level to debug , what does slon report in
>> the log in cases where it doesn't work.   I must be logging some stuff
>> even if it then stops/hangs.
>>
>> I have attached the normal configuration and error configuration master
>> node log. Can you take a look and see if there is anything abnormal?
>>
>>  >slon using the connection settings from the service config to connect
>> to its 'local' database that it generates the syncs on.  It sounds like
>> slon isn't able to talk to this database.
>>
>> Is there any log we can check on that since postgresql on the master
>> node runs well?
>>
>> Please also let me know if you need other more information.
>>
>> Thanks,
>> Jason
>>
>>
> The error log stops after a few minutes.  Does slon just stop writing to
> the file?
>
> As you can see in the normal log file,
> the localListener thread sees the STORE NODE event and then the STORE PATH
> event a bit further down.
>
> 2010-10-29 15:01:38 UTCDEBUG2 localListenThread: Received event
> 1,5000000179 STORE_NODE
> 2010-10-29 15:01:38 UTCCONFIG storeNode: no_id=2 no_comment='slave'
>
>
> Once it processes that store node event it then starts the remoteWorker and
> remoteListener threads that actually do stuff
>
> In the error case, if you query the sl_event table on the master you should
> see the STORE NODE and STORE PATH events. (this is worth confirming).  The
> question is why is the slon not getting to this events. What event numbers
> are assigned to them?
>
> In the error case it got as far as 1,5000000081  in the normal case the
> STORE NODE event was 1,5000000180 so if the time from when you started slon
> until when you ran the storeNode is similar in both cases then you still
> have a fair number of events left to process (though processing 100 SYNC
> events when no tables are replicated should be pretty fast)
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-hackers/attachments/20101029/03bc1aae/attachment-0001.htm 

From ssinger at ca.afilias.info  Fri Oct 29 13:28:29 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 29 Oct 2010 16:28:29 -0400
Subject: [Slony1-hackers] Abnormal <event pending> in sl_path just after
 configure one slave.
In-Reply-To: <AANLkTimqzbG+-vCnotUueJ8tfv_1kygca-5MkZJP2LA3@mail.gmail.com>
References: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>	<4CC9BB54.9010807@ca.afilias.info>	<AANLkTimnjH5XqCX6wyAgQCcL5P51ESYsybocrNKf-TjG@mail.gmail.com>	<AANLkTin-fLZDnnOZBmRUfsZxuRf1caxoaON2oS2sZVdU@mail.gmail.com>	<4CCABCCB.4080103@ca.afilias.info>	<AANLkTimk0Qxs6UGaB+mtsO1fnKNPDH5NZXuJb5aAG+K2@mail.gmail.com>	<4CCADCBC.9030401@ca.afilias.info>
	<AANLkTimqzbG+-vCnotUueJ8tfv_1kygca-5MkZJP2LA3@mail.gmail.com>
Message-ID: <4CCB2E6D.9020705@ca.afilias.info>

On 10-10-29 11:12 AM, Jason Chen wrote:
> That is correct. In the error node, the master node cannot get
> STORE_PATH event and cannot start remoteListen and remoteWorker threads.
>

You mentioned previosuly something about gdb.

Can you connect to the slon process while it is in this state to see 
what it is doing.

ie  'info threads' to display a list of threads

thread 1
thread 2
etc..
to switch between threads.

and bt to show the stack trace of each thread.





From yunfeng82 at gmail.com  Sat Oct 30 04:19:53 2010
From: yunfeng82 at gmail.com (Jason Chen)
Date: Sat, 30 Oct 2010 19:19:53 +0800
Subject: [Slony1-hackers] Abnormal <event pending> in sl_path just after
 configure one slave.
In-Reply-To: <4CCB2E6D.9020705@ca.afilias.info>
References: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>
	<4CC9BB54.9010807@ca.afilias.info>
	<AANLkTimnjH5XqCX6wyAgQCcL5P51ESYsybocrNKf-TjG@mail.gmail.com>
	<AANLkTin-fLZDnnOZBmRUfsZxuRf1caxoaON2oS2sZVdU@mail.gmail.com>
	<4CCABCCB.4080103@ca.afilias.info>
	<AANLkTimk0Qxs6UGaB+mtsO1fnKNPDH5NZXuJb5aAG+K2@mail.gmail.com>
	<4CCADCBC.9030401@ca.afilias.info>
	<AANLkTimqzbG+-vCnotUueJ8tfv_1kygca-5MkZJP2LA3@mail.gmail.com>
	<4CCB2E6D.9020705@ca.afilias.info>
Message-ID: <AANLkTikmOBbCW6A2aZ84C_c4+Gfu=9V3TO+DqOr94zbX@mail.gmail.com>

After the error system run several hours, it becomes normal again. So I need
to redeploy the testbed and get the backtrace. Basically, I have compared
the error master node with normal master node. The only difference are there
have only 5 threads in error master which missing remoteListener and
remoteWorker thread. If you need this details, I will get it and let you
know next Monday after access my system.

Do you think there has any issue in the configuration process?

Here is the backtrace of the error master node which has become normal
currently.

*(gdb) thread apply all bt

Thread 7 (Thread 0x4159a940 (LWP 6365)):
#0  0x00007fc74a5f6da2 in select () from /lib64/libc.so.6
#1  0x000000000041396e in sched_mainloop (dummy=<value optimized out>) at
scheduler.c:532
#2  0x00007fc74a8852f7 in start_thread () from /lib64/libpthread.so.0
#3  0x00007fc74a5fd85d in clone () from /lib64/libc.so.6
#4  0x0000000000000000 in ?? ()

Thread 6 (Thread 0x4094c940 (LWP 6371)):
#0  0x00007fc74a8894a6 in pthread_cond_wait@@GLIBC_2.3.2 () from
/lib64/libpthread.so.0
#1  0x000000000041334e in sched_wait_conn (conn=0x630d70, condition=0) at
scheduler.c:230
#2  0x00000000004056ee in localListenThread_main (dummy=<value optimized
out>) at local_listen.c:701
#3  0x00007fc74a8852f7 in start_thread () from /lib64/libpthread.so.0
#4  0x00007fc74a5fd85d in clone () from /lib64/libc.so.6
#5  0x0000000000000000 in ?? ()

Thread 5 (Thread 0x41d9b940 (LWP 6376)):
#0  0x00007fc74a8894a6 in pthread_cond_wait@@GLIBC_2.3.2 () from
/lib64/libpthread.so.0
#1  0x000000000041334e in sched_wait_conn (conn=0x6317f0, condition=0) at
scheduler.c:230
#2  0x0000000000412a7e in cleanupThread_main (dummy=<value optimized out>)
at cleanup_thread.c:113
#3  0x00007fc74a8852f7 in start_thread () from /lib64/libpthread.so.0
#4  0x00007fc74a5fd85d in clone () from /lib64/libc.so.6
#5  0x0000000000000000 in ?? ()

Thread 4 (Thread 0x4274c940 (LWP 6380)):
#0  0x00007fc74a8894a6 in pthread_cond_wait@@GLIBC_2.3.2 () from
/lib64/libpthread.so.0
#1  0x000000000041334e in sched_wait_conn (conn=0x642650, condition=0) at
scheduler.c:230
#2  0x00000000004125b6 in syncThread_main (dummy=<value optimized out>) at
sync_thread.c:101
#3  0x00007fc74a8852f7 in start_thread () from /lib64/libpthread.so.0
#4  0x00007fc74a5fd85d in clone () from /lib64/libc.so.6
#5  0x0000000000000000 in ?? ()

Thread 3 (Thread 0x42f4d940 (LWP 8283)):
#0  0x00007fc74a8894a6 in pthread_cond_wait@@GLIBC_2.3.2 () from
/lib64/libpthread.so.0
#1  0x000000000040c5c3 in remoteWorkerThread_main (cdata=<value optimized
out>) at remote_worker.c:479
#2  0x00007fc74a8852f7 in start_thread () from /lib64/libpthread.so.0
#3  0x00007fc74a5fd85d in clone () from /lib64/libc.so.6
#4  0x0000000000000000 in ?? ()

Thread 2 (Thread 0x4374e940 (LWP 8285)):
#0  0x00007fc74a8894a6 in pthread_cond_wait@@GLIBC_2.3.2 () from
/lib64/libpthread.so.0
#1  0x000000000041334e in sched_wait_conn (conn=0x6433b0, condition=0) at
scheduler.c:230
#2  0x0000000000406b0a in remoteListenThread_main (cdata=<value optimized
out>) at remote_listen.c:339
#3  0x00007fc74a8852f7 in start_thread () from /lib64/libpthread.so.0
#4  0x00007fc74a5fd85d in clone () from /lib64/libc.so.6
#5  0x0000000000000000 in ?? ()

Thread 1 (Thread 0x7fc74aeba6e0 (LWP 6363)):
#0  0x00007fc74a8865b5 in pthread_join () from /lib64/libpthread.so.0
#1  0x0000000000413582 in sched_wait_mainloop () at scheduler.c:172
#2  0x0000000000402f31 in SlonWatchdog () at slon.c:740
#3  0x0000000000403c58 in main (argc=6, argv=0x7fff9a3202b8) at slon.c:355
#0  0x00007fc74a8865b5 in pthread_join () from /lib64/libpthread.so.0*


On Sat, Oct 30, 2010 at 4:28 AM, Steve Singer <ssinger at ca.afilias.info>wrote:

> On 10-10-29 11:12 AM, Jason Chen wrote:
>
>> That is correct. In the error node, the master node cannot get
>> STORE_PATH event and cannot start remoteListen and remoteWorker threads.
>>
>>
> You mentioned previosuly something about gdb.
>
> Can you connect to the slon process while it is in this state to see what
> it is doing.
>
> ie  'info threads' to display a list of threads
>
> thread 1
> thread 2
> etc..
> to switch between threads.
>
> and bt to show the stack trace of each thread.
>
>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-hackers/attachments/20101030/d6eb5f5f/attachment.htm 

From yunfeng82 at gmail.com  Sun Oct 31 21:53:23 2010
From: yunfeng82 at gmail.com (Jason Chen)
Date: Mon, 1 Nov 2010 12:53:23 +0800
Subject: [Slony1-hackers] Abnormal <event pending> in sl_path just after
 configure one slave.
In-Reply-To: <AANLkTikmOBbCW6A2aZ84C_c4+Gfu=9V3TO+DqOr94zbX@mail.gmail.com>
References: <AANLkTimwsJ8TN1Jkm5yk+RKAuCspab3jgceX+PMs+mUs@mail.gmail.com>
	<4CC9BB54.9010807@ca.afilias.info>
	<AANLkTimnjH5XqCX6wyAgQCcL5P51ESYsybocrNKf-TjG@mail.gmail.com>
	<AANLkTin-fLZDnnOZBmRUfsZxuRf1caxoaON2oS2sZVdU@mail.gmail.com>
	<4CCABCCB.4080103@ca.afilias.info>
	<AANLkTimk0Qxs6UGaB+mtsO1fnKNPDH5NZXuJb5aAG+K2@mail.gmail.com>
	<4CCADCBC.9030401@ca.afilias.info>
	<AANLkTimqzbG+-vCnotUueJ8tfv_1kygca-5MkZJP2LA3@mail.gmail.com>
	<4CCB2E6D.9020705@ca.afilias.info>
	<AANLkTikmOBbCW6A2aZ84C_c4+Gfu=9V3TO+DqOr94zbX@mail.gmail.com>
Message-ID: <AANLkTik4E2whAyieL+z9ysf=RoeSrOK_dWtXobG6iqXm@mail.gmail.com>

Hi Steve,

After detail check log/core dump and sl_event table, I have figured out the
root cause which is the time change issue.

During the master node configuration, time has changed after configure slon
service. I am configuring VM machine in a ESX host which time is earlier 7
hours than NTP server which VM machine is using after configuration. This
will cause slon sched thread continuously check and wait for 7 hours. The
simple workaround here is to restart slon service to refresh the time in
slon sched thread.

This might bring a new requirement on slony. Do we have any kind of
mechanism to handle time change other than restart slon service? Consider
one scenario, after slon service configured successfully and there have many
SYNC events generated, then user configures a new external NTP server which
might has several days before the current time. This will cause all previous
un-confirmed SYNC events cannot be synced until time has caught up.

Could you share your insight on this potential issue?

Thanks,
Jason


On Sat, Oct 30, 2010 at 7:19 PM, Jason Chen <yunfeng82 at gmail.com> wrote:

> After the error system run several hours, it becomes normal again. So I
> need to redeploy the testbed and get the backtrace. Basically, I have
> compared the error master node with normal master node. The only difference
> are there have only 5 threads in error master which missing remoteListener
> and remoteWorker thread. If you need this details, I will get it and let you
> know next Monday after access my system.
>
> Do you think there has any issue in the configuration process?
>
> Here is the backtrace of the error master node which has become normal
> currently.
>
> *(gdb) thread apply all bt
>
> Thread 7 (Thread 0x4159a940 (LWP 6365)):
> #0  0x00007fc74a5f6da2 in select () from /lib64/libc.so.6
> #1  0x000000000041396e in sched_mainloop (dummy=<value optimized out>) at
> scheduler.c:532
> #2  0x00007fc74a8852f7 in start_thread () from /lib64/libpthread.so.0
> #3  0x00007fc74a5fd85d in clone () from /lib64/libc.so.6
> #4  0x0000000000000000 in ?? ()
>
> Thread 6 (Thread 0x4094c940 (LWP 6371)):
> #0  0x00007fc74a8894a6 in pthread_cond_wait@@GLIBC_2.3.2 () from
> /lib64/libpthread.so.0
> #1  0x000000000041334e in sched_wait_conn (conn=0x630d70, condition=0) at
> scheduler.c:230
> #2  0x00000000004056ee in localListenThread_main (dummy=<value optimized
> out>) at local_listen.c:701
> #3  0x00007fc74a8852f7 in start_thread () from /lib64/libpthread.so.0
> #4  0x00007fc74a5fd85d in clone () from /lib64/libc.so.6
> #5  0x0000000000000000 in ?? ()
>
> Thread 5 (Thread 0x41d9b940 (LWP 6376)):
> #0  0x00007fc74a8894a6 in pthread_cond_wait@@GLIBC_2.3.2 () from
> /lib64/libpthread.so.0
> #1  0x000000000041334e in sched_wait_conn (conn=0x6317f0, condition=0) at
> scheduler.c:230
> #2  0x0000000000412a7e in cleanupThread_main (dummy=<value optimized out>)
> at cleanup_thread.c:113
> #3  0x00007fc74a8852f7 in start_thread () from /lib64/libpthread.so.0
> #4  0x00007fc74a5fd85d in clone () from /lib64/libc.so.6
> #5  0x0000000000000000 in ?? ()
>
> Thread 4 (Thread 0x4274c940 (LWP 6380)):
> #0  0x00007fc74a8894a6 in pthread_cond_wait@@GLIBC_2.3.2 () from
> /lib64/libpthread.so.0
> #1  0x000000000041334e in sched_wait_conn (conn=0x642650, condition=0) at
> scheduler.c:230
> #2  0x00000000004125b6 in syncThread_main (dummy=<value optimized out>) at
> sync_thread.c:101
> #3  0x00007fc74a8852f7 in start_thread () from /lib64/libpthread.so.0
> #4  0x00007fc74a5fd85d in clone () from /lib64/libc.so.6
> #5  0x0000000000000000 in ?? ()
>
> Thread 3 (Thread 0x42f4d940 (LWP 8283)):
> #0  0x00007fc74a8894a6 in pthread_cond_wait@@GLIBC_2.3.2 () from
> /lib64/libpthread.so.0
> #1  0x000000000040c5c3 in remoteWorkerThread_main (cdata=<value optimized
> out>) at remote_worker.c:479
> #2  0x00007fc74a8852f7 in start_thread () from /lib64/libpthread.so.0
> #3  0x00007fc74a5fd85d in clone () from /lib64/libc.so.6
> #4  0x0000000000000000 in ?? ()
>
> Thread 2 (Thread 0x4374e940 (LWP 8285)):
> #0  0x00007fc74a8894a6 in pthread_cond_wait@@GLIBC_2.3.2 () from
> /lib64/libpthread.so.0
> #1  0x000000000041334e in sched_wait_conn (conn=0x6433b0, condition=0) at
> scheduler.c:230
> #2  0x0000000000406b0a in remoteListenThread_main (cdata=<value optimized
> out>) at remote_listen.c:339
> #3  0x00007fc74a8852f7 in start_thread () from /lib64/libpthread.so.0
> #4  0x00007fc74a5fd85d in clone () from /lib64/libc.so.6
> #5  0x0000000000000000 in ?? ()
>
> Thread 1 (Thread 0x7fc74aeba6e0 (LWP 6363)):
> #0  0x00007fc74a8865b5 in pthread_join () from /lib64/libpthread.so.0
> #1  0x0000000000413582 in sched_wait_mainloop () at scheduler.c:172
> #2  0x0000000000402f31 in SlonWatchdog () at slon.c:740
> #3  0x0000000000403c58 in main (argc=6, argv=0x7fff9a3202b8) at slon.c:355
> #0  0x00007fc74a8865b5 in pthread_join () from /lib64/libpthread.so.0*
>
>
>
> On Sat, Oct 30, 2010 at 4:28 AM, Steve Singer <ssinger at ca.afilias.info>wrote:
>
>> On 10-10-29 11:12 AM, Jason Chen wrote:
>>
>>> That is correct. In the error node, the master node cannot get
>>> STORE_PATH event and cannot start remoteListen and remoteWorker threads.
>>>
>>>
>> You mentioned previosuly something about gdb.
>>
>> Can you connect to the slon process while it is in this state to see what
>> it is doing.
>>
>> ie  'info threads' to display a list of threads
>>
>> thread 1
>> thread 2
>> etc..
>> to switch between threads.
>>
>> and bt to show the stack trace of each thread.
>>
>>
>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-hackers/attachments/20101101/b253bd66/attachment.htm 

