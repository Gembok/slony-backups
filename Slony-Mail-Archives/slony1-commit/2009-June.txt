From cbbrowne at lists.slony.info  Fri Jun  5 10:54:49 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jun  5 10:54:52 2009
Subject: [Slony1-commit] slony1-www/content frontpage.txt
Message-ID: <20090605175449.EA0B7290439@main.slony.info>

Update of /home/cvsd/slony1/slony1-www/content
In directory main.slony.info:/tmp/cvs-serv3544/content

Modified Files:
	frontpage.txt 
Log Message:
Add in link to RPMs


Index: frontpage.txt
===================================================================
RCS file: /home/cvsd/slony1/slony1-www/content/frontpage.txt,v
retrieving revision 1.34
retrieving revision 1.35
diff -C2 -d -r1.34 -r1.35
*** frontpage.txt	11 May 2009 19:57:24 -0000	1.34
--- frontpage.txt	5 Jun 2009 17:54:47 -0000	1.35
***************
*** 5,13 ****
  release notes.  This version fixes quite a number of issues found in
  early use of version 2.0.
- ---
- Slony-I 1.2.16 Released
  
  <P> See the "news" area for more details, including a copy of the
  release notes.  This version fixes issues relating to FAILOVER.
  ---
  Slony-I 2.0.1 Released
--- 5,15 ----
  release notes.  This version fixes quite a number of issues found in
  early use of version 2.0.
  
  <P> See the "news" area for more details, including a copy of the
  release notes.  This version fixes issues relating to FAILOVER.
+ 
+ <P> Source RPMs (SRPMs) are available <a href=
+ "http://yum.pgsqlrpms.org/srpms/8.4/fedora/fedora-11-i386/slony1-2.0.2-1.f11.src.rpm">
+ here </a> --- Slony-I 1.2.16 Released
  ---
  Slony-I 2.0.1 Released

From cbbrowne at lists.slony.info  Fri Jun  5 12:10:26 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jun  5 12:10:27 2009
Subject: [Slony1-commit] slony1-engine/tests/testseqnames README
	generate_dml.sh init_add_tables.ik init_schema.sql
Message-ID: <20090605191026.887AF290BF1@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tests/testseqnames
In directory main.slony.info:/tmp/cvs-serv11036

Modified Files:
      Tag: REL_2_0_STABLE
	README generate_dml.sh init_add_tables.ik init_schema.sql 
Log Message:
Update sequence test to validate that big ID #'s do not cause
grief


Index: README
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testseqnames/README,v
retrieving revision 1.1
retrieving revision 1.1.6.1
diff -C2 -d -r1.1 -r1.1.6.1
*** README	15 Nov 2005 21:25:34 -0000	1.1
--- README	5 Jun 2009 19:10:24 -0000	1.1.6.1
***************
*** 3,4 ****
--- 3,8 ----
  This test involves creating some sequences with wacky names involving
  StudlyCaps, spaces, and ".".
+ 
+ It also creates a Large Number of sequences, to validate that
+ we don't break down with either large quantities of them, or
+ if the IDs are large numbers

Index: generate_dml.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testseqnames/generate_dml.sh,v
retrieving revision 1.5.2.1
retrieving revision 1.5.2.2
diff -C2 -d -r1.5.2.1 -r1.5.2.2
*** generate_dml.sh	28 Apr 2009 21:48:20 -0000	1.5.2.1
--- generate_dml.sh	5 Jun 2009 19:10:24 -0000	1.5.2.2
***************
*** 25,29 ****
    GENDATA="$mktmp/generate.data"
    echo "" > ${GENDATA}
!   numrows=$(random_number 50 1000)
    i=0;
    trippoint=`expr $numrows / 20`
--- 25,29 ----
    GENDATA="$mktmp/generate.data"
    echo "" > ${GENDATA}
!   numrows=$(random_number 25 35)
    i=0;
    trippoint=`expr $numrows / 20`
***************
*** 45,48 ****
--- 45,57 ----
      echo "select nextval('\"Schema.name\".\"a.periodic.sequence\"');" >> $GENDATA
      echo "select nextval('\"Studly Spacey Schema\".\"user\"');" >> $GENDATA
+     for d4 in 8 3 9 0 6 7 1 4 5 2; do
+ 	for d2 in 0 2 1 3 9 5 6 4 8 7; do
+ 	    for d1 in 0 1; do
+ 		for d3 in 5 2 1 6 4 8 3 9 0 7 ; do
+ 		    echo "select nextval('public.seq40${d1}${d2}${d3}${d4}');" >> $GENDATA
+ 		done
+ 	    done
+ 	done
+     done
      if [ ${i} -ge ${numrows} ]; then
        break;

Index: init_add_tables.ik
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testseqnames/init_add_tables.ik,v
retrieving revision 1.2
retrieving revision 1.2.2.1
diff -C2 -d -r1.2 -r1.2.2.1
*** init_add_tables.ik	18 Apr 2007 19:26:54 -0000	1.2
--- init_add_tables.ik	5 Jun 2009 19:10:24 -0000	1.2.2.1
***************
*** 7,8 ****
--- 7,2009 ----
  
  set add sequence (set id = 1, origin = 1, id = 3, fully qualified name = '"Schema.name"."a.periodic.sequence"');
+ set add sequence (set id = 1, origin = 1, id = 23400000, fully qualified name = 'public.seq400000');
+ set add sequence (set id = 1, origin = 1, id = 23400001, fully qualified name = 'public.seq400001');
+ set add sequence (set id = 1, origin = 1, id = 23400002, fully qualified name = 'public.seq400002');
+ set add sequence (set id = 1, origin = 1, id = 23400003, fully qualified name = 'public.seq400003');
+ set add sequence (set id = 1, origin = 1, id = 23400004, fully qualified name = 'public.seq400004');
+ set add sequence (set id = 1, origin = 1, id = 23400005, fully qualified name = 'public.seq400005');
+ set add sequence (set id = 1, origin = 1, id = 23400006, fully qualified name = 'public.seq400006');
[...1974 lines suppressed...]
+ set add sequence (set id = 1, origin = 1, id = 23401981, fully qualified name = 'public.seq401981');
+ set add sequence (set id = 1, origin = 1, id = 23401982, fully qualified name = 'public.seq401982');
+ set add sequence (set id = 1, origin = 1, id = 23401983, fully qualified name = 'public.seq401983');
+ set add sequence (set id = 1, origin = 1, id = 23401984, fully qualified name = 'public.seq401984');
+ set add sequence (set id = 1, origin = 1, id = 23401985, fully qualified name = 'public.seq401985');
+ set add sequence (set id = 1, origin = 1, id = 23401986, fully qualified name = 'public.seq401986');
+ set add sequence (set id = 1, origin = 1, id = 23401987, fully qualified name = 'public.seq401987');
+ set add sequence (set id = 1, origin = 1, id = 23401988, fully qualified name = 'public.seq401988');
+ set add sequence (set id = 1, origin = 1, id = 23401989, fully qualified name = 'public.seq401989');
+ set add sequence (set id = 1, origin = 1, id = 23401990, fully qualified name = 'public.seq401990');
+ set add sequence (set id = 1, origin = 1, id = 23401991, fully qualified name = 'public.seq401991');
+ set add sequence (set id = 1, origin = 1, id = 23401992, fully qualified name = 'public.seq401992');
+ set add sequence (set id = 1, origin = 1, id = 23401993, fully qualified name = 'public.seq401993');
+ set add sequence (set id = 1, origin = 1, id = 23401994, fully qualified name = 'public.seq401994');
+ set add sequence (set id = 1, origin = 1, id = 23401995, fully qualified name = 'public.seq401995');
+ set add sequence (set id = 1, origin = 1, id = 23401996, fully qualified name = 'public.seq401996');
+ set add sequence (set id = 1, origin = 1, id = 23401997, fully qualified name = 'public.seq401997');
+ set add sequence (set id = 1, origin = 1, id = 23401998, fully qualified name = 'public.seq401998');
+ set add sequence (set id = 1, origin = 1, id = 23401999, fully qualified name = 'public.seq401999');
+ set add sequence (set id = 1, origin = 1, id = 23402000, fully qualified name = 'public.seq402000');

Index: init_schema.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testseqnames/init_schema.sql,v
retrieving revision 1.2
retrieving revision 1.2.2.1
diff -C2 -d -r1.2 -r1.2.2.1
*** init_schema.sql	18 Apr 2007 19:26:54 -0000	1.2
--- init_schema.sql	5 Jun 2009 19:10:24 -0000	1.2.2.1
***************
*** 27,28 ****
--- 27,2029 ----
  create sequence "Studly Spacey Schema"."user";
  create sequence "Schema.name"."a.periodic.sequence";
+ create sequence public.seq400000;
+ create sequence public.seq400001;
+ create sequence public.seq400002;
+ create sequence public.seq400003;
+ create sequence public.seq400004;
+ create sequence public.seq400005;
+ create sequence public.seq400006;
[...1974 lines suppressed...]
+ create sequence public.seq401981;
+ create sequence public.seq401982;
+ create sequence public.seq401983;
+ create sequence public.seq401984;
+ create sequence public.seq401985;
+ create sequence public.seq401986;
+ create sequence public.seq401987;
+ create sequence public.seq401988;
+ create sequence public.seq401989;
+ create sequence public.seq401990;
+ create sequence public.seq401991;
+ create sequence public.seq401992;
+ create sequence public.seq401993;
+ create sequence public.seq401994;
+ create sequence public.seq401995;
+ create sequence public.seq401996;
+ create sequence public.seq401997;
+ create sequence public.seq401998;
+ create sequence public.seq401999;
+ create sequence public.seq402000;

From cbbrowne at lists.slony.info  Tue Jun  9 14:38:29 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Tue Jun  9 14:38:31 2009
Subject: [Slony1-commit] slony1-engine/doc/adminguide adminscripts.sgml
Message-ID: <20090609213829.E3411148228@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/doc/adminguide
In directory main.slony.info:/tmp/cvs-serv4394/doc/adminguide

Modified Files:
      Tag: REL_2_0_STABLE
	adminscripts.sgml 
Log Message:
Add in a slonik configuration dump tool, that will be helpful when doing
upgrades from 1.2 to 2.0, along with documentation.


Index: adminscripts.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/adminscripts.sgml,v
retrieving revision 1.52.2.1
retrieving revision 1.52.2.2
diff -C2 -d -r1.52.2.1 -r1.52.2.2
*** adminscripts.sgml	15 Dec 2008 23:30:58 -0000	1.52.2.1
--- adminscripts.sgml	9 Jun 2009 21:38:27 -0000	1.52.2.2
***************
*** 759,762 ****
--- 759,812 ----
  
  </sect2>
+ <sect2 id="slonikconfdump"> <title>slonikconfdump.sh</title>
+ 
+ <indexterm><primary>slonik configuration dump</primary></indexterm>
+ 
+ <para> The tool <filename>tools/slonikconfdump.sh</filename> was
+ created to help dump out a &lslonik; script to duplicate the
+ configuration of a functioning &slony1; cluster.</para>
+ 
+ <para> It dumps out: </para>
+ 
+ <itemizedlist>
+ <listitem><para>Cluster name </para> </listitem>
+ <listitem><para>Node connection information </para> <para> Note that it uses the first value it finds (<emphasis>e.g.</emphasis> - for the lowest numbered client node). </para> </listitem>
+ <listitem><para> Nodes </para> </listitem>
+ <listitem><para> Sets </para> </listitem>
+ <listitem><para> Tables </para> </listitem>
+ <listitem><para> Sequences </para> </listitem>
+ <listitem><para> Subscriptions </para> </listitem>
+ </itemizedlist>
+ 
+ <para> It may be run as follows: </para>
+ <programlisting>
+ chris@dba2:Slony-I/CMD/slony1-2.0/tools> SLONYCLUSTER=slony_regress1 PGDATABASE=slonyregress1 bash slonikconfdump.sh
+ # building slonik config files for cluster slony_regress1
+ # generated by: slonikconfdump.sh
+ # Generated on:  Tue Jun 9 17:34:12 EDT 2009
+ cluster name=slony_regress1;
+ include <admin-conninfos.slonik>;  # Draw in ADMIN CONNINFO lines
+ node 1 admin conninfo='dbname=slonyregress1 host=localhost user=chris port=7083';
+ node 2 admin conninfo='dbname=slonyregress2 host=localhost user=chris port=7083';
+ init cluster (id=1, comment='Regress test node');
+ store node (id=2, comment='node 2');
+ store path (server=1, client=2, conninfo='dbname=slonyregress1 host=localhost user=chris port=7083', connretry=10);
+ store path (server=2, client=1, conninfo='dbname=slonyregress2 host=localhost user=chris port=7083', connretry=10);
+ create set (id=1, origin=1, comment='All test1 tables');
+ set add table (id=1, set id=1, origin=1, fully qualified name='"public"."table1"', comment='accounts table, key='table1_pkey');
+ set add table (id=2, set id=1, origin=1, fully qualified name='"public"."table2"', comment='public.table2, key='table2_id_key');
+ set add table (id=4, set id=1, origin=1, fully qualified name='"public"."table4"', comment='a table of many types, key='table4_pkey');
+ set add table (id=5, set id=1, origin=1, fully qualified name='"public"."table5"', comment='a table with composite PK strewn across the table, key='table5_pkey');
+ subscribe set (id=1, provider=1, receiver=2, forward=YES);
+ chris@dba2:Slony-I/CMD/slony1-2.0/tools>
+ </programlisting>
+ 
+ <para> The output should be reviewed before it is applied elsewhere;
+ particular attention should be paid to the <command>ADMIN
+ CONNINFO</command> statements, as it picks the first value that it
+ sees for each node; in a complex environment, it may not pull out the
+ right value.</para>
+ 
+ </sect2>
  </sect1>
  <!-- Keep this comment at the end of the file

From cbbrowne at lists.slony.info  Tue Jun  9 14:38:29 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Tue Jun  9 14:38:32 2009
Subject: [Slony1-commit] slony1-engine/tools slonikconfdump.sh
Message-ID: <20090609213829.D7FD5148220@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tools
In directory main.slony.info:/tmp/cvs-serv4394/tools

Added Files:
      Tag: REL_2_0_STABLE
	slonikconfdump.sh 
Log Message:
Add in a slonik configuration dump tool, that will be helpful when doing
upgrades from 1.2 to 2.0, along with documentation.


--- NEW FILE: slonikconfdump.sh ---
#!/bin/bash
# $Id: slonikconfdump.sh,v 1.1.2.1 2009-06-09 21:38:27 cbbrowne Exp $
# This tool rummages through a Slony-I cluster, generating a slonik script
# suitable to recreate the cluster

# Start with:
# SLONYCLUSTER indicating the cluster name
echo "# building slonik config files for cluster ${SLONYCLUSTER}"
echo "# generated by: slonikconfdump.sh"
echo "# Generated on: " `date`
SS="\"_${SLONYCLUSTER}\""
echo "cluster name=${SLONYCLUSTER};"

echo "include <admin-conninfos.slonik>;  # Draw in ADMIN CONNINFO lines"
Q="select distinct pa_server from ${SS}.sl_path order by pa_server;"
PATHS=`psql -qtA -F ":" -c "${Q}"`
for svr in `echo ${PATHS}`; do
    SQ="select pa_conninfo from ${SS}.sl_path where pa_server=${svr} order by pa_client asc limit 1;"
    conninfo=`psql -qtA -F ":" -c "${SQ}"`
    echo "node ${svr} admin conninfo='${conninfo}';"
done

Q="select no_id, no_comment from ${SS}.sl_node order by no_id limit 1;"

NODE1=`psql -qtA -F ":" -c "${Q}"`
nn=`echo ${NODE1} | cut -d : -f 1`
comment=`echo ${NODE1} | cut -d : -f 2-`
echo "init cluster (id=${nn}, comment='${comment}');"

Q="select no_id from ${SS}.sl_node order by no_id offset 1;"
NODES=`psql -qtA -F ":" -c "${Q}"`
for node in `echo ${NODES}`; do
    CQ="select no_comment from ${SS}.sl_node where no_id = ${node};"
    comment=`psql -qtA -c "${CQ}"`
    echo "store node (id=${node}, comment='${comment}');"
done

#slonyregress1=# select * from sl_path;
# pa_server | pa_client |                       pa_conninfo                        | pa_connretry
#-----------+-----------+----------------------------------------------------------+--------------
#         2 |         1 | dbname=slonyregress2 host=localhost user=chris port=7083 |           10
#         1 |         2 | dbname=slonyregress1 host=localhost user=chris port=7083 |           10
#(2 rows)

Q="select pa_server, pa_client, pa_connretry from ${SS}.sl_path order by pa_server, pa_client;"
PATHS=`psql -qtA -F ":" -R " " -c "${Q}"`
for sc in `echo $PATHS`; do
    server=`echo $sc | cut -d : -f 1`
    client=`echo $sc | cut -d : -f 2`
    retry=`echo $sc | cut -d : -f 3`
    Q2="select pa_conninfo from ${SS}.sl_path where pa_server=${server} and pa_client=${client};"
    conninfo=`psql -qtA -c "${Q2}"`
    echo "store path (server=${server}, client=${client}, conninfo='${conninfo}', connretry=${retry});"
done

Q="select set_id, set_origin from ${SS}.sl_set order by set_id;"
SETS=`psql -qtA -F ":" -R " " -c "${Q}"`
for sc in `echo ${SETS}`; do
    set=`echo ${sc} | cut -d : -f 1`
    origin=`echo ${sc} | cut -d : -f 2`
    Q2="select set_comment from ${SS}.sl_set where set_id=${set};"
    comment=`psql -qtA -c "${Q2}"`
    echo "create set (id=${set}, origin=${origin}, comment='${comment}');"
done

Q="select tab_id,tab_set, set_origin from ${SS}.sl_table, ${SS}.sl_set where tab_set = set_id order by tab_id;"
TABS=`psql -qtA -F ":" -R " " -c "${Q}"`
for tb in `echo ${TABS}`; do
    tab=`echo ${tb} | cut -d : -f 1`
    set=`echo ${tb} | cut -d : -f 2`
    origin=`echo ${tb} | cut -d : -f 3`
    RQ="select tab_relname from ${SS}.sl_table where tab_id = ${tab};"
    relname=`psql -qtA -c "${RQ}"`
    NSQ="select tab_nspname from ${SS}.sl_table where tab_id = ${tab};"
    nsp=`psql -qtA -c "${NSQ}"`
    IDX="select tab_idxname from ${SS}.sl_table where tab_id = ${tab};"
    idx=`psql -qtA -c "${IDX}"`
    COM="select tab_comment from ${SS}.sl_table where tab_id = ${tab};"
    comment=`psql -qtA -c "${COM}"`
    echo "set add table (id=${tab}, set id=${set}, origin=${origin}, fully qualified name='\"${nsp}\".\"${relname}\"', comment='${comment}, key='${idx}');"
done


Q="select seq_id,seq_set,set_origin from ${SS}.sl_sequence, ${SS}.sl_set where seq_set = set_id order by seq_id;"
SEQS=`psql -qtA -F ":" -R " " -c "${Q}"`
for sq in `echo ${SEQS}`; do
    seq=`echo ${sq} | cut -d : -f 1`
    set=`echo ${sq} | cut -d : -f 2`
    origin=`echo ${sq} | cut -d : -f 3`
    RQ="select seq_relname from ${SS}.sl_sequence where seq_id = ${seq};"
    relname=`psql -qtA -c "${RQ}"`
    NSQ="select seq_nspname from ${SS}.sl_sequence where seq_id = ${seq};"
    nsp=`psql -qtA -c "${NSQ}"`
    COM="select seq_comment from ${SS}.sl_sequence where seq_id = ${seq};"
    comment=`psql -qtA -c "${COM}"`
    echo "set add sequence(id=${seq}, set id=${set}, origin=${origin}, fully qualified name='\"${nsp}\".\"${relname}\"', comment='${comment}');"
done

Q="select sub_set,sub_provider,sub_receiver,case when sub_forward then 'YES' else 'NO' end from ${SS}.sl_subscribe;"
SUBS=`psql -qtA -F ":" -R " " -c "${Q}"`
for sb in `echo ${SUBS}`; do
    set=`echo ${sb} | cut -d : -f 1`
    prov=`echo ${sb} | cut -d : -f 2`
    recv=`echo ${sb} | cut -d : -f 3`
    forw=`echo ${sb} | cut -d : -f 4`
    echo "subscribe set (id=${set}, provider=${prov}, receiver=${recv}, forward=${forw});"
done

From wieck at lists.slony.info  Wed Jun 10 08:00:54 2009
From: wieck at lists.slony.info (Jan Wieck)
Date: Wed Jun 10 08:00:56 2009
Subject: [Slony1-commit] slony1-engine/src/slon scheduler.c
Message-ID: <20090610150054.B718C29027C@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv7382

Modified Files:
	scheduler.c 
Log Message:
Applied patch from Oleg A. Mamontov:

> there is a logical mistake in slon/scheduler.c, in sched_mainloop  
> fdsets copied
> for select before checking connections for their timeouts. In timeout  
> case this
> descriptors will be removed with DLLIST_REMOVE and sched_remove_fdset,  
> but stayed in
> select descriptors bit vector.

Good work, thank you.

Jan


Index: scheduler.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/scheduler.c,v
retrieving revision 1.26
retrieving revision 1.27
diff -C2 -d -r1.26 -r1.27
*** scheduler.c	28 May 2008 19:09:37 -0000	1.26
--- scheduler.c	10 Jun 2009 15:00:52 -0000	1.27
***************
*** 423,439 ****
  
  		/*
- 		 * Make copies of the file descriptor sets for select(2)
- 		 */
- 		FD_ZERO(&rfds);
- 		FD_ZERO(&wfds);
- 		for (i = 0; i < sched_numfd; i++)
- 		{
- 			if (FD_ISSET(i, &sched_fdset_read))
- 				FD_SET(i, &rfds);
- 			if (FD_ISSET(i, &sched_fdset_write))
- 				FD_SET(i, &wfds);
- 		}
- 
- 		/*
  		 * Check if any of the connections in the wait queue have reached
  		 * their timeout. While doing so, we also remember the closest timeout
--- 423,426 ----
***************
*** 527,530 ****
--- 514,530 ----
  
  		/*
+ 		 * Make copies of the file descriptor sets for select(2)
+ 		 */
+ 		FD_ZERO(&rfds);
+ 		FD_ZERO(&wfds);
+ 		for (i = 0; i < sched_numfd; i++)
+ 		{
+ 			if (FD_ISSET(i, &sched_fdset_read))
+ 				FD_SET(i, &rfds);
+ 			if (FD_ISSET(i, &sched_fdset_write))
+ 				FD_SET(i, &wfds);
+ 		}
+ 
+ 		/*
  		 * Do the select(2) while unlocking the master lock.
  		 */

From wieck at lists.slony.info  Wed Jun 10 08:02:42 2009
From: wieck at lists.slony.info (Jan Wieck)
Date: Wed Jun 10 08:02:43 2009
Subject: [Slony1-commit] slony1-engine/src/slon scheduler.c
Message-ID: <20090610150242.64B6929027D@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv7760

Modified Files:
      Tag: REL_1_2_STABLE
	scheduler.c 
Log Message:
Applied patch from Oleg A. Mamontov:

> there is a logical mistake in slon/scheduler.c, in sched_mainloop  
> fdsets copied
> for select before checking connections for their timeouts. In timeout  
> case this
> descriptors will be removed with DLLIST_REMOVE and sched_remove_fdset,  
> but stayed in
> select descriptors bit vector.

Good work, thank you.

Jan


Index: scheduler.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/scheduler.c,v
retrieving revision 1.24.2.2
retrieving revision 1.24.2.3
diff -C2 -d -r1.24.2.2 -r1.24.2.3
*** scheduler.c	27 Oct 2006 20:09:56 -0000	1.24.2.2
--- scheduler.c	10 Jun 2009 15:02:40 -0000	1.24.2.3
***************
*** 426,442 ****
  
  		/*
- 		 * Make copies of the file descriptor sets for select(2)
- 		 */
- 		FD_ZERO(&rfds);
- 		FD_ZERO(&wfds);
- 		for (i = 0; i < sched_numfd; i++)
- 		{
- 			if (FD_ISSET(i, &sched_fdset_read))
- 				FD_SET(i, &rfds);
- 			if (FD_ISSET(i, &sched_fdset_write))
- 				FD_SET(i, &wfds);
- 		}
- 
- 		/*
  		 * Check if any of the connections in the wait queue have reached
  		 * their timeout. While doing so, we also remember the closest timeout
--- 426,429 ----
***************
*** 530,533 ****
--- 517,533 ----
  
  		/*
+ 		 * Make copies of the file descriptor sets for select(2)
+ 		 */
+ 		FD_ZERO(&rfds);
+ 		FD_ZERO(&wfds);
+ 		for (i = 0; i < sched_numfd; i++)
+ 		{
+ 			if (FD_ISSET(i, &sched_fdset_read))
+ 				FD_SET(i, &rfds);
+ 			if (FD_ISSET(i, &sched_fdset_write))
+ 				FD_SET(i, &wfds);
+ 		}
+ 
+ 		/*
  		 * Do the select(2) while unlocking the master lock.
  		 */

From cbbrowne at lists.slony.info  Wed Jun 10 14:11:58 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jun 10 14:12:00 2009
Subject: [Slony1-commit] slony1-engine/doc/adminguide adminscripts.sgml
Message-ID: <20090610211158.953BC29027C@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/doc/adminguide
In directory main.slony.info:/tmp/cvs-serv18169/doc/adminguide

Modified Files:
      Tag: REL_2_0_STABLE
	adminscripts.sgml 
Log Message:
Change ordering of subscription extraction, and document the restrictions
a bit more carefully for the configuration dumper


Index: adminscripts.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/adminscripts.sgml,v
retrieving revision 1.52.2.2
retrieving revision 1.52.2.3
diff -C2 -d -r1.52.2.2 -r1.52.2.3
*** adminscripts.sgml	9 Jun 2009 21:38:27 -0000	1.52.2.2
--- adminscripts.sgml	10 Jun 2009 21:11:56 -0000	1.52.2.3
***************
*** 776,780 ****
  <listitem><para> Tables </para> </listitem>
  <listitem><para> Sequences </para> </listitem>
! <listitem><para> Subscriptions </para> </listitem>
  </itemizedlist>
  
--- 776,785 ----
  <listitem><para> Tables </para> </listitem>
  <listitem><para> Sequences </para> </listitem>
! <listitem><para> Subscriptions </para> 
! 
! <para> Note that the subscriptions are ordered by set, then by
! provider, then by receiver.  This ordering does not necessarily
! indicate the order in which subscriptions need to be
! applied. </para></listitem>
  </itemizedlist>
  
***************
*** 802,810 ****
  </programlisting>
  
! <para> The output should be reviewed before it is applied elsewhere;
! particular attention should be paid to the <command>ADMIN
! CONNINFO</command> statements, as it picks the first value that it
! sees for each node; in a complex environment, it may not pull out the
! right value.</para>
  
  </sect2>
--- 807,817 ----
  </programlisting>
  
! <para> The output should be reviewed before it is applied elsewhere.
! Particular attention should be paid to the <command>ADMIN
! CONNINFO</command>, as it picks the first value that it sees for each
! node; in a complex environment, where visibility of nodes may vary
! from subnet to subnet, it may not pick the right value.  In addition,
! <command>SUBSCRIBE SET</command> statements do not necessarily
! indicate the order in which subscriptions need to be applied.</para>
  
  </sect2>

From cbbrowne at lists.slony.info  Wed Jun 10 14:11:58 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jun 10 14:12:00 2009
Subject: [Slony1-commit] slony1-engine/tools slonikconfdump.sh
Message-ID: <20090610211158.9ECC129032B@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tools
In directory main.slony.info:/tmp/cvs-serv18169/tools

Modified Files:
      Tag: REL_2_0_STABLE
	slonikconfdump.sh 
Log Message:
Change ordering of subscription extraction, and document the restrictions
a bit more carefully for the configuration dumper


Index: slonikconfdump.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tools/Attic/slonikconfdump.sh,v
retrieving revision 1.1.2.1
retrieving revision 1.1.2.2
diff -C2 -d -r1.1.2.1 -r1.1.2.2
*** slonikconfdump.sh	9 Jun 2009 21:38:27 -0000	1.1.2.1
--- slonikconfdump.sh	10 Jun 2009 21:11:56 -0000	1.1.2.2
***************
*** 97,101 ****
  done
  
! Q="select sub_set,sub_provider,sub_receiver,case when sub_forward then 'YES' else 'NO' end from ${SS}.sl_subscribe;"
  SUBS=`psql -qtA -F ":" -R " " -c "${Q}"`
  for sb in `echo ${SUBS}`; do
--- 97,101 ----
  done
  
! Q="select sub_set,sub_provider,sub_receiver,case when sub_forward then 'YES' else 'NO' end from ${SS}.sl_subscribe order by sub_set, sub_provider, sub_receiver;"
  SUBS=`psql -qtA -F ":" -R " " -c "${Q}"`
  for sb in `echo ${SUBS}`; do

From cbbrowne at lists.slony.info  Wed Jun 10 14:13:43 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jun 10 14:13:46 2009
Subject: [Slony1-commit] slony1-engine/src/slon scheduler.c
Message-ID: <20090610211343.F197329027C@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv18275

Modified Files:
      Tag: REL_2_0_STABLE
	scheduler.c 
Log Message:
Per Jan's comments, this is a valid change; it also needs to be applied
to the 2.0 branch


Index: scheduler.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/scheduler.c,v
retrieving revision 1.26
retrieving revision 1.26.2.1
diff -C2 -d -r1.26 -r1.26.2.1
*** scheduler.c	28 May 2008 19:09:37 -0000	1.26
--- scheduler.c	10 Jun 2009 21:13:41 -0000	1.26.2.1
***************
*** 423,439 ****
  
  		/*
- 		 * Make copies of the file descriptor sets for select(2)
- 		 */
- 		FD_ZERO(&rfds);
- 		FD_ZERO(&wfds);
- 		for (i = 0; i < sched_numfd; i++)
- 		{
- 			if (FD_ISSET(i, &sched_fdset_read))
- 				FD_SET(i, &rfds);
- 			if (FD_ISSET(i, &sched_fdset_write))
- 				FD_SET(i, &wfds);
- 		}
- 
- 		/*
  		 * Check if any of the connections in the wait queue have reached
  		 * their timeout. While doing so, we also remember the closest timeout
--- 423,426 ----
***************
*** 527,530 ****
--- 514,530 ----
  
  		/*
+ 		 * Make copies of the file descriptor sets for select(2)
+ 		 */
+ 		FD_ZERO(&rfds);
+ 		FD_ZERO(&wfds);
+ 		for (i = 0; i < sched_numfd; i++)
+ 		{
+ 			if (FD_ISSET(i, &sched_fdset_read))
+ 				FD_SET(i, &rfds);
+ 			if (FD_ISSET(i, &sched_fdset_write))
+ 				FD_SET(i, &wfds);
+ 		}
+ 
+ 		/*
  		 * Do the select(2) while unlocking the master lock.
  		 */

From cbbrowne at lists.slony.info  Thu Jun 11 12:03:47 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jun 11 12:03:49 2009
Subject: [Slony1-commit] slony1-engine/src/slonik slonik.c
Message-ID: <20090611190347.3007729032B@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slonik
In directory main.slony.info:/tmp/cvs-serv5001/src/slonik

Modified Files:
	slonik.c 
Log Message:
Draw a whole pile of changes into HEAD from the 2.0 branch


Index: slonik.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/slonik.c,v
retrieving revision 1.91
retrieving revision 1.92
diff -C2 -d -r1.91 -r1.92
*** slonik.c	28 May 2008 18:23:13 -0000	1.91
--- slonik.c	11 Jun 2009 19:03:45 -0000	1.92
***************
*** 108,112 ****
  	 * We need to find a share directory like PostgreSQL. 
  	 */
! 	if (find_my_exec(argv[0],myfull_path) < 0)
  	{
  		strcpy(share_path, PGSHARE);
--- 108,112 ----
  	 * We need to find a share directory like PostgreSQL. 
  	 */
! 	if (strlen(PGSHARE) > 0)
  	{
  		strcpy(share_path, PGSHARE);

From cbbrowne at lists.slony.info  Thu Jun 11 12:03:47 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jun 11 12:03:50 2009
Subject: [Slony1-commit] slony1-engine/src/slon cleanup_thread.c
	confoptions.c misc.c scheduler.c
Message-ID: <20090611190347.212402902C2@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv5001/src/slon

Modified Files:
	cleanup_thread.c confoptions.c misc.c scheduler.c 
Log Message:
Draw a whole pile of changes into HEAD from the 2.0 branch



Index: cleanup_thread.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/cleanup_thread.c,v
retrieving revision 1.45
retrieving revision 1.46
diff -C2 -d -r1.45 -r1.46
*** cleanup_thread.c	28 May 2008 19:09:37 -0000	1.45
--- cleanup_thread.c	11 Jun 2009 19:03:45 -0000	1.46
***************
*** 190,193 ****
--- 190,194 ----
  				char	   *tab_nspname = PQgetvalue(res, t, 0);
  				char	   *tab_relname = PQgetvalue(res, t, 1);
+ 				ExecStatusType vrc;
  
  				slon_log(SLON_DEBUG1, "cleanupThread: %s analyze \"%s\".%s;\n",
***************
*** 197,209 ****
  							 vacuum_action, tab_nspname, tab_relname);
  				res2 = PQexec(dbconn, dstring_data(&query_pertbl));
! 				if (PQresultStatus(res) != PGRES_COMMAND_OK)	/* query error */
  				{
  					slon_log(SLON_ERROR,
! 							 "cleanupThread: \"%s\" - %s",
! 					dstring_data(&query_pertbl), PQresultErrorMessage(res2));
  
  					/*
  					 * slon_retry(); break;
  					 */
  				}
  				PQclear(res2);
--- 198,218 ----
  							 vacuum_action, tab_nspname, tab_relname);
  				res2 = PQexec(dbconn, dstring_data(&query_pertbl));
! 				vrc = PQresultStatus(res);
! 				if (vrc == PGRES_FATAL_ERROR)
  				{
  					slon_log(SLON_ERROR,
! 							 "cleanupThread: \"%s\" - %s\n",
! 							 dstring_data(&query_pertbl), PQresultErrorMessage(res2));
  
  					/*
  					 * slon_retry(); break;
  					 */
+ 				} else {
+ 					if (vrc == PGRES_NONFATAL_ERROR) {
+ 						slon_log(SLON_WARN,
+ 								 "cleanupThread: \"%s\" - %s\n",
+ 								 dstring_data(&query_pertbl), PQresultErrorMessage(res2));
+ 						
+ 					}
  				}
  				PQclear(res2);

Index: confoptions.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/confoptions.c,v
retrieving revision 1.30
retrieving revision 1.31
diff -C2 -d -r1.30 -r1.31
*** confoptions.c	1 Apr 2009 17:11:52 -0000	1.30
--- confoptions.c	11 Jun 2009 19:03:45 -0000	1.31
***************
*** 47,51 ****
  	{
  		slon_log(SLON_CONFIG, "main: String option %s = %s\n",
! 				 ConfigureNamesString[i].gen.name, *(ConfigureNamesString[i].variable));
  	}
  
--- 47,51 ----
  	{
  		slon_log(SLON_CONFIG, "main: String option %s = %s\n",
! 				 ConfigureNamesString[i].gen.name, ((*ConfigureNamesString[i].variable)==NULL)?"[NULL]":*(ConfigureNamesString[i].variable));
  	}
  
***************
*** 755,759 ****
  			(const char *) "cleanup_deletelogs",
  			gettext_noop("Should the cleanup thread DELETE sl_log_? entries or not"),
! 			gettext_noop("Should the cleanup thread DELETE sl_log_? entries or not"),
  			SLON_C_BOOL
  		},
--- 755,759 ----
  			(const char *) "cleanup_deletelogs",
  			gettext_noop("Should the cleanup thread DELETE sl_log_? entries or not"),
! 			gettext_noop("Should the cleanup thread DELETE sl_log_? entries or leave trimming to the TRUNCATE"),
  			SLON_C_BOOL
  		},


From cbbrowne at lists.slony.info  Thu Jun 11 12:03:47 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jun 11 12:03:50 2009
Subject: [Slony1-commit] slony1-engine/src/backend slony1_base.sql
	slony1_funcs.c slony1_funcs.sql
Message-ID: <20090611190347.555DE290BD3@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/backend
In directory main.slony.info:/tmp/cvs-serv5001/src/backend

Modified Files:
	slony1_base.sql slony1_funcs.c slony1_funcs.sql 
Log Message:
Draw a whole pile of changes into HEAD from the 2.0 branch



Index: slony1_base.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/backend/slony1_base.sql,v
retrieving revision 1.40
retrieving revision 1.41
diff -C2 -d -r1.40 -r1.41
*** slony1_base.sql	17 Nov 2008 22:40:27 -0000	1.40
--- slony1_base.sql	11 Jun 2009 19:03:44 -0000	1.41
***************
*** 68,72 ****
  comment on column @NAMESPACE@.sl_set.set_origin is 
  	'The ID number of the source node for the replication set.';
! comment on column @NAMESPACE@.sl_set.set_locked is 'Indicates whether or not the set is locked.';
  comment on column @NAMESPACE@.sl_set.set_comment is 'A human-oriented description of the set.';
  
--- 68,72 ----
  comment on column @NAMESPACE@.sl_set.set_origin is 
  	'The ID number of the source node for the replication set.';
! comment on column @NAMESPACE@.sl_set.set_locked is 'Transaction ID where the set was locked.';
  comment on column @NAMESPACE@.sl_set.set_comment is 'A human-oriented description of the set.';
  

Index: slony1_funcs.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/backend/slony1_funcs.sql,v
retrieving revision 1.148
retrieving revision 1.149
diff -C2 -d -r1.148 -r1.149
*** slony1_funcs.sql	16 Jan 2009 22:59:36 -0000	1.148
--- slony1_funcs.sql	11 Jun 2009 19:03:44 -0000	1.149
***************
*** 199,202 ****
--- 199,228 ----
  select @NAMESPACE@.checkmoduleversion();
  
+ -----------------------------------------------------------------------
+ -- This function checks to see if the namespace name is valid.  
+ --
+ -- Apparently pgAdminIII does different validation than Slonik, and so
+ -- users that set up cluster names using pgAdminIII can get in trouble in
+ -- that they do not get around to needing Slonik until it is too
+ -- late...
+ -----------------------------------------------------------------------
+ 
+ create or replace function @NAMESPACE@.check_namespace_validity () returns boolean as $$
+ declare
+ 	c_cluster text;
+ begin
+ 	c_cluster := '@CLUSTERNAME@';
+ 	if c_cluster !~ E'^[[:alpha:]_][[:alnum:]_\$]{0,62}$' then
+ 		raise exception 'Cluster name % is not a valid SQL symbol!', c_cluster;
+ 	else
+ 		raise notice 'checked validity of cluster % namespace - OK!', c_cluster;
+ 	end if;
+ 	return 't';
+ end
+ $$ language plpgsql;
+ 
+ select @NAMESPACE@.check_namespace_validity();
+ drop function @NAMESPACE@.check_namespace_validity();
+ 
  -- ----------------------------------------------------------------------
  -- FUNCTION logTrigger ()
***************
*** 408,412 ****
  as $$
  begin
! 	return 0;
  end;
  $$ language plpgsql;
--- 434,438 ----
  as $$
  begin
! 	return 2;
  end;
  $$ language plpgsql;
***************
*** 5033,5036 ****
--- 5059,5063 ----
          v_no_id                 int4;
          v_set_origin            int4;
+ 	prec			record;
  begin
          -- ----
***************
*** 5066,5069 ****
--- 5093,5104 ----
                  return 0;
          end if;
+ 
+ 	-- Update OIDs for tables to values pulled from non-table objects in pg_class
+ 	-- This ensures that we won't have collisions when repairing the oids
+ 	for prec in select tab_id from @NAMESPACE@.sl_table loop
+ 		update @NAMESPACE@.sl_table set tab_reloid = (select oid from pg_class pc where relkind <> 'r' and not exists (select 1 from @NAMESPACE@.sl_table t2 where t2.tab_reloid = pc.oid) limit 1)
+ 		where tab_id = prec.tab_id;
+ 	end loop;
+ 
          update @NAMESPACE@.sl_table set
                  tab_reloid = PGC.oid
***************
*** 5073,5076 ****
--- 5108,5116 ----
  			and @NAMESPACE@.slon_quote_brute(PGN.nspname) = @NAMESPACE@.slon_quote_brute(@NAMESPACE@.sl_table.tab_nspname);
  
+ 	for prec in select seq_id from @NAMESPACE@.sl_sequence loop
+ 		update @NAMESPACE@.sl_sequence set seq_reloid = (select oid from pg_class pc where relkind <> 'S' and not exists (select 1 from @NAMESPACE@.sl_sequence t2 where t2.tab_reloid = pc.oid) limit 1)
+ 		where tab_id = prec.seq_id;
+ 	end loop;
+ 
          update @NAMESPACE@.sl_sequence set
                  seq_reloid = PGC.oid
***************
*** 5390,5452 ****
  		v_tab_row	record;
  begin
! 	-- ----
! 	-- Changes for 2.0
! 	-- ----
! 	if p_old IN ('1.0.2', '1.0.5', '1.0.6',
! 			'1.1.0', '1.1.1', '1.1.2', '1.1.3', '1.1.5', '1.1.6', '1.1.7', '1.1.8', '1.1.9') then
! 		raise exception 'Upgrading to Slony-I 2.x requires running 1.2.x';
! 	end if;
! 
! 	if p_old IN ('1.2.0', '1.2.1', '1.2.2', '1.2.3', '1.2.4', '1.2.5', '1.2.6', '1.2.7', '1.2.8', '1.2.9', '1.2.10', '1.2.11', '1.2.12', '1.2.13', '1.2.14', '1.2.15', '1.2.16') then
! 		-- ---- 
! 		-- Upgrading from a pre-2.0 ... repair the system catalog
! 		-- ----
! 		for v_tab_row in select * from @NAMESPACE@.sl_table order by tab_id loop
! 			perform @NAMESPACE@.alterTableRestore(v_tab_row.tab_id);
! 		end loop;
! 
! 		-- ----
! 		-- drop obsolete functions
! 		-- ----
! 		execute 'drop function @NAMESPACE@.alterTableForReplication(int4)';
! 		execute 'drop function @NAMESPACE@.pre74()';
! 
! 		-- ----
! 		-- and create the new versions of the log and deny access triggers.
! 		-- ----
! 		for v_tab_row in select * from @NAMESPACE@.sl_table order by tab_id loop
! 			perform @NAMESPACE@.alterTableAddTriggers(v_tab_row.tab_id);
! 			perform @NAMESPACE@.alterTableConfigureTriggers(v_tab_row.tab_id);
! 		end loop;
! 
! 		-- ----
! 		-- Drop no_spool from sl_node
! 		-- ----
! 		execute 'alter table @NAMESPACE@.sl_node drop column no_spool;';
! 
! 		-- ----
! 		-- Drop sl_trigger
! 		-- ----
! 		execute 'drop table @NAMESPACE@.sl_trigger;';
! 
! 		execute 'alter table @NAMESPACE@.sl_event add column ev_snapshot "pg_catalog".txid_snapshot;';
! 		execute 'alter table @NAMESPACE@.sl_set_sync add column ev_snapshot "pg_catalog".txid_snapshot;';
! 	end if;
! 
! 	-- ----
! 	-- The following is already in 1.2.11, do not add any future
! 	-- 1.2 version numbers.
! 	-- ----
! 	if p_old IN ('1.2.0', '1.2.1', '1.2.2', '1.2.3', '1.2.4', '1.2.5', '1.2.6', '1.2.7', '1.2.8', '1.2.9', '1.2.10') then
! 		-- ----
! 		-- Add new table sl_archive_counter
! 		-- ----
! 		execute 'create table @NAMESPACE@.sl_archive_counter (
! 					ac_num			bigint,
! 					ac_timestamp	timestamp
! 				) without oids';
! 		execute 'insert into @NAMESPACE@.sl_archive_counter
! 				(ac_num, ac_timestamp) values (0, ' || pg_catalog.quote_literal('epoch') || '::timestamp)';
! 
  	end if;
  
--- 5430,5436 ----
  		v_tab_row	record;
  begin
! 	-- If old version is pre-2.0, then we require a special upgrade process
! 	if p_old like '1.%' then
! 		raise exception 'Upgrading to Slony-I 2.x requires running slony_upgrade_20';
  	end if;
  
***************
*** 5864,5865 ****
--- 5848,5850 ----
  tab_idxname is optional - if NULL, then we use the primary key.
  This function looks up replication configuration via the parent table.';
+ 

From cbbrowne at lists.slony.info  Thu Jun 11 12:03:47 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jun 11 12:03:53 2009
Subject: [Slony1-commit] slony1-engine/tools/altperl slon-tools.pm
	slon_watchdog.pl slonik_drop_sequence.pl slonik_merge_sets.pl
Message-ID: <20090611190348.65B51290C1C@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tools/altperl
In directory main.slony.info:/tmp/cvs-serv5001/tools/altperl

Modified Files:
	slon-tools.pm slon_watchdog.pl slonik_drop_sequence.pl 
	slonik_merge_sets.pl 
Log Message:
Draw a whole pile of changes into HEAD from the 2.0 branch


Index: slon-tools.pm
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tools/altperl/slon-tools.pm,v
retrieving revision 1.34
retrieving revision 1.35
diff -C2 -d -r1.34 -r1.35
*** slon-tools.pm	21 Jan 2009 15:55:25 -0000	1.34
--- slon-tools.pm	11 Jun 2009 19:03:45 -0000	1.35
***************
*** 133,137 ****
    my ($dsn, $dbname) = ($DSN[$nodenum], $DBNAME[$nodenum]);
    $SYNC_CHECK_INTERVAL ||= 1000;
!   $DEBUG_INTERVAL ||= 0;
    system("mkdir -p $LOGDIR/slony1/node$nodenum");
    my $cmd = "@@SLONBINDIR@@/slon -s $SYNC_CHECK_INTERVAL -d$DEBUGLEVEL $CLUSTER_NAME '$dsn' ";
--- 133,137 ----
    my ($dsn, $dbname) = ($DSN[$nodenum], $DBNAME[$nodenum]);
    $SYNC_CHECK_INTERVAL ||= 1000;
!   $DEBUGLEVEL ||= 0;
    system("mkdir -p $LOGDIR/slony1/node$nodenum");
    my $cmd = "@@SLONBINDIR@@/slon -s $SYNC_CHECK_INTERVAL -d$DEBUGLEVEL $CLUSTER_NAME '$dsn' ";

Index: slonik_drop_sequence.pl
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tools/altperl/slonik_drop_sequence.pl,v
retrieving revision 1.1
retrieving revision 1.2
diff -C2 -d -r1.1 -r1.2
*** slonik_drop_sequence.pl	12 Mar 2008 16:33:29 -0000	1.1
--- slonik_drop_sequence.pl	11 Jun 2009 19:03:45 -0000	1.2
***************
*** 34,38 ****
  }
  
! require '@@PGLIBDIR@@/slon-tools.pm';
  require $CONFIG_FILE;
  
--- 34,38 ----
  }
  
! require '@@PERLSHAREDIR@@/slon-tools.pm';
  require $CONFIG_FILE;
  



From cbbrowne at lists.slony.info  Thu Jun 11 12:03:46 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jun 11 12:03:53 2009
Subject: [Slony1-commit] slony1-engine RELEASE RELEASE-2.0 config.h.in
	configure
Message-ID: <20090611190348.7B869290C1E@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine
In directory main.slony.info:/tmp/cvs-serv5001

Modified Files:
	RELEASE RELEASE-2.0 config.h.in configure 
Log Message:
Draw a whole pile of changes into HEAD from the 2.0 branch


Index: RELEASE
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/RELEASE,v
retrieving revision 1.3
retrieving revision 1.4
diff -C2 -d -r1.3 -r1.4
*** RELEASE	24 Nov 2008 14:50:22 -0000	1.3
--- RELEASE	11 Jun 2009 19:03:44 -0000	1.4
***************
*** 5,6 ****
--- 5,23 ----
  The first release of version 2.0. See RELEASE-2.0 to see changes leading
  from version 1.2 to 2.0.
+ 
+ RELEASE 2.0.1
+ 
+ - Bug #69 - vactables type was being referenced before UPGRADE FUNCTIONS could actually have created it, when upgrading from an earlier version.
+ 
+   This would cause UPGRADE FUNCTIONS to fail.
+ 
+ - Bug #64 - use of syslog levels had some inappropriate break statements so that some logging would get lost.
+ 
+ - If you had multiple clusters where one cluster name was a substring of the other, slon-tools.pm could find
+   both when looking for slon processes relevant to the shorter cluster name.  Added a space to the relevant
+   bit of slon-tools.pm
+ 
+ - Failover had an insert into sl_event where # of columns provided didn't match those expected.  This
+   resulted from the change of snapshot handling which used to involve 3 columns where in 8.3+, there is
+   now a snapshot type.
+ 

Index: RELEASE-2.0
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/RELEASE-2.0,v
retrieving revision 1.24
retrieving revision 1.25
diff -C2 -d -r1.24 -r1.25
*** RELEASE-2.0	17 Nov 2008 22:47:45 -0000	1.24
--- RELEASE-2.0	11 Jun 2009 19:03:44 -0000	1.25
***************
*** 222,223 ****
--- 222,229 ----
  - Enhancement - bug #61 - logshipper process should rescan the queue
    when it empties
+ 
+ - Note about "duct tape" tests:  There are many of these tests that
+   reside in src/ducttape that reference features removed in v2.0.
+ 
+   We will eventually be replacing these with a more proper "test suite"
+   so we're not remedying all the ducttape tests.

Index: config.h.in
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/config.h.in,v
retrieving revision 1.21
retrieving revision 1.22
diff -C2 -d -r1.21 -r1.22
*** config.h.in	24 Sep 2008 19:54:09 -0000	1.21
--- config.h.in	11 Jun 2009 19:03:44 -0000	1.22
***************
*** 13,18 ****
  #define SLONY_I_CONFIG_H
  
! #define SLONY_I_VERSION_STRING	"2.0.0"
! #define SLONY_I_VERSION_STRING_DEC 2,0,0
  
  #ifndef PG_VERSION_MAJOR
--- 13,18 ----
  #define SLONY_I_CONFIG_H
  
! #define SLONY_I_VERSION_STRING	"2.0.2"
! #define SLONY_I_VERSION_STRING_DEC 2,0,2
  
  #ifndef PG_VERSION_MAJOR
***************
*** 20,24 ****
  #endif
  #ifndef PG_VERSION_MINOR
! #define PG_VERSION_MINOR 0
  #endif
  
--- 20,24 ----
  #endif
  #ifndef PG_VERSION_MINOR
! #define PG_VERSION_MINOR 2
  #endif
  

Index: configure
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/configure,v
retrieving revision 1.75
retrieving revision 1.76
diff -C2 -d -r1.75 -r1.76
*** configure	24 Sep 2008 21:15:41 -0000	1.75
--- configure	11 Jun 2009 19:03:44 -0000	1.76
***************
*** 1,8 ****
  #! /bin/sh
  # Guess values for system-dependent variables and create Makefiles.
! # Generated by GNU Autoconf 2.61 for slony1 HEAD_20080924.
  #
  # Copyright (C) 1992, 1993, 1994, 1995, 1996, 1998, 1999, 2000, 2001,
! # 2002, 2003, 2004, 2005, 2006 Free Software Foundation, Inc.
  # This configure script is free software; the Free Software Foundation
  # gives unlimited permission to copy, distribute and modify it.
--- 1,8 ----
  #! /bin/sh
[...14601 lines suppressed...]
--- 12414,12422 ----
  ac_clean_files=$ac_clean_files_save
  
+ test $ac_write_fail = 0 ||
+   { { $as_echo "$as_me:$LINENO: error: write failure creating $CONFIG_STATUS" >&5
+ $as_echo "$as_me: error: write failure creating $CONFIG_STATUS" >&2;}
+    { (exit 1); exit 1; }; }
+ 
  
  # configure is writing to config.log, and then calls config.status.
***************
*** 12027,12029 ****
--- 12440,12446 ----
    $ac_cs_success || { (exit 1); exit 1; }
  fi
+ if test -n "$ac_unrecognized_opts" && test "$enable_option_checking" != no; then
+   { $as_echo "$as_me:$LINENO: WARNING: unrecognized options: $ac_unrecognized_opts" >&5
+ $as_echo "$as_me: WARNING: unrecognized options: $ac_unrecognized_opts" >&2;}
+ fi
  

From cbbrowne at lists.slony.info  Thu Jun 11 12:03:47 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jun 11 12:03:53 2009
Subject: [Slony1-commit] slony1-engine/tests run_test.sh
Message-ID: <20090611190347.3AABB29044C@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tests
In directory main.slony.info:/tmp/cvs-serv5001/tests

Modified Files:
	run_test.sh 
Log Message:
Draw a whole pile of changes into HEAD from the 2.0 branch


Index: run_test.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/run_test.sh,v
retrieving revision 1.27
retrieving revision 1.28
diff -C2 -d -r1.27 -r1.28
*** run_test.sh	5 Jan 2009 22:05:09 -0000	1.27
--- run_test.sh	11 Jun 2009 19:03:45 -0000	1.28
***************
*** 628,644 ****
  }      
  
! wait_for_catchup()
! {
!   node=1
!   status "waiting for nodes to catch up"
  
!   poll_cluster
  
!   sleep 20
  
!   poll_cluster
!   status "done"
! }
  
  diff_db()
  {
--- 628,654 ----
  }      
  
! # wait_for_catchup()
! # {
! #   node=1
! #   status "waiting for nodes to catch up"
  
! #   poll_cluster
  
! #   sleep 20
  
! #   poll_cluster
! #   status "done"
! # }
  
+ wait_for_catchup ()
+ {
+     eval onode=${ORIGINNODE:-"1"}
+     status "submit SYNC to node ${onode}, wait for event to propagate to all nodes..."
+     echo "include <${mktmp}/slonik.preamble>;" > $mktmp/wait-for-propagation.slonik
+     echo "sync (ID=${onode});" >> $mktmp/wait-for-propagation.slonik
+     echo "wait for event (origin=${onode},confirmed=ALL,wait on=${onode});" >> $mktmp/wait-for-propagation.slonik
+     $pgbindir/slonik < $mktmp/wait-for-propagation.slonik > $mktmp/wait-for-propagation.log 2>&1
+     status "...event propagated to all nodes"
+ }
  diff_db()
  {

From cbbrowne at lists.slony.info  Thu Jun 11 12:03:47 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jun 11 12:03:54 2009
Subject: [Slony1-commit] slony1-engine/tools release_checklist.sh
	slony-cluster-analysis-mass.sh slony-cluster-analysis.sh
	start_slon.sh
Message-ID: <20090611190348.64CF0290C1A@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tools
In directory main.slony.info:/tmp/cvs-serv5001/tools

Modified Files:
	release_checklist.sh slony-cluster-analysis-mass.sh 
	slony-cluster-analysis.sh start_slon.sh 
Log Message:
Draw a whole pile of changes into HEAD from the 2.0 branch



Index: release_checklist.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tools/release_checklist.sh,v
retrieving revision 1.4
retrieving revision 1.5
diff -C2 -d -r1.4 -r1.5
*** release_checklist.sh	7 Jul 2008 21:16:03 -0000	1.4
--- release_checklist.sh	11 Jun 2009 19:03:45 -0000	1.5
***************
*** 33,38 ****
  fi
  
! if egrep "^PACKAGE_STRING='postgresql-slony1-engine ${VERDOTTED}'\$" configure >/dev/null 2>&1; then
!    echo "PACKAGE_STRING in configure matches ${VERDOTTED}"
  else
     echo "ERROR: configure PACKAGE_STRING does not match ${VERDOTTED}"
--- 33,38 ----
  fi
  
! if egrep "^PACKAGE_STRING='slony1 ${VERDOTTED}'\$" configure >/dev/null 2>&1; then
!    echo "PACKAGE_STRING in configure matches slony1 ${VERDOTTED}"
  else
     echo "ERROR: configure PACKAGE_STRING does not match ${VERDOTTED}"

Index: start_slon.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tools/start_slon.sh,v
retrieving revision 1.2
retrieving revision 1.3
diff -C2 -d -r1.2 -r1.3
*** start_slon.sh	1 Aug 2008 19:33:24 -0000	1.2
--- start_slon.sh	11 Jun 2009 19:03:45 -0000	1.3
***************
*** 35,40 ****
  	touch $SLON_LOG
  	test -w "$SLON_LOG" || (echo "**** SLON_LOG not writable - $SLON_LOG ****"; exit 1)
!         echo "Starting slon: $SLON_BIN_PATH/slon -f ${SLON_CONF} 1>> ${SLON_LOG} 2>>1" &
! 	$SLON_BIN_PATH/slon -f ${SLON_CONF} 1>> ${SLON_LOG} 2>>1 &
          ;;
    stop)
--- 35,40 ----
  	touch $SLON_LOG
  	test -w "$SLON_LOG" || (echo "**** SLON_LOG not writable - $SLON_LOG ****"; exit 1)
!         echo "Starting slon: $SLON_BIN_PATH/slon -f ${SLON_CONF} 1>> ${SLON_LOG} 2>&1 &"
! 	$SLON_BIN_PATH/slon -f ${SLON_CONF} 1>> ${SLON_LOG} 2>&1 &
          ;;
    stop)


From cbbrowne at lists.slony.info  Thu Jun 11 12:03:47 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jun 11 12:03:54 2009
Subject: [Slony1-commit] slony1-engine/tests/testseqnames README
	generate_dml.sh init_add_tables.ik init_schema.sql
Message-ID: <20090611190349.1CF09290C2D@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tests/testseqnames
In directory main.slony.info:/tmp/cvs-serv5001/tests/testseqnames

Modified Files:
	README generate_dml.sh init_add_tables.ik init_schema.sql 
Log Message:
Draw a whole pile of changes into HEAD from the 2.0 branch


Index: README
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testseqnames/README,v
retrieving revision 1.1
retrieving revision 1.2
diff -C2 -d -r1.1 -r1.2
*** README	15 Nov 2005 21:25:34 -0000	1.1
--- README	11 Jun 2009 19:03:45 -0000	1.2
***************
*** 3,4 ****
--- 3,8 ----
  This test involves creating some sequences with wacky names involving
  StudlyCaps, spaces, and ".".
+ 
+ It also creates a Large Number of sequences, to validate that
+ we don't break down with either large quantities of them, or
+ if the IDs are large numbers

Index: generate_dml.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testseqnames/generate_dml.sh,v
retrieving revision 1.5
retrieving revision 1.6
diff -C2 -d -r1.5 -r1.6
*** generate_dml.sh	2 Apr 2007 18:52:19 -0000	1.5
--- generate_dml.sh	11 Jun 2009 19:03:45 -0000	1.6
***************
*** 25,29 ****
    GENDATA="$mktmp/generate.data"
    echo "" > ${GENDATA}
!   numrows=$(random_number 50 1000)
    i=0;
    trippoint=`expr $numrows / 20`
--- 25,29 ----
    GENDATA="$mktmp/generate.data"
    echo "" > ${GENDATA}
!   numrows=$(random_number 25 35)
    i=0;
    trippoint=`expr $numrows / 20`
***************
*** 45,48 ****
--- 45,57 ----
      echo "select nextval('\"Schema.name\".\"a.periodic.sequence\"');" >> $GENDATA
      echo "select nextval('\"Studly Spacey Schema\".\"user\"');" >> $GENDATA
+     for d4 in 8 3 9 0 6 7 1 4 5 2; do
+ 	for d2 in 0 2 1 3 9 5 6 4 8 7; do
+ 	    for d1 in 0 1; do
+ 		for d3 in 5 2 1 6 4 8 3 9 0 7 ; do
+ 		    echo "select nextval('public.seq40${d1}${d2}${d3}${d4}');" >> $GENDATA
+ 		done
+ 	    done
+ 	done
+     done
      if [ ${i} -ge ${numrows} ]; then
        break;
***************
*** 62,72 ****
  do_initdata()
  {
!    originnode=${ORIGINNODE:-"1"}
    eval db=\$DB${originnode}
!    eval host=\$HOST${originnode}
    eval user=\$USER${originnode}
    eval port=\$PORT${originnode}
    generate_initdata
-   launch_poll
    status "loading data"
    $pgbindir/psql -h $host -p $port -d $db -U $user < $mktmp/generate.data 1> $mktmp/initdata.log 2> $mktmp/initdata.log
--- 71,80 ----
  do_initdata()
  {
!   originnode=${ORIGINNODE:-"1"}
    eval db=\$DB${originnode}
!   eval host=\$HOST${originnode}
    eval user=\$USER${originnode}
    eval port=\$PORT${originnode}
    generate_initdata
    status "loading data"
    $pgbindir/psql -h $host -p $port -d $db -U $user < $mktmp/generate.data 1> $mktmp/initdata.log 2> $mktmp/initdata.log
***************
*** 74,77 ****
--- 82,86 ----
      warn 3 "do_initdata failed, see $mktmp/initdata.log for details"
    fi 
+   wait_for_catchup
    status "done"
  }

Index: init_add_tables.ik
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testseqnames/init_add_tables.ik,v
retrieving revision 1.2
retrieving revision 1.3
diff -C2 -d -r1.2 -r1.3
*** init_add_tables.ik	18 Apr 2007 19:26:54 -0000	1.2
--- init_add_tables.ik	11 Jun 2009 19:03:45 -0000	1.3
***************
*** 7,8 ****
--- 7,2009 ----
  
  set add sequence (set id = 1, origin = 1, id = 3, fully qualified name = '"Schema.name"."a.periodic.sequence"');
+ set add sequence (set id = 1, origin = 1, id = 23400000, fully qualified name = 'public.seq400000');
+ set add sequence (set id = 1, origin = 1, id = 23400001, fully qualified name = 'public.seq400001');
+ set add sequence (set id = 1, origin = 1, id = 23400002, fully qualified name = 'public.seq400002');
+ set add sequence (set id = 1, origin = 1, id = 23400003, fully qualified name = 'public.seq400003');
+ set add sequence (set id = 1, origin = 1, id = 23400004, fully qualified name = 'public.seq400004');
+ set add sequence (set id = 1, origin = 1, id = 23400005, fully qualified name = 'public.seq400005');
+ set add sequence (set id = 1, origin = 1, id = 23400006, fully qualified name = 'public.seq400006');
[...1974 lines suppressed...]
+ set add sequence (set id = 1, origin = 1, id = 23401981, fully qualified name = 'public.seq401981');
+ set add sequence (set id = 1, origin = 1, id = 23401982, fully qualified name = 'public.seq401982');
+ set add sequence (set id = 1, origin = 1, id = 23401983, fully qualified name = 'public.seq401983');
+ set add sequence (set id = 1, origin = 1, id = 23401984, fully qualified name = 'public.seq401984');
+ set add sequence (set id = 1, origin = 1, id = 23401985, fully qualified name = 'public.seq401985');
+ set add sequence (set id = 1, origin = 1, id = 23401986, fully qualified name = 'public.seq401986');
+ set add sequence (set id = 1, origin = 1, id = 23401987, fully qualified name = 'public.seq401987');
+ set add sequence (set id = 1, origin = 1, id = 23401988, fully qualified name = 'public.seq401988');
+ set add sequence (set id = 1, origin = 1, id = 23401989, fully qualified name = 'public.seq401989');
+ set add sequence (set id = 1, origin = 1, id = 23401990, fully qualified name = 'public.seq401990');
+ set add sequence (set id = 1, origin = 1, id = 23401991, fully qualified name = 'public.seq401991');
+ set add sequence (set id = 1, origin = 1, id = 23401992, fully qualified name = 'public.seq401992');
+ set add sequence (set id = 1, origin = 1, id = 23401993, fully qualified name = 'public.seq401993');
+ set add sequence (set id = 1, origin = 1, id = 23401994, fully qualified name = 'public.seq401994');
+ set add sequence (set id = 1, origin = 1, id = 23401995, fully qualified name = 'public.seq401995');
+ set add sequence (set id = 1, origin = 1, id = 23401996, fully qualified name = 'public.seq401996');
+ set add sequence (set id = 1, origin = 1, id = 23401997, fully qualified name = 'public.seq401997');
+ set add sequence (set id = 1, origin = 1, id = 23401998, fully qualified name = 'public.seq401998');
+ set add sequence (set id = 1, origin = 1, id = 23401999, fully qualified name = 'public.seq401999');
+ set add sequence (set id = 1, origin = 1, id = 23402000, fully qualified name = 'public.seq402000');

Index: init_schema.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testseqnames/init_schema.sql,v
retrieving revision 1.2
retrieving revision 1.3
diff -C2 -d -r1.2 -r1.3
*** init_schema.sql	18 Apr 2007 19:26:54 -0000	1.2
--- init_schema.sql	11 Jun 2009 19:03:45 -0000	1.3
***************
*** 27,28 ****
--- 27,2029 ----
  create sequence "Studly Spacey Schema"."user";
  create sequence "Schema.name"."a.periodic.sequence";
+ create sequence public.seq400000;
+ create sequence public.seq400001;
+ create sequence public.seq400002;
+ create sequence public.seq400003;
+ create sequence public.seq400004;
+ create sequence public.seq400005;
+ create sequence public.seq400006;
[...1974 lines suppressed...]
+ create sequence public.seq401981;
+ create sequence public.seq401982;
+ create sequence public.seq401983;
+ create sequence public.seq401984;
+ create sequence public.seq401985;
+ create sequence public.seq401986;
+ create sequence public.seq401987;
+ create sequence public.seq401988;
+ create sequence public.seq401989;
+ create sequence public.seq401990;
+ create sequence public.seq401991;
+ create sequence public.seq401992;
+ create sequence public.seq401993;
+ create sequence public.seq401994;
+ create sequence public.seq401995;
+ create sequence public.seq401996;
+ create sequence public.seq401997;
+ create sequence public.seq401998;
+ create sequence public.seq401999;
+ create sequence public.seq402000;

From cbbrowne at lists.slony.info  Thu Jun 11 12:03:47 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jun 11 12:03:54 2009
Subject: [Slony1-commit] slony1-engine/tests/testschemanames README
	gen_weak_user.sh generate_dml.sh init_add_tables.ik
	init_data.sql init_schema.sql schema.diff
Message-ID: <20090611190349.404E3290BEA@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tests/testschemanames
In directory main.slony.info:/tmp/cvs-serv5001/tests/testschemanames

Modified Files:
	README gen_weak_user.sh generate_dml.sh init_add_tables.ik 
	init_data.sql init_schema.sql schema.diff 
Log Message:
Draw a whole pile of changes into HEAD from the 2.0 branch


Index: init_add_tables.ik
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testschemanames/init_add_tables.ik,v
retrieving revision 1.2
retrieving revision 1.3
diff -C2 -d -r1.2 -r1.3
*** init_add_tables.ik	18 Apr 2007 19:26:54 -0000	1.2
--- init_add_tables.ik	11 Jun 2009 19:03:45 -0000	1.3
***************
*** 1,5 ****
! set add table (id=1, set id=1, origin=1, fully qualified name = 'public.table1', comment='accounts table');
! set add table (id=2, set id=1, origin=1, fully qualified name = 'public.table2', key='table2_id_key');
! set add table (id=3, set id=1, origin=1, fully qualified name = 'public.table3');
  
  set add table (set id = 1, origin = 1, id = 6, fully qualified name =
--- 1,5 ----
! set add table (id=1, set id=1, origin=1, fully qualified name = 'foo.table1', comment='accounts table');
! set add table (id=2, set id=1, origin=1, fully qualified name = 'foo.table2', key='table2_id_key');
! set add table (id=3, set id=1, origin=1, fully qualified name = 'foo.table3');
  
  set add table (set id = 1, origin = 1, id = 6, fully qualified name =

Index: gen_weak_user.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testschemanames/gen_weak_user.sh,v
retrieving revision 1.1
retrieving revision 1.2
diff -C2 -d -r1.1 -r1.2
*** gen_weak_user.sh	1 Mar 2007 21:02:32 -0000	1.1
--- gen_weak_user.sh	11 Jun 2009 19:03:45 -0000	1.2
***************
*** 1,7 ****
  weakuser=$1;
  
  for i in 1 2 3; do
!    echo "grant select on table public.table${i} to ${weakuser};"
!    echo "grant select on table public.table${i}_id_seq to ${weakuser};"
  done
  
--- 1,8 ----
  weakuser=$1;
+ echo "grant usage on schema \"foo\" to ${weakuser};"
  
  for i in 1 2 3; do
!    echo "grant select on table foo.table${i} to ${weakuser};"
!    echo "grant select on table foo.table${i}_id_seq to ${weakuser};"
  done
  

Index: generate_dml.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testschemanames/generate_dml.sh,v
retrieving revision 1.5
retrieving revision 1.6
diff -C2 -d -r1.5 -r1.6
*** generate_dml.sh	2 Apr 2007 18:52:19 -0000	1.5
--- generate_dml.sh	11 Jun 2009 19:03:45 -0000	1.6
***************
*** 40,46 ****
      txtb=$(random_string ${txtblen})
      txtb=`echo ${txtb} | sed -e "s/\\\\\\\/\\\\\\\\\\\\\\/g" -e "s/'/''/g"`
!     echo "INSERT INTO table1(data) VALUES ('${txta}');" >> $GENDATA
!     echo "INSERT INTO table2(table1_id,data) SELECT id, '${txtb}' FROM table1 WHERE data='${txta}';" >> $GENDATA
!     echo "INSERT INTO table3(table2_id) SELECT id FROM table2 WHERE data ='${txtb}';" >> $GENDATA
      echo "INSERT INTO \"Schema.name\".\"Capital Idea\" (\"user\", description) values ('${txta}', '${txtb}');" >> $GENDATA
      echo "INSERT INTO \"Schema.name\".\"user\" (\"user\", id) values ('${txtb}', $txtblen);" >> $GENDATA
--- 40,46 ----
      txtb=$(random_string ${txtblen})
      txtb=`echo ${txtb} | sed -e "s/\\\\\\\/\\\\\\\\\\\\\\/g" -e "s/'/''/g"`
!     echo "INSERT INTO foo.table1(data) VALUES ('${txta}');" >> $GENDATA
!     echo "INSERT INTO foo.table2(table1_id,data) SELECT id, '${txtb}' FROM table1 WHERE data='${txta}';" >> $GENDATA
!     echo "INSERT INTO foo.table3(table2_id) SELECT id FROM table2 WHERE data ='${txtb}';" >> $GENDATA
      echo "INSERT INTO \"Schema.name\".\"Capital Idea\" (\"user\", description) values ('${txta}', '${txtb}');" >> $GENDATA
      echo "INSERT INTO \"Schema.name\".\"user\" (\"user\", id) values ('${txtb}', $txtblen);" >> $GENDATA

Index: init_data.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testschemanames/init_data.sql,v
retrieving revision 1.1
retrieving revision 1.2
diff -C2 -d -r1.1 -r1.2
*** init_data.sql	15 Nov 2005 21:25:34 -0000	1.1
--- init_data.sql	11 Jun 2009 19:03:45 -0000	1.2
***************
*** 1,3 ****
! INSERT INTO table1(data) VALUES ('placeholder 1');
! INSERT INTO table2(table1_id,data) VALUES (1,'placeholder 1');
! INSERT INTO table3(table2_id) VALUES (1);
--- 1,4 ----
! set search_path to foo;
! INSERT INTO foo.table1(data) VALUES ('placeholder 1');
! INSERT INTO foo.table2(table1_id,data) VALUES (1,'placeholder 1');
! INSERT INTO foo.table3(table2_id) VALUES (1);

Index: init_schema.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testschemanames/init_schema.sql,v
retrieving revision 1.2
retrieving revision 1.3
diff -C2 -d -r1.2 -r1.3
*** init_schema.sql	18 Apr 2007 19:26:54 -0000	1.2
--- init_schema.sql	11 Jun 2009 19:03:45 -0000	1.3
***************
*** 1,8 ****
! CREATE TABLE table1(
    id		SERIAL		PRIMARY KEY, 
    data		TEXT
  );
  
! CREATE TABLE table2(
    id		SERIAL		UNIQUE NOT NULL, 
    table1_id	INT4		REFERENCES table1(id) 
--- 1,11 ----
! create schema foo;
! set search_path to foo;
! drop schema public;
! CREATE TABLE foo.table1(
    id		SERIAL		PRIMARY KEY, 
    data		TEXT
  );
  
! CREATE TABLE foo.table2(
    id		SERIAL		UNIQUE NOT NULL, 
    table1_id	INT4		REFERENCES table1(id) 
***************
*** 11,15 ****
  );
  
! CREATE TABLE table3(
    id		SERIAL,
    table2_id	INT4		REFERENCES table2(id)
--- 14,18 ----
  );
  
! CREATE TABLE foo.table3(
    id		SERIAL,
    table2_id	INT4		REFERENCES table2(id)

Index: schema.diff
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testschemanames/schema.diff,v
retrieving revision 1.1
retrieving revision 1.2
diff -C2 -d -r1.1 -r1.2
*** schema.diff	15 Nov 2005 21:25:34 -0000	1.1
--- schema.diff	11 Jun 2009 19:03:45 -0000	1.2
***************
*** 1,7 ****
! SELECT id,data FROM table1 ORDER BY id
! SELECT id,table1_id,data FROM table2 ORDER BY id
! SELECT id,table2_id,mod_date, data FROM table3 ORDER BY id
  SELECT id, "user" from "Schema.name"."user" order by id
  SELECT "user", description from "Schema.name"."Capital Idea" order by "user"
  select last_value from "Studly Spacey Schema"."user"
! select last_value from "Schema.name"."a.periodic.sequence"
\ No newline at end of file
--- 1,7 ----
! SELECT id,data FROM foo.table1 ORDER BY id
! SELECT id,table1_id,data FROM foo.table2 ORDER BY id
! SELECT id,table2_id,mod_date, data FROM foo.table3 ORDER BY id
  SELECT id, "user" from "Schema.name"."user" order by id
  SELECT "user", description from "Schema.name"."Capital Idea" order by "user"
  select last_value from "Studly Spacey Schema"."user"
! select last_value from "Schema.name"."a.periodic.sequence"

Index: README
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testschemanames/README,v
retrieving revision 1.1
retrieving revision 1.2
diff -C2 -d -r1.1 -r1.2
*** README	15 Nov 2005 21:25:34 -0000	1.1
--- README	11 Jun 2009 19:03:45 -0000	1.2
***************
*** 3,4 ****
--- 3,8 ----
  This test involves creating tables and sequences in namespaces with
  some wacky names, with StudlyCaps, spaces, and ".".
+ 
+ It drops the "public" schema, using schema "foo" instead.  This
+ validates that we can operate without there being a "public"
+ schema.

From cbbrowne at lists.slony.info  Thu Jun 11 12:03:46 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jun 11 12:03:54 2009
Subject: [Slony1-commit] slony1-engine/doc/adminguide Makefile
	adminscripts.sgml failover.sgml faq.sgml firstdb.sgml
	installation.sgml monitoring.sgml
Message-ID: <20090611190351.22FC6290BEA@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/doc/adminguide
In directory main.slony.info:/tmp/cvs-serv5001/doc/adminguide

Modified Files:
	Makefile adminscripts.sgml failover.sgml faq.sgml firstdb.sgml 
	installation.sgml monitoring.sgml 
Log Message:
Draw a whole pile of changes into HEAD from the 2.0 branch




Index: Makefile
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/Makefile,v
retrieving revision 1.21
retrieving revision 1.22
diff -C2 -d -r1.21 -r1.22
*** Makefile	20 Feb 2009 15:47:22 -0000	1.21
--- Makefile	11 Jun 2009 19:03:44 -0000	1.22
***************
*** 74,84 ****
  
  install: installdirs
  ifdef docdir
  	for file in man1/*.1; do \
! 	   $(INSTALL_DATA) $$file $(DESTDIR)$(mandir)/man1/$$file || exit;\
  	done
  	for file in man7/*.7; do \
! 	   echo $$file \
! 	   $(INSTALL_DATA) $$file $(DESTDIR)$(mandir)/man7/$$file || exit;\
  	done
  	for file in $(wildcard *.html) stylesheet.css ; do \
--- 74,85 ----
  
  install: installdirs
+ ifdef D2MSCRIPT
  ifdef docdir
  	for file in man1/*.1; do \
! 	   $(INSTALL_DATA) $$file $(DESTDIR)$(mandir)/$$file || exit;\
  	done
  	for file in man7/*.7; do \
! 	   echo $$file; \
! 	   $(INSTALL_DATA) "$$file" $(DESTDIR)$(mandir)/$$file || exit;\
  	done
  	for file in $(wildcard *.html) stylesheet.css ; do \
***************
*** 86,89 ****
--- 87,91 ----
  	done
  endif
+ endif
  
  .PHONY: html



Index: adminscripts.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/adminscripts.sgml,v
retrieving revision 1.54
retrieving revision 1.55
diff -C2 -d -r1.54 -r1.55
*** adminscripts.sgml	30 Apr 2009 16:07:47 -0000	1.54
--- adminscripts.sgml	11 Jun 2009 19:03:44 -0000	1.55
***************
*** 759,762 ****
--- 759,819 ----
  
  </sect2>
+ <sect2 id="slonikconfdump"> <title>slonikconfdump.sh</title>
+ 
+ <indexterm><primary>slonik configuration dump</primary></indexterm>
+ 
+ <para> The tool <filename>tools/slonikconfdump.sh</filename> was
+ created to help dump out a &lslonik; script to duplicate the
+ configuration of a functioning &slony1; cluster.</para>
+ 
+ <para> It dumps out: </para>
+ 
+ <itemizedlist>
+ <listitem><para>Cluster name </para> </listitem>
+ <listitem><para>Node connection information </para> <para> Note that it uses the first value it finds (<emphasis>e.g.</emphasis> - for the lowest numbered client node). </para> </listitem>
+ <listitem><para> Nodes </para> </listitem>
+ <listitem><para> Sets </para> </listitem>
+ <listitem><para> Tables </para> </listitem>
+ <listitem><para> Sequences </para> </listitem>
+ <listitem><para> Subscriptions </para> 
+ 
+ <para> Note that the subscriptions are ordered by set, then by
+ provider, then by receiver.  This ordering does not necessarily
+ indicate the order in which subscriptions need to be
+ applied. </para></listitem>
+ </itemizedlist>
+ 
+ <para> It may be run as follows: </para>
+ <programlisting>
+ chris@dba2:Slony-I/CMD/slony1-2.0/tools> SLONYCLUSTER=slony_regress1 PGDATABASE=slonyregress1 bash slonikconfdump.sh
+ # building slonik config files for cluster slony_regress1
+ # generated by: slonikconfdump.sh
+ # Generated on:  Tue Jun 9 17:34:12 EDT 2009
+ cluster name=slony_regress1;
+ include <admin-conninfos.slonik>;  # Draw in ADMIN CONNINFO lines
+ node 1 admin conninfo='dbname=slonyregress1 host=localhost user=chris port=7083';
+ node 2 admin conninfo='dbname=slonyregress2 host=localhost user=chris port=7083';
+ init cluster (id=1, comment='Regress test node');
+ store node (id=2, comment='node 2');
+ store path (server=1, client=2, conninfo='dbname=slonyregress1 host=localhost user=chris port=7083', connretry=10);
+ store path (server=2, client=1, conninfo='dbname=slonyregress2 host=localhost user=chris port=7083', connretry=10);
+ create set (id=1, origin=1, comment='All test1 tables');
+ set add table (id=1, set id=1, origin=1, fully qualified name='"public"."table1"', comment='accounts table, key='table1_pkey');
+ set add table (id=2, set id=1, origin=1, fully qualified name='"public"."table2"', comment='public.table2, key='table2_id_key');
+ set add table (id=4, set id=1, origin=1, fully qualified name='"public"."table4"', comment='a table of many types, key='table4_pkey');
+ set add table (id=5, set id=1, origin=1, fully qualified name='"public"."table5"', comment='a table with composite PK strewn across the table, key='table5_pkey');
+ subscribe set (id=1, provider=1, receiver=2, forward=YES);
+ chris@dba2:Slony-I/CMD/slony1-2.0/tools>
+ </programlisting>
+ 
+ <para> The output should be reviewed before it is applied elsewhere.
+ Particular attention should be paid to the <command>ADMIN
+ CONNINFO</command>, as it picks the first value that it sees for each
+ node; in a complex environment, where visibility of nodes may vary
+ from subnet to subnet, it may not pick the right value.  In addition,
+ <command>SUBSCRIBE SET</command> statements do not necessarily
+ indicate the order in which subscriptions need to be applied.</para>
+ 
+ </sect2>
  </sect1>
  <!-- Keep this comment at the end of the file


From cbbrowne at lists.slony.info  Fri Jun 12 12:28:35 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jun 12 12:28:37 2009
Subject: [Slony1-commit] slony1-engine/tests/testomitcopy  - New directory
Message-ID: <20090612192835.1128729032B@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tests/testomitcopy
In directory main.slony.info:/tmp/cvs-serv19926/testomitcopy

Log Message:
Directory /home/cvsd/slony1/slony1-engine/tests/testomitcopy added to the repository
--> Using per-directory sticky tag `REL_2_0_STABLE'


From cbbrowne at lists.slony.info  Fri Jun 12 13:34:01 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jun 12 13:34:02 2009
Subject: [Slony1-commit] slony1-engine/tests/testomitcopy README
	gen_weak_user.sh generate_dml.sh init_add_tables.ik
	init_cluster.ik init_create_set.ik init_data.sql
	init_schema.sql init_subscribe_set.ik schema.diff settings.ik
Message-ID: <20090612203401.92DA9290BF5@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tests/testomitcopy
In directory main.slony.info:/tmp/cvs-serv24740

Added Files:
      Tag: REL_2_0_STABLE
	README gen_weak_user.sh generate_dml.sh init_add_tables.ik 
	init_cluster.ik init_create_set.ik init_data.sql 
	init_schema.sql init_subscribe_set.ik schema.diff settings.ik 
Log Message:
Add OMIT COPY test to 2.0


--- NEW FILE: settings.ik ---
NUMCLUSTERS=${NUMCLUSTERS:-"1"}
NUMNODES=${NUMNODES:-"2"}
ORIGINNODE=1
WORKERS=${WORKERS:-"1"}

--- NEW FILE: init_cluster.ik ---
init cluster (id=1, comment = 'Regress test node');
echo 'update functions on node 1 after initializing it';
update functions (id=1);

--- NEW FILE: gen_weak_user.sh ---
weakuser=$1;

for i in 1 2 3 4 5; do
   echo "grant select on table public.table${i} to ${weakuser};"
   echo "grant select on table public.table${i}_id_seq to ${weakuser};"
done
--- NEW FILE: generate_dml.sh ---
. support_funcs.sh

init_dml()
{
  echo "init_dml()"
}

begin()
{
  echo "begin()"
}

rollback()
{
  echo "rollback()"
}

commit()
{
  echo "commit()"
}

generate_initdata()
{
  numrows=$(random_number 50 1000)
  i=0;
  trippoint=`expr $numrows / 20`
  j=0;
  percent=0
  status "generating ${numrows} transactions of random data"
  percent=`expr $j \* 5`
  status "$percent %"
  GENDATA="$mktmp/generate.data"
  echo "" > ${GENDATA}
  while : ; do
    txtalen=$(random_number 1 100)
    txta=$(random_string ${txtalen})
    txta=`echo ${txta} | sed -e "s/\\\\\\\/\\\\\\\\\\\\\\/g" -e "s/'/''/g"`
    txtblen=$(random_number 1 100)
    txtb=$(random_string ${txtblen})
    txtb=`echo ${txtb} | sed -e "s/\\\\\\\/\\\\\\\\\\\\\\/g" -e "s/'/''/g"`
    ra=$(random_number 1 9)
    rb=$(random_number 1 9)
    rc=$(random_number 1 9)
    echo "INSERT INTO table1(data) VALUES ('${txta}');" >> $GENDATA
    echo "INSERT INTO table2(table1_id,data) SELECT id, '${txtb}' FROM table1 WHERE data='${txta}';" >> $GENDATA
    echo "INSERT INTO table3(table2_id) SELECT id FROM table2 WHERE data ='${txtb}';" >> $GENDATA
    echo "INSERT INTO table4(numcol,realcol,ptcol,pathcol,polycol,circcol,ipcol,maccol,bitcol) values ('${ra}${rb}.${rc}','${ra}.${rb}${rc}','(${ra},${rb})','((${ra},${ra}),(${rb},${rb}),(${rc},${rc}),(${ra},${rc}))','((${ra},${rb}),(${rc},${ra}),(${rb},${rc}),(${rc},${rb}))','<(${ra},${rb}),${rc}>','192.168.${ra}.${rb}${rc}','08:00:2d:0${ra}:0${rb}:0${rc}',X'${ra}${rb}${rc}');" >> $GENDATA
    echo "INSERT INTO table5(d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11) values ('${txta}${ra}','${txta}${rb}','${txta}${rc}','${txtb}${ra}','${txtb}${rb}','${txtb}${rc}','${txtb}${ra}','${txtb}${rb}','${txtb}${rc}','${txtb}${ra}','${txtb}${rb}');" >> $GENDATA
    if [ ${i} -ge ${numrows} ]; then
      break;
    else
      i=$((${i} +1))
      working=`expr $i % $trippoint`
      if [ $working -eq 0 ]; then
        j=`expr $j + 1`
        percent=`expr $j \* 5`
        status "$percent %"
      fi 
    fi
  done
  status "done"
}

do_initdata()
{
  originnode=${ORIGINNODE:-"1"}
  eval db=\$DB${originnode}
  eval host=\$HOST${originnode}
  eval user=\$USER${originnode}
  eval port=\$PORT${originnode}
  generate_initdata
  status "run updateReloid() - equivalent to REPAIR NODE"
  $pgbindir/psql -h $host -p $port -d $db -U $user -c "select \"_${CLUSTER1}\".updateReloid(1, 0);" 1> $mktmp/reloidtest.log 2> $mktmp/reloidtest.log
  
  status "loading data"
  $pgbindir/psql -h $host -p $port -d $db -U $user < $mktmp/generate.data 1> $mktmp/initdata.log 2> $mktmp/initdata.log
  if [ $? -ne 0 ]; then
    warn 3 "do_initdata failed, see $mktmp/initdata.log for details"
  fi 
  status "data load complete"
  wait_for_catchup
  status "done"
}

--- NEW FILE: init_add_tables.ik ---
set add table (id=1, set id=1, origin=1, fully qualified name = 'public.table1', comment='accounts table');
set add table (id=2, set id=1, origin=1, fully qualified name = 'public.table2', key='table2_id_key');
set add table (id=3, set id=1, origin=1, fully qualified name = 'public.table4', comment='a table of many types');
set add table (id=4, set id=1, origin=1, fully qualified name = 'public.table5', comment='a table with composite PK strewn across the table');
--- NEW FILE: init_create_set.ik ---
create set (id=1, origin=1, comment='All test1 tables');


--- NEW FILE: init_data.sql ---
INSERT INTO table1(data) VALUES ('placeholder 1');
INSERT INTO table1(data) VALUES ('placeholder 2');
INSERT INTO table2(table1_id,data) VALUES (1,'placeholder 1');
INSERT INTO table2(table1_id,data) VALUES (2,'placeholder 2');

INSERT INTO table4(numcol,realcol,ptcol,pathcol,polycol,circcol,ipcol,maccol,bitcol) values ('74.0','7.40','(7,4)','((7,7),(4,4),(0,0),(7,0))','((7,4),(0,7),(4,0),(0,4))','<(7,4),0>','192.168.7.40','08:00:2d:07:04:00',X'740');

INSERT INTO table4(numcol,realcol,ptcol,pathcol,polycol,circcol,ipcol,maccol,bitcol) values ('93.1','9.31','(9,3)','((9,9),(3,3),(1,1),(9,1))','((9,3),(1,9),(3,1),(1,3))','<(9,3),1>','192.168.9.31','08:00:2d:09:03:01',X'931');
--- NEW FILE: init_schema.sql ---
CREATE TABLE table1(
  id		SERIAL		PRIMARY KEY, 
  data		TEXT
);

CREATE TABLE table2(
  id		SERIAL		UNIQUE NOT NULL, 
  table1_id	INT4		REFERENCES table1(id) 
					ON UPDATE CASCADE ON DELETE CASCADE, 
  data		TEXT
);

create table table3 (
  id serial NOT NULL,
  id2 integer
);

create unique index no_good_candidate_pk on table3 (id, id2);

create table table4 (
  id serial primary key,
  numcol numeric(12,4), -- 1.23
  realcol real,     -- (1.23)
  ptcol point,      -- (1,2)
  pathcol path,     -- ((1,1),(2,2),(3,3),(4,4))
  polycol polygon,  -- ((1,1),(2,2),(3,3),(4,4))
  circcol circle,   -- <(1,2>,3>
  ipcol inet,       -- "192.168.1.1"
  maccol macaddr,   -- "04:05:06:07:08:09"
  bitcol bit varying(20)  -- X'123' 
);

create table table5 (
  id serial,
  d1 text,
  d2 text,
  id2 serial,
  d3 text,
  d4 text,
  d5 text,
  d6 text,
  id3 serial,
  d7 text,
  d8 text,
  d9 text,
  d10 text,
  d11 text,
  primary key(id, id2, id3)
);
--- NEW FILE: schema.diff ---
SELECT id,data FROM table1 ORDER BY id
SELECT id,table1_id,data FROM table2 ORDER BY id
SELECT id,numcol,realcol,ptcol,pathcol,polycol,circcol,ipcol,maccol, bitcol from table4 order by id
SELECT id,d1,d2,id2,d3,d4,d5,d6,id3,d7,d8,d9,d10,d11 from table5 order by id,id2,id3
--- NEW FILE: README ---
$Id: README,v 1.1.2.1 2009-06-12 20:33:59 cbbrowne Exp $
  
This test validates the OMIT COPY functionality added to SUBSCRIBE SET
  
It creates three simple tables as one replication set, and replicates
them from one database to another.
  
The tables are of the several interesting types:
  
1.  table1 has a formal primary key

2.  table2 lacks a formal primary key, but has a candidate primary key

3.  table4 which has columns of all sorts of vaguely esoteric types to
exercise that points, paths, bitmaps, mac addresses, and inet types
replicate properly.

4.  table5 has a composite primary key (on id1,id2,id3) where
the primary key attributes are strewn throughout the table.  This is
to make sure we have a case that exercises the logic that changed with
bug #18.

--- NEW FILE: init_subscribe_set.ik ---
subscribe set (id = 1, provider = 1, receiver = 2, forward = yes, omit copy=true);
echo 'sleep a couple of seconds...';
sleep (seconds = 2);
echo 'done sleeping...';

From cbbrowne at lists.slony.info  Fri Jun 12 13:34:46 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jun 12 13:34:48 2009
Subject: [Slony1-commit] slony1-engine/tests/testomitcopy README
	gen_weak_user.sh generate_dml.sh init_add_tables.ik
	init_cluster.ik init_create_set.ik init_data.sql
	init_schema.sql init_subscribe_set.ik schema.diff settings.ik
Message-ID: <20090612203446.A9973290BF5@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tests/testomitcopy
In directory main.slony.info:/tmp/cvs-serv24772

Added Files:
	README gen_weak_user.sh generate_dml.sh init_add_tables.ik 
	init_cluster.ik init_create_set.ik init_data.sql 
	init_schema.sql init_subscribe_set.ik schema.diff settings.ik 
Log Message:
Add OMIT COPY tests to HEAD


--- NEW FILE: settings.ik ---
NUMCLUSTERS=${NUMCLUSTERS:-"1"}
NUMNODES=${NUMNODES:-"2"}
ORIGINNODE=1
WORKERS=${WORKERS:-"1"}

--- NEW FILE: init_cluster.ik ---
init cluster (id=1, comment = 'Regress test node');
echo 'update functions on node 1 after initializing it';
update functions (id=1);

--- NEW FILE: gen_weak_user.sh ---
weakuser=$1;

for i in 1 2 3 4 5; do
   echo "grant select on table public.table${i} to ${weakuser};"
   echo "grant select on table public.table${i}_id_seq to ${weakuser};"
done
--- NEW FILE: generate_dml.sh ---
. support_funcs.sh

init_dml()
{
  echo "init_dml()"
}

begin()
{
  echo "begin()"
}

rollback()
{
  echo "rollback()"
}

commit()
{
  echo "commit()"
}

generate_initdata()
{
  numrows=$(random_number 50 1000)
  i=0;
  trippoint=`expr $numrows / 20`
  j=0;
  percent=0
  status "generating ${numrows} transactions of random data"
  percent=`expr $j \* 5`
  status "$percent %"
  GENDATA="$mktmp/generate.data"
  echo "" > ${GENDATA}
  while : ; do
    txtalen=$(random_number 1 100)
    txta=$(random_string ${txtalen})
    txta=`echo ${txta} | sed -e "s/\\\\\\\/\\\\\\\\\\\\\\/g" -e "s/'/''/g"`
    txtblen=$(random_number 1 100)
    txtb=$(random_string ${txtblen})
    txtb=`echo ${txtb} | sed -e "s/\\\\\\\/\\\\\\\\\\\\\\/g" -e "s/'/''/g"`
    ra=$(random_number 1 9)
    rb=$(random_number 1 9)
    rc=$(random_number 1 9)
    echo "INSERT INTO table1(data) VALUES ('${txta}');" >> $GENDATA
    echo "INSERT INTO table2(table1_id,data) SELECT id, '${txtb}' FROM table1 WHERE data='${txta}';" >> $GENDATA
    echo "INSERT INTO table3(table2_id) SELECT id FROM table2 WHERE data ='${txtb}';" >> $GENDATA
    echo "INSERT INTO table4(numcol,realcol,ptcol,pathcol,polycol,circcol,ipcol,maccol,bitcol) values ('${ra}${rb}.${rc}','${ra}.${rb}${rc}','(${ra},${rb})','((${ra},${ra}),(${rb},${rb}),(${rc},${rc}),(${ra},${rc}))','((${ra},${rb}),(${rc},${ra}),(${rb},${rc}),(${rc},${rb}))','<(${ra},${rb}),${rc}>','192.168.${ra}.${rb}${rc}','08:00:2d:0${ra}:0${rb}:0${rc}',X'${ra}${rb}${rc}');" >> $GENDATA
    echo "INSERT INTO table5(d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11) values ('${txta}${ra}','${txta}${rb}','${txta}${rc}','${txtb}${ra}','${txtb}${rb}','${txtb}${rc}','${txtb}${ra}','${txtb}${rb}','${txtb}${rc}','${txtb}${ra}','${txtb}${rb}');" >> $GENDATA
    if [ ${i} -ge ${numrows} ]; then
      break;
    else
      i=$((${i} +1))
      working=`expr $i % $trippoint`
      if [ $working -eq 0 ]; then
        j=`expr $j + 1`
        percent=`expr $j \* 5`
        status "$percent %"
      fi 
    fi
  done
  status "done"
}

do_initdata()
{
  originnode=${ORIGINNODE:-"1"}
  eval db=\$DB${originnode}
  eval host=\$HOST${originnode}
  eval user=\$USER${originnode}
  eval port=\$PORT${originnode}
  generate_initdata
  status "run updateReloid() - equivalent to REPAIR NODE"
  $pgbindir/psql -h $host -p $port -d $db -U $user -c "select \"_${CLUSTER1}\".updateReloid(1, 0);" 1> $mktmp/reloidtest.log 2> $mktmp/reloidtest.log
  
  status "loading data"
  $pgbindir/psql -h $host -p $port -d $db -U $user < $mktmp/generate.data 1> $mktmp/initdata.log 2> $mktmp/initdata.log
  if [ $? -ne 0 ]; then
    warn 3 "do_initdata failed, see $mktmp/initdata.log for details"
  fi 
  status "data load complete"
  wait_for_catchup
  status "done"
}

--- NEW FILE: init_add_tables.ik ---
set add table (id=1, set id=1, origin=1, fully qualified name = 'public.table1', comment='accounts table');
set add table (id=2, set id=1, origin=1, fully qualified name = 'public.table2', key='table2_id_key');
set add table (id=3, set id=1, origin=1, fully qualified name = 'public.table4', comment='a table of many types');
set add table (id=4, set id=1, origin=1, fully qualified name = 'public.table5', comment='a table with composite PK strewn across the table');
--- NEW FILE: init_create_set.ik ---
create set (id=1, origin=1, comment='All test1 tables');


--- NEW FILE: init_data.sql ---
INSERT INTO table1(data) VALUES ('placeholder 1');
INSERT INTO table1(data) VALUES ('placeholder 2');
INSERT INTO table2(table1_id,data) VALUES (1,'placeholder 1');
INSERT INTO table2(table1_id,data) VALUES (2,'placeholder 2');

INSERT INTO table4(numcol,realcol,ptcol,pathcol,polycol,circcol,ipcol,maccol,bitcol) values ('74.0','7.40','(7,4)','((7,7),(4,4),(0,0),(7,0))','((7,4),(0,7),(4,0),(0,4))','<(7,4),0>','192.168.7.40','08:00:2d:07:04:00',X'740');

INSERT INTO table4(numcol,realcol,ptcol,pathcol,polycol,circcol,ipcol,maccol,bitcol) values ('93.1','9.31','(9,3)','((9,9),(3,3),(1,1),(9,1))','((9,3),(1,9),(3,1),(1,3))','<(9,3),1>','192.168.9.31','08:00:2d:09:03:01',X'931');
--- NEW FILE: init_schema.sql ---
CREATE TABLE table1(
  id		SERIAL		PRIMARY KEY, 
  data		TEXT
);

CREATE TABLE table2(
  id		SERIAL		UNIQUE NOT NULL, 
  table1_id	INT4		REFERENCES table1(id) 
					ON UPDATE CASCADE ON DELETE CASCADE, 
  data		TEXT
);

create table table3 (
  id serial NOT NULL,
  id2 integer
);

create unique index no_good_candidate_pk on table3 (id, id2);

create table table4 (
  id serial primary key,
  numcol numeric(12,4), -- 1.23
  realcol real,     -- (1.23)
  ptcol point,      -- (1,2)
  pathcol path,     -- ((1,1),(2,2),(3,3),(4,4))
  polycol polygon,  -- ((1,1),(2,2),(3,3),(4,4))
  circcol circle,   -- <(1,2>,3>
  ipcol inet,       -- "192.168.1.1"
  maccol macaddr,   -- "04:05:06:07:08:09"
  bitcol bit varying(20)  -- X'123' 
);

create table table5 (
  id serial,
  d1 text,
  d2 text,
  id2 serial,
  d3 text,
  d4 text,
  d5 text,
  d6 text,
  id3 serial,
  d7 text,
  d8 text,
  d9 text,
  d10 text,
  d11 text,
  primary key(id, id2, id3)
);
--- NEW FILE: schema.diff ---
SELECT id,data FROM table1 ORDER BY id
SELECT id,table1_id,data FROM table2 ORDER BY id
SELECT id,numcol,realcol,ptcol,pathcol,polycol,circcol,ipcol,maccol, bitcol from table4 order by id
SELECT id,d1,d2,id2,d3,d4,d5,d6,id3,d7,d8,d9,d10,d11 from table5 order by id,id2,id3
--- NEW FILE: README ---
$Id: README,v 1.2 2009-06-12 20:34:44 cbbrowne Exp $
  
This test validates the OMIT COPY functionality added to SUBSCRIBE SET
  
It creates three simple tables as one replication set, and replicates
them from one database to another.
  
The tables are of the several interesting types:
  
1.  table1 has a formal primary key

2.  table2 lacks a formal primary key, but has a candidate primary key

3.  table4 which has columns of all sorts of vaguely esoteric types to
exercise that points, paths, bitmaps, mac addresses, and inet types
replicate properly.

4.  table5 has a composite primary key (on id1,id2,id3) where
the primary key attributes are strewn throughout the table.  This is
to make sure we have a case that exercises the logic that changed with
bug #18.

--- NEW FILE: init_subscribe_set.ik ---
subscribe set (id = 1, provider = 1, receiver = 2, forward = yes, omit copy=true);
echo 'sleep a couple of seconds...';
sleep (seconds = 2);
echo 'done sleeping...';

From cbbrowne at lists.slony.info  Fri Jun 12 15:42:15 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jun 12 15:42:18 2009
Subject: [Slony1-commit] slony1-engine/tools slonikconfdump.sh
Message-ID: <20090612224215.AAB362902D3@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tools
In directory main.slony.info:/tmp/cvs-serv1425/tools

Modified Files:
      Tag: REL_2_0_STABLE
	slonikconfdump.sh 
Log Message:
Revised slonik dump script based on input from our DBA group...
It now uses tsort to determine the subscription ordering, so should
work even with fairly sophisticated cascaded subscriptions


Index: slonikconfdump.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tools/Attic/slonikconfdump.sh,v
retrieving revision 1.1.2.2
retrieving revision 1.1.2.3
diff -C2 -d -r1.1.2.2 -r1.1.2.3
*** slonikconfdump.sh	10 Jun 2009 21:11:56 -0000	1.1.2.2
--- slonikconfdump.sh	12 Jun 2009 22:42:13 -0000	1.1.2.3
***************
*** 12,21 ****
  echo "cluster name=${SLONYCLUSTER};"
  
! echo "include <admin-conninfos.slonik>;  # Draw in ADMIN CONNINFO lines"
  Q="select distinct pa_server from ${SS}.sl_path order by pa_server;"
! PATHS=`psql -qtA -F ":" -c "${Q}"`
  for svr in `echo ${PATHS}`; do
      SQ="select pa_conninfo from ${SS}.sl_path where pa_server=${svr} order by pa_client asc limit 1;"
!     conninfo=`psql -qtA -F ":" -c "${SQ}"`
      echo "node ${svr} admin conninfo='${conninfo}';"
  done
--- 12,42 ----
  echo "cluster name=${SLONYCLUSTER};"
  
! function RQ () {
!     local QUERY=$1
!     RESULTSET=`psql -qtA -F ":" -R " " -c "${QUERY}"`
!     echo ${RESULTSET}
! }
! function argn () {
!     local V=$1
!     local n=$2
!     local res=`echo ${V} | cut -d : -f ${n}`
!     echo $res
! }
!     
! function arg1 () {
!     echo `argn "$1" 1`
! }
! function arg2 () {
!     echo `argn "$1" 2`
! }
! function arg3 () {
!     echo `argn "$1" 3`
! }
! 
  Q="select distinct pa_server from ${SS}.sl_path order by pa_server;"
! PATHS=`RQ "${Q}"`
  for svr in `echo ${PATHS}`; do
      SQ="select pa_conninfo from ${SS}.sl_path where pa_server=${svr} order by pa_client asc limit 1;"
!     conninfo=`RQ "${SQ}"`
      echo "node ${svr} admin conninfo='${conninfo}';"
  done
***************
*** 23,81 ****
  Q="select no_id, no_comment from ${SS}.sl_node order by no_id limit 1;"
  
! NODE1=`psql -qtA -F ":" -c "${Q}"`
! nn=`echo ${NODE1} | cut -d : -f 1`
! comment=`echo ${NODE1} | cut -d : -f 2-`
  echo "init cluster (id=${nn}, comment='${comment}');"
  
  Q="select no_id from ${SS}.sl_node order by no_id offset 1;"
! NODES=`psql -qtA -F ":" -c "${Q}"`
  for node in `echo ${NODES}`; do
      CQ="select no_comment from ${SS}.sl_node where no_id = ${node};"
!     comment=`psql -qtA -c "${CQ}"`
      echo "store node (id=${node}, comment='${comment}');"
  done
  
- #slonyregress1=# select * from sl_path;
- # pa_server | pa_client |                       pa_conninfo                        | pa_connretry
- #-----------+-----------+----------------------------------------------------------+--------------
- #         2 |         1 | dbname=slonyregress2 host=localhost user=chris port=7083 |           10
- #         1 |         2 | dbname=slonyregress1 host=localhost user=chris port=7083 |           10
- #(2 rows)
- 
  Q="select pa_server, pa_client, pa_connretry from ${SS}.sl_path order by pa_server, pa_client;"
! PATHS=`psql -qtA -F ":" -R " " -c "${Q}"`
  for sc in `echo $PATHS`; do
!     server=`echo $sc | cut -d : -f 1`
!     client=`echo $sc | cut -d : -f 2`
!     retry=`echo $sc | cut -d : -f 3`
      Q2="select pa_conninfo from ${SS}.sl_path where pa_server=${server} and pa_client=${client};"
!     conninfo=`psql -qtA -c "${Q2}"`
      echo "store path (server=${server}, client=${client}, conninfo='${conninfo}', connretry=${retry});"
  done
  
  Q="select set_id, set_origin from ${SS}.sl_set order by set_id;"
! SETS=`psql -qtA -F ":" -R " " -c "${Q}"`
  for sc in `echo ${SETS}`; do
!     set=`echo ${sc} | cut -d : -f 1`
!     origin=`echo ${sc} | cut -d : -f 2`
      Q2="select set_comment from ${SS}.sl_set where set_id=${set};"
!     comment=`psql -qtA -c "${Q2}"`
      echo "create set (id=${set}, origin=${origin}, comment='${comment}');"
  done
  
  Q="select tab_id,tab_set, set_origin from ${SS}.sl_table, ${SS}.sl_set where tab_set = set_id order by tab_id;"
! TABS=`psql -qtA -F ":" -R " " -c "${Q}"`
  for tb in `echo ${TABS}`; do
!     tab=`echo ${tb} | cut -d : -f 1`
!     set=`echo ${tb} | cut -d : -f 2`
!     origin=`echo ${tb} | cut -d : -f 3`
      RQ="select tab_relname from ${SS}.sl_table where tab_id = ${tab};"
!     relname=`psql -qtA -c "${RQ}"`
      NSQ="select tab_nspname from ${SS}.sl_table where tab_id = ${tab};"
!     nsp=`psql -qtA -c "${NSQ}"`
      IDX="select tab_idxname from ${SS}.sl_table where tab_id = ${tab};"
!     idx=`psql -qtA -c "${IDX}"`
      COM="select tab_comment from ${SS}.sl_table where tab_id = ${tab};"
!     comment=`psql -qtA -c "${COM}"`
      echo "set add table (id=${tab}, set id=${set}, origin=${origin}, fully qualified name='\"${nsp}\".\"${relname}\"', comment='${comment}, key='${idx}');"
  done
--- 44,95 ----
  Q="select no_id, no_comment from ${SS}.sl_node order by no_id limit 1;"
  
! NODE1=`RQ "${Q}"`
! nn=`arg1 "${NODE1}"`
! comment=`arg2 ${NODE1}`
  echo "init cluster (id=${nn}, comment='${comment}');"
  
  Q="select no_id from ${SS}.sl_node order by no_id offset 1;"
! NODES=`RQ "${Q}"`
  for node in `echo ${NODES}`; do
      CQ="select no_comment from ${SS}.sl_node where no_id = ${node};"
!     comment=`RQ "${CQ}"`
      echo "store node (id=${node}, comment='${comment}');"
  done
  
  Q="select pa_server, pa_client, pa_connretry from ${SS}.sl_path order by pa_server, pa_client;"
! PATHS=`RQ "${Q}"`
  for sc in `echo $PATHS`; do
!     server=`arg1 $sc`
!     client=`arg2 $sc`
!     retry=`arg3 $sc`
      Q2="select pa_conninfo from ${SS}.sl_path where pa_server=${server} and pa_client=${client};"
!     conninfo=`RQ "${Q2}"`
      echo "store path (server=${server}, client=${client}, conninfo='${conninfo}', connretry=${retry});"
  done
  
  Q="select set_id, set_origin from ${SS}.sl_set order by set_id;"
! SETS=`RQ "${Q}"`
  for sc in `echo ${SETS}`; do
!     set=`arg1 ${sc}`
!     origin=`arg2 ${sc}`
      Q2="select set_comment from ${SS}.sl_set where set_id=${set};"
!     comment=`RQ "${Q2}"`
      echo "create set (id=${set}, origin=${origin}, comment='${comment}');"
  done
  
  Q="select tab_id,tab_set, set_origin from ${SS}.sl_table, ${SS}.sl_set where tab_set = set_id order by tab_id;"
! TABS=`RQ "${Q}"`
  for tb in `echo ${TABS}`; do
!     tab=`arg1 ${tb}`
!     set=`arg2 ${tb}`
!     origin=`arg3 ${tb}`
      RQ="select tab_relname from ${SS}.sl_table where tab_id = ${tab};"
!     relname=`RQ "${RQ}"`
      NSQ="select tab_nspname from ${SS}.sl_table where tab_id = ${tab};"
!     nsp=`RQ "${NSQ}"`
      IDX="select tab_idxname from ${SS}.sl_table where tab_id = ${tab};"
!     idx=`RQ "${IDX}"`
      COM="select tab_comment from ${SS}.sl_table where tab_id = ${tab};"
!     comment=`RQ "${COM}"`
      echo "set add table (id=${tab}, set id=${set}, origin=${origin}, fully qualified name='\"${nsp}\".\"${relname}\"', comment='${comment}, key='${idx}');"
  done
***************
*** 83,107 ****
  
  Q="select seq_id,seq_set,set_origin from ${SS}.sl_sequence, ${SS}.sl_set where seq_set = set_id order by seq_id;"
! SEQS=`psql -qtA -F ":" -R " " -c "${Q}"`
  for sq in `echo ${SEQS}`; do
!     seq=`echo ${sq} | cut -d : -f 1`
!     set=`echo ${sq} | cut -d : -f 2`
!     origin=`echo ${sq} | cut -d : -f 3`
!     RQ="select seq_relname from ${SS}.sl_sequence where seq_id = ${seq};"
!     relname=`psql -qtA -c "${RQ}"`
      NSQ="select seq_nspname from ${SS}.sl_sequence where seq_id = ${seq};"
!     nsp=`psql -qtA -c "${NSQ}"`
      COM="select seq_comment from ${SS}.sl_sequence where seq_id = ${seq};"
!     comment=`psql -qtA -c "${COM}"`
      echo "set add sequence(id=${seq}, set id=${set}, origin=${origin}, fully qualified name='\"${nsp}\".\"${relname}\"', comment='${comment}');"
  done
  
! Q="select sub_set,sub_provider,sub_receiver,case when sub_forward then 'YES' else 'NO' end from ${SS}.sl_subscribe order by sub_set, sub_provider, sub_receiver;"
! SUBS=`psql -qtA -F ":" -R " " -c "${Q}"`
! for sb in `echo ${SUBS}`; do
!     set=`echo ${sb} | cut -d : -f 1`
!     prov=`echo ${sb} | cut -d : -f 2`
!     recv=`echo ${sb} | cut -d : -f 3`
!     forw=`echo ${sb} | cut -d : -f 4`
!     echo "subscribe set (id=${set}, provider=${prov}, receiver=${recv}, forward=${forw});"
  done
--- 97,133 ----
  
  Q="select seq_id,seq_set,set_origin from ${SS}.sl_sequence, ${SS}.sl_set where seq_set = set_id order by seq_id;"
! SEQS=`RQ "${Q}"`
  for sq in `echo ${SEQS}`; do
!     seq=`arg1 ${sq}`
!     set=`arg2 ${sq}`
!     origin=`arg3 ${sq}`
!     RELQ="select seq_relname from ${SS}.sl_sequence where seq_id = ${seq};"
!     relname=`RQ "${RELQ}"`
      NSQ="select seq_nspname from ${SS}.sl_sequence where seq_id = ${seq};"
!     nsp=`RQ "${NSQ}"`
      COM="select seq_comment from ${SS}.sl_sequence where seq_id = ${seq};"
!     comment=`RQ "${COM}"`
      echo "set add sequence(id=${seq}, set id=${set}, origin=${origin}, fully qualified name='\"${nsp}\".\"${relname}\"', comment='${comment}');"
  done
  
! Q="select set_id, set_origin from ${SS}.sl_set;"
! SETS=`RQ "${Q}"`
! for seti in `echo ${SETS}`; do
!     set=`arg1 ${seti}`
!     origins=`arg2 ${seti}`
!     SUBQ="select sub_provider, sub_receiver from ${SS}.sl_subscribe where sub_set=${set};"
!     # We use tsort to determine a feasible ordering for subscriptions
!     SUBRES=`psql -qtA -F " " -c "${SUBQ}" | tsort | egrep -v "^${origin}\$"`
!     for recv in `echo ${SUBRES}`; do
! 	SF="select sub_provider, sub_forward from ${SS}.sl_subscribe where sub_set=${set} and sub_receiver=${recv};"
! 	SR=`RQ "${SF}"`
! 	prov=`arg1 ${SR}`
! 	forw=`arg2 ${SR}`
! 	echo "subscribe set (id=${set}, provider=${prov}, receiver=${recv}, forward=${forw}, omit copy=true);"
! 	if [ $prov != $origin ]; then
! 	    echo "wait for event (origin=$provider, confirmed=$origin, wait on=$provider, timeout=0);"
! 	fi
! 	echo "sync (id=$origin);"
! 	echo "wait for event (origin=$origin, confirmed=ALL, wait on=$origin, timeout=0);"
!     done
  done

From cbbrowne at lists.slony.info  Fri Jun 12 15:42:15 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jun 12 15:42:18 2009
Subject: [Slony1-commit] slony1-engine/doc/adminguide adminscripts.sgml
Message-ID: <20090612224215.B6CFC290BE9@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/doc/adminguide
In directory main.slony.info:/tmp/cvs-serv1425/doc/adminguide

Modified Files:
      Tag: REL_2_0_STABLE
	adminscripts.sgml 
Log Message:
Revised slonik dump script based on input from our DBA group...
It now uses tsort to determine the subscription ordering, so should
work even with fairly sophisticated cascaded subscriptions


Index: adminscripts.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/adminscripts.sgml,v
retrieving revision 1.52.2.3
retrieving revision 1.52.2.4
diff -C2 -d -r1.52.2.3 -r1.52.2.4
*** adminscripts.sgml	10 Jun 2009 21:11:56 -0000	1.52.2.3
--- adminscripts.sgml	12 Jun 2009 22:42:13 -0000	1.52.2.4
***************
*** 778,785 ****
  <listitem><para> Subscriptions </para> 
  
! <para> Note that the subscriptions are ordered by set, then by
! provider, then by receiver.  This ordering does not necessarily
! indicate the order in which subscriptions need to be
! applied. </para></listitem>
  </itemizedlist>
  
--- 778,783 ----
  <listitem><para> Subscriptions </para> 
  
! <para> Note that the subscriptions are ordered topologically, using
! <command>tsort</command> </para></listitem>
  </itemizedlist>
  
***************
*** 811,817 ****
  CONNINFO</command>, as it picks the first value that it sees for each
  node; in a complex environment, where visibility of nodes may vary
! from subnet to subnet, it may not pick the right value.  In addition,
! <command>SUBSCRIBE SET</command> statements do not necessarily
! indicate the order in which subscriptions need to be applied.</para>
  
  </sect2>
--- 809,813 ----
  CONNINFO</command>, as it picks the first value that it sees for each
  node; in a complex environment, where visibility of nodes may vary
! from subnet to subnet, it may not pick the right value.  </para>
  
  </sect2>

From cbbrowne at lists.slony.info  Wed Jun 17 14:37:40 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jun 17 14:37:44 2009
Subject: [Slony1-commit] slony1-engine/src/slon remote_worker.c
Message-ID: <20090617213740.7B65D290363@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv2472/src/slon

Modified Files:
      Tag: REL_2_0_STABLE
	remote_worker.c 
Log Message:
Add in OMIT COPY option to SUBSCRIBE SET in support of upgrading from
elder Slony-I versions.


Index: remote_worker.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/remote_worker.c,v
retrieving revision 1.176
retrieving revision 1.176.2.1
diff -C2 -d -r1.176 -r1.176.2.1
*** remote_worker.c	29 Aug 2008 21:06:45 -0000	1.176
--- remote_worker.c	17 Jun 2009 21:37:38 -0000	1.176.2.1
***************
*** 1181,1184 ****
--- 1181,1185 ----
  				int			sub_receiver = (int) strtol(event->ev_data3, NULL, 10);
  				char	   *sub_forward = event->ev_data4;
+ 				char	   *omit_copy = event->ev_data5;
  
  				if (sub_receiver == rtcfg_nodeid)
***************
*** 1186,1192 ****
  
  				slon_appendquery(&query1,
! 							"select %s.subscribeSet_int(%d, %d, %d, '%q'); ",
  								 rtcfg_namespace,
! 						   sub_set, sub_provider, sub_receiver, sub_forward);
  				need_reloadListen = true;
  			}
--- 1187,1193 ----
  
  				slon_appendquery(&query1,
! 								 "select %s.subscribeSet_int(%d, %d, %d, '%q', '%q'); ",
  								 rtcfg_namespace,
! 								 sub_set, sub_provider, sub_receiver, sub_forward, omit_copy);
  				need_reloadListen = true;
  			}
***************
*** 2430,2440 ****
  	char		seqbuf[64];
  	char	   *copydata = NULL;
  	struct timeval tv_start;
  	struct timeval tv_start2;
  	struct timeval tv_now;
  
- 	slon_log(SLON_INFO, "copy_set %d\n", set_id);
  	gettimeofday(&tv_start, NULL);
  
  	/*
  	 * Lookup the provider nodes conninfo
--- 2431,2459 ----
  	char		seqbuf[64];
  	char	   *copydata = NULL;
+ 	bool omit_copy = false;
+ 	char *v_omit_copy = event->ev_data5;
  	struct timeval tv_start;
  	struct timeval tv_start2;
  	struct timeval tv_now;
  
  	gettimeofday(&tv_start, NULL);
  
+ 	if (strcmp(v_omit_copy, "f") == 0) {
+ 		omit_copy = false;
+ 	} else {
+ 		if (strcmp(v_omit_copy, "t") == 0) {
+ 			omit_copy = true;
+ 		} else {
+ 			slon_log(SLON_ERROR, "copy_set %d - omit_copy not in (t,f)- [%s]\n", set_id, v_omit_copy);
+ 		}
+ 	}
+ 	slon_log(SLON_INFO, "copy_set %d - omit=%s - bool=%d\n", set_id, v_omit_copy, omit_copy);
+ 
+ 	if (omit_copy) {
+ 		slon_log(SLON_INFO, "omit is TRUE\n");
+ 	} else {
+ 		slon_log(SLON_INFO, "omit is FALSE\n");
+ 	}
+ 
  	/*
  	 * Lookup the provider nodes conninfo
***************
*** 2859,2862 ****
--- 2878,2886 ----
  		 * Begin a COPY from stdin for the table on the local DB
  		 */
+ 		if (omit_copy) {
+ 			slon_log(SLON_CONFIG, "remoteWorkerThread_%d: "
+ 					 "COPY of table %s suppressed due to OMIT COPY option\n",
+ 					 node->no_id, tab_fqname);
+ 		} else {
  		slon_log(SLON_CONFIG, "remoteWorkerThread_%d: "
  				 "Begin COPY of table %s\n",
***************
*** 3148,3152 ****
  			}
  		}
! 
  		gettimeofday(&tv_now, NULL);
  		slon_log(SLON_CONFIG, "remoteWorkerThread_%d: "
--- 3172,3176 ----
  			}
  		}
! 		}
  		gettimeofday(&tv_now, NULL);
  		slon_log(SLON_CONFIG, "remoteWorkerThread_%d: "

From cbbrowne at lists.slony.info  Wed Jun 17 14:37:40 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jun 17 14:37:44 2009
Subject: [Slony1-commit] slony1-engine/src/backend slony1_funcs.sql
Message-ID: <20090617213740.63D71290250@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/backend
In directory main.slony.info:/tmp/cvs-serv2472/src/backend

Modified Files:
      Tag: REL_2_0_STABLE
	slony1_funcs.sql 
Log Message:
Add in OMIT COPY option to SUBSCRIBE SET in support of upgrading from
elder Slony-I versions.


Index: slony1_funcs.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/backend/slony1_funcs.sql,v
retrieving revision 1.145.2.10
retrieving revision 1.145.2.11
diff -C2 -d -r1.145.2.10 -r1.145.2.11
*** slony1_funcs.sql	28 Apr 2009 19:25:36 -0000	1.145.2.10
--- slony1_funcs.sql	17 Jun 2009 21:37:38 -0000	1.145.2.11
***************
*** 4100,4106 ****
  
  -- ----------------------------------------------------------------------
! -- FUNCTION subscribeSet (sub_set, sub_provider, sub_receiver, sub_forward)
  -- ----------------------------------------------------------------------
! create or replace function @NAMESPACE@.subscribeSet (int4, int4, int4, bool)
  returns bigint
  as $$
--- 4100,4106 ----
  
  -- ----------------------------------------------------------------------
! -- FUNCTION subscribeSet (sub_set, sub_provider, sub_receiver, sub_forward, omit_copy)
  -- ----------------------------------------------------------------------
! create or replace function @NAMESPACE@.subscribeSet (int4, int4, int4, bool, bool)
  returns bigint
  as $$
***************
*** 4110,4113 ****
--- 4110,4114 ----
  	p_sub_receiver		alias for $3;
  	p_sub_forward		alias for $4;
+ 	p_omit_copy		alias for $5;
  	v_set_origin		int4;
  	v_ev_seqno			int8;
***************
*** 4119,4122 ****
--- 4120,4125 ----
  	lock table @NAMESPACE@.sl_config_lock;
  
+ 	raise notice 'subscribe set: omit_copy=%', p_omit_copy;
+ 
  	-- ----
  	-- Check that this is called on the provider node
***************
*** 4162,4166 ****
  	v_ev_seqno :=  @NAMESPACE@.createEvent('_@CLUSTERNAME@', 'SUBSCRIBE_SET', 
  			p_sub_set::text, p_sub_provider::text, p_sub_receiver::text, 
! 			case p_sub_forward when true then 't' else 'f' end);
  
  	-- ----
--- 4165,4171 ----
  	v_ev_seqno :=  @NAMESPACE@.createEvent('_@CLUSTERNAME@', 'SUBSCRIBE_SET', 
  			p_sub_set::text, p_sub_provider::text, p_sub_receiver::text, 
! 			case p_sub_forward when true then 't' else 'f' end,
! 			case p_omit_copy when true then 't' else 'f' end
!                         );
  
  	-- ----
***************
*** 4168,4186 ****
  	-- ----
  	perform @NAMESPACE@.subscribeSet_int(p_sub_set, p_sub_provider,
! 			p_sub_receiver, p_sub_forward);
  
  	return v_ev_seqno;
  end;
  $$ language plpgsql;
! comment on function @NAMESPACE@.subscribeSet (int4, int4, int4, bool) is
! 'subscribeSet (sub_set, sub_provider, sub_receiver, sub_forward)
  
  Makes sure that the receiver is not the provider, then stores the
! subscription, and publishes the SUBSCRIBE_SET event to other nodes.';
  
! -- ----------------------------------------------------------------------
! -- FUNCTION subscribeSet_int (sub_set, sub_provider, sub_receiver, sub_forward)
! -- ----------------------------------------------------------------------
! create or replace function @NAMESPACE@.subscribeSet_int (int4, int4, int4, bool)
  returns int4
  as $$
--- 4173,4194 ----
  	-- ----
  	perform @NAMESPACE@.subscribeSet_int(p_sub_set, p_sub_provider,
! 			p_sub_receiver, p_sub_forward, p_omit_copy);
  
  	return v_ev_seqno;
  end;
  $$ language plpgsql;
! comment on function @NAMESPACE@.subscribeSet (int4, int4, int4, bool, bool) is
! 'subscribeSet (sub_set, sub_provider, sub_receiver, sub_forward, omit_copy)
  
  Makes sure that the receiver is not the provider, then stores the
! subscription, and publishes the SUBSCRIBE_SET event to other nodes.
  
! If omit_copy is true, then no data copy will be done.
! ';
! 
! -- -------------------------------------------------------------------------------------------
! -- FUNCTION subscribeSet_int (sub_set, sub_provider, sub_receiver, sub_forward, omit_copy)
! -- -------------------------------------------------------------------------------------------
! create or replace function @NAMESPACE@.subscribeSet_int (int4, int4, int4, bool, bool)
  returns int4
  as $$
***************
*** 4190,4193 ****
--- 4198,4202 ----
  	p_sub_receiver		alias for $3;
  	p_sub_forward		alias for $4;
+ 	p_omit_copy		alias for $5;
  	v_set_origin		int4;
  	v_sub_row			record;
***************
*** 4198,4201 ****
--- 4207,4212 ----
  	lock table @NAMESPACE@.sl_config_lock;
  
+ 	raise notice 'subscribe set: omit_copy=%', p_omit_copy;
+ 
  	-- ----
  	-- Provider change is only allowed for active sets
***************
*** 4261,4265 ****
  		perform @NAMESPACE@.createEvent('_@CLUSTERNAME@', 'ENABLE_SUBSCRIPTION', 
  				p_sub_set::text, p_sub_provider::text, p_sub_receiver::text, 
! 				case p_sub_forward when true then 't' else 'f' end);
  		perform @NAMESPACE@.enableSubscription(p_sub_set, 
  				p_sub_provider, p_sub_receiver);
--- 4272,4278 ----
  		perform @NAMESPACE@.createEvent('_@CLUSTERNAME@', 'ENABLE_SUBSCRIPTION', 
  				p_sub_set::text, p_sub_provider::text, p_sub_receiver::text, 
! 				case p_sub_forward when true then 't' else 'f' end,
! 				case p_omit_copy when true then 't' else 'f' end
! 				);
  		perform @NAMESPACE@.enableSubscription(p_sub_set, 
  				p_sub_provider, p_sub_receiver);
***************
*** 4275,4280 ****
  $$ language plpgsql;
  
! comment on function @NAMESPACE@.subscribeSet_int (int4, int4, int4, bool) is
! 'subscribeSet_int (sub_set, sub_provider, sub_receiver, sub_forward)
  
  Internal actions for subscribing receiver sub_receiver to subscription
--- 4288,4293 ----
  $$ language plpgsql;
  
! comment on function @NAMESPACE@.subscribeSet_int (int4, int4, int4, bool, bool) is
! 'subscribeSet_int (sub_set, sub_provider, sub_receiver, sub_forward, omit_copy)
  
  Internal actions for subscribing receiver sub_receiver to subscription
***************
*** 4405,4409 ****
  
  -- ----------------------------------------------------------------------
! -- FUNCTION enableSubscription (sub_set, sub_provider, sub_receiver)
  -- ----------------------------------------------------------------------
  create or replace function @NAMESPACE@.enableSubscription (int4, int4, int4)
--- 4418,4422 ----
  
  -- ----------------------------------------------------------------------
! -- FUNCTION enableSubscription (sub_set, sub_provider, sub_receiver, omit_copy)
  -- ----------------------------------------------------------------------
  create or replace function @NAMESPACE@.enableSubscription (int4, int4, int4)
***************
*** 4427,4433 ****
  enableSubscription_int (sub_set, sub_provider, sub_receiver).';
  
! -- ----------------------------------------------------------------------
  -- FUNCTION enableSubscription_int (sub_set, sub_provider, sub_receiver)
! -- ----------------------------------------------------------------------
  create or replace function @NAMESPACE@.enableSubscription_int (int4, int4, int4)
  returns int4
--- 4440,4446 ----
  enableSubscription_int (sub_set, sub_provider, sub_receiver).';
  
! -- -----------------------------------------------------------------------------------
  -- FUNCTION enableSubscription_int (sub_set, sub_provider, sub_receiver)
! -- -----------------------------------------------------------------------------------
  create or replace function @NAMESPACE@.enableSubscription_int (int4, int4, int4)
  returns int4

From cbbrowne at lists.slony.info  Wed Jun 17 14:37:40 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jun 17 14:37:44 2009
Subject: [Slony1-commit] slony1-engine/doc/adminguide adminscripts.sgml
	intro.sgml slonik_ref.sgml slonyupgrade.sgml
Message-ID: <20090617213740.99AD82903B6@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/doc/adminguide
In directory main.slony.info:/tmp/cvs-serv2472/doc/adminguide

Modified Files:
      Tag: REL_2_0_STABLE
	adminscripts.sgml intro.sgml slonik_ref.sgml slonyupgrade.sgml 
Log Message:
Add in OMIT COPY option to SUBSCRIBE SET in support of upgrading from
elder Slony-I versions.


Index: slonyupgrade.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/slonyupgrade.sgml,v
retrieving revision 1.10
retrieving revision 1.10.2.1
diff -C2 -d -r1.10 -r1.10.2.1
*** slonyupgrade.sgml	15 Oct 2008 21:51:54 -0000	1.10
--- slonyupgrade.sgml	17 Jun 2009 21:37:38 -0000	1.10.2.1
***************
*** 254,257 ****
--- 254,364 ----
  
  </sect2>
+ 
+ <sect2 id="upgrade20"> <title> Upgrading to &slony1; version 2 </title>
+ 
+ <para> The version 2 branch is <emphasis>substantially</emphasis>
+ different from earlier releases, dropping support for versions of
+ &postgres; prior to 8.3, as in version 8.3, support for a
+ <quote>session replication role</quote> was added, thereby eliminating
+ the need for system catalog hacks as well as the
+ not-entirely-well-supported <envar>xxid</envar> data type. </para>
+ 
+ <para> As a result of the replacement of the <envar>xxid</envar> type
+ with a (native-to-8.3) &postgres; transaction XID type, the &lslonik;
+ command <xref linkend="stmtupdatefunctions"> is quite inadequate to
+ the process of upgrading earlier versions of &slony1; to version
+ 2.</para>
+ 
+ <para> In version 2.0.2, we have added a new option to <xref
+ linkend="stmtsubscribeset">, <command>OMIT COPY</command>, which
+ allows taking an alternative approach to upgrade which amounts to:</para>
+ 
+ <itemizedlist>
+ <listitem><para> Uninstall old version of &slony1; </para>
+ <para> When &slony1; uninstalls itself, catalog corruptions are fixed back up.</para> </listitem>
+ <listitem><para> Install &slony1; version 2 </para></listitem>
+ <listitem><para> Resubscribe, with <command>OMIT COPY</command></para></listitem>
+ </itemizedlist>
+ 
+ <warning><para> There is a large <quote>foot gun</quote> here: during
+ part of the process, &slony1; is not installed in any form, and if an
+ application updates one or another of the databases, the
+ resubscription, omitting copying data, will be left with data
+ <emphasis>out of sync.</emphasis> </para>
+ 
+ <para> The administrator <emphasis>must take care</emphasis>; &slony1;
+ has no way to help ensure the integrity of the data during this
+ process.</para>
+ </warning>
+ 
+ <para> The following process is suggested to help make the upgrade
+ process as safe as possible, given the above risks. </para>
+ 
+ <itemizedlist>
+ 
+ <listitem><para> Use <xref linkend="slonikconfdump"> to generate a
+ &lslonik; script to recreate the replication cluster.  </para>
+ 
+ <para> Be sure to verify the <xref linkend="admconninfo"> statements,
+ as the values are pulled are drawn from the PATH configuration, which
+ may not necessarily be suitable for running &lslonik;. </para>
+ 
+ <para> This step may be done before the application outage. </para>
+ </listitem>
+ 
+ <listitem><para> Determine what triggers have <xref
+ linkend="stmtstoretrigger"> configuration on subscriber nodes.
+ </para>
+ 
+ <para> As discussed in <xref linkend="triggers">, the handling has
+ fundamentally changed between &slony1; 1.2 and 2.0. </para>
+ 
+ <para> Generally speaking, what needs to happen is to query
+ <envar>sl_table</envar> on each node, and, for any triggers found in
+ <envar>sl_table</envar>, it is likely to be appropriate to set up a
+ script indicating either <command>ENABLE REPLICA TRIGGER</command> or
+ <command>ENABLE ALWAYS TRIGGER</command> for these triggers.</para>
+ 
+ <para> This step may be done before the application outage. </para>
+ </listitem>
+ 
+ <listitem><para> Begin an application outage during which updates should no longer be applied to the database. </para> </listitem>
+ 
+ <listitem><para> To ensure that applications cease to make changes, it would be appropriate to lock them out via modifications to <filename>pg_hba.conf</filename> </para> </listitem>
+ 
+ <listitem><para> Ensure replication is entirely caught up, via examination of the <envar>sl_status</envar> view, and any application data that may seem appropriate. </para> </listitem>
+ 
+ <listitem><para> Shut down &lslon; processes. </para> </listitem>
+ 
+ <listitem><para> Uninstall the old version of &slony1; from the database. </para> 
+ 
+ <para> This involves running a &lslonik; script that runs <xref
+ linkend="stmtuninstallnode"> against each node in the cluster. </para>
+ 
+ </listitem>
+ 
+ <listitem><para> Ensure new &slony1; binaries are in place. </para> 
+ 
+ <para> A convenient way to handle this is to have old and new in different directories alongside two &postgres; builds, stop the <application>postmaster</application>, repoint to the new directory, and restart the <application>postmaster</application>. </para>
+ </listitem>
+ 
+ <listitem><para> Run the script that reconfigures replication as generated earlier.  </para> 
+ 
+ <para> This script should probably be split into two portions to be run separately:</para> 
+ <itemizedlist>
+ <listitem><para> Firstly, set up nodes, paths, sets, and such </para> </listitem>
+ <listitem><para> At this point, start up &lslon; processes </para> </listitem>
+ <listitem><para> Then, run the portion which runs <xref linkend="stmtsubscribeset"> </para> </listitem>
+ </itemizedlist>
+ 
+ <para> Splitting the <xref linkend="slonikconfdump"> script as described above is left as an exercise for the reader.</para>
+ </listitem>
+ 
+ <listitem><para> If there were triggers that needed to be activated on subscriber nodes, this is the time to activate them. </para> </listitem>
+ <listitem><para> At this point, the cluster should be back up and running, ready to be reconfigured so that applications may access it again.  </para> </listitem>
+ 
+ </itemizedlist>
+ 
+ </sect2>
  </sect1>
  <!-- Keep this comment at the end of the file

Index: adminscripts.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/adminscripts.sgml,v
retrieving revision 1.52.2.4
retrieving revision 1.52.2.5
diff -C2 -d -r1.52.2.4 -r1.52.2.5
*** adminscripts.sgml	12 Jun 2009 22:42:13 -0000	1.52.2.4
--- adminscripts.sgml	17 Jun 2009 21:37:38 -0000	1.52.2.5
***************
*** 765,769 ****
  <para> The tool <filename>tools/slonikconfdump.sh</filename> was
  created to help dump out a &lslonik; script to duplicate the
! configuration of a functioning &slony1; cluster.</para>
  
  <para> It dumps out: </para>
--- 765,771 ----
  <para> The tool <filename>tools/slonikconfdump.sh</filename> was
  created to help dump out a &lslonik; script to duplicate the
! configuration of a functioning &slony1; cluster.  It should be
! particularly useful when upgrading &slony1; to version 2.0; see <xref
! linkend="upgrade20"> for more details.</para>
  
  <para> It dumps out: </para>
***************
*** 789,793 ****
  # Generated on:  Tue Jun 9 17:34:12 EDT 2009
  cluster name=slony_regress1;
! include <admin-conninfos.slonik>;  # Draw in ADMIN CONNINFO lines
  node 1 admin conninfo='dbname=slonyregress1 host=localhost user=chris port=7083';
  node 2 admin conninfo='dbname=slonyregress2 host=localhost user=chris port=7083';
--- 791,795 ----
  # Generated on:  Tue Jun 9 17:34:12 EDT 2009
  cluster name=slony_regress1;
! include &lt;admin-conninfos.slonik&gt;;  # Draw in ADMIN CONNINFO lines
  node 1 admin conninfo='dbname=slonyregress1 host=localhost user=chris port=7083';
  node 2 admin conninfo='dbname=slonyregress2 host=localhost user=chris port=7083';

Index: slonik_ref.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/slonik_ref.sgml,v
retrieving revision 1.92.2.6
retrieving revision 1.92.2.7
diff -C2 -d -r1.92.2.6 -r1.92.2.7
*** slonik_ref.sgml	16 Apr 2009 16:47:41 -0000	1.92.2.6
--- slonik_ref.sgml	17 Jun 2009 21:37:38 -0000	1.92.2.7
***************
*** 2122,2125 ****
--- 2122,2144 ----
  
        </varlistentry>
+       <varlistentry><term><literal> OMIT COPY = boolean </literal></term>
+        
+        <listitem><para> Flag whether or not the subscription process
+        should omit doing the <command>COPY</command> of the existing
+        data in the set.  In effect, use this option indicates
+        <quote>Trust me, the data is already in sync!</quote>
+        </para>
+ 
+        <para> This is notably useful for the following sorts of cases:
+        </para>
+ 
+        <itemizedlist>
+ 	<listitem><para> Major inter-version upgrades (<emphasis>e.g. </emphasis> - as from &slony1; 1.2 to 2.0) may be done quickly. </para> </listitem>
+ 	<listitem><para> Cloning a <quote>master node</quote>.  <xref linkend="stmtcloneprepare">/<xref linkend="stmtclonefinish">   </para> </listitem>
+ 	<listitem><para> </para> </listitem>
+        </itemizedlist>
+        </listitem>
+ 
+       </varlistentry>
       </variablelist>
      <para> This uses &funsubscribeset;. </para>
***************
*** 2211,2214 ****
--- 2230,2237 ----
       populated <emphasis>from scratch</emphasis>.</para> </listitem>
  
+      <listitem><para> The <command>OMIT COPY</command> option has the
+      potential to be a large <quote>foot gun</quote> in that it allows
+      the administrator to push replication sets out of sync. </para>
+      </listitem>
     </itemizedlist>
  
***************
*** 2229,2232 ****
--- 2252,2256 ----
     <refsect1> <title> Version Information </title>
      <para> This command was introduced in &slony1; 1.0 </para>
+     <para> The <command>OMIT COPY</command> option was introduced in &slony1; 2.0.3.</para>
     </refsect1>
    </refentry>
***************
*** 3093,3097 ****
      <title>Description</title>
      <para>
!      Prepares for cloning a specified node.
      </para>
  
--- 3117,3121 ----
      <title>Description</title>
      <para>
!      Prepares for cloning a specified subscriber node.
      </para>
  

Index: intro.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/intro.sgml,v
retrieving revision 1.29
retrieving revision 1.29.2.1
diff -C2 -d -r1.29 -r1.29.2.1
*** intro.sgml	25 Feb 2008 15:37:58 -0000	1.29
--- intro.sgml	17 Jun 2009 21:37:38 -0000	1.29.2.1
***************
*** 158,167 ****
  data in replicated tables.  In addition, any
  <emphasis>other</emphasis> triggers and rules on replicated tables are
! <emphasis>suppressed</emphasis> on the subscribers: This is done by
! pointing them, in the system table, to the primary key index instead
! of to the table itself.  This represents something of a
! <quote>corruption</quote> of the data dictionary, and is why you
! should not directly use <application>pg_dump</application> to dump
! schemas on subscribers. </para>
  
  <para>There is a capability for &slony1; to propagate other kinds of
--- 158,170 ----
  data in replicated tables.  In addition, any
  <emphasis>other</emphasis> triggers and rules on replicated tables are
! <emphasis>suppressed</emphasis> on the subscribers.  On versions of
! &slony1; prior to 2.0, this is done by pointing them, in the system
! table, to the primary key index instead of to the table itself, which
! represents a <quote>corruption</quote> of the data dictionary, and is
! why you should not directly use <application>pg_dump</application> to
! dump schemas on subscribers.  In version 2.0, this functionality is
! handled via native &postgres; functionality, so that with &slony1;
! 2.0+, <application>pg_dump</application> may be expected to work fine.
! </para>
  
  <para>There is a capability for &slony1; to propagate other kinds of
***************
*** 192,195 ****
--- 195,202 ----
  
  </itemizedlist></para>
+ 
+ <para> &slony1; does not automatically determine what sequences ought
+ to be replicated; you need to add them explicitly using <xref
+ linkend="stmtsetaddsequence">. </para>
  </sect2>
  

From cbbrowne at lists.slony.info  Wed Jun 17 14:37:40 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jun 17 14:37:44 2009
Subject: [Slony1-commit] slony1-engine/src/upgrade_to_20 README
	check_readiness.sh dbutil.c dump_config.sh lock_sets.sh
	slony_upgrade_20.c slony_upgrade_20.h upgrade_12_20_common.sh
	upgrade_12_20_part1.sh upgrade_function.sql
Message-ID: <20090617213740.A0C19290412@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/upgrade_to_20
In directory main.slony.info:/tmp/cvs-serv2472/src/upgrade_to_20

Removed Files:
      Tag: REL_2_0_STABLE
	README check_readiness.sh dbutil.c dump_config.sh lock_sets.sh 
	slony_upgrade_20.c slony_upgrade_20.h upgrade_12_20_common.sh 
	upgrade_12_20_part1.sh upgrade_function.sql 
Log Message:
Add in OMIT COPY option to SUBSCRIBE SET in support of upgrading from
elder Slony-I versions.


--- slony_upgrade_20.c DELETED ---

--- dbutil.c DELETED ---

--- dump_config.sh DELETED ---

--- upgrade_function.sql DELETED ---

--- check_readiness.sh DELETED ---

--- slony_upgrade_20.h DELETED ---

--- README DELETED ---

--- upgrade_12_20_common.sh DELETED ---

--- lock_sets.sh DELETED ---

--- upgrade_12_20_part1.sh DELETED ---

From cbbrowne at lists.slony.info  Wed Jun 17 14:37:40 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jun 17 14:37:45 2009
Subject: [Slony1-commit] slony1-engine/tests run_test.sh
Message-ID: <20090617213740.AE629290432@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tests
In directory main.slony.info:/tmp/cvs-serv2472/tests

Modified Files:
      Tag: REL_2_0_STABLE
	run_test.sh 
Log Message:
Add in OMIT COPY option to SUBSCRIBE SET in support of upgrading from
elder Slony-I versions.


Index: run_test.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/run_test.sh,v
retrieving revision 1.26.2.2
retrieving revision 1.26.2.3
diff -C2 -d -r1.26.2.2 -r1.26.2.3
*** run_test.sh	28 Apr 2009 21:48:19 -0000	1.26.2.2
--- run_test.sh	17 Jun 2009 21:37:38 -0000	1.26.2.3
***************
*** 294,298 ****
  		$pgbindir/createlang -h $host -U $user -p $port plpgsql $db
  		status "loading subscriber ${node} DB from $odb"
! 	        $opgbindir/pg_dump -s  -h $ohost -U $ouser -p $oport $odb | $pgbindir/psql -h $host -p $port $db $user 1> ${mktmp}/init_schema.sql.${node} 2> ${mktmp}/init_schema.sql.${node}
  		status "done"
                fi
--- 294,298 ----
  		$pgbindir/createlang -h $host -U $user -p $port plpgsql $db
  		status "loading subscriber ${node} DB from $odb"
! 	        $opgbindir/pg_dump -h $ohost -U $ouser -p $oport $odb | $pgbindir/psql -h $host -p $port $db $user 1> ${mktmp}/init_schema.sql.${node} 2> ${mktmp}/init_schema.sql.${node}
  		status "done"
                fi

From cbbrowne at lists.slony.info  Wed Jun 17 14:37:40 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jun 17 14:37:45 2009
Subject: [Slony1-commit] slony1-engine/src/slonik parser.y scan.l slonik.c
	slonik.h
Message-ID: <20090617213741.1DFA029043F@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slonik
In directory main.slony.info:/tmp/cvs-serv2472/src/slonik

Modified Files:
      Tag: REL_2_0_STABLE
	parser.y scan.l slonik.c slonik.h 
Log Message:
Add in OMIT COPY option to SUBSCRIBE SET in support of upgrading from
elder Slony-I versions.


Index: slonik.h
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/slonik.h,v
retrieving revision 1.34
retrieving revision 1.34.2.1
diff -C2 -d -r1.34 -r1.34.2.1
*** slonik.h	14 Feb 2008 22:21:42 -0000	1.34
--- slonik.h	17 Jun 2009 21:37:38 -0000	1.34.2.1
***************
*** 352,355 ****
--- 352,356 ----
  	int			sub_receiver;
  	int			sub_forward;
+ 	int			omit_copy;
  };
  

Index: parser.y
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/parser.y,v
retrieving revision 1.32
retrieving revision 1.32.2.1
diff -C2 -d -r1.32 -r1.32.2.1
*** parser.y	11 Apr 2008 15:44:23 -0000	1.32
--- parser.y	17 Jun 2009 21:37:38 -0000	1.32.2.1
***************
*** 37,40 ****
--- 37,41 ----
  	O_NODE_ID,
  	O_OLD_ORIGIN,
+ 	O_OMIT_COPY,
  	O_ORIGIN,
  	O_PROVIDER,
***************
*** 184,187 ****
--- 185,189 ----
  %token	K_CONNINFO
  %token	K_CONNRETRY
+ %token	K_COPY
  %token	K_CREATE
  %token	K_DROP
***************
*** 213,216 ****
--- 215,219 ----
  %token	K_OFF
  %token	K_OLD
+ %token  K_OMIT
  %token	K_ON
  %token	K_ONLY
***************
*** 1161,1164 ****
--- 1164,1168 ----
  							STMT_OPTION_INT( O_RECEIVER, -1 ),
  							STMT_OPTION_YN( O_FORWARD, 0 ),
+ 							STMT_OPTION_YN( O_OMIT_COPY, 0 ),
  							STMT_OPTION_END
  						};
***************
*** 1177,1180 ****
--- 1181,1185 ----
  							new->sub_receiver	= opt[2].ival;
  							new->sub_forward	= opt[3].ival;
+ 							new->omit_copy      = opt[4].ival;
  						}
  						else
***************
*** 1544,1547 ****
--- 1549,1557 ----
  						$$ = $4;
  					}
+ 					| K_OMIT K_COPY '=' option_item_yn
+ 					{
+ 						$4->opt_code	= O_OMIT_COPY;
+ 						$$ = $4;
+ 					}
  					| K_NEW K_ORIGIN '=' option_item_id
  					{
***************
*** 1800,1803 ****
--- 1810,1814 ----
  		case O_NODE_ID:			return "node id";
  		case O_OLD_ORIGIN:		return "old origin";
+ 		case O_OMIT_COPY:       return "omit copy";
  		case O_ORIGIN:			return "origin";
  		case O_PROVIDER:		return "provider";

Index: slonik.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/slonik.c,v
retrieving revision 1.91.2.1
retrieving revision 1.91.2.2
diff -C2 -d -r1.91.2.1 -r1.91.2.2
*** slonik.c	30 Apr 2009 15:46:15 -0000	1.91.2.1
--- slonik.c	17 Jun 2009 21:37:38 -0000	1.91.2.2
***************
*** 3426,3434 ****
  
  	slon_mkquery(&query,
! 				 "select \"_%s\".subscribeSet(%d, %d, %d, '%s'); ",
  				 stmt->hdr.script->clustername,
  				 stmt->sub_setid, stmt->sub_provider,
  				 stmt->sub_receiver,
! 				 (stmt->sub_forward) ? "t" : "f");
  	if (db_exec_evcommand((SlonikStmt *) stmt, adminfo1, &query) < 0)
  	{
--- 3426,3435 ----
  
  	slon_mkquery(&query,
! 				 "select \"_%s\".subscribeSet(%d, %d, %d, '%s', '%s'); ",
  				 stmt->hdr.script->clustername,
  				 stmt->sub_setid, stmt->sub_provider,
  				 stmt->sub_receiver,
! 				 (stmt->sub_forward) ? "t" : "f",
! 				 (stmt->omit_copy) ? "t" : "f");
  	if (db_exec_evcommand((SlonikStmt *) stmt, adminfo1, &query) < 0)
  	{

Index: scan.l
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/scan.l,v
retrieving revision 1.30
retrieving revision 1.30.2.1
diff -C2 -d -r1.30 -r1.30.2.1
*** scan.l	14 Feb 2008 22:21:42 -0000	1.30
--- scan.l	17 Jun 2009 21:37:38 -0000	1.30.2.1
***************
*** 72,75 ****
--- 72,76 ----
  backup			{ return K_BACKUP;			}
  client			{ return K_CLIENT;			}
+ copy			{ return K_COPY;			}
  clone			{ return K_CLONE;			}
  cluster			{ return K_CLUSTER;			}
***************
*** 109,112 ****
--- 110,114 ----
  off				{ return K_OFF;				}
  old				{ return K_OLD;				}
+ omit				{ return K_OMIT;				}
  on				{ return K_ON;				}
  only			{ return K_ONLY;			}

From cbbrowne at lists.slony.info  Thu Jun 18 09:52:24 2009
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jun 18 09:52:26 2009
Subject: [Slony1-commit] slony1-engine/tools slonikconfdump.sh
Message-ID: <20090618165224.4ABAA290432@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tools
In directory main.slony.info:/tmp/cvs-serv7258

Modified Files:
      Tag: REL_2_0_STABLE
	slonikconfdump.sh 
Log Message:
Cleanup of slonikconfdump.sh 
 - There were a couple bugs
 - Variables were quite badly named making it rather opaque


Index: slonikconfdump.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tools/Attic/slonikconfdump.sh,v
retrieving revision 1.1.2.3
retrieving revision 1.1.2.4
diff -C2 -d -r1.1.2.3 -r1.1.2.4
*** slonikconfdump.sh	12 Jun 2009 22:42:13 -0000	1.1.2.3
--- slonikconfdump.sh	18 Jun 2009 16:52:22 -0000	1.1.2.4
***************
*** 12,16 ****
  echo "cluster name=${SLONYCLUSTER};"
  
! function RQ () {
      local QUERY=$1
      RESULTSET=`psql -qtA -F ":" -R " " -c "${QUERY}"`
--- 12,16 ----
  echo "cluster name=${SLONYCLUSTER};"
  
! function RUNQUERY () {
      local QUERY=$1
      RESULTSET=`psql -qtA -F ":" -R " " -c "${QUERY}"`
***************
*** 35,133 ****
  
  Q="select distinct pa_server from ${SS}.sl_path order by pa_server;"
! PATHS=`RQ "${Q}"`
  for svr in `echo ${PATHS}`; do
!     SQ="select pa_conninfo from ${SS}.sl_path where pa_server=${svr} order by pa_client asc limit 1;"
!     conninfo=`RQ "${SQ}"`
      echo "node ${svr} admin conninfo='${conninfo}';"
  done
  
! Q="select no_id, no_comment from ${SS}.sl_node order by no_id limit 1;"
! 
! NODE1=`RQ "${Q}"`
  nn=`arg1 "${NODE1}"`
  comment=`arg2 ${NODE1}`
  echo "init cluster (id=${nn}, comment='${comment}');"
  
! Q="select no_id from ${SS}.sl_node order by no_id offset 1;"
! NODES=`RQ "${Q}"`
  for node in `echo ${NODES}`; do
!     CQ="select no_comment from ${SS}.sl_node where no_id = ${node};"
!     comment=`RQ "${CQ}"`
      echo "store node (id=${node}, comment='${comment}');"
  done
  
! Q="select pa_server, pa_client, pa_connretry from ${SS}.sl_path order by pa_server, pa_client;"
! PATHS=`RQ "${Q}"`
  for sc in `echo $PATHS`; do
      server=`arg1 $sc`
      client=`arg2 $sc`
      retry=`arg3 $sc`
!     Q2="select pa_conninfo from ${SS}.sl_path where pa_server=${server} and pa_client=${client};"
!     conninfo=`RQ "${Q2}"`
      echo "store path (server=${server}, client=${client}, conninfo='${conninfo}', connretry=${retry});"
  done
  
! Q="select set_id, set_origin from ${SS}.sl_set order by set_id;"
! SETS=`RQ "${Q}"`
  for sc in `echo ${SETS}`; do
      set=`arg1 ${sc}`
      origin=`arg2 ${sc}`
!     Q2="select set_comment from ${SS}.sl_set where set_id=${set};"
!     comment=`RQ "${Q2}"`
      echo "create set (id=${set}, origin=${origin}, comment='${comment}');"
  done
  
! Q="select tab_id,tab_set, set_origin from ${SS}.sl_table, ${SS}.sl_set where tab_set = set_id order by tab_id;"
! TABS=`RQ "${Q}"`
! for tb in `echo ${TABS}`; do
!     tab=`arg1 ${tb}`
!     set=`arg2 ${tb}`
!     origin=`arg3 ${tb}`
!     RQ="select tab_relname from ${SS}.sl_table where tab_id = ${tab};"
!     relname=`RQ "${RQ}"`
!     NSQ="select tab_nspname from ${SS}.sl_table where tab_id = ${tab};"
!     nsp=`RQ "${NSQ}"`
!     IDX="select tab_idxname from ${SS}.sl_table where tab_id = ${tab};"
!     idx=`RQ "${IDX}"`
!     COM="select tab_comment from ${SS}.sl_table where tab_id = ${tab};"
!     comment=`RQ "${COM}"`
      echo "set add table (id=${tab}, set id=${set}, origin=${origin}, fully qualified name='\"${nsp}\".\"${relname}\"', comment='${comment}, key='${idx}');"
  done
  
  
! Q="select seq_id,seq_set,set_origin from ${SS}.sl_sequence, ${SS}.sl_set where seq_set = set_id order by seq_id;"
! SEQS=`RQ "${Q}"`
  for sq in `echo ${SEQS}`; do
!     seq=`arg1 ${sq}`
!     set=`arg2 ${sq}`
      origin=`arg3 ${sq}`
!     RELQ="select seq_relname from ${SS}.sl_sequence where seq_id = ${seq};"
!     relname=`RQ "${RELQ}"`
!     NSQ="select seq_nspname from ${SS}.sl_sequence where seq_id = ${seq};"
!     nsp=`RQ "${NSQ}"`
!     COM="select seq_comment from ${SS}.sl_sequence where seq_id = ${seq};"
!     comment=`RQ "${COM}"`
!     echo "set add sequence(id=${seq}, set id=${set}, origin=${origin}, fully qualified name='\"${nsp}\".\"${relname}\"', comment='${comment}');"
  done
  
  Q="select set_id, set_origin from ${SS}.sl_set;"
! SETS=`RQ "${Q}"`
! for seti in `echo ${SETS}`; do
!     set=`arg1 ${seti}`
!     origins=`arg2 ${seti}`
      SUBQ="select sub_provider, sub_receiver from ${SS}.sl_subscribe where sub_set=${set};"
!     # We use tsort to determine a feasible ordering for subscriptions
      SUBRES=`psql -qtA -F " " -c "${SUBQ}" | tsort | egrep -v "^${origin}\$"`
      for recv in `echo ${SUBRES}`; do
! 	SF="select sub_provider, sub_forward from ${SS}.sl_subscribe where sub_set=${set} and sub_receiver=${recv};"
! 	SR=`RQ "${SF}"`
! 	prov=`arg1 ${SR}`
! 	forw=`arg2 ${SR}`
  	echo "subscribe set (id=${set}, provider=${prov}, receiver=${recv}, forward=${forw}, omit copy=true);"
  	if [ $prov != $origin ]; then
! 	    echo "wait for event (origin=$provider, confirmed=$origin, wait on=$provider, timeout=0);"
  	fi
! 	echo "sync (id=$origin);"
! 	echo "wait for event (origin=$origin, confirmed=ALL, wait on=$origin, timeout=0);"
      done
  done
--- 35,132 ----
  
  Q="select distinct pa_server from ${SS}.sl_path order by pa_server;"
! PATHS=`RUNQUERY "${Q}"`
  for svr in `echo ${PATHS}`; do
!     CONNINFOQ="select pa_conninfo from ${SS}.sl_path where pa_server=${svr} order by pa_client asc limit 1;"
!     conninfo=`RUNQUERY "${CONNINFOQ}"`
      echo "node ${svr} admin conninfo='${conninfo}';"
  done
  
! FIRSTNODEQ="select no_id, no_comment from ${SS}.sl_node order by no_id limit 1;"
! NODE1=`RUNQUERY "${FIRSTNODEQ}"`
  nn=`arg1 "${NODE1}"`
  comment=`arg2 ${NODE1}`
  echo "init cluster (id=${nn}, comment='${comment}');"
  
! RESTOFNODESQ="select no_id from ${SS}.sl_node where no_id <> ${nn};"
! NODES=`RUNQUERY "${RESTOFNODESQ}"`
  for node in `echo ${NODES}`; do
!     NODECOMMENT="select no_comment from ${SS}.sl_node where no_id = ${node};"
!     comment=`RUNQUERY "${NODECOMMENT}"`
      echo "store node (id=${node}, comment='${comment}');"
  done
  
! PATHSQ="select pa_server, pa_client, pa_connretry from ${SS}.sl_path order by pa_server, pa_client;"
! PATHS=`RUNQUERY "${PATHSQ}"`
  for sc in `echo $PATHS`; do
      server=`arg1 $sc`
      client=`arg2 $sc`
      retry=`arg3 $sc`
!     PATHCONN="select pa_conninfo from ${SS}.sl_path where pa_server=${server} and pa_client=${client};"
!     conninfo=`RUNQUERY "${PATHCONN}"`
      echo "store path (server=${server}, client=${client}, conninfo='${conninfo}', connretry=${retry});"
  done
  
! SETSQ="select set_id, set_origin from ${SS}.sl_set order by set_id;"
! SETS=`RUNQUERY "${SETSQ}"`
  for sc in `echo ${SETS}`; do
      set=`arg1 ${sc}`
      origin=`arg2 ${sc}`
!     SETCOMMENT="select set_comment from ${SS}.sl_set where set_id=${set};"
!     comment=`RUNQUERY "${SETCOMMENT}"`
      echo "create set (id=${set}, origin=${origin}, comment='${comment}');"
  done
  
! TABLESOVERVIEW="select tab_id,tab_set, set_origin from ${SS}.sl_table, ${SS}.sl_set where tab_set = set_id order by tab_id;"
! TABIDS=`RUNQUERY "${TABLESOVERVIEW}"`
! for tablebase in `echo ${TABIDS}`; do
!     tab=`arg1 ${tablebase}`
!     set=`arg2 ${tablebase}`
!     origin=`arg3 ${tablebase}`
!     TABNAME="select tab_relname from ${SS}.sl_table where tab_id = ${tab};"
!     relname=`RUNQUERY "${TABNAME}"`
!     TABNSP="select tab_nspname from ${SS}.sl_table where tab_id = ${tab};"
!     nsp=`RUNQUERY "${TABNSP}"`
!     TABIDX="select tab_idxname from ${SS}.sl_table where tab_id = ${tab};"
!     idx=`RUNQUERY "${TABIDX}"`
!     TABCOMMENT="select tab_comment from ${SS}.sl_table where tab_id = ${tab};"
!     comment=`RUNQUERY "${TABCOMMENT}"`
      echo "set add table (id=${tab}, set id=${set}, origin=${origin}, fully qualified name='\"${nsp}\".\"${relname}\"', comment='${comment}, key='${idx}');"
  done
  
  
! SEQSQ="select seq_id,seq_set,set_origin from ${SS}.sl_sequence, ${SS}.sl_set where seq_set = set_id order by seq_id;"
! SEQS=`RUNQUERY "${SEQSQ}"`
  for sq in `echo ${SEQS}`; do
!     seqid=`arg1 ${sq}`
!     setid=`arg2 ${sq}`
      origin=`arg3 ${sq}`
!     RELQ="select seq_relname from ${SS}.sl_sequence where seq_id = ${seqid};"
!     relname=`RUNQUERY "${RELQ}"`
!     NSQ="select seq_nspname from ${SS}.sl_sequence where seq_id = ${seqid};"
!     nsp=`RUNQUERY "${NSQ}"`
!     COMQ="select seq_comment from ${SS}.sl_sequence where seq_id = ${seqid};"
!     comment=`RUNQUERY "${COMQ}"`
!     echo "set add sequence(id=${seqid}, set id=${setid}, origin=${origin}, fully qualified name='\"${nsp}\".\"${relname}\"', comment='${comment}');"
  done
  
  Q="select set_id, set_origin from ${SS}.sl_set;"
! SETS=`RUNQUERY "${Q}"`
! for setinfo in `echo ${SETS}`; do
!     set=`arg1 ${setinfo}`
!     origin=`arg2 ${setinfo}`
      SUBQ="select sub_provider, sub_receiver from ${SS}.sl_subscribe where sub_set=${set};"
!     # We use tsort to determine a feasible ordering for subscriptions, filter8ng out the origin node
      SUBRES=`psql -qtA -F " " -c "${SUBQ}" | tsort | egrep -v "^${origin}\$"`
      for recv in `echo ${SUBRES}`; do
! 	PROVIDERSQUERY="select sub_provider, sub_forward from ${SS}.sl_subscribe where sub_set=${set} and sub_receiver=${recv};"
! 	SUBSCRIPTIONS=`RUNQUERY "${PROVIDERSQUERY}"`
! 	prov=`arg1 ${SUBSCRIPTIONS}`
! 	forw=`arg2 ${SUBSCRIPTIONS}`
  	echo "subscribe set (id=${set}, provider=${prov}, receiver=${recv}, forward=${forw}, omit copy=true);"
  	if [ $prov != $origin ]; then
! 	    echo "wait for event (origin=${prov}, confirmed=${origin}, wait on=${prov}, timeout=0);"
  	fi
! 	echo "sync (id=${origin});"
! 	echo "wait for event (origin=${origin}, confirmed=ALL, wait on=${origin}, timeout=0);"
      done
  done

