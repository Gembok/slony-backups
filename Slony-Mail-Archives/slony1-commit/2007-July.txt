From wieck at lists.slony.info  Tue Jul  3 05:45:25 2007
From: wieck at lists.slony.info (Jan Wieck)
Date: Tue Jul  3 05:45:27 2007
Subject: [Slony1-commit] slony1-engine/src/slon remote_worker.c
Message-ID: <20070703124525.A5A3F29041F@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv28653

Modified Files:
	remote_worker.c 
Log Message:
Changed log selection query to be less affected by long running
transaction. 

Jan


Index: remote_worker.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/remote_worker.c,v
retrieving revision 1.146
retrieving revision 1.147
diff -C2 -d -r1.146 -r1.147
*** remote_worker.c	27 Jun 2007 16:20:24 -0000	1.146
--- remote_worker.c	3 Jul 2007 12:45:23 -0000	1.147
***************
*** 3932,3940 ****
  			if (strlen(ssy_xip) != 0)
  				slon_appendquery(provider_qual,
! 								 "(log_xid >= '%s' and "
! 								 "%s.xxid_ge_snapshot(log_xid, '%s:%s:%q'))",
! 								 ssy_minxid,
! 								 rtcfg_namespace,
! 								 ssy_minxid, ssy_maxxid, ssy_xip);
  			else
  				slon_appendquery(provider_qual,
--- 3932,3938 ----
  			if (strlen(ssy_xip) != 0)
  				slon_appendquery(provider_qual,
! 								 "(log_xid >= '%s' or "
! 								 "log_xid IN (%s))",
! 								 ssy_maxxid, ssy_xip);
  			else
  				slon_appendquery(provider_qual,

From cbbrowne at lists.slony.info  Wed Jul  4 08:05:49 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jul  4 08:05:50 2007
Subject: [Slony1-commit] slony1-engine/tools/altperl show_configuration.pl
Message-ID: <20070704150549.765D12903C6@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tools/altperl
In directory main.slony.info:/tmp/cvs-serv26619

Removed Files:
	show_configuration.pl 
Log Message:
Per Peter Eisentraut, show_configuration.pl is redundant as there's also a
script called slony_show_configuration.pl that does the same thing.


--- show_configuration.pl DELETED ---

From cbbrowne at lists.slony.info  Wed Jul  4 08:10:42 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jul  4 08:10:43 2007
Subject: [Slony1-commit] slony1-engine/tools/altperl Makefile
Message-ID: <20070704151042.4D037290C0B@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tools/altperl
In directory main.slony.info:/tmp/cvs-serv26772

Modified Files:
	Makefile 
Log Message:
Per Peter Eisentraut

Use perlsharedir rather than pglibdir to indicate (in altperl tools) where
the main .pm file is installed.


Index: Makefile
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tools/altperl/Makefile,v
retrieving revision 1.15
retrieving revision 1.16
diff -C2 -d -r1.15 -r1.16
*** Makefile	6 Dec 2006 18:37:58 -0000	1.15
--- Makefile	4 Jul 2007 15:10:40 -0000	1.16
***************
*** 27,31 ****
  		$(SED) -e "s#@@PERL@@#$(PERL)#;" \
                         -e "s#@@SYSCONFDIR@@#$(sysconfdir)#;" \
!                        -e "s#@@PGLIBDIR@@#$(pglibdir)#;" \
                         -e "s#@@PGBINDIR@@#$(pgbindir)#;" \
                         -e "s#@@SLONBINDIR@@#$(slonbindir)#;" \
--- 27,31 ----
  		$(SED) -e "s#@@PERL@@#$(PERL)#;" \
                         -e "s#@@SYSCONFDIR@@#$(sysconfdir)#;" \
!                        -e "s#@@PGLIBDIR@@#$(pgsharedir)#;" \
                         -e "s#@@PGBINDIR@@#$(pgbindir)#;" \
                         -e "s#@@SLONBINDIR@@#$(slonbindir)#;" \

From wieck at lists.slony.info  Thu Jul  5 11:19:06 2007
From: wieck at lists.slony.info (Jan Wieck)
Date: Thu Jul  5 11:19:08 2007
Subject: [Slony1-commit] slony1-engine/src/ducttape test_1_pgbench.in
Message-ID: <20070705181906.88F99290C2D@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/ducttape
In directory main.slony.info:/tmp/cvs-serv2930/src/ducttape

Modified Files:
	test_1_pgbench.in 
Log Message:
Removed all support for STORE/DROP TRIGGER commands. Users are supposed
to use the ALTER TABLE [ENABLE|DISABLE] TRIGGER functionality in
Postgres from now on.

Jan


Index: test_1_pgbench.in
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/ducttape/test_1_pgbench.in,v
retrieving revision 1.4
retrieving revision 1.5
diff -C2 -d -r1.4 -r1.5
*** test_1_pgbench.in	8 Jun 2007 13:25:02 -0000	1.4
--- test_1_pgbench.in	5 Jul 2007 18:19:04 -0000	1.5
***************
*** 281,285 ****
  	sync (id = 11);
  	echo '**** waiting for node 22 to catch up';
! 	wait for event (origin = 11, confirmed = 22, wait on = 11);
  	echo '**** done.';
  _EOF_
--- 281,285 ----
  	sync (id = 11);
  	echo '**** waiting for node 22 to catch up';
! 	wait for event (origin = 11, confirmed = 22, wait on = 11, timeout = 0);
  	echo '**** done.';
  _EOF_

From wieck at lists.slony.info  Thu Jul  5 11:19:06 2007
From: wieck at lists.slony.info (Jan Wieck)
Date: Thu Jul  5 11:19:09 2007
Subject: [Slony1-commit] slony1-engine/src/slon cleanup_thread.c
	remote_worker.c
Message-ID: <20070705181906.A4038290C30@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv2930/src/slon

Modified Files:
	cleanup_thread.c remote_worker.c 
Log Message:
Removed all support for STORE/DROP TRIGGER commands. Users are supposed
to use the ALTER TABLE [ENABLE|DISABLE] TRIGGER functionality in
Postgres from now on.

Jan


Index: remote_worker.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/remote_worker.c,v
retrieving revision 1.147
retrieving revision 1.148
diff -C2 -d -r1.147 -r1.148
*** remote_worker.c	3 Jul 2007 12:45:23 -0000	1.147
--- remote_worker.c	5 Jul 2007 18:19:04 -0000	1.148
***************
*** 958,981 ****
  								 seq_id, new_set_id);
  			}
- 			else if (strcmp(event->ev_type, "STORE_TRIGGER") == 0)
- 			{
- 				int			trig_tabid = (int)strtol(event->ev_data1, NULL, 10);
- 				char	   *trig_tgname = event->ev_data2;
- 
- 				slon_appendquery(&query1,
- 								 "select %s.storeTrigger_int(%d, '%q'); ",
- 								 rtcfg_namespace,
- 								 trig_tabid, trig_tgname);
- 			}
- 			else if (strcmp(event->ev_type, "DROP_TRIGGER") == 0)
- 			{
- 				int			trig_tabid = (int)strtol(event->ev_data1, NULL, 10);
- 				char	   *trig_tgname = event->ev_data2;
- 
- 				slon_appendquery(&query1,
- 								 "select %s.dropTrigger_int(%d, '%q'); ",
- 								 rtcfg_namespace,
- 								 trig_tabid, trig_tgname);
- 			}
  			else if (strcmp(event->ev_type, "ACCEPT_SET") == 0)
  			{
--- 958,961 ----
***************
*** 2357,2363 ****
  	SlonDString indexregenquery;
  	int			ntuples1;
- 	int			ntuples2;
  	int			tupno1;
- 	int			tupno2;
  	PGresult   *res1;
  	PGresult   *res2;
--- 2337,2341 ----
***************
*** 2779,2829 ****
  
  		/*
- 		 * Copy the content of sl_trigger for this table
- 		 */
- 		(void) slon_mkquery(&query1,
- 					 "select trig_tgname from %s.sl_trigger "
- 					 "where trig_tabid = %d; ",
- 					 rtcfg_namespace, tab_id);
- 		res2 = PQexec(pro_dbconn, dstring_data(&query1));
- 		if (PQresultStatus(res2) != PGRES_TUPLES_OK)
- 		{
- 			slon_log(SLON_ERROR, "remoteWorkerThread_%d: \"%s\" %s\n",
- 					 node->no_id, dstring_data(&query1),
- 					 PQresultErrorMessage(res2));
- 			PQclear(res2);
- 			PQclear(res1);
- 			slon_disconnectdb(pro_conn);
- 			dstring_free(&query1);
- 			dstring_free(&query2);
- 			dstring_free(&query3);
- 			dstring_free(&lsquery);
- 			dstring_free(&indexregenquery);
- 			archive_terminate(node);
- 			return -1;
- 		}
- 		ntuples2 = PQntuples(res2);
- 		for (tupno2 = 0; tupno2 < ntuples2; tupno2++)
- 		{
- 			(void) slon_mkquery(&query1,
- 						 "select %s.storeTrigger(%d, '%q'); ",
- 					   rtcfg_namespace, tab_id, PQgetvalue(res2, tupno2, 0));
- 			if (query_execute(node, loc_dbconn, &query1) < 0)
- 			{
- 				PQclear(res2);
- 				PQclear(res1);
- 				slon_disconnectdb(pro_conn);
- 				dstring_free(&query1);
- 				dstring_free(&query2);
- 				dstring_free(&query3);
- 				dstring_free(&lsquery);
- 				dstring_free(&indexregenquery);
- 				archive_terminate(node);
- 				return -1;
- 			}
- 		}
- 		PQclear(res2);
- 
- 
- 		/*
  		 * Begin a COPY from stdin for the table on the local DB
  		 */
--- 2757,2760 ----
***************
*** 3799,3803 ****
  		{
  			int			sub_set = strtol(PQgetvalue(res1, tupno1, 0), NULL, 10);
- 			char	   *ssy_minxid = PQgetvalue(res1, tupno1, 2);
  			char	   *ssy_maxxid = PQgetvalue(res1, tupno1, 3);
  			char	   *ssy_xip = PQgetvalue(res1, tupno1, 4);
--- 3730,3733 ----

Index: cleanup_thread.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/cleanup_thread.c,v
retrieving revision 1.38
retrieving revision 1.39
diff -C2 -d -r1.38 -r1.39
*** cleanup_thread.c	27 Jun 2007 15:51:36 -0000	1.38
--- cleanup_thread.c	5 Jul 2007 18:19:04 -0000	1.39
***************
*** 35,56 ****
  static unsigned long get_earliest_xid(PGconn *dbconn);
  
- /* The list of tables that need to be vacuumed by Slony-I */
- /* @-nullassign @*/
- static char *table_list[] = {
- 	"%s.sl_event",
- 	"%s.sl_confirm",
- 	"%s.sl_setsync",
- 	"%s.sl_log_1",
- 	"%s.sl_log_2",
- 	"%s.sl_seqlog",
- 	"pg_catalog.pg_listener",
- 	"pg_catalog.pg_statistic",
- 	NULL  
- };
-  /* @end@ */
- 
- static char tstring[255];		/* string used to store table names for the
- 								 * VACUUM statements */
- 
  /* ----------
   * cleanupThread_main
--- 35,38 ----

From wieck at lists.slony.info  Thu Jul  5 11:19:06 2007
From: wieck at lists.slony.info (Jan Wieck)
Date: Thu Jul  5 11:19:09 2007
Subject: [Slony1-commit] slony1-engine/src/backend slony1_base.sql
	slony1_funcs.sql test_listen_path_gen.sql
Message-ID: <20070705181906.C4DB0290C31@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/backend
In directory main.slony.info:/tmp/cvs-serv2930/src/backend

Modified Files:
	slony1_base.sql slony1_funcs.sql test_listen_path_gen.sql 
Log Message:
Removed all support for STORE/DROP TRIGGER commands. Users are supposed
to use the ALTER TABLE [ENABLE|DISABLE] TRIGGER functionality in
Postgres from now on.

Jan


Index: test_listen_path_gen.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/backend/test_listen_path_gen.sql,v
retrieving revision 1.1
retrieving revision 1.2
diff -C2 -d -r1.1 -r1.2
*** test_listen_path_gen.sql	20 Mar 2006 22:20:48 -0000	1.1
--- test_listen_path_gen.sql	5 Jul 2007 18:19:04 -0000	1.2
***************
*** 103,107 ****
  -- 21 <-> 20 <-> 1 <-> 10 <-> 11
  
! truncate _slony_regress1.sl_set, _slony_regress1.sl_setsync, _slony_regress1.sl_table, _slony_regress1.sl_trigger, _slony_regress1.sl_sequence, _slony_regress1.sl_subscribe, _slony_regress1.sl_listen, _slony_regress1.sl_path, _slony_regress1.sl_node;
  
  insert into _slony_regress1.sl_node(no_id) values (1);
--- 103,107 ----
  -- 21 <-> 20 <-> 1 <-> 10 <-> 11
  
! truncate _slony_regress1.sl_set, _slony_regress1.sl_setsync, _slony_regress1.sl_table, _slony_regress1.sl_sequence, _slony_regress1.sl_subscribe, _slony_regress1.sl_listen, _slony_regress1.sl_path, _slony_regress1.sl_node;
  
  insert into _slony_regress1.sl_node(no_id) values (1);
***************
*** 146,150 ****
  -- v / \ v
  -- 3 5
! truncate _slony_regress1.sl_set, _slony_regress1.sl_setsync, _slony_regress1.sl_table, _slony_regress1.sl_trigger, _slony_regress1.sl_sequence, _slony_regress1.sl_subscribe, _slony_regress1.sl_listen, _slony_regress1.sl_path, _slony_regress1.sl_node;
  
  insert into _slony_regress1.sl_node(no_id) values (1);
--- 146,150 ----
  -- v / \ v
  -- 3 5
! truncate _slony_regress1.sl_set, _slony_regress1.sl_setsync, _slony_regress1.sl_table, _slony_regress1.sl_sequence, _slony_regress1.sl_subscribe, _slony_regress1.sl_listen, _slony_regress1.sl_path, _slony_regress1.sl_node;
  
  insert into _slony_regress1.sl_node(no_id) values (1);
***************
*** 169,173 ****
  --Test3
  --Fully meshed setup with 10 nodes
! truncate _slony_regress1.sl_set, _slony_regress1.sl_setsync, _slony_regress1.sl_table, _slony_regress1.sl_trigger, _slony_regress1.sl_sequence, _slony_regress1.sl_subscribe, _slony_regress1.sl_listen, _slony_regress1.sl_path, _slony_regress1.sl_node;
  
  insert into _slony_regress1.sl_node (no_id) select * from nodes;
--- 169,173 ----
  --Test3
  --Fully meshed setup with 10 nodes
! truncate _slony_regress1.sl_set, _slony_regress1.sl_setsync, _slony_regress1.sl_table, _slony_regress1.sl_sequence, _slony_regress1.sl_subscribe, _slony_regress1.sl_listen, _slony_regress1.sl_path, _slony_regress1.sl_node;
  
  insert into _slony_regress1.sl_node (no_id) select * from nodes;
***************
*** 187,191 ****
  --A transitiv graph with 10 nodes
  --This should warn about unreachable nodes
! truncate _slony_regress1.sl_set, _slony_regress1.sl_setsync, _slony_regress1.sl_table, _slony_regress1.sl_trigger, _slony_regress1.sl_sequence, _slony_regress1.sl_subscribe, _slony_regress1.sl_listen, _slony_regress1.sl_path, _slony_regress1.sl_node;
  
  insert into _slony_regress1.sl_node (no_id) select * from nodes;
--- 187,191 ----
  --A transitiv graph with 10 nodes
  --This should warn about unreachable nodes
! truncate _slony_regress1.sl_set, _slony_regress1.sl_setsync, _slony_regress1.sl_table, _slony_regress1.sl_sequence, _slony_regress1.sl_subscribe, _slony_regress1.sl_listen, _slony_regress1.sl_path, _slony_regress1.sl_node;
  
  insert into _slony_regress1.sl_node (no_id) select * from nodes;
***************
*** 204,208 ****
  --A (nearly) transitiv graph with 10 nodes, but with the missing
  --connection (1 -> 10) added.
! truncate _slony_regress1.sl_set, _slony_regress1.sl_setsync, _slony_regress1.sl_table, _slony_regress1.sl_trigger, _slony_regress1.sl_sequence, _slony_regress1.sl_subscribe, _slony_regress1.sl_listen, _slony_regress1.sl_path, _slony_regress1.sl_node;
  
  insert into _slony_regress1.sl_node (no_id) select * from nodes;
--- 204,208 ----
  --A (nearly) transitiv graph with 10 nodes, but with the missing
  --connection (1 -> 10) added.
! truncate _slony_regress1.sl_set, _slony_regress1.sl_setsync, _slony_regress1.sl_table, _slony_regress1.sl_sequence, _slony_regress1.sl_subscribe, _slony_regress1.sl_listen, _slony_regress1.sl_path, _slony_regress1.sl_node;
  
  insert into _slony_regress1.sl_node (no_id) select * from nodes;
***************
*** 225,229 ****
  -- 21 <-> 20 <-> 1 <-> 10 <-> 11
  
! truncate _slony_regress1.sl_set, _slony_regress1.sl_setsync, _slony_regress1.sl_table, _slony_regress1.sl_trigger, _slony_regress1.sl_sequence, _slony_regress1.sl_subscribe, _slony_regress1.sl_listen, _slony_regress1.sl_path, _slony_regress1.sl_node;
  
  insert into _slony_regress1.sl_node(no_id) values (1);
--- 225,229 ----
  -- 21 <-> 20 <-> 1 <-> 10 <-> 11
  
! truncate _slony_regress1.sl_set, _slony_regress1.sl_setsync, _slony_regress1.sl_table, _slony_regress1.sl_sequence, _slony_regress1.sl_subscribe, _slony_regress1.sl_listen, _slony_regress1.sl_path, _slony_regress1.sl_node;
  
  insert into _slony_regress1.sl_node(no_id) values (1);

Index: slony1_base.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/backend/slony1_base.sql,v
retrieving revision 1.34
retrieving revision 1.35
diff -C2 -d -r1.34 -r1.35
*** slony1_base.sql	27 Jun 2007 15:51:35 -0000	1.34
--- slony1_base.sql	5 Jul 2007 18:19:04 -0000	1.35
***************
*** 137,159 ****
  
  -- ----------------------------------------------------------------------
- -- TABLE sl_trigger
- -- ----------------------------------------------------------------------
- create table @NAMESPACE@.sl_trigger (
- 	trig_tabid			int4,
- 	trig_tgname			name,
- 
- 	CONSTRAINT "sl_trigger-pkey"
- 		PRIMARY KEY (trig_tabid, trig_tgname),
- 	CONSTRAINT "trig_tabid-tab_id-ref"
- 		FOREIGN KEY (trig_tabid)
- 		REFERENCES @NAMESPACE@.sl_table (tab_id)
- 		ON DELETE CASCADE
- ) WITHOUT OIDS;
- comment on table @NAMESPACE@.sl_trigger is 'Holds information about triggers on tables managed using Slony-I';
- comment on column @NAMESPACE@.sl_trigger.trig_tabid is 'Slony-I ID number of table the trigger is on';
- comment on column @NAMESPACE@.sl_trigger.trig_tgname is 'Indicates the name of a trigger';
- 
- 
- -- ----------------------------------------------------------------------
  -- TABLE sl_sequence
  -- ----------------------------------------------------------------------
--- 137,140 ----

Index: slony1_funcs.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/backend/slony1_funcs.sql,v
retrieving revision 1.113
retrieving revision 1.114
diff -C2 -d -r1.113 -r1.114
*** slony1_funcs.sql	27 Jun 2007 15:51:35 -0000	1.113
--- slony1_funcs.sql	5 Jul 2007 18:19:04 -0000	1.114
***************
*** 3443,3584 ****
  
  -- ----------------------------------------------------------------------
- -- FUNCTION storeTrigger (trig_tabid, trig_tgname)
- -- ----------------------------------------------------------------------
- create or replace function @NAMESPACE@.storeTrigger (int4, name)
- returns bigint
- as '
- declare
- 	p_trig_tabid		alias for $1;
- 	p_trig_tgname		alias for $2;
- begin
- 	perform @NAMESPACE@.storeTrigger_int(p_trig_tabid, p_trig_tgname);
- 	return  @NAMESPACE@.createEvent(''_@CLUSTERNAME@'', ''STORE_TRIGGER'',
- 			p_trig_tabid::text, p_trig_tgname::text);
- end;
- ' language plpgsql;
- comment on function @NAMESPACE@.storeTrigger (int4, name) is
- 'storeTrigger (trig_tabid, trig_tgname)
- 
- Submits STORE_TRIGGER event to indicate that trigger trig_tgname on
- replicated table trig_tabid will NOT be disabled.';
- 
- -- ----------------------------------------------------------------------
- -- FUNCTION storeTrigger_int (trig_tabid, trig_tgname)
- -- ----------------------------------------------------------------------
- create or replace function @NAMESPACE@.storeTrigger_int (int4, name)
- returns int4
- as '
- declare
- 	p_trig_tabid		alias for $1;
- 	p_trig_tgname		alias for $2;
- 	v_tab_altered		boolean;
- begin
- 	-- ----
- 	-- Grab the central configuration lock
- 	-- ----
- 	lock table @NAMESPACE@.sl_config_lock;
- 
- 	-- ----
- 	-- Get the current table status (altered or not)
- 	-- ----
- 	select tab_altered into v_tab_altered
- 			from @NAMESPACE@.sl_table where tab_id = p_trig_tabid;
- 	if not found then
- 		-- ----
- 		-- Not found is no hard error here, because that might
- 		-- mean that we are not subscribed to that set
- 		-- ----
- 		return 0;
- 	end if;
- 
- 	-- ----
- 	-- Make sure that an entry for this trigger exists
- 	-- ----
- 	delete from @NAMESPACE@.sl_trigger
- 			where trig_tabid = p_trig_tabid
- 			  and trig_tgname = p_trig_tgname;
- 	insert into @NAMESPACE@.sl_trigger (
- 				trig_tabid, trig_tgname
- 			) values (
- 				p_trig_tabid, p_trig_tgname
- 			);
- 
- 	return p_trig_tabid;
- end;
- ' language plpgsql;
- comment on function @NAMESPACE@.storeTrigger_int (int4, name) is
- 'storeTrigger_int (trig_tabid, trig_tgname)
- 
- Processes STORE_TRIGGER event to make sure that trigger trig_tgname on
- replicated table trig_tabid is NOT disabled.';
- 
- -- ----------------------------------------------------------------------
- -- FUNCTION dropTrigger (trig_tabid, trig_tgname)
- -- ----------------------------------------------------------------------
- create or replace function @NAMESPACE@.dropTrigger (int4, name)
- returns bigint
- as '
- declare
- 	p_trig_tabid		alias for $1;
- 	p_trig_tgname		alias for $2;
- begin
- 	perform @NAMESPACE@.dropTrigger_int(p_trig_tabid, p_trig_tgname);
- 	return  @NAMESPACE@.createEvent(''_@CLUSTERNAME@'', ''DROP_TRIGGER'',
- 			p_trig_tabid::text, p_trig_tgname::text);
- end;
- ' language plpgsql;
- comment on function @NAMESPACE@.dropTrigger (int4, name) is
- 'dropTrigger (trig_tabid, trig_tgname)
- 
- Submits DROP_TRIGGER event to indicate that trigger trig_tgname on
- replicated table trig_tabid WILL be disabled.';
- 
- 
- -- ----------------------------------------------------------------------
- -- FUNCTION dropTrigger_int (trig_tabid, trig_tgname)
- -- ----------------------------------------------------------------------
- create or replace function @NAMESPACE@.dropTrigger_int (int4, name)
- returns int4
- as '
- declare
- 	p_trig_tabid		alias for $1;
- 	p_trig_tgname		alias for $2;
- 	v_tab_altered		boolean;
- begin
- 	-- ----
- 	-- Grab the central configuration lock
- 	-- ----
- 	lock table @NAMESPACE@.sl_config_lock;
- 
- 	-- ----
- 	-- Get the current table status (altered or not)
- 	-- ----
- 	select tab_altered into v_tab_altered
- 			from @NAMESPACE@.sl_table where tab_id = p_trig_tabid;
- 	if not found then
- 		-- ----
- 		-- Not found is no hard error here, because that might
- 		-- mean that we are not subscribed to that set
- 		-- ----
- 		return 0;
- 	end if;
- 
- 	-- ----
- 	-- Remove the entry from sl_trigger
- 	-- ----
- 	delete from @NAMESPACE@.sl_trigger
- 			where trig_tabid = p_trig_tabid
- 			  and trig_tgname = p_trig_tgname;
- 
- 	return p_trig_tabid;
- end;
- ' language plpgsql;
- comment on function @NAMESPACE@.dropTrigger_int (int4, name) is
- 'dropTrigger_int (trig_tabid, trig_tgname)
- 
- Processes DROP_TRIGGER event to make sure that trigger trig_tgname on
- replicated table trig_tabid IS disabled.';
- 
- -- ----------------------------------------------------------------------
  -- FUNCTION ddlScript_prepare (set_id, only_on_node)
  --
--- 3443,3446 ----

From wieck at lists.slony.info  Thu Jul  5 11:19:06 2007
From: wieck at lists.slony.info (Jan Wieck)
Date: Thu Jul  5 11:19:09 2007
Subject: [Slony1-commit] slony1-engine/src/slonik parser.y scan.l slonik.c
	slonik.h
Message-ID: <20070705181907.727EE290C30@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slonik
In directory main.slony.info:/tmp/cvs-serv2930/src/slonik

Modified Files:
	parser.y scan.l slonik.c slonik.h 
Log Message:
Removed all support for STORE/DROP TRIGGER commands. Users are supposed
to use the ALTER TABLE [ENABLE|DISABLE] TRIGGER functionality in
Postgres from now on.

Jan


Index: slonik.h
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/slonik.h,v
retrieving revision 1.31
retrieving revision 1.32
diff -C2 -d -r1.31 -r1.32
*** slonik.h	5 Jun 2007 22:22:07 -0000	1.31
--- slonik.h	5 Jul 2007 18:19:04 -0000	1.32
***************
*** 38,43 ****
  typedef struct SlonikStmt_set_move_table_s SlonikStmt_set_move_table;
  typedef struct SlonikStmt_set_move_sequence_s SlonikStmt_set_move_sequence;
- typedef struct SlonikStmt_store_trigger_s SlonikStmt_store_trigger;
- typedef struct SlonikStmt_drop_trigger_s SlonikStmt_drop_trigger;
  typedef struct SlonikStmt_subscribe_set_s SlonikStmt_subscribe_set;
  typedef struct SlonikStmt_unsubscribe_set_s SlonikStmt_unsubscribe_set;
--- 38,41 ----
***************
*** 61,65 ****
  	STMT_DROP_PATH,
  	STMT_DROP_SET,
- 	STMT_DROP_TRIGGER,
  	STMT_ECHO,
  	STMT_EXIT,
--- 59,62 ----
***************
*** 80,84 ****
  	STMT_STORE_NODE,
  	STMT_STORE_PATH,
- 	STMT_STORE_TRIGGER,
  	STMT_SUBSCRIBE_SET,
  	STMT_UNINSTALL_NODE,
--- 77,80 ----
***************
*** 329,350 ****
  
  
- struct SlonikStmt_store_trigger_s
- {
- 	SlonikStmt	hdr;
- 	int			trig_tabid;
- 	char	   *trig_tgname;
- 	int			ev_origin;
- };
- 
- 
- struct SlonikStmt_drop_trigger_s
- {
- 	SlonikStmt	hdr;
- 	int			trig_tabid;
- 	char	   *trig_tgname;
- 	int			ev_origin;
- };
- 
- 
  struct SlonikStmt_subscribe_set_s
  {
--- 325,328 ----
***************
*** 548,553 ****
  extern int	slonik_set_move_table(SlonikStmt_set_move_table * stmt);
  extern int	slonik_set_move_sequence(SlonikStmt_set_move_sequence * stmt);
- extern int	slonik_store_trigger(SlonikStmt_store_trigger * stmt);
- extern int	slonik_drop_trigger(SlonikStmt_drop_trigger * stmt);
  extern int	slonik_subscribe_set(SlonikStmt_subscribe_set * stmt);
  extern int	slonik_unsubscribe_set(SlonikStmt_unsubscribe_set * stmt);
--- 526,529 ----

Index: parser.y
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/parser.y,v
retrieving revision 1.28
retrieving revision 1.29
diff -C2 -d -r1.28 -r1.29
*** parser.y	18 Apr 2007 15:03:51 -0000	1.28
--- parser.y	5 Jul 2007 18:19:04 -0000	1.29
***************
*** 148,153 ****
  %type <statement>	stmt_set_move_table
  %type <statement>	stmt_set_move_sequence
- %type <statement>	stmt_store_trigger
- %type <statement>	stmt_drop_trigger
  %type <statement>	stmt_subscribe_set
  %type <statement>	stmt_unsubscribe_set
--- 148,151 ----
***************
*** 234,238 ****
  %token	K_TABLE
  %token	K_TIMEOUT
- %token	K_TRIGGER
  %token	K_TRUE
  %token	K_TRY
--- 232,235 ----
***************
*** 458,465 ****
  					| stmt_set_move_sequence
  						{ $$ = $1; }
- 					| stmt_store_trigger
- 						{ $$ = $1; }
- 					| stmt_drop_trigger
- 						{ $$ = $1; }
  					| stmt_subscribe_set
  						{ $$ = $1; }
--- 455,458 ----
***************
*** 1098,1161 ****
  					;
  
- stmt_store_trigger	: lno K_STORE K_TRIGGER option_list
- 					{
- 						SlonikStmt_store_trigger *new;
- 						statement_option opt[] = {
- 							STMT_OPTION_INT( O_TAB_ID, -1 ),
- 							STMT_OPTION_STR( O_TRIG_NAME, NULL ),
- 							STMT_OPTION_INT( O_EVENT_NODE, 1 ),
- 							STMT_OPTION_END
- 						};
- 
- 						new = (SlonikStmt_store_trigger *)
- 								malloc(sizeof(SlonikStmt_store_trigger));
- 						memset(new, 0, sizeof(SlonikStmt_store_trigger));
- 						new->hdr.stmt_type		= STMT_STORE_TRIGGER;
- 						new->hdr.stmt_filename	= current_file;
- 						new->hdr.stmt_lno		= $1;
- 
- 						if (assign_options(opt, $4) == 0)
- 						{
- 							new->trig_tabid		= opt[0].ival;
- 							new->trig_tgname	= opt[1].str;
- 							new->ev_origin		= opt[2].ival;
- 						}
- 						else
- 							parser_errors++;
- 
- 						$$ = (SlonikStmt *)new;
- 					}
- 					;
- 
- stmt_drop_trigger	: lno K_DROP K_TRIGGER option_list
- 					{
- 						SlonikStmt_drop_trigger *new;
- 						statement_option opt[] = {
- 							STMT_OPTION_INT( O_TAB_ID, -1 ),
- 							STMT_OPTION_STR( O_TRIG_NAME, NULL ),
- 							STMT_OPTION_INT( O_EVENT_NODE, 1 ),
- 							STMT_OPTION_END
- 						};
- 
- 						new = (SlonikStmt_drop_trigger *)
- 								malloc(sizeof(SlonikStmt_drop_trigger));
- 						memset(new, 0, sizeof(SlonikStmt_drop_trigger));
- 						new->hdr.stmt_type		= STMT_DROP_TRIGGER;
- 						new->hdr.stmt_filename	= current_file;
- 						new->hdr.stmt_lno		= $1;
- 
- 						if (assign_options(opt, $4) == 0)
- 						{
- 							new->trig_tabid		= opt[0].ival;
- 							new->trig_tgname	= opt[1].str;
- 							new->ev_origin		= opt[2].ival;
- 						}
- 						else
- 							parser_errors++;
- 
- 						$$ = (SlonikStmt *)new;
- 					}
- 					;
- 
  stmt_subscribe_set	: lno K_SUBSCRIBE K_SET option_list
  					{
--- 1091,1094 ----
***************
*** 1605,1613 ****
  						$$ = $4;
  					}
- 					| K_TRIGGER K_NAME '=' option_item_literal
- 					{
- 						$4->opt_code	= O_TRIG_NAME;
- 						$$ = $4;
- 					}
  					| K_FULL K_QUALIFIED K_NAME '=' option_item_literal
  					{
--- 1538,1541 ----
***************
*** 1825,1829 ****
  		case O_TAB_ID:			return "table id";
  		case O_TIMEOUT:			return "timeout";
- 		case O_TRIG_NAME:		return "trigger name";
  		case O_USE_KEY:			return "key";
  		case O_WAIT_CONFIRMED:	return "confirmed";
--- 1753,1756 ----

Index: slonik.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/slonik.c,v
retrieving revision 1.78
retrieving revision 1.79
diff -C2 -d -r1.78 -r1.79
*** slonik.c	5 Jun 2007 22:22:07 -0000	1.78
--- slonik.c	5 Jul 2007 18:19:04 -0000	1.79
***************
*** 769,830 ****
  
  
- 			case STMT_STORE_TRIGGER:
- 				{
- 					SlonikStmt_store_trigger *stmt =
- 					(SlonikStmt_store_trigger *) hdr;
- 
- 					if (stmt->ev_origin < 0)
- 					{
- 						stmt->ev_origin = 1;
- 					}
- 					if (stmt->trig_tabid < 0)
- 					{
- 						printf("%s:%d: Error: "
- 							   "table id must be specified\n",
- 							   hdr->stmt_filename, hdr->stmt_lno);
- 						errors++;
- 					}
- 					if (stmt->trig_tgname == NULL)
- 					{
- 						printf("%s:%d: Error: "
- 							   "trigger name must be specified\n",
- 							   hdr->stmt_filename, hdr->stmt_lno);
- 						errors++;
- 					}
- 
- 					if (script_check_adminfo(hdr, stmt->ev_origin) < 0)
- 						errors++;
- 				}
- 				break;
- 
- 			case STMT_DROP_TRIGGER:
- 				{
- 					SlonikStmt_drop_trigger *stmt =
- 					(SlonikStmt_drop_trigger *) hdr;
- 
- 					if (stmt->ev_origin < 0)
- 					{
- 						stmt->ev_origin = 1;
- 					}
- 					if (stmt->trig_tabid < 0)
- 					{
- 						printf("%s:%d: Error: "
- 							   "table id must be specified\n",
- 							   hdr->stmt_filename, hdr->stmt_lno);
- 						errors++;
- 					}
- 					if (stmt->trig_tgname == NULL)
- 					{
- 						printf("%s:%d: Error: "
- 							   "trigger name must be specified\n",
- 							   hdr->stmt_filename, hdr->stmt_lno);
- 						errors++;
- 					}
- 
- 					if (script_check_adminfo(hdr, stmt->ev_origin) < 0)
- 						errors++;
- 				}
- 				break;
- 
  			case STMT_SUBSCRIBE_SET:
  				{
--- 769,772 ----
***************
*** 1403,1426 ****
  				break;
  
- 			case STMT_STORE_TRIGGER:
- 				{
- 					SlonikStmt_store_trigger *stmt =
- 					(SlonikStmt_store_trigger *) hdr;
- 
- 					if (slonik_store_trigger(stmt) < 0)
- 						errors++;
- 				}
- 				break;
- 
- 			case STMT_DROP_TRIGGER:
- 				{
- 					SlonikStmt_drop_trigger *stmt =
- 					(SlonikStmt_drop_trigger *) hdr;
- 
- 					if (slonik_drop_trigger(stmt) < 0)
- 						errors++;
- 				}
- 				break;
- 
  			case STMT_SUBSCRIBE_SET:
  				{
--- 1345,1348 ----
***************
*** 3394,3457 ****
  
  int
- slonik_store_trigger(SlonikStmt_store_trigger * stmt)
- {
- 	SlonikAdmInfo *adminfo1;
- 	SlonDString query;
- 
- 	adminfo1 = get_active_adminfo((SlonikStmt *) stmt, stmt->ev_origin);
- 	if (adminfo1 == NULL)
- 		return -1;
- 
- 	if (db_begin_xact((SlonikStmt *) stmt, adminfo1) < 0)
- 		return -1;
- 
- 	dstring_init(&query);
- 
- 	slon_mkquery(&query,
- 				 "select \"_%s\".storeTrigger(%d, '%q'); ",
- 				 stmt->hdr.script->clustername,
- 				 stmt->trig_tabid, stmt->trig_tgname);
- 	if (db_exec_evcommand((SlonikStmt *) stmt, adminfo1, &query) < 0)
- 	{
- 		dstring_free(&query);
- 		return -1;
- 	}
- 
- 	dstring_free(&query);
- 	return 0;
- }
- 
- 
- int
- slonik_drop_trigger(SlonikStmt_drop_trigger * stmt)
- {
- 	SlonikAdmInfo *adminfo1;
- 	SlonDString query;
- 
- 	adminfo1 = get_active_adminfo((SlonikStmt *) stmt, stmt->ev_origin);
- 	if (adminfo1 == NULL)
- 		return -1;
- 
- 	if (db_begin_xact((SlonikStmt *) stmt, adminfo1) < 0)
- 		return -1;
- 
- 	dstring_init(&query);
- 
- 	slon_mkquery(&query,
- 				 "select \"_%s\".dropTrigger(%d, '%q'); ",
- 				 stmt->hdr.script->clustername,
- 				 stmt->trig_tabid, stmt->trig_tgname);
- 	if (db_exec_evcommand((SlonikStmt *) stmt, adminfo1, &query) < 0)
- 	{
- 		dstring_free(&query);
- 		return -1;
- 	}
- 
- 	dstring_free(&query);
- 	return 0;
- }
- 
- 
- int
  slonik_subscribe_set(SlonikStmt_subscribe_set * stmt)
  {
--- 3316,3319 ----

Index: scan.l
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/scan.l,v
retrieving revision 1.27
retrieving revision 1.28
diff -C2 -d -r1.27 -r1.28
*** scan.l	18 Apr 2007 15:03:51 -0000	1.27
--- scan.l	5 Jul 2007 18:19:04 -0000	1.28
***************
*** 130,134 ****
  table			{ return K_TABLE;			}
  timeout			{ return K_TIMEOUT;			}
- trigger			{ return K_TRIGGER;			}
  true			{ return K_TRUE;			}
  try				{ return K_TRY;				}
--- 130,133 ----

From cbbrowne at lists.slony.info  Thu Jul  5 12:50:03 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jul  5 12:50:05 2007
Subject: [Slony1-commit] slony1-engine TODO
Message-ID: <20070705195003.6E42A290C39@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine
In directory main.slony.info:/tmp/cvs-serv8215

Modified Files:
	TODO 
Log Message:
Added a LOT of items to the not-much-updated TODO list


Index: TODO
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/TODO,v
retrieving revision 1.3
retrieving revision 1.4
diff -C2 -d -r1.3 -r1.4
*** TODO	15 Apr 2005 19:33:15 -0000	1.3
--- TODO	5 Jul 2007 19:50:01 -0000	1.4
***************
*** 1,4 ****
! * Documentation
! ----------------
  
! -Provide instructions on how to upgrade from 1.0 to 1.1
--- 1,120 ----
! ToDo List for Slony-I
! -----------------------------------------
  
! $Id$
! 
! Documentation Improvements
! --------------------------------------------
! 
! - Document how to fix tables that presently use Slony-I-generated
!   primary key candidates generated by TABLE ADD KEY
! 
! - Removed all support for STORE/DROP TRIGGER commands. Users are
!   supposed to use the ALTER TABLE [ENABLE|DISABLE] TRIGGER
!   functionality in Postgres from now on.
! 
! 
! Short Term Items
! ---------------------------
! 
! CANCEL SUBSCRIPTION
!    <http://lists.slony.info/pipermail/slony1-hackers/2007-May/000011.html>
! 
! Improve script that tries to run UPDATE FUNCTIONS across versions to
! verify that upgrades work properly.
! 
! Improve Wiki page generation script so that it has an option to add in
! a set of [[Category:Foo]] tags to allow automated categorization.
! 
! 
! Bill Moran had some timestamps that were not handled well; should make
! sure that these specific timestamps are included in our test cases...
! 
! 03/12/2007 11:05:32.913154 edt vs. 03/12/2007 10:05:32.913154 est
! 03/14/2007 17:39:28.595669 edt vs. 03/14/2007 16:39:28.595669 est
! 03/28/2007 14:45:55.75936 edt  vs. 03/28/2007 13:45:55.75936 est
! 03/29/2007 13:35:19.960505 edt vs. 03/29/2007 12:35:19.960505 est
! 
! - Add Drew Hammond's "mkservice" scripts to the 1.2 branch
! 
! - update autoconf to be better aware of where DocBook document
!   generation tools live
! 
! Longer Term Items
! ---------------------------
! 
! - Add more tests (what???) to test_slony_state script(s).
! 
!   e.g. - add a warning if there exist tables with generated PK.
! 
! - Use PGXS
! 
! - Windows-compatible version of tools/slony1_dump.sh
! 
! - Clone Node - use pg_dump/PITR to populate a new subscriber node
! 
! Wishful Thinking
! ----------------------------
! 
! SYNC pipelining
! 
!   - the notion here is to open two connections to the source DB, and
!     to start running the queries to generate the next LOG cursor while
!     the previous request is pushing INSERT/UPDATE/DELETE requests to
!     the subscriber.
! 
! COPY pipelining
! 
!   - the notion here is to try to parallelize the data load at
!     SUBSCRIBE time.  Suppose we decide we can process 4 tables at a
!     time, we set up 4 threads.  We then iterate thus:
! 
!     For each table
!        - acquire a thread (waiting as needed)
!        - submit COPY TO stdout to the provider, and feed to 
!          COPY FROM stdin on the subscriber
!        - Submit the REINDEX request on the subscriber
! 
!     Even with a fairly small number of threads, we should be able to
!     process the whole subscription in as long as it takes to process
!     the single largest table.
! 
!     This introduces a risk of locking problems not true at present
!     (alas) in that, at present, the subscription process is able to
!     demand exclusive locks on all tables up front; that is no longer
!     possible if the subscriptions are split across multiple tables.
!     In addition, the updates will COMMIT across some period of time on
!     the subscriber rather than appearing at one instant in time.
! 
!     The timing improvement is probably still worthwhile.
! 
!     http://lists.slony.info/pipermail/slony1-hackers/2007-April/000000.html
! 
! Slonik ALTER TABLE event
! 
!     This would permit passing through changes targeted at a single
!     table, and require much less extensive locking than traditional
!     EXECUTE SCRIPT.
! 
! Compress DELETE/UPDATE/INSERT requests
! 
!     Some performance benefits could be gotten by compressing sets of
!     DELETEs on the same table into a single DELETE statement.  This
!     doesn't help the time it takes to fire triggers on the origin, but
!     can speed the process of "mass" deleting records on subscribers.
! 
!     <http://lists.slony.info/pipermail/slony1-general/2007-July/006249.html>
! 
!     Unfortunately, this would complicate the application code, which
!     people agreed would be a net loss...
! 
!     <http://lists.slony.info/pipermail/slony1-general/2007-July/006267.html>
! 
! Data Transformations on Subscriber
! 
!     Have an alternative "logtrigger()" scheme which permits creating a
!     custom logtrigger function that can read both OLD.* and NEW.* and
!     assortedly:
! 
!     - Omit columns on a subscriber
!     - Omit tuples

From cbbrowne at lists.slony.info  Thu Jul  5 13:52:08 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jul  5 13:52:09 2007
Subject: [Slony1-commit] slony1-engine/tools mkmediawiki.pl
Message-ID: <20070705205208.D3B50290C41@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tools
In directory main.slony.info:/tmp/cvs-serv10795/tools

Modified Files:
	mkmediawiki.pl 
Log Message:
Add in [[Category:foo]] support for automagic indexing to mkmediawiki.pl script


Index: mkmediawiki.pl
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tools/mkmediawiki.pl,v
retrieving revision 1.1
retrieving revision 1.2
diff -C2 -d -r1.1 -r1.2
*** mkmediawiki.pl	24 Jan 2007 15:43:01 -0000	1.1
--- mkmediawiki.pl	5 Jul 2007 20:52:06 -0000	1.2
***************
*** 29,33 ****
    "m|mailprog=s" => \$mailprog,
    "f|finalquery=s" => \$finalquery,
!   "r|recipient=s" => \$recipient);
  
  if (defined($help)) {
--- 29,34 ----
    "m|mailprog=s" => \$mailprog,
    "f|finalquery=s" => \$finalquery,
!   "r|recipient=s" => \$recipient,
!   "g|categories=s" => \$categories);
  
  if (defined($help)) {
***************
*** 161,164 ****
--- 162,166 ----
  }
  &mktblfooter();
+ &gencategories();
  
  sub gennodeline {
***************
*** 203,207 ****
      print $inerr, "\n";
    }
!   die "$0  --host --database --user --cluster --port=integer --password --recipient --mailprog\nnote also that libpq environment variables PGDATABASE, PGPORT, ... may also be passed in";
  }
  
--- 205,209 ----
      print $inerr, "\n";
    }
!   die "$0  --host --database --user --cluster --port=integer --password --recipient --mailprog --categories\nnote also that libpq environment variables PGDATABASE, PGPORT, ... may also be passed in";
  }
  
***************
*** 222,226 ****
  
  sub mktblfooter {
! print "|};\n\n";
  }
  
--- 224,228 ----
  
  sub mktblfooter {
! print "|}\n\n";
  }
  
***************
*** 260,261 ****
--- 262,273 ----
  ];
  }
+ 
+ # End off by splitting the --categories option into a comma-delimited
+ # list of categories and dropping them into place
+ sub gencategories {
+   if ($categories ne "") {
+     foreach my $cat (split(',', $categories)) {
+       print "[Category:${cat}]\n";
+     }
+   }
+ }

From cbbrowne at lists.slony.info  Thu Jul  5 13:52:08 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Thu Jul  5 13:52:10 2007
Subject: [Slony1-commit] slony1-engine/doc/adminguide monitoring.sgml
Message-ID: <20070705205208.EDD1B290C42@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/doc/adminguide
In directory main.slony.info:/tmp/cvs-serv10795/doc/adminguide

Modified Files:
	monitoring.sgml 
Log Message:
Add in [[Category:foo]] support for automagic indexing to mkmediawiki.pl script


Index: monitoring.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/monitoring.sgml,v
retrieving revision 1.37
retrieving revision 1.38
diff -C2 -d -r1.37 -r1.38
*** monitoring.sgml	11 Jun 2007 16:02:50 -0000	1.37
--- monitoring.sgml	5 Jul 2007 20:52:06 -0000	1.38
***************
*** 95,98 ****
--- 95,133 ----
  Options[db_replication_lagtime]: gauge,nopercent,growright
  </programlisting>
+ 
+ <para> Alternatively, Ismail Yenigul points out how he managed to
+ monitor slony using <application>MRTG</application> without installing
+ <application>SNMPD</application>.</para>
+ 
+ <para> Here is the mrtg configuration</para>
+ 
+ <programlisting>
+ Target[db_replication_lagtime]:`/bin/snmpReplicationLagTime.sh 2`
+ MaxBytes[db_replication_lagtime]: 400000000
+ Title[db_replication_lagtime]: db: replication lag time
+ PageTop[db_replication_lagtime]: <H1>db: replication lag time</H1>
+ Options[db_replication_lagtime]: gauge,nopercent,growright
+ </programlisting>
+ 
+ <para> and here is the modified version of the script</para>
+ 
+ <programlisting>
+ # cat /bin/snmpReplicationLagTime.sh
+ #!/bin/bash
+ 
+ output=`/usr/bin/psql -U slony -h 192.168.1.1 -d endersysecm -qAt -c
+ "select cast(extract(epoch from st_lag_time) as int8) FROM _mycluster.sl_status WHERE st_received = $1"`
+ echo $output
+ echo $output
+ echo 
+ echo
+ # end of script#
+ </programlisting>
+ 
+ 
+ <note><para> MRTG expects four lines from the script, and since there
+ are only two lines provided, the output must be padded to four
+ lines. </para> </note>
+ 
  </sect2>
  
***************
*** 194,198 ****
  <filename>tools</filename>, may be used to generate a cluster summary
  compatible with the popular <ulink url="http://www.mediawiki.org/">
! MediaWiki </ulink> software. </para>
  
  <para> The gentle user might use the script as follows: </para>
--- 229,239 ----
  <filename>tools</filename>, may be used to generate a cluster summary
  compatible with the popular <ulink url="http://www.mediawiki.org/">
! MediaWiki </ulink> software.  Note that the
! <option>--categories</option> permits the user to specify a set of
! (comma-delimited) categories with which to associate the output.  If
! you have a series of &slony1; clusters, passing in the option
! <option>--categories=&slony1;</option> leads to the MediaWiki instance
! generating a category page listing all &slony1; clusters so
! categorized on the wiki.  </para>
  
  <para> The gentle user might use the script as follows: </para>
***************
*** 201,205 ****
  ~/logtail.en>         mvs login -d mywiki.example.info -u "Chris Browne" -p `cat ~/.wikipass` -w wiki/index.php                     
  Doing login with host: logtail and lang: en
! ~/logtail.en> perl $SLONYHOME/tools/mkmediawiki.pl --host localhost --database slonyregress1 --cluster slony_regress1  > Slony_replication.wiki
  ~/logtail.en> mvs commit -m "More sophisticated generated Slony-I cluster docs" Slony_replication.wiki
  Doing commit Slony_replication.wiki with host: logtail and lang: en
--- 242,246 ----
  ~/logtail.en>         mvs login -d mywiki.example.info -u "Chris Browne" -p `cat ~/.wikipass` -w wiki/index.php                     
  Doing login with host: logtail and lang: en
! ~/logtail.en> perl $SLONYHOME/tools/mkmediawiki.pl --host localhost --database slonyregress1 --cluster slony_regress1 --categories=Slony-I  > Slony_replication.wiki
  ~/logtail.en> mvs commit -m "More sophisticated generated Slony-I cluster docs" Slony_replication.wiki
  Doing commit Slony_replication.wiki with host: logtail and lang: en

From wieck at lists.slony.info  Thu Jul  5 14:34:26 2007
From: wieck at lists.slony.info (Jan Wieck)
Date: Thu Jul  5 14:34:29 2007
Subject: [Slony1-commit] slony1-engine/src/slon runtime_config.c
Message-ID: <20070705213426.EF085290C50@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv19818

Modified Files:
      Tag: REL_1_2_STABLE
	runtime_config.c 
Log Message:
Fix copy/paste mistake in disableNode().

Jan


Index: runtime_config.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/runtime_config.c,v
retrieving revision 1.27.2.2
retrieving revision 1.27.2.3
diff -C2 -d -r1.27.2.2 -r1.27.2.3
*** runtime_config.c	27 Oct 2006 20:09:56 -0000	1.27.2.2
--- runtime_config.c	5 Jul 2007 21:34:24 -0000	1.27.2.3
***************
*** 276,280 ****
  
  		slon_log(SLON_FATAL,
! 				 "enableNode: unknown node ID %d\n", no_id);
  		slon_retry();
  		return;
--- 276,280 ----
  
  		slon_log(SLON_FATAL,
! 				 "disableNode: unknown node ID %d\n", no_id);
  		slon_retry();
  		return;

From cbbrowne at lists.slony.info  Fri Jul  6 11:40:27 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul  6 11:40:29 2007
Subject: [Slony1-commit] slony1-engine TODO
Message-ID: <20070706184027.ADC8C290BE9@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine
In directory main.slony.info:/tmp/cvs-serv16187

Modified Files:
	TODO 
Log Message:
Per Vivek Khera, note in TODO that we shouldn't email around SQL scripts
representing test results; this is an injection attack waiting to
happen...


Index: TODO
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/TODO,v
retrieving revision 1.4
retrieving revision 1.5
diff -C2 -d -r1.4 -r1.5
*** TODO	5 Jul 2007 19:50:01 -0000	1.4
--- TODO	6 Jul 2007 18:40:25 -0000	1.5
***************
*** 54,57 ****
--- 54,69 ----
  - Clone Node - use pg_dump/PITR to populate a new subscriber node
  
+ - test scripts should generate output that can be readily aggregated.
+ 
+   Initial prototype has them generating SQL output; unfortunately,
+   if we accept this from arbitrary sources, this is the very picture
+   of an SQL injection attack.  Before doing that, we'll need to
+   turn it into some suitable tabular/delimited format that can be
+   parsed into SQL.
+ 
+   When defining what data there should be, it is useful to use SQL for
+   now.  But this needs NOT to be the form transmitted "across the
+   wire."
+ 
  Wishful Thinking
  ----------------------------

From cbbrowne at lists.slony.info  Mon Jul  9 08:19:51 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul  9 08:19:53 2007
Subject: [Slony1-commit] slony1-engine/doc/adminguide slonyupgrade.sgml
Message-ID: <20070709151951.B8E17290048@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/doc/adminguide
In directory main.slony.info:/tmp/cvs-serv26870

Modified Files:
	slonyupgrade.sgml 
Log Message:
Add to upgrade-to-2.0 docs another approach to handling tables with
columns defined via TABLE ADD KEY.


Index: slonyupgrade.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/slonyupgrade.sgml,v
retrieving revision 1.6
retrieving revision 1.7
diff -C2 -d -r1.6 -r1.7
*** slonyupgrade.sgml	18 Apr 2007 15:03:51 -0000	1.6
--- slonyupgrade.sgml	9 Jul 2007 15:19:49 -0000	1.7
***************
*** 113,121 ****
  command <xref linkend="stmtsetdroptable">. </para>
  
! <para> This does <emphasis>not</emphasis> drop out the &slony1;-generated column. </para>
! 
  </listitem>
! <listitem><para> On each node, run an SQL script to alter the table, dropping the extra column.</para> 
! <para> <command> alter table whatever drop column "_Slony-I_cluster-rowID";</command> </para>
  
  <para> This needs to be run individually against each node.  Depending
--- 113,123 ----
  command <xref linkend="stmtsetdroptable">. </para>
  
! <para> This does <emphasis>not</emphasis> drop out the
! &slony1;-generated column. </para>
  </listitem>
! 
! <listitem><para> On each node, run an SQL script to alter the table,
! dropping the extra column.</para> <para> <command> alter table
! whatever drop column "_Slony-I_cluster-rowID";</command> </para>
  
  <para> This needs to be run individually against each node.  Depending
***************
*** 190,193 ****
--- 192,240 ----
  
  </itemizedlist>
+ 
+ <para> This approach should be fine for tables that are relatively
+ small, or infrequently used.  If, on the other hand, the table is
+ large and heavily used, another approach may prove necessary, namely
+ to create your own sequence, and <quote>promote</quote> the formerly
+ &slony1;-generated column into a <quote>real</quote> column in your
+ database schema.  An outline of the steps is as follows: </para>
+ 
+ <itemizedlist>
+ 
+ <listitem><para> Add a sequence that assigns values to the
+ column. </para>
+ 
+ <para> Setup steps will include SQL <command>CREATE
+ SEQUENCE</command>, SQL <command>SELECT SETVAL()</command> (to set the
+ value of the sequence high enough to reflect values used in the
+ table), Slonik <xref linkend="stmtcreateset"> (to create a set to
+ assign the sequence to), Slonik <xref linkend="stmtsetaddsequence">
+ (to assign the sequence to the set), Slonik <xref
+ linkend="stmtsubscribeset"> (to set up subscriptions to the new
+ set)</para>
+ </listitem>
+ 
+ <listitem><para> Attach the sequence to the column on the
+ table. </para>
+ 
+ <para> This involves <command>ALTER TABLE ALTER COLUMN</command>,
+ which must be submitted via the Slonik command <xref
+ linkend="stmtddlscript">. </para>
+ </listitem>
+ 
+ <listitem><para> Rename the column
+ <envar>_Slony-I_@CLUSTERNAME@_rowID</envar> so that &slony1; won't
+ consider it to be under its control.</para>
+ 
+ <para> This involves <command>ALTER TABLE ALTER COLUMN</command>,
+ which must be submitted via the Slonik command <xref
+ linkend="stmtddlscript">. </para>
+ 
+ <para> Note that these two alterations might be accomplished via the
+ same <xref linkend="stmtddlscript"> request. </para>
+ </listitem>
+ 
+ </itemizedlist>
+ 
  </sect2>
  </sect1>

From cbbrowne at lists.slony.info  Mon Jul  9 08:20:39 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul  9 08:20:42 2007
Subject: [Slony1-commit] slony1-engine/doc/adminguide slonik_ref.sgml
Message-ID: <20070709152039.0D067290C25@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/doc/adminguide
In directory main.slony.info:/tmp/cvs-serv26934

Modified Files:
	slonik_ref.sgml 
Log Message:
Note that trigger manipulation commands become obsolete in v2.0


Index: slonik_ref.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/slonik_ref.sgml,v
retrieving revision 1.72
retrieving revision 1.73
diff -C2 -d -r1.72 -r1.73
*** slonik_ref.sgml	27 Jun 2007 17:56:11 -0000	1.72
--- slonik_ref.sgml	9 Jul 2007 15:20:36 -0000	1.73
***************
*** 1864,1867 ****
--- 1864,1872 ----
     <refsect1> <title> Version Information </title>
      <para> This command was introduced in &slony1; 1.0 </para>
+ 
+     <para> In &slony1; version 2.0, this command is removed as
+     obsolete because triggers are no longer <quote>messed around
+     with</quote> in the system catalogue. </para>
+ 
     </refsect1>
    </refentry>
***************
*** 1926,1929 ****
--- 1931,1939 ----
     <refsect1> <title> Version Information </title>
      <para> This command was introduced in &slony1; 1.0 </para>
+ 
+     <para> In &slony1; version 2.0, this command is removed as
+     obsolete because triggers are no longer <quote>messed around
+     with</quote> in the system catalogue. </para>
+ 
     </refsect1>
    </refentry>
***************
*** 2396,2400 ****
       instead of <command>FAILOVER</command>, if at all possible, as
       <command>FAILOVER</command> winds up discarding the old origin
!      node as being corrupted. Before <commadand>MOVE SET</command> will
       function a <command>LOCK SET</command> is needed.
  </para>
--- 2406,2410 ----
       instead of <command>FAILOVER</command>, if at all possible, as
       <command>FAILOVER</command> winds up discarding the old origin
!      node as being corrupted. Before <command>MOVE SET</command> will
       function a <command>LOCK SET</command> is needed.
  </para>

From cbbrowne at lists.slony.info  Mon Jul  9 08:21:30 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul  9 08:21:31 2007
Subject: [Slony1-commit] slony1-engine/doc/adminguide monitoring.sgml
Message-ID: <20070709152130.E6A772903D4@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/doc/adminguide
In directory main.slony.info:/tmp/cvs-serv26960

Modified Files:
	monitoring.sgml 
Log Message:
Put in embedded tagging of embedded HTML


Index: monitoring.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/monitoring.sgml,v
retrieving revision 1.38
retrieving revision 1.39
diff -C2 -d -r1.38 -r1.39
*** monitoring.sgml	5 Jul 2007 20:52:06 -0000	1.38
--- monitoring.sgml	9 Jul 2007 15:21:28 -0000	1.39
***************
*** 106,110 ****
  MaxBytes[db_replication_lagtime]: 400000000
  Title[db_replication_lagtime]: db: replication lag time
! PageTop[db_replication_lagtime]: <H1>db: replication lag time</H1>
  Options[db_replication_lagtime]: gauge,nopercent,growright
  </programlisting>
--- 106,110 ----
  MaxBytes[db_replication_lagtime]: 400000000
  Title[db_replication_lagtime]: db: replication lag time
! PageTop[db_replication_lagtime]: &lt;H1&gt;db: replication lag time&lt;/H1&gt;
  Options[db_replication_lagtime]: gauge,nopercent,growright
  </programlisting>

From cbbrowne at lists.slony.info  Mon Jul  9 12:07:03 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul  9 12:07:05 2007
Subject: [Slony1-commit] slony1-engine RELEASE
Message-ID: <20070709190703.5FF292903BE@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine
In directory main.slony.info:/tmp/cvs-serv29295

Modified Files:
      Tag: REL_1_2_STABLE
	RELEASE 
Log Message:
Various little 1.2 branch changes:

1.  Minor documentation fixes
2.  Add tools/mkservice to 1.2 branch
3.  Note this in release notes for possible future release


Index: RELEASE
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/RELEASE,v
retrieving revision 1.1.2.6
retrieving revision 1.1.2.7
diff -C2 -d -r1.1.2.6 -r1.1.2.7
*** RELEASE	21 Jun 2007 20:29:12 -0000	1.1.2.6
--- RELEASE	9 Jul 2007 19:07:01 -0000	1.1.2.7
***************
*** 1,4 ****
--- 1,8 ----
  $Id$
  
+ RELEASE 1.2.???
+ 
+ - Add in tools/mkservice scripts previously added to CVS HEAD
+ 
  RELEASE 1.2.10
  

From cbbrowne at lists.slony.info  Mon Jul  9 12:07:03 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul  9 12:07:05 2007
Subject: [Slony1-commit] slony1-engine/doc/adminguide slonik_ref.sgml
Message-ID: <20070709190703.72398290BDF@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/doc/adminguide
In directory main.slony.info:/tmp/cvs-serv29295/doc/adminguide

Modified Files:
      Tag: REL_1_2_STABLE
	slonik_ref.sgml 
Log Message:
Various little 1.2 branch changes:

1.  Minor documentation fixes
2.  Add tools/mkservice to 1.2 branch
3.  Note this in release notes for possible future release


Index: slonik_ref.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/slonik_ref.sgml,v
retrieving revision 1.61.2.8
retrieving revision 1.61.2.9
diff -C2 -d -r1.61.2.8 -r1.61.2.9
*** slonik_ref.sgml	22 Jun 2007 16:01:38 -0000	1.61.2.8
--- slonik_ref.sgml	9 Jul 2007 19:07:01 -0000	1.61.2.9
***************
*** 2365,2369 ****
       instead of <command>FAILOVER</command>, if at all possible, as
       <command>FAILOVER</command> winds up discarding the old origin
!      node as being corrupted.</para>
       
      <para> Note that this is a &rlocking; operation, which means that
--- 2365,2371 ----
       instead of <command>FAILOVER</command>, if at all possible, as
       <command>FAILOVER</command> winds up discarding the old origin
!      node as being corrupted. Before <commadand>MOVE SET</command> will
!      function a <command>LOCK SET</command> is needed.
! </para>
       
      <para> Note that this is a &rlocking; operation, which means that
***************
*** 2391,2394 ****
--- 2393,2400 ----
     <refsect1><title>Example</title>
      <programlisting>
+ LOCK SET (
+    ID = 1,
+    ORIGIN = 1
+ );
  MOVE SET (
     ID = 1,

From cbbrowne at lists.slony.info  Mon Jul  9 12:07:03 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul  9 12:07:05 2007
Subject: [Slony1-commit] slony1-engine/tools/mkservice README
	logrep-mkservice.sh slon-mkservice.sh
Message-ID: <20070709190703.98CFE290C0E@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tools/mkservice
In directory main.slony.info:/tmp/cvs-serv29295/tools/mkservice

Added Files:
      Tag: REL_1_2_STABLE
	README logrep-mkservice.sh slon-mkservice.sh 
Log Message:
Various little 1.2 branch changes:

1.  Minor documentation fixes
2.  Add tools/mkservice to 1.2 branch
3.  Note this in release notes for possible future release


--- NEW FILE: README ---
$Id: README,v 1.3.2.1 2007-07-09 19:07:01 cbbrowne Exp $

contributed by Andrew Hammond <andrew.george.hammond@gmail.com>

slon-mkservice.sh
-------------------
Create a slon service directory for use with svscan from daemontools.
This uses multilog in a pretty basic way, which seems to be standard 
for daemontools / multilog setups. If you want clever logging, see
logrep below. Currently this script has very limited error handling
capabilities.

For non-interactive use, set the following environment variables.
BASEDIR LOGBASE SYSUSR PASSFILE DBUSER HOST PORT DATABASE CLUSTER SLON_BINARY
If any of the above are not set, the script asks for configuration
information interactively. The following environment variables are optional.
LOGMAX LOGNUM
If they are not set, they will silently default to reasonable values.

BASEDIR where you want the service directory structure for the slon
to be created. This should _not_ be the /var/service directory.
(default /usr/local/etc)
LOGBASE where you want your logs to end up. (default /var/log)
if set to - then revert to old behaviour and put logs under log/main.
SYSUSR the unix user under which the slon (and multilog) process should run.
PASSFILE location of the .pgpass file to be used. (default ~sysusr/.pgpass)
DBUSER the postgres user the slon should connect as (default slony)
HOST what database server to connect to (default localhost)
PORT what port to connect to (default 5432)
DATABASE which database to connect to (default dbuser)
CLUSTER the name of your Slony1 cluster? (default database)
SLON_BINARY the full path name of the slon binary (default `which slon`)
LOGMAX maximum size (in bytes) of logfiles (default 10485760 which is 10MB)
LOGNUM number of files to maintain (default 99, assume other tool prunes)

logrep-mkservice.sh
--------------------

This uses "tail -F" to pull data from log files allowing you to use
multilog filters (by setting the CRITERIA) to create special purpose
log files. The goal is to provide a way to monitor log files in near 
realtime for "interesting" data without either hacking up the initial
log file or wasting CPU/IO by re-scanning the same log repeatedly.

For non-interactive use, set the following environment variables.
BASEDIR LOGBASE SYSUSR SOURCE EXTENSION CRITERIA 
If any of the above are not set, the script asks for configuration
information interactively. The following environment variables are optional.
LOGMAX LOGNUM
If they are not set, they will silently default to reasonable values.

BASEDIR where you want the service directory structure for the logrep
to be created. This should _not_ be the /var/service directory.
LOGBASE where you want your logs to end up. (default /var/log)
if set to - then revert to old behaviour and put logs under log/main.
SYSUSR unix user under which the service should run.
SOURCE name of the service with the log you want to follow.
EXTENSION a tag to differentiate this logrep from others using the same source.
CRITERIA the multilog filter you want to use.
LOGMAX maximum size (in bytes) of logfiles (default 10485760 which is 10MB)
LOGNUM number of files to maintain (default 99, assume other tool prunes)

A trivial example of this would be to provide a log file of all slon
ERROR messages which could be used to trigger a nagios alarm.
EXTENSION='ERRORS'
CRITERIA="'-*' '+* * ERROR*'"
(Reset the monitor by rotating the log using svc -a $svc_dir)

A more interesting application is a subscription progress log.
EXTENSION='COPY'
CRITERIA="'-*' '+* * ERROR*' '+* * WARN*' '+* * CONFIG enableSubscription*' '+* * DEBUG2 remoteWorkerThread_* prepare to copy table*' '+* * DEBUG2 remoteWorkerThread_* all tables for set * found on subscriber*' '+* * DEBUG2 remoteWorkerThread_* copy*' '+* * DEBUG2 remoteWorkerThread_* Begin COPY of table*' '+* * DEBUG2 remoteWorkerThread_* * bytes copied for table*' '+* * DEBUG2 remoteWorkerThread_* * seconds to*' '+* * DEBUG2 remoteWorkerThread_* set last_value of sequence*' '+* * DEBUG2 remoteWorkerThread_* copy_set*'"

If you have a subscription log then it's easy to determine if a given
slon is in the process of handling copies or other subscription activity.
If the log isn't empty, and doesn't end with a 
"CONFIG enableSubscription: sub_set:1"
(or whatever set number you've subscribed) then the slon is currently in
the middle of initial copies.
If you happen to be monitoring the mtime of your primary slony logs to 
determine if your slon has gone brain-dead, checking this is a good way
to avoid mistakenly clobbering it in the middle of a subscribe. As a bonus,
recall that since the the slons are running under svscan, you only need to
kill it (via the svc interface) and let svscan start it up again laster.
I've also found the COPY logs handy for following subscribe activity 
interactively.

--- NEW FILE: slon-mkservice.sh ---
#!/bin/sh
#
# $Id: slon-mkservice.sh,v 1.2.2.1 2007-07-09 19:07:01 cbbrowne Exp $
#
# contributed by Andrew Hammond <andrew.george.hammond@gmail.com>
#
# Create a slon service directory for use with svscan from deamontools.
# This uses multilog in a pretty basic way, which seems to be standard 
# for daemontools / multilog setups. If you want clever logging, see
# logrep below. Currently this script has very limited error handling
# capabilities.
# 
# For non-interactive use, set the following environment variables.
# BASEDIR LOGBASE SYSUSR PASSFILE DBUSER HOST PORT DATABASE CLUSTER SLON_BINARY
# If any of the above are not set, the script asks for configuration
# information interactively. The following environment variables are optional.
# LOGMAX LOGNUM
# If they are not set, they will silently default to reasonable values.
# 
# BASEDIR where you want the service directory structure for the slon
# to be created. This should _not_ be the /var/service directory.
# (default /usr/local/etc)
# LOGBASE where you want your logs to end up. (default /var/log)
# if set to - then revert to old behaviour and put logs under log/main.
# SYSUSR the unix user under which the slon (and multilog) process should run.
# PASSFILE location of the .pgpass file to be used. (default ~sysusr/.pgpass)
# DBUSER the postgres user the slon should connect as (default slony)
# HOST what database server to connect to (default localhost)
# PORT what port to connect to (default 5432)
# DATABASE which database to connect to (default dbuser)
# CLUSTER name of your Slony1 cluster? (default database)
# SLON_BINARY full path name of the slon binary (default `which slon`)
# LOGMAX maximum size (in bytes) of logfiles (default 10485760 which is 10MB)
# LOGNUM number of files to maintain (default 99, assume other tool prunes)

DEFAULT_SLON_BINARY=`which slon`                # silly, wild-ass guess
DEFAULT_BASEDIR='/usr/local/etc'
DEFAULT_LOGBASE='/var/log'
DEFAULT_SYSUSR='pgsql'                          # FreeBSD-centric. Oh well.
DEFAULT_DBUSR='slony'                           # Best Practice...
DEFAULT_SLON_DEBUG_LEVEL=2                      # default to "debug2" level
DEFAULT_HOST='localhost'                        # maybe the unix socket would be better?
DEFAULT_PORT=5432

if [ -z "$BASEDIR" ]; then
    echo -n "Where do you want the service dir created? Don't create this in 
/service or /var/service. Once it's created, either symlink or move
it to the service directory (since linking is an atomic filesystem action). 
Note that log files will not be stored here (that's the next question), so 
this doesn't have to be on a high storage / IO capacity filesystem.
[$DEFAULT_BASEDIR]: "
    read BASEDIR
    if [ -z "$BASEDIR" ]; then
        BASEDIR="$DEFAULT_BASEDIR"
    fi
fi
echo "BASEDIR=$BASEDIR"

if [ -z "$LOGBASE" ]; then
    echo -n "Where should the logfiles live? You probably want to put this
somewhere with plenty of storage and some IO capacity. Note that this
creates a subdirectory where the actual log files are stored.
Use - to disable this (putting the log files under log/main according to
daemontools convention).
[$DEFAULT_LOGDIR]: "
    read LOGDIR
    if [ -z "$LOGDIR" ]; then
        LOGDIR="$DEFAULT_LOGDIR"
    fi
fi

if [ -z "$SYSUSR" ]; then
    echo -n "System user name for slon to run under [$DEFAULT_SYSUSR]: "
    read SYSUSR
    if [ -z "$SYSUSR" ]; then
        SYSUSR="$DEFAULT_SYSUSR"
    fi
fi
echo "SYSUSR=$SYSUSR"

if [ -z "$PASSFILE" ]; then
    DEFAULT_PASSFILE=`eval echo "~$SYSUSR/.pgpass"`
    echo -n "And $SYSUSR's .pgpass file? [$DEFAULT_PASSFILE]: "
    read PASSFILE
    if [ -z "$PASSFILE" ]; then
        PASSFILE="$DEFAULT_PASSFILE"
    fi
fi
echo "PASSFILE=$PASSFILE"

if [ -z "$DBUSER" ]; then
    echo -n "Database user for slon to connect as [$DEFAULT_DBUSR]: "
    read DBUSER
    if [ -z "$DBUSER" ]; then
        DBUSER="$DEFAULT_DBUSR"
    fi
fi
echo "DBUSER=$DBUSER"

if [ -z "$HOST" ]; then
    echo -n "Host to connect to [$DEFAULT_HOST]: "
    read HOST
    if [ -z "$HOST" ]; then
        HOST="$DEFAULT_HOST"
    fi
fi
echo "HOST=$HOST"
if echo "$HOST" | grep / > /dev/null; then
    echo "Using / in your host name will make things break. Aborting."
    exit -1
fi

if [ -z "$PORT" ]; then
    echo -n "Port [$DEFAULT_PORT]: "
    read PORT
    if [ -z "$PORT" ]; then
        PORT="$DEFAULT_PORT"
    fi
fi
echo "PORT=$PORT"

if [ -z "$DATABASE" ]; then
    echo -n "Database [$DBUSER]: "
    read DATABASE
    if [ -z "$DATABASE" ]; then
        DATABASE="$DBUSER"
    fi
fi
echo "DATABASE=$DATABASE"
if echo "$DATABASE" | grep / > /dev/null; then
    echo "Using / in your database name will make things break. Aborting."
    exit -1
fi

if [ -z "$CLUSTER" ]; then
    echo -n "Cluster name: [$DATABASE]: "
    read CLUSTER
    if [ -z "$CLUSTER" ]; then
        CLUSTER="$DATABASE"
    fi
fi
echo "CLUSTER=$CLUSTER"
if echo "$CLUSTER" | grep / > /dev/null; then
    echo "Using / in your cluster name will make things break. Aborting."
    exit -1
fi

if [ -z "$SLON_BINARY" ]; then
    echo -n "Where is the slon binary? [$DEFAULT_SLON_BINARY]: "
    read SLON_BINARY
    if [ -z "$SLON_BINARY" ]; then
        SLON_BINARY=$DEFAULT_SLON_BINARY
    fi
fi
echo "SLON_BINARY=$SLON_BINARY"

SVCNAME="slon_${CLUSTER}_${HOST}_${PORT}_$DATABASE"
DIR="$BASEDIR/$SVCNAME"
LOGDIR="$DIR/log/main"
if [ '-' != "$LOGBASE" ]; then      # - means don't use a different logdir
    LOGDIR="$LOGBASE/$SVCNAME"      # otherwise we're logging somewhere else
fi
CONFIGFILE="$DIR/slon.conf"
echo "CONFIGFILE=$CONFIGFILE"

echo "Service dir will be created under $DIR"
echo "Logs will live under $LOGDIR"

mkdir -p "$DIR/env" "$DIR/supervise" "$DIR/log/env" "$DIR/log/supervise" "$LOGDIR" || exit -1
if [ '-' != "$LOGBASE" ]; then          # - means it's not a linked logdir
    ln -s "$LOGDIR" "$DIR/log/main"
fi
# Make sure the log file initially exists. This allows others to tail -F it
# before it starts getting populated. go go logrep!
touch "$DIR/log/main/current" || exit -1

# Set up the slon.conf file
cat > "$CONFIGFILE" <<EOF
# $CONFIGFILE
##############################################################################
# Connection settings

# Set the cluster name that this instance of slon is running against.
# The default is to read it off the command line.
cluster_name "$CLUSTER"

# Set slon's connection info; default is to read it off the command line.
conn_info "host=$HOST port=$PORT dbname=$DATABASE user=$DBUSER"

# Execute this SQL on each node at slon connect time. Useful to set logging
# levels, or to tune the planner/memory settings. You can specify multiple
# statements by separating them with a ; 
#sql_on_connection 

##############################################################################
# Logging

# If you want to use syslog then redir output from the slon to /dev/null and
# remove the log dir.

# Sets up logging to syslog. If this parameter is 1, messages go both to
# syslog and the standard output. A value of 2 sends output only to syslog
# (some messages will still go to the standard output/error). 
# Default is 0, which means syslog is off.
#syslog 0

# Sets the syslog "facility" to be used when syslog enabled. Valid values
# are LOCAL0, LOCAL1, LOCAL2, LOCAL3, LOCAL4, LOCAL5, LOCAL6, LOCAL7. 
# Default is LOCAL0.
#syslog_facility LOCAL0

# Sets the program name used to identify slon messages in syslog.
# The default is slon.
#syslog_ident slon

# Debug log level (higher value ==> more output).
# Range: [0,4], default 4
log_level $DEFAULT_SLON_DEBUG_LEVEL     # 3 and up is generally too high for production

# Determins, if you would like the pid of the (parent) slon process to appear
# in each log line entry.
# Default 0
log_pid 1           # good to know

# Determines if you would like the timestamp of the event being logged to
# appear in each log line entry.
log_timestamp  0    # multilog will insert a tai64n timestamp

# A strftime()-conformant format string for use if log_timestamp is enabled.
# The default is "%Y-%m-%d %H:%M:%S %Z"
#log_timestamp_format = "%Y-%m-%d %H:%M:%S %Z"

# Location and filename you would like for a file containing the Process ID
# of the slon process.
# The default is not defined in which case no file is written.
#pid_file       # daemontools renders this unnecessary, even undesireable
                # use instead the svc interface to signal the slon.

##############################################################################
# Archive Logging

# This indicates in what directory sync archive files should be stored.
#archive_dir

# This indicates a Unix command to be submitted each time an archive log
# is successfully generated.
#command_on_logarchive

##############################################################################
# Event Tuning

# Check for updates at least this often in milliseconds.
# Range: [10-60000], default 100
#sync_interval 100 

# Maximum amount of time in milliseconds before issuing a SYNC event, 
# This prevents a possible race condition in which the action sequence is
# bumped by the trigger while inserting the log row, which makes this bump
# is immediately visible to the sync thread, but the resulting log rows are
# not visible yet. If the SYNC is picked up by the subscriber, processed
# and finished before the transaction commits, this transaction's changes
# will not be replicated until the next SYNC. But if all application
# activity suddenly stops, there will be no more sequence bumps, so the
# high frequent -s check won't detect that. Thus, the need for
# sync_interval_timeout.
# Range: [0-120000], default 1000
#sync_interval_timeout 1000 

# Maximum number of SYNC events to group together when/if a subscriber falls
# behind. SYNCs are batched only if there are that many available and if they
# are contiguous. Every other event type in between leads to a smaller batch.
# And if there is only one SYNC available, even -g60 will apply just that one.
# As soon as a subscriber catches up, it will apply every single SYNC by itself.
# Range: [0,10000], default: 6
#sync_group_maxsize 6

# Sets how many cleanup cycles to run before a vacuum is done. 0 disables the
# builtin vacuum, intended to be used with the pg_autovacuum daemon.
# Range: [0,100], default: 3
#vac_frequency 3

# Maximum time planned for grouped SYNCs. If replication is behind, slon will
# try to increase numbers of syncs done targetting that they should take this
# quantity of time to process. If the value is set to 0, this logic will be
# ignored. 
# Range [10000,600000] ms, default 60000.
#desired_sync_time 60000 

# This must be used in conjunction with quit_sync_finalsync, and indicates
# which provider node's worker thread should be watched to see if the slon
# should terminate due to reaching some desired "final" event number.
#quit_sync_provider 0

# Final event number to process. This must be used in conjunction with
# quit_sync_finalsync, and allows the slon to terminate itself once it
# reaches a certain event for the specified provider. If the value is set
# to 0, this logic will be ignored. 
#quit_sync_finalsync 0

# Indicates an interval by which this node should lag its providers. If set,
# this is used in the event processing loop to modify what events are to be
# considered for queueing; those events newer than
# now() - lag_interval::interval are left out, to be processed later.
# If the value is left empty, this logic will be ignored. 
#lag_interval

# Size above which an sl_log_? row's log_cmddata is considered large. Up to
# 500 rows of this size are allowed in memory at once. Rows larger than that
# count into the sync_max_largemem space allocated and free()'ed on demand.
# The default value is 8192, meaning that your expected memory consumption
# (for the LOG cursor) should not exceed 8MB.
#sync_max_rowsize 8192

# Maximum memory allocated for large rows, where log_cmddata are larger than
# sync_max_rowsize. Note that the algorithm reads rows until after this value
# is exceeded. Otherwise, a tuple larger than this value would stall
# replication. As a result, don't assume that memory consumption will remain
# smaller than this value.  The default value is 5242880.
#sync_max_largemem 5242880

# How long should the remote listener wait before treating the event selection
# criteria as having timed out?
# Range: [30-30000], default 300 
#remote_listen_timeout 300

EOF

# Set up the envdir contents for the admins. Generously.
echo "$SLON_BINARY"                 > $DIR/env/SLON_BINARY
echo "$CONFIGFILE"                  > $DIR/env/CONFIGFILE
echo "$CLUSTER"                     > $DIR/env/CLUSTER
echo "$HOST"                        > $DIR/env/PGHOST
echo "$PORT"                        > $DIR/env/PGPORT
echo "$DATABASE"                    > $DIR/env/PGDATABASE
# The absence of PGPASSWORD is not an oversight. Use .pgpass, see
# http://www.postgresql.org/docs/current/interactive/libpq-pgpass.html
# Configure the location of .pgpass file here...
# I'd like a better solution than this for expanding the homedir.
echo "$PASSFILE"                    > $DIR/env/PGPASSFILE 
echo "$DBUSER"                      > $DIR/env/PGUSER
# Change these if you're stupid or unfortunate enough to have to.
echo 'ISO'                          > $DIR/env/PGDATESTYLE
echo 'UTC'                          > $DIR/env/PGTZ

# Avoid some subtle errors by documenting stuff... such as
cat > "$DIR/README.txt" <<EOF
This service will start on boot. If you do not want it to, then
touch $DIR/down

To upgrade your slon, first update env/SLON_BINARY to the full
path and name of the new slon binary. Then stop the slon.
svc -d $DIR
Apply your slonik UPDATE FUNCTIONS script(s) then restart your slon.
svc -u $DIR
Finally, check your logs to ensure that the new slon has started and
is running happily.

If you need to have a special purpose config file, or test version,
then you can simply copy the existing slon.conf to some other name,
make your changes there, update env/CONFIGFILE to point at the new
config and restart the slon.
svc -k $DIR

Note that changing variables such as CLUSTER, PGHOST, PGPORT,
PGDATABASE and PGUSER in the env directory will not change where
the slon connects. They are only there for admin/DBA convenience.
exec envdir $DIR/env bash
Is a quick way to get your variables all set up.

If you want to change where the slon connects, you need to edit
$CONFIGFILE
But you probably should not be doing that anyway, because then you
have to rename a whole bunch of stuff and edit all over the place
to keep the naming scheme consistent. Yuck. You should probably
just create a new slon service directory with the correct information,
and shut this one down.
touch $DIR/down; svc -dx $DIR $DIR/log

EOF

cat > "$DIR/env/README.txt" <<EOF
Many of these environment variables are only set as a convenience
for administrators and DBAs. To load them, try
exec envdir $DIR/env bash
Before you change stuff here, please read ../README.txt
EOF

# create the run script for the slon
cat > "$DIR/run" <<EOF
#!/bin/sh
# Note that the slon binary is a variable, so you can edit the value in
# env/SLON_BINARY and restart to upgrade slons. See README.txt in this dir.
exec 2>&1
exec envdir ./env sh -c 'exec setuidgid ${SYSUSR} "\${SLON_BINARY}" -f "\${CONFIGFILE}"'
EOF
chmod a+x "$DIR/run"
echo "$DIR/run created"

# setup an envdir for multilog
echo ${LOGMAX-"10485760"}           > $DIR/log/env/LOGMAX
echo ${LOGNUM-"99"}                 > $DIR/log/env/LOGNUM

cat > "$DIR/log/README.txt" <<EOF
To force a log rotation, use
svc -a $DIR/log

The size (in bytes) of the log files (before they get rotated) is controlled
by the s parameter for multilog. This is set up as an envdir variable at
$DIR/log/env/LOGMAX
You might want to increase or decrease this. It goes up to a maximum of
16777215 (15MB) and defaults to 99999 (97kB) if unset. Leaving it unset 
will break this script. It defaults to 10485760 (which is 10MB).
You need to restart multilog for changes to this to take effect.
svc -k $DIR/log

The n paramter decides how many old log files to keep around. This is set
up as an envdir variable at
$DIR/log/env/LOGNUM
You will probably want to decrease this if you are not using some other
tool to manage old logfiles. Multilog defaults to 10 if this is unset, but
like the size above, it will break this script if left unset. The script
defaults to 99 under the assumption that you are using some other, system
wide tool (like cfengine) to prune your logs.
EOF

# create the run file for the multilog
cat > "$DIR/log/run" <<EOF
#!/bin/sh
# This puts everything in the main log. Unfortunately multilog only allows
# you to select which log you want to write to as opposed to writing each
# line to every log which matches the criteria. Split up logs would make
# debugging harder. See also README.txt in this directory.

exec envdir ./env sh -c 'exec setuidgid $SYSUSR multilog t s"\$LOGMAX" n"\$LOGNUM" ./main'
EOF
chmod a+x "$DIR/log/run"
echo "$DIR/log/run created"

# create and fix ownerships and permissions for .pgpass appropriately
touch "$PASSFILE"
chown "$SYSUSR" "$PASSFILE"
chmod 600 "$PASSFILE"
if [ ! -s "$PASSFILE" ]; then
    echo "Populating $PASSFILE with header and example."
    cat > "$PASSFILE" <<EOF
#hostname:port:database:username:password
#$HOST:$PORT:*:$DBUSER:secret
EOF
fi

# fix permissions and ownership
chown -R "$SYSUSR" "$DIR"
chmod a+rX "$DIR"

cat <<EOF
When you're ready to start the slon, simply link the newly created dir, 
$DIR
under your current supervisor's directory. On FreeBSD this is /var/service
by default. So the command would be:

sudo ln -s $DIR /var/service

The slon should be started within 5 seconds.

You can further configure the slon by modifying stuff in the 
$DIR/env
directory. Specifically, make sure that the SLON variable points to the right
slon binary. You may also want to edit
$CONFIGFILE

Finally, you need to make sure that $PASSFILE 
is correctly in place. If you didn't have one before (or it was empty), it
has been created and populated with some sample data.

Logfiles can be found at $LOGDIR
You may also want to set up a logrep to filter out the more intresting
log lines. See logrep-mkservice.sh.
EOF

--- NEW FILE: logrep-mkservice.sh ---
#!/bin/sh
#
# $Id: logrep-mkservice.sh,v 1.2.2.1 2007-07-09 19:07:01 cbbrowne Exp $
#
# contributed by Andrew Hammond <andrew.george.hammond@gmail.com>
#
# This uses "tail -F" to pull data from log files allowing you to use
# multilog filters (by setting the CRITERIA) to create special purpose
# log files. The goal is to provide a way to monitor log files in near 
# realtime for "interesting" data without either hacking up the initial
# log file or wasting CPU/IO by re-scanning the same log repeatedly.
# 
# For non-interactive use, set the following environment variables.
# BASEDIR LOGBASE SYSUSR SOURCE EXTENSION CRITERIA 
# If any of the above are not set, the script asks for configuration
# information interactively. The following environment variables are optional.
# LOGMAX LOGNUM
# If they are not set, they will silently default to reasonable values.
# 
# BASEDIR where you want the service directory structure for the logrep
# to be created. This should _not_ be the /var/service directory.
# LOGBASE where you want your logs to end up. (default /var/log)
# if set to - then revert to old behaviour and put logs under log/main.
# SYSUSR unix user under which the service should run.
# SOURCE name of the service with the log you want to follow.
# EXTENSION a tag to differentiate this logrep from others using the same source.
# CRITERIA the multilog filter you want to use.
# LOGMAX maximum size (in bytes) of logfiles (default 10485760 which is 10MB)
# LOGNUM number of files to maintain (default 99, assume other tool prunes)
# 
# A trivial example of this would be to provide a log file of all slon
# ERROR messages which could be used to trigger a nagios alarm.
# EXTENSION='ERRORS'
# CRITERIA="'-*' '+* * ERROR*'"
# (Reset the monitor by rotating the log using svc -a $svc_dir)
# 
# A more interesting application is a subscription progress log.
# EXTENSION='COPY'
# CRITERIA="'-*' '+* * ERROR*' '+* * WARN*' '+* * CONFIG enableSubscription*' '+* * DEBUG2 remoteWorkerThread_* prepare to copy table*' '+* * DEBUG2 remoteWorkerThread_* all tables for set * found on subscriber*' '+* * DEBUG2 remoteWorkerThread_* copy*' '+* * DEBUG2 remoteWorkerThread_* Begin COPY of table*' '+* * DEBUG2 remoteWorkerThread_* * bytes copied for table*' '+* * DEBUG2 remoteWorkerThread_* * seconds to*' '+* * DEBUG2 remoteWorkerThread_* set last_value of sequence*' '+* * DEBUG2 remoteWorkerThread_* copy_set*'"
# 
# If you have a subscription log then it's easy to determine if a given
# slon is in the process of handling copies or other subscription activity.
# If the log isn't empty, and doesn't end with a 
# "CONFIG enableSubscription: sub_set:1"
# (or whatever set number you've subscribed) then the slon is currently in
# the middle of initial copies.
# If you happen to be monitoring the mtime of your primary slony logs to 
# determine if your slon has gone brain-dead, checking this is a good way
# to avoid mistakenly clobbering it in the middle of a subscribe. As a bonus,
# recall that since the the slons are running under svscan, you only need to
# kill it (via the svc interface) and let svscan start it up again laster.
# I've also found the COPY logs handy for following subscribe activity 
# interactively.

DEFAULT_BASEDIR='/usr/local/etc'
DEFAULT_LOGDIR='/var/log'
DEFAULT_SYSUSR='pgsql'                          # FreeBSD-centric. Oh well.
DEFAULT_SOURCE='slon_123'
DEFAULT_EXTENSION='_NODEBUG'
DEFAULT_CRITERIA="'-* [*] DEBUG*'"

if [ -z "$BASEDIR" ]; then
    echo -n "Where do you want the service dir created? Don't create this in 
/service or /var/service. Once it's created, either symlink or move
it to the service directory (since linking is an atomic filesystem action). 
Note that log files will not be stored here (that's the next question), so 
this doesn't have to be on a high storage / IO capacity filesystem.
[$DEFAULT_BASEDIR]: "
    read BASEDIR
    if [ -z "$BASEDIR" ]; then
        BASEDIR="$DEFAULT_BASEDIR"
    fi
fi
echo "BASEDIR=$BASEDIR"

if [ -z "$LOGBASE" ]; then
    echo -n "Where should the logfiles live? You probably want to put this 
somewhere with plenty of storage and some IO capacity. Note that this
creates a subdirectory where the actual log files are stored.
Use - to disable this (putting the log files under log/main according to
daemontools convention).
[$DEFAULT_LOGDIR]: "
    read LOGDIR
    if [ -z "$LOGDIR" ]; then
        LOGDIR="$DEFAULT_LOGDIR"
    fi
fi

if [ -z "$SYSUSR" ]; then
    echo -n "System user name for followgrep to run under [$DEFAULT_SYSUSR]: "
    read SYSUSR
    if [ -z "$SYSUSR" ]; then
        SYSUSR="$DEFAULT_SYSUSR"
    fi
fi
echo "SYSUSR=$SYSUSR"

if [ -z "$SOURCE" ]; then
    echo -n "Service to follow [$DEFAULT_SOURCE]: "
    read SOURCE
    if [ -z "$SOURCE" ]; then
        DATABASE="$DEFAULT_SOURCE"
    fi
fi
echo "SOURCE=$SOURCE"

if [ -z "$EXTENSION" ]; then
    echo -n "Name extension [$DEFAULT_EXTENSION]: "
    read EXTENSION
    if [ -z "$EXTENSION" ]; then
        EXTENSION="$DEFAULT_EXTENSION"
    fi
fi
echo "EXTENSION=$EXTENSION"

if [ -z "$CRITERIA" ]; then
    echo -n "Criteria [$DEFAULT_CRITERIA]: "
    read CRITERIA
    if [ -z "$CRITERIA" ]; then
        CRITERIA="$DEFAULT_CRITERIA"
    fi
fi
echo "CRITERIA=$CRITERIA"


SVCNAME="logrep_$SOURCE$EXTENSION"
DIR="$BASEDIR/$SVCNAME"
LOGDIR="$DIR/log/main"
if [ '-' != "$LOGBASE" ]; then      # - means don't use a different logdir
    LOGDIR="$LOGBASE/$SVCNAME"      # otherwise we're logging somewhere else
fi

echo "Service dir will be created under $DIR"
echo "Logs will live under $LOGDIR"


mkdir -p "$DIR/env" "$DIR/supervise" "$DIR/log/env" "$DIR/log/supervise" "$LOGDIR" || exit -1
if [ '-' != "$LOGBASE" ]; then          # - means it's not a linked logdir
    ln -s "$LOGDIR" "$DIR/log/main"
fi
# Make sure the log file initially exists. This allows others to tail -F it
# before it starts getting populated. go go recursive logrep!
touch "$DIR/log/main/current" || exit -1

# create the run script
cat > "$DIR/run" <<EOF
#!/bin/sh
exec 2>&1
exec env ./env setuidgid $SYSUSR tail -F "$BASEDIR/$SOURCE/log/main/current"
EOF
chmod a+x "$DIR/run"
echo "$DIR/run created"

# setup an envdir for multilog
echo ${LOGMAX-"10485760"}           > $DIR/log/env/LOGMAX
echo ${LOGNUM-"99"}                 > $DIR/log/env/LOGNUM

cat > "$DIR/log/README.txt" <<EOF
To force a log rotation, use
svc -a $DIR/log

The size (in bytes) of the log files (before they get rotated) is controlled
by the s parameter for multilog. This is set up as an envdir variable at
$DIR/log/env/LOGMAX
You might want to increase or decrease this. It goes up to a maximum of
16777215 (15MB) and defaults to 99999 (97kB) if unset. Leaving it unset 
will break this script. It defaults to 10485760 (which is 10MB).
You need to restart multilog for changes to this to take effect.
svc -k $DIR/log

The n paramter decides how many old log files to keep around. This is set
up as an envdir variable at
$DIR/log/env/LOGNUM
You will probably want to decrease this if you are not using some other
tool to manage old logfiles. Multilog defaults to 10 if this is unset, but
like the size above, it will break this script if left unset. The script
defaults to 99 under the assumption that you are using some other, system
wide tool (like cfengine) to prune your logs.
EOF

# create the run file for the multilog
cat > "$DIR/log/run" <<EOF
#!/bin/sh
# This puts everything in the main log. Unfortunately multilog only allows
# you to select which log you want to write to as opposed to writing each
# line to every log which matches the criteria. Split up logs would make
# debugging harder. See also README.txt in this directory.
# Since we're presumably drawing data from another logfile which already 
# has timestamps, adding another would simply sow confusion.

exec envdir ./env sh -c 'exec setuidgid $SYSUSR multilog s"\$LOGMAX" n"\$LOGNUM" ./main'
EOF
chmod a+x "$DIR/log/run"
echo "$DIR/log/run created"

# fix permissions and ownership
chown -R "$SYSUSR" "$DIR"
chmod a+rX "$DIR"

cat <<EOF
When you're ready to start logrep, simply link the newly created dir, 
$DIR
under your current supervisor's directory. On FreeBSD this is /var/service
by default. So the command would be:

sudo ln -s $DIR /var/service

The service should be started within 5 seconds.
EOF

From cbbrowne at lists.slony.info  Mon Jul  9 12:10:22 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul  9 12:10:23 2007
Subject: [Slony1-commit] slony1-engine UPGRADING RELEASE-2.0 TODO
Message-ID: <20070709191022.C85622902FE@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine
In directory main.slony.info:/tmp/cvs-serv29426

Modified Files:
	UPGRADING RELEASE-2.0 TODO 
Log Message:
- Mark off some TODO items that have been completed

- Update release notes to reflect more patches for v2.0

- Added notes to UPGRADING indicating the issue with TABLE ADD KEY in v2.0


Index: UPGRADING
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/UPGRADING,v
retrieving revision 1.3
retrieving revision 1.4
diff -C2 -d -r1.3 -r1.4
*** UPGRADING	16 Feb 2007 23:35:13 -0000	1.3
--- UPGRADING	9 Jul 2007 19:10:20 -0000	1.4
***************
*** 31,35 ****
  
  Nullable Column issue in version 1.2
! ===================================
  
  In version 1.2, a check has been added to reject subscriptions to
--- 31,35 ----
  
  Nullable Column issue in version 1.2
! =====================================
  
  In version 1.2, a check has been added to reject subscriptions to
***************
*** 64,65 ****
--- 64,76 ----
  contains a great deal of data, as the alteration will scan the table
  to verify that there are no tuples where the column is NULL.
+ 
+ TABLE ADD KEY change in version 2.0
+ =====================================
+ 
+ In version 2.0, Slony-I drops out support for creating
+ system-generated "pseudo primary keys" that involve adding in a custom
+ Slony-I-generated column.
+ 
+ There is documentation in the Admin Guide (slonyupgrade.sgml,
+ slonyupgrade.html) explaining approaches to "cleaning up" after having
+ used TABLE ADD KEY.

Index: RELEASE-2.0
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/RELEASE-2.0,v
retrieving revision 1.3
retrieving revision 1.4
diff -C2 -d -r1.3 -r1.4
*** RELEASE-2.0	27 Jun 2007 15:54:37 -0000	1.3
--- RELEASE-2.0	9 Jul 2007 19:10:20 -0000	1.4
***************
*** 40,41 ****
--- 40,63 ----
  
    This fairly massively simplifies the C code.
+ 
+ - Revised logging levels so that most of the interesting messages are
+   spit out at SLON_CONFIG and SLON_INFO levels.  This can allow users
+   to drop out the higher DEBUG levels and still have useful logs.
+ 
+ - Changed log selection query to be less affected by long running
+   transaction.  This should help, in particular, the scenario where
+   it takes a very long time to subscribe to a set.  In that situation,
+   we have had the problem where applying the later SYNCs gets
+   extremely costly as the query selecting logs wound up forced into a
+   Seq Scan rather than an index scan.
+ 
+ 
+ - Removed all support for STORE/DROP TRIGGER commands. Users are supposed
+   to use the ALTER TABLE [ENABLE|DISABLE] TRIGGER functionality in
+   Postgres from now on.
+ 
+ - Improve Wiki page generation script so that it has an option to add in
+   a set of [[Category:Foo]] tags to allow automated categorization.
+ 
+ - Documented how to fix tables that presently use Slony-I-generated
+   primary key candidates generated by TABLE ADD KEY

Index: TODO
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/TODO,v
retrieving revision 1.5
retrieving revision 1.6
diff -C2 -d -r1.5 -r1.6
*** TODO	6 Jul 2007 18:40:25 -0000	1.5
--- TODO	9 Jul 2007 19:10:20 -0000	1.6
***************
*** 7,17 ****
  --------------------------------------------
  
- - Document how to fix tables that presently use Slony-I-generated
-   primary key candidates generated by TABLE ADD KEY
- 
  - Removed all support for STORE/DROP TRIGGER commands. Users are
    supposed to use the ALTER TABLE [ENABLE|DISABLE] TRIGGER
    functionality in Postgres from now on.
  
  
  Short Term Items
--- 7,16 ----
  --------------------------------------------
  
  - Removed all support for STORE/DROP TRIGGER commands. Users are
    supposed to use the ALTER TABLE [ENABLE|DISABLE] TRIGGER
    functionality in Postgres from now on.
  
+   There is now mention of this in docs/adminguide/slonyupgrade.sgml;
+   need to enhance it further after discussion with Jan Wieck.
  
  Short Term Items
***************
*** 24,31 ****
  verify that upgrades work properly.
  
- Improve Wiki page generation script so that it has an option to add in
- a set of [[Category:Foo]] tags to allow automated categorization.
- 
- 
  Bill Moran had some timestamps that were not handled well; should make
  sure that these specific timestamps are included in our test cases...
--- 23,26 ----
***************
*** 36,41 ****
  03/29/2007 13:35:19.960505 edt vs. 03/29/2007 12:35:19.960505 est
  
- - Add Drew Hammond's "mkservice" scripts to the 1.2 branch
- 
  - update autoconf to be better aware of where DocBook document
    generation tools live
--- 31,34 ----

From cbbrowne at lists.slony.info  Mon Jul  9 12:31:12 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul  9 12:31:14 2007
Subject: [Slony1-commit] slony1-engine TODO RELEASE-2.0
Message-ID: <20070709193112.B911E290C1C@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine
In directory main.slony.info:/tmp/cvs-serv29680

Modified Files:
	TODO RELEASE-2.0 
Log Message:
Added some extra tuples to date test so that we have tuples within the
somewhat ambiguous date range which is now DST that didn't use to be...

PostgreSQL stores "zoned" data in UTC form, so that the only reason to
expect any disagreement between nodes would be if two nodes were on
different versions of PostgreSQL that have a different idea as to how
to output those dates (thus, you have one that is aware of the new rules,
and one unaware, and are using TZ/PGTZ in a relevant zone).

Thus, we don't expect this test to "fall over" terribly much, but the
data's handy, if someone wants to do such a test...


Index: RELEASE-2.0
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/RELEASE-2.0,v
retrieving revision 1.4
retrieving revision 1.5
diff -C2 -d -r1.4 -r1.5
*** RELEASE-2.0	9 Jul 2007 19:10:20 -0000	1.4
--- RELEASE-2.0	9 Jul 2007 19:31:10 -0000	1.5
***************
*** 62,63 ****
--- 62,71 ----
  - Documented how to fix tables that presently use Slony-I-generated
    primary key candidates generated by TABLE ADD KEY
+ 
+ - Add some specific timestamps during the 2007 "DST rule change
+   ambiguous time" (e.g. - during the period which, under former rules,
+   was not DST, but which now is, due to the recent rule change).
+ 
+   Bill Moran ran into some problems with such dates; varying
+   PostgreSQL versions returned somewhat varying results.  This wasn't
+   a Slony-I problem; the data was indeed being replicated correctly.

Index: TODO
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/TODO,v
retrieving revision 1.6
retrieving revision 1.7
diff -C2 -d -r1.6 -r1.7
*** TODO	9 Jul 2007 19:10:20 -0000	1.6
--- TODO	9 Jul 2007 19:31:10 -0000	1.7
***************
*** 23,34 ****
  verify that upgrades work properly.
  
- Bill Moran had some timestamps that were not handled well; should make
- sure that these specific timestamps are included in our test cases...
- 
- 03/12/2007 11:05:32.913154 edt vs. 03/12/2007 10:05:32.913154 est
- 03/14/2007 17:39:28.595669 edt vs. 03/14/2007 16:39:28.595669 est
- 03/28/2007 14:45:55.75936 edt  vs. 03/28/2007 13:45:55.75936 est
- 03/29/2007 13:35:19.960505 edt vs. 03/29/2007 12:35:19.960505 est
- 
  - update autoconf to be better aware of where DocBook document
    generation tools live
--- 23,26 ----

From cbbrowne at lists.slony.info  Mon Jul  9 12:31:12 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul  9 12:31:15 2007
Subject: [Slony1-commit] slony1-engine/tests/testdatestyles init_data.sql
Message-ID: <20070709193112.C2114290C1E@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tests/testdatestyles
In directory main.slony.info:/tmp/cvs-serv29680/tests/testdatestyles

Modified Files:
	init_data.sql 
Log Message:
Added some extra tuples to date test so that we have tuples within the
somewhat ambiguous date range which is now DST that didn't use to be...

PostgreSQL stores "zoned" data in UTC form, so that the only reason to
expect any disagreement between nodes would be if two nodes were on
different versions of PostgreSQL that have a different idea as to how
to output those dates (thus, you have one that is aware of the new rules,
and one unaware, and are using TZ/PGTZ in a relevant zone).

Thus, we don't expect this test to "fall over" terribly much, but the
data's handy, if someone wants to do such a test...


Index: init_data.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testdatestyles/init_data.sql,v
retrieving revision 1.1
retrieving revision 1.2
diff -C2 -d -r1.1 -r1.2
*** init_data.sql	23 Jun 2006 15:37:57 -0000	1.1
--- init_data.sql	9 Jul 2007 19:31:10 -0000	1.2
***************
*** 2,3 ****
--- 2,19 ----
  insert into table1(ts, tsz, ds) values ('infinity', 'infinity', now());
  insert into table1(ts, tsz, ds) values ('-infinity', '-infinity', now());
+ 
+ insert into table1 (ts, tsz, ds) values (
+ 
+ -- Some nice dates that take place inside the time window that was
+ -- a tad ambiguous in 2007 in that the definition of daylight savings time
+ -- was changed - per Bill Moran
+ 
+ insert into table1 (ts, tsz, ds) values (now(), '2007-03-12 11:05:32.913154 edt', now());
+ insert into table1 (ts, tsz, ds) values (now(), '2007-03-12 10:05:32.913154 est', now());
+ insert into table1 (ts, tsz, ds) values (now(), '2007-03-14 17:39:28.595669 edt', now());
+ insert into table1 (ts, tsz, ds) values (now(), '2007-03-14 16:39:28.595669 est', now());
+ insert into table1 (ts, tsz, ds) values (now(), '2007-03-28 14:45:55.75936 edt', now());
+ insert into table1 (ts, tsz, ds) values (now(), '2007-03-28 13:45:55.75936 est', now());
+ insert into table1 (ts, tsz, ds) values (now(), '2007-03-29 13:35:19.960505 edt', now());
+ insert into table1 (ts, tsz, ds) values (now(), '2007-03-29 12:35:19.960505 est', now());
+ 

From cbbrowne at lists.slony.info  Mon Jul  9 12:34:37 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul  9 12:34:38 2007
Subject: [Slony1-commit] slony1-engine TODO
Message-ID: <20070709193437.33F7B2903BE@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine
In directory main.slony.info:/tmp/cvs-serv29839

Modified Files:
	TODO 
Log Message:
Add some more notes to TODO


Index: TODO
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/TODO,v
retrieving revision 1.7
retrieving revision 1.8
diff -C2 -d -r1.7 -r1.8
*** TODO	9 Jul 2007 19:31:10 -0000	1.7
--- TODO	9 Jul 2007 19:34:35 -0000	1.8
***************
*** 33,36 ****
--- 33,45 ----
    e.g. - add a warning if there exist tables with generated PK.
  
+   Arguably, that isn't really a good thing to do; if there is a table
+   with column generated via TABLE ADD KEY, then we have the
+   undesirable result that there will be an error/warning reported
+   every time test_slony_state is run.
+ 
+   Perhaps there should be a second script that looks for "static"
+   problems, so we can leave test_slony_state to look for "dynamic"
+   problems.
+ 
  - Use PGXS
  

From cbbrowne at lists.slony.info  Mon Jul  9 13:42:29 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul  9 13:42:31 2007
Subject: [Slony1-commit] slony1-engine/config docbook.m4
Message-ID: <20070709204229.7AAE3290BDF@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/config
In directory main.slony.info:/tmp/cvs-serv1982

Modified Files:
	docbook.m4 
Log Message:
Add rules that detect docbook-utils paths for Debian, Fedora, SuSE, *BSD


Index: docbook.m4
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/config/docbook.m4,v
retrieving revision 1.5
retrieving revision 1.6
diff -C2 -d -r1.5 -r1.6
*** docbook.m4	8 Dec 2005 20:44:57 -0000	1.5
--- docbook.m4	9 Jul 2007 20:42:27 -0000	1.6
***************
*** 19,22 ****
--- 19,28 ----
  AC_DEFUN([SLON_AC_PROG_D2M],
  [AC_MSG_CHECKING([for docbook2man-spec.pl],[slon_cv_check_d2mdir])
+ for slonac_prefix in /usr/local/share/sgml/docbook/utils-0.6.14/helpers /usr/share/perl5/sgmlspl-specs /usr/share/sgml/docbook/utils-0.6.14/helpers $with_d2mdir ; do
+   if test -s "$slonac_prefix/docbook2man-spec.pl" ; then
+      with_d2mdir="$slonac_prefix"
+   fi
+ done
+ 
  if test -s "$with_d2mdir/docbook2man-spec.pl" ; then
      AC_SUBST(d2mdir, $with_d2mdir)

From cbbrowne at lists.slony.info  Wed Jul 11 10:20:20 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jul 11 10:20:22 2007
Subject: [Slony1-commit] slony1-engine RELEASE-2.0
Message-ID: <20070711172020.A180E29045F@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine
In directory main.slony.info:/tmp/cvs-serv14278

Modified Files:
	RELEASE-2.0 
Log Message:
Tests now generate output in a |pipe delimited| form for eventual
aggregation in a "regression test repository."


Index: RELEASE-2.0
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/RELEASE-2.0,v
retrieving revision 1.5
retrieving revision 1.6
diff -C2 -d -r1.5 -r1.6
*** RELEASE-2.0	9 Jul 2007 19:31:10 -0000	1.5
--- RELEASE-2.0	11 Jul 2007 17:20:18 -0000	1.6
***************
*** 52,56 ****
    Seq Scan rather than an index scan.
  
- 
  - Removed all support for STORE/DROP TRIGGER commands. Users are supposed
    to use the ALTER TABLE [ENABLE|DISABLE] TRIGGER functionality in
--- 52,55 ----
***************
*** 70,71 ****
--- 69,77 ----
    PostgreSQL versions returned somewhat varying results.  This wasn't
    a Slony-I problem; the data was indeed being replicated correctly.
+ 
+ - Made configure a bit smarter about automatically locating
+   docbook2man-spec.pl on Debian, Fedora, BSD.
+ 
+ - Tests now generate |pipe|delimited|output| indicating a number of
+   attributes of each test, including system/platform information,
+   versions, and whether or not the test succeeded or failed.

From cbbrowne at lists.slony.info  Wed Jul 11 10:20:20 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jul 11 10:20:22 2007
Subject: [Slony1-commit] slony1-engine/tests run_test.sh settings.ik
	support_funcs.sh
Message-ID: <20070711172020.B7B49290C1C@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tests
In directory main.slony.info:/tmp/cvs-serv14278/tests

Modified Files:
	run_test.sh settings.ik support_funcs.sh 
Log Message:
Tests now generate output in a |pipe delimited| form for eventual
aggregation in a "regression test repository."


Index: support_funcs.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/support_funcs.sh,v
retrieving revision 1.5
retrieving revision 1.6
diff -C2 -d -r1.5 -r1.6
*** support_funcs.sh	6 Jun 2007 22:20:39 -0000	1.5
--- support_funcs.sh	11 Jul 2007 17:20:18 -0000	1.6
***************
*** 6,9 ****
--- 6,11 ----
      echo 1>&2 "$0: ERROR: $*"
      numerrors=`expr ${numerrors} + 1`
+ 
+     gen_testinfo "$*"
      exit $exitval
  }
***************
*** 199,200 ****
--- 201,234 ----
    echo ${ranstring}
  }
+ 
+ gen_testinfo ()
+ {
+     DESC=$1;
+     UNAMEM=`uname -m`
+     UNAMER=`uname -r`
+     UNAMES=`uname -s`
+     UNAMEV=`uname -v`
+     HOST=`hostname -f`
+     USERNAME=`whoami`
+     
+     #TESTSTARTTIME is calculated at the very beginning...
+     TESTENDTIME=`date +"%Y-%m-%d %H:%M:%S %Z"`
+ 
+     CLNAME="\"_${CLUSTER1}\""
+ 
+     if [[ x$DESC = x'' ]]; then
+ 	OK="true"
+     else
+ 	OK="false"
+     fi
+ 
+     BASEOUTPUT="select ${CLNAME}.getModuleversion() || '|' || ${CLNAME}.slonyVersionMajor() || '|' || ${CLNAME}.slonyVersionMinor() || '|' || ${CLNAME}.slonyVersionPatchlevel() || '|' || version() || '|';"
+ 
+     BASEOUTPUT=`${pgbindir}/psql -d ${DB1} -h ${HOST1} -p ${PORT1} -U ${USER1} -c "${QUERY}" -qAt`
+     BASEOUTPUT="${BASEOUTPUT}|${UNAMEM}|${UNAMER}|${UNAMES}|${UNAMEV}|"
+     BASEOUTPUT="${BASEOUTPUT}|${HOST}|${SLONYTESTER}|${testname}|${TESTSTARTTIME}|${TESTENDTIME}|${OK}|${DESC}"
+ 
+ 
+     echo "${BASEOUTPUT}" >> ${SLONYTESTFILE}
+     echo "${BASEOUTPUT}"
+ }

Index: settings.ik
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/settings.ik,v
retrieving revision 1.7
retrieving revision 1.8
diff -C2 -d -r1.7 -r1.8
*** settings.ik	22 Jun 2007 16:12:22 -0000	1.7
--- settings.ik	11 Jul 2007 17:20:18 -0000	1.8
***************
*** 105,107 ****
  
  # Email address of the tester
! SLONYTESTER=${SLONYTESTER:-"j.random.luser@example.net"}
\ No newline at end of file
--- 105,110 ----
  
  # Email address of the tester
! SLONYTESTER=${SLONYTESTER:-"j.random.luser@example.net"}
! 
! # File in which to stow SQL queries that summarize test results
! SLONYTESTFILE=${SLONYTESTFILE:-"/tmp/Slony-I-test-results.log"}

Index: run_test.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/run_test.sh,v
retrieving revision 1.14
retrieving revision 1.15
diff -C2 -d -r1.14 -r1.15
*** run_test.sh	20 Apr 2007 21:43:14 -0000	1.14
--- run_test.sh	11 Jul 2007 17:20:18 -0000	1.15
***************
*** 39,44 ****
  fi
  
  if [ ! -x "$pgbindir/psql" ]; then
!   echo "please set the PGBINDIR envvar to the directory containing psql, createdb, ..."
    exit 1;
  fi
--- 39,47 ----
  fi
  
+ TESTSTARTTIME=`date +"%Y-%m-%d %H:%M:%S %Z"`
+ 
+ 
  if [ ! -x "$pgbindir/psql" ]; then
!   echo "please set the PGBINDIR environment variable to the directory containing psql, createdb, ..."
    exit 1;
  fi
***************
*** 56,59 ****
--- 59,64 ----
  . support_funcs.sh
  
+ echo "Test by ${SLONYTESTER} to be summarized in ${SLONYTESTFILE}"
+ 
  trap '
  	echo ""
***************
*** 759,762 ****
--- 764,769 ----
  status "done"
  
+ gen_testinfo
  drop_databases
  cleanup
+ 

From cbbrowne at lists.slony.info  Wed Jul 11 10:20:20 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jul 11 10:20:22 2007
Subject: [Slony1-commit] slony1-engine/doc/adminguide testbed.sgml
Message-ID: <20070711172020.C1897290C22@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/doc/adminguide
In directory main.slony.info:/tmp/cvs-serv14278/doc/adminguide

Modified Files:
	testbed.sgml 
Log Message:
Tests now generate output in a |pipe delimited| form for eventual
aggregation in a "regression test repository."


Index: testbed.sgml
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/doc/adminguide/testbed.sgml,v
retrieving revision 1.12
retrieving revision 1.13
diff -C2 -d -r1.12 -r1.13
*** testbed.sgml	20 Apr 2007 20:55:33 -0000	1.12
--- testbed.sgml	11 Jul 2007 17:20:18 -0000	1.13
***************
*** 180,183 ****
--- 180,199 ----
  </glossentry>
  
+ <glossentry>
+ <glossterm><envar>SLONYTESTER</envar></glossterm>
+ 
+ <glossdef><para> Email address of the person who might be
+ contacted about the test results. This is stored in the
+ <envar>SLONYTESTFILE</envar>, and may eventually be aggregated in some
+ sort of buildfarm-like registry. </para> </glossdef>
+ </glossentry>
+ 
+ <glossentry>
+ <glossterm><envar>SLONYTESTFILE</envar></glossterm>
+ 
+ <glossdef><para> File in which to store summary results from tests.
+ Eventually, this may be used to construct a buildfarm-like repository of
+ aggregated test results. </para> </glossdef>
+ </glossentry>
  
  </glosslist>

From cbbrowne at lists.slony.info  Wed Jul 11 10:21:33 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Wed Jul 11 10:21:35 2007
Subject: [Slony1-commit] slony1-engine TODO
Message-ID: <20070711172133.DD24929045F@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine
In directory main.slony.info:/tmp/cvs-serv14593

Modified Files:
	TODO 
Log Message:
Revise TODO based on work done and commitments made


Index: TODO
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/TODO,v
retrieving revision 1.8
retrieving revision 1.9
diff -C2 -d -r1.8 -r1.9
*** TODO	9 Jul 2007 19:34:35 -0000	1.8
--- TODO	11 Jul 2007 17:21:31 -0000	1.9
***************
*** 26,29 ****
--- 26,33 ----
    generation tools live
  
+ - Clone Node - use pg_dump/PITR to populate a new subscriber node
+ 
+   Jan working on this
+ 
  Longer Term Items
  ---------------------------
***************
*** 46,63 ****
  - Windows-compatible version of tools/slony1_dump.sh
  
- - Clone Node - use pg_dump/PITR to populate a new subscriber node
- 
- - test scripts should generate output that can be readily aggregated.
- 
-   Initial prototype has them generating SQL output; unfortunately,
-   if we accept this from arbitrary sources, this is the very picture
-   of an SQL injection attack.  Before doing that, we'll need to
-   turn it into some suitable tabular/delimited format that can be
-   parsed into SQL.
- 
-   When defining what data there should be, it is useful to use SQL for
-   now.  But this needs NOT to be the form transmitted "across the
-   wire."
- 
  Wishful Thinking
  ----------------------------
--- 50,53 ----

From cbbrowne at lists.slony.info  Fri Jul 13 15:08:25 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 13 15:08:26 2007
Subject: [Slony1-commit] slony1-engine TODO
Message-ID: <20070713220825.329402903CD@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine
In directory main.slony.info:/tmp/cvs-serv23882

Modified Files:
	TODO 
Log Message:
Add new item about statement parser


Index: TODO
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/TODO,v
retrieving revision 1.9
retrieving revision 1.10
diff -C2 -d -r1.9 -r1.10
*** TODO	11 Jul 2007 17:21:31 -0000	1.9
--- TODO	13 Jul 2007 22:08:23 -0000	1.10
***************
*** 23,29 ****
  verify that upgrades work properly.
  
- - update autoconf to be better aware of where DocBook document
-   generation tools live
- 
  - Clone Node - use pg_dump/PITR to populate a new subscriber node
  
--- 23,26 ----
***************
*** 50,53 ****
--- 47,54 ----
  - Windows-compatible version of tools/slony1_dump.sh
  
+ - Consider pulling the lexer from psql
+ 
+   http://developer.postgresql.org/cvsweb.cgi/pgsql/src/bin/psql/psqlscan.l?rev=1.21;content-type=text%2Fx-cvsweb-markup
+ 
  Wishful Thinking
  ----------------------------

From cbbrowne at lists.slony.info  Fri Jul 20 10:33:31 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 20 10:33:33 2007
Subject: [Slony1-commit] slony1-engine/src/slonik slonik.c
Message-ID: <20070720173331.AF392290C01@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slonik
In directory main.slony.info:/tmp/cvs-serv18296/slonik

Modified Files:
	slonik.c 
Log Message:
Patch per Drew Hammond

- add support longopt options for --help, --version and add them to
  help output for slon


Index: slonik.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/slonik.c,v
retrieving revision 1.79
retrieving revision 1.80
diff -C2 -d -r1.79 -r1.80
*** slonik.c	5 Jul 2007 18:19:04 -0000	1.79
--- slonik.c	20 Jul 2007 17:33:29 -0000	1.80
***************
*** 83,87 ****
  	int			opt;
  
! 	while ((opt = getopt(argc, (char **)argv, "hv")) != EOF)
  	{
  		switch (opt)
--- 83,92 ----
  	int			opt;
  
!     static struct option longopts[] = {
!         { "help",       no_argument,    NULL,   "h"},
!         { "version",    no_argument,    NULL,   "v"}
!     };
! 
! 	while ((opt = getopt_long(argc, (char **)argv, "hv", longopts, NULL)) != -1)
  	{
  		switch (opt)

From cbbrowne at lists.slony.info  Fri Jul 20 10:33:31 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 20 10:33:33 2007
Subject: [Slony1-commit] slony1-engine/src/slon slon.c
Message-ID: <20070720173331.BB4C2290C25@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv18296/slon

Modified Files:
	slon.c 
Log Message:
Patch per Drew Hammond

- add support longopt options for --help, --version and add them to
  help output for slon


Index: slon.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/slon.c,v
retrieving revision 1.74
retrieving revision 1.75
diff -C2 -d -r1.74 -r1.75
*** slon.c	27 Jun 2007 16:20:24 -0000	1.74
--- slon.c	20 Jul 2007 17:33:29 -0000	1.75
***************
*** 96,99 ****
--- 96,101 ----
  	fprintf(stderr, "Options:\n");
  
+     fprintf(stderr, "    -h, --help            print usage message and exit\n")
+     fprintf(stedrr, "    -v, --version         print version and exit\n");
  	fprintf(stderr, "    -d <debuglevel>       verbosity of logging (1..4)\n");
  	fprintf(stderr, "    -s <milliseconds>     SYNC check interval (default 10000)\n");
***************
*** 135,138 ****
--- 137,145 ----
  	extern char *optarg;
  
+     static struct option longopts[] = {
+         { "help",       no_argument,    NULL,   "h"},
+         { "version",    no_argument,    NULL,   "v"}
+     };
+ 
  #ifdef WIN32
  	WSADATA		wsaData;
***************
*** 166,170 ****
  	InitializeConfOptions();
  
! 	while ((c = getopt(argc, argv, "f:a:d:s:t:g:c:p:o:q:r:l:x:hv?")) != EOF)
  	{
  		switch (c)
--- 173,177 ----
  	InitializeConfOptions();
  
! 	while ((c = getopt_long(argc, argv, "f:a:d:s:t:g:c:p:o:q:r:l:x:hv?", longopts, NULL)) != -1)
  	{
  		switch (c)

From cbbrowne at lists.slony.info  Fri Jul 20 12:53:27 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 20 12:53:29 2007
Subject: [Slony1-commit] slony1-engine/src/slon slon.c
Message-ID: <20070720195327.79315290C23@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv19828/slon

Modified Files:
      Tag: REL_1_2_STABLE
	slon.c 
Log Message:
Add documentation to slon of -h and -v options


Index: slon.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/slon.c,v
retrieving revision 1.66.2.6
retrieving revision 1.66.2.7
diff -C2 -d -r1.66.2.6 -r1.66.2.7
*** slon.c	14 Jun 2007 14:56:22 -0000	1.66.2.6
--- slon.c	20 Jul 2007 19:53:25 -0000	1.66.2.7
***************
*** 95,98 ****
--- 95,100 ----
  	fprintf(stderr, "Options:\n");
  
+ 	fprintf(stderr, "    -h                    print usage message and exit\n");
+ 	fprintf(stderr, "    -v                    print version and exit\n");
  	fprintf(stderr, "    -d <debuglevel>       verbosity of logging (1..4)\n");
  	fprintf(stderr, "    -s <milliseconds>     SYNC check interval (default 10000)\n");

From cbbrowne at lists.slony.info  Fri Jul 20 12:55:59 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 20 12:56:00 2007
Subject: [Slony1-commit] slony1-engine/src/slonik slonik.c
Message-ID: <20070720195559.51559290C41@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slonik
In directory main.slony.info:/tmp/cvs-serv19875/slonik

Modified Files:
      Tag: REL_1_2_STABLE
	slonik.c 
Log Message:
Need for individual DDL requests to be submitted into a "%s" format, rather
than allowing printf() to perhaps mangle the DDL request.

Per Dmitry Koterov <dmitry@koterov.ru>


Index: slonik.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/slonik.c,v
retrieving revision 1.67.2.11
retrieving revision 1.67.2.12
diff -C2 -d -r1.67.2.11 -r1.67.2.12
*** slonik.c	7 Jun 2007 19:36:14 -0000	1.67.2.11
--- slonik.c	20 Jul 2007 19:55:57 -0000	1.67.2.12
***************
*** 3922,3926 ****
  		strncpy(dest, dstring_data(&script) + startpos, endpos-startpos);
  		dest[STMTS[stmtno]-startpos] = 0;
! 		slon_mkquery(&query, dest);
  		printf("DDL Statement %d: (%d,%d) [%s]\n", stmtno, startpos, endpos, dest);
  		free(dest);
--- 3922,3926 ----
  		strncpy(dest, dstring_data(&script) + startpos, endpos-startpos);
  		dest[STMTS[stmtno]-startpos] = 0;
! 		slon_mkquery(&query, "%s", dest);
  		printf("DDL Statement %d: (%d,%d) [%s]\n", stmtno, startpos, endpos, dest);
  		free(dest);

From cbbrowne at lists.slony.info  Fri Jul 20 12:55:59 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 20 12:56:00 2007
Subject: [Slony1-commit] slony1-engine/src/slon remote_worker.c
Message-ID: <20070720195559.3FE93290C25@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv19875/slon

Modified Files:
      Tag: REL_1_2_STABLE
	remote_worker.c 
Log Message:
Need for individual DDL requests to be submitted into a "%s" format, rather
than allowing printf() to perhaps mangle the DDL request.

Per Dmitry Koterov <dmitry@koterov.ru>


Index: remote_worker.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/remote_worker.c,v
retrieving revision 1.124.2.16
retrieving revision 1.124.2.17
diff -C2 -d -r1.124.2.16 -r1.124.2.17
*** remote_worker.c	19 Jun 2007 15:51:18 -0000	1.124.2.16
--- remote_worker.c	20 Jul 2007 19:55:57 -0000	1.124.2.17
***************
*** 6064,6068 ****
  			strncpy(dest, ddl_script + startpos, endpos-startpos);
  			dest[STMTS[stmtno]-startpos] = 0;
! 			slon_mkquery(&query1, dest);
  			slon_log(SLON_CONFIG, "remoteWorkerThread_%d: DDL Statement %d: [%s]\n", 
  					 node->no_id, stmtno, dest);						 
--- 6064,6068 ----
  			strncpy(dest, ddl_script + startpos, endpos-startpos);
  			dest[STMTS[stmtno]-startpos] = 0;
! 			slon_mkquery(&query1, "%s", dest);
  			slon_log(SLON_CONFIG, "remoteWorkerThread_%d: DDL Statement %d: [%s]\n", 
  					 node->no_id, stmtno, dest);						 

From cbbrowne at lists.slony.info  Fri Jul 20 12:59:57 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 20 12:59:57 2007
Subject: [Slony1-commit] slony1-engine/src/slonik slonik.c
Message-ID: <20070720195957.185A4290C41@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slonik
In directory main.slony.info:/tmp/cvs-serv19988/slonik

Modified Files:
	slonik.c 
Log Message:
Don't use long options for --help/--version (sorry Drew), but make sure
-h and -v are generated by slon -h option.


Index: slonik.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/slonik.c,v
retrieving revision 1.80
retrieving revision 1.81
diff -C2 -d -r1.80 -r1.81
*** slonik.c	20 Jul 2007 17:33:29 -0000	1.80
--- slonik.c	20 Jul 2007 19:59:54 -0000	1.81
***************
*** 83,92 ****
  	int			opt;
  
!     static struct option longopts[] = {
!         { "help",       no_argument,    NULL,   "h"},
!         { "version",    no_argument,    NULL,   "v"}
!     };
! 
! 	while ((opt = getopt_long(argc, (char **)argv, "hv", longopts, NULL)) != -1)
  	{
  		switch (opt)
--- 83,87 ----
  	int			opt;
  
! 	while ((opt = getopt(argc, (char **)argv, "hv")) != EOF)
  	{
  		switch (opt)

From cbbrowne at lists.slony.info  Fri Jul 20 12:59:56 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 20 12:59:58 2007
Subject: [Slony1-commit] slony1-engine/src/slon slon.c
Message-ID: <20070720195956.EE90F290C25@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv19988/slon

Modified Files:
	slon.c 
Log Message:
Don't use long options for --help/--version (sorry Drew), but make sure
-h and -v are generated by slon -h option.


Index: slon.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/slon.c,v
retrieving revision 1.75
retrieving revision 1.76
diff -C2 -d -r1.75 -r1.76
*** slon.c	20 Jul 2007 17:33:29 -0000	1.75
--- slon.c	20 Jul 2007 19:59:54 -0000	1.76
***************
*** 96,101 ****
  	fprintf(stderr, "Options:\n");
  
!     fprintf(stderr, "    -h, --help            print usage message and exit\n")
!     fprintf(stedrr, "    -v, --version         print version and exit\n");
  	fprintf(stderr, "    -d <debuglevel>       verbosity of logging (1..4)\n");
  	fprintf(stderr, "    -s <milliseconds>     SYNC check interval (default 10000)\n");
--- 96,101 ----
  	fprintf(stderr, "Options:\n");
  
! 	fprintf(stderr, "    -h                    print usage message and exit\n");
! 	fprintf(stderr, "    -v                    print version and exit\n");
  	fprintf(stderr, "    -d <debuglevel>       verbosity of logging (1..4)\n");
  	fprintf(stderr, "    -s <milliseconds>     SYNC check interval (default 10000)\n");
***************
*** 137,144 ****
  	extern char *optarg;
  
-     static struct option longopts[] = {
-         { "help",       no_argument,    NULL,   "h"},
-         { "version",    no_argument,    NULL,   "v"}
-     };
  
  #ifdef WIN32
--- 137,140 ----
***************
*** 173,177 ****
  	InitializeConfOptions();
  
! 	while ((c = getopt_long(argc, argv, "f:a:d:s:t:g:c:p:o:q:r:l:x:hv?", longopts, NULL)) != -1)
  	{
  		switch (c)
--- 169,173 ----
  	InitializeConfOptions();
  
! 	while ((c = getopt(argc, argv, "f:a:d:s:t:g:c:p:o:q:r:l:x:hv?")) != EOF)
  	{
  		switch (c)

From cbbrowne at lists.slony.info  Fri Jul 20 13:20:16 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 20 13:20:17 2007
Subject: [Slony1-commit] slony1-engine/src/slon remote_worker.c
Message-ID: <20070720202016.1387A290C47@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv20342/slon

Modified Files:
	remote_worker.c 
Log Message:
Add "%s" parameter so that printf() does not interpret anything inside
DDL requests.  As observed by Dmitry Koterov <dmitry@koterov.ru>.


Index: remote_worker.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/remote_worker.c,v
retrieving revision 1.148
retrieving revision 1.149
diff -C2 -d -r1.148 -r1.149
*** remote_worker.c	5 Jul 2007 18:19:04 -0000	1.148
--- remote_worker.c	20 Jul 2007 20:20:13 -0000	1.149
***************
*** 1333,1337 ****
  					strncpy(dest, ddl_script + startpos, endpos-startpos);
  					dest[STMTS[stmtno]-startpos] = 0;
! 					(void) slon_mkquery(&query1, dest);
  					slon_log(SLON_CONFIG, "remoteWorkerThread_%d: DDL Statement %d: [%s]\n", 
  						 node->no_id, stmtno, dest);						 
--- 1333,1337 ----
  					strncpy(dest, ddl_script + startpos, endpos-startpos);
  					dest[STMTS[stmtno]-startpos] = 0;
! 					(void) slon_mkquery(&query1, "%s", dest);
  					slon_log(SLON_CONFIG, "remoteWorkerThread_%d: DDL Statement %d: [%s]\n", 
  						 node->no_id, stmtno, dest);						 

From cbbrowne at lists.slony.info  Fri Jul 20 13:20:15 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 20 13:20:17 2007
Subject: [Slony1-commit] slony1-engine/src/slonik slonik.c
Message-ID: <20070720202016.021E7290C45@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slonik
In directory main.slony.info:/tmp/cvs-serv20342/slonik

Modified Files:
	slonik.c 
Log Message:
Add "%s" parameter so that printf() does not interpret anything inside
DDL requests.  As observed by Dmitry Koterov <dmitry@koterov.ru>.


Index: slonik.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/slonik.c,v
retrieving revision 1.81
retrieving revision 1.82
diff -C2 -d -r1.81 -r1.82
*** slonik.c	20 Jul 2007 19:59:54 -0000	1.81
--- slonik.c	20 Jul 2007 20:20:13 -0000	1.82
***************
*** 3601,3605 ****
  		strncpy(dest, dstring_data(&script) + startpos, endpos-startpos);
  		dest[STMTS[stmtno]-startpos] = 0;
! 		slon_mkquery(&query, dest);
  		printf("DDL Statement %d: (%d,%d) [%s]\n", stmtno, startpos, endpos, dest);
  		free(dest);
--- 3601,3605 ----
  		strncpy(dest, dstring_data(&script) + startpos, endpos-startpos);
  		dest[STMTS[stmtno]-startpos] = 0;
! 		slon_mkquery(&query, "%s", dest);
  		printf("DDL Statement %d: (%d,%d) [%s]\n", stmtno, startpos, endpos, dest);
  		free(dest);

From cbbrowne at lists.slony.info  Fri Jul 27 14:35:38 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 27 14:35:39 2007
Subject: [Slony1-commit] slony1-engine/src/backend slony1_funcs.sql
Message-ID: <20070727213538.80B5D2902D0@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/backend
In directory main.slony.info:/tmp/cvs-serv21195

Modified Files:
	slony1_funcs.sql 
Log Message:
Per Jacques Caron, shift UPDATE to pg_class.hasrelindex to *after* the
TRUNCATE, as, in 8.2+, TRUNCATE resets this column (which was undoing
our change).

Without this change, indexes would get updated during the COPY, with
a pretty enormous performance "hit."


Index: slony1_funcs.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/backend/slony1_funcs.sql,v
retrieving revision 1.114
retrieving revision 1.115
diff -C2 -d -r1.114 -r1.115
*** slony1_funcs.sql	5 Jul 2007 18:19:04 -0000	1.114
--- slony1_funcs.sql	27 Jul 2007 21:35:36 -0000	1.115
***************
*** 5409,5412 ****
--- 5409,5418 ----
  
  	-- ----
+ 	-- Try using truncate to empty the table and fallback to
+ 	-- delete on error.
+ 	-- ----
+ 	execute ''truncate '' || @NAMESPACE@.slon_quote_input(v_tab_fqname);
+ 	raise notice ''truncate of % succeeded'', v_tab_fqname;
+ 	-- ----
  	-- Setting pg_class.relhasindex to false will cause copy not to
  	-- maintain any indexes. At the end of the copy we will reenable
***************
*** 5416,5425 ****
  	update pg_class set relhasindex = ''f'' where oid = v_tab_oid;
  
- 	-- ----
- 	-- Try using truncate to empty the table and fallback to
- 	-- delete on error.
- 	-- ----
- 	execute ''truncate '' || @NAMESPACE@.slon_quote_input(v_tab_fqname);
- 	raise notice ''truncate of % succeeded'', v_tab_fqname;
  	return 1;
  	exception when others then
--- 5422,5425 ----

From cbbrowne at lists.slony.info  Fri Jul 27 14:37:35 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 27 14:37:36 2007
Subject: [Slony1-commit] slony1-engine/src/backend slony1_funcs.v81.sql
Message-ID: <20070727213735.2CD642903C1@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/backend
In directory main.slony.info:/tmp/cvs-serv21938

Modified Files:
      Tag: REL_1_2_STABLE
	slony1_funcs.v81.sql 
Log Message:
Per Jacques Caron, shift UPDATE to pg_class.hasrelindex to *after* the
TRUNCATE, as, in 8.2+, TRUNCATE resets this column (which was undoing
our change).

Without this change, indexes would get updated during the COPY, with
a pretty enormous performance "hit."



Index: slony1_funcs.v81.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/backend/Attic/slony1_funcs.v81.sql,v
retrieving revision 1.1.2.1
retrieving revision 1.1.2.2
diff -C2 -d -r1.1.2.1 -r1.1.2.2
*** slony1_funcs.v81.sql	8 Feb 2007 22:55:58 -0000	1.1.2.1
--- slony1_funcs.v81.sql	27 Jul 2007 21:37:33 -0000	1.1.2.2
***************
*** 41,44 ****
--- 41,51 ----
  
  	-- ----
+ 	-- Try using truncate to empty the table and fallback to
+ 	-- delete on error.
+ 	-- ----
+ 	execute ''truncate '' || @NAMESPACE@.slon_quote_input(v_tab_fqname);
+ 	raise notice ''truncate of % succeeded'', v_tab_fqname;
+ 
+ 	-- ----
  	-- Setting pg_class.relhasindex to false will cause copy not to
  	-- maintain any indexes. At the end of the copy we will reenable
***************
*** 48,57 ****
  	update pg_class set relhasindex = ''f'' where oid = v_tab_oid;
  
- 	-- ----
- 	-- Try using truncate to empty the table and fallback to
- 	-- delete on error.
- 	-- ----
- 	execute ''truncate '' || @NAMESPACE@.slon_quote_input(v_tab_fqname);
- 	raise notice ''truncate of % succeeded'', v_tab_fqname;
  	return 1;
  	exception when others then
--- 55,58 ----

From cbbrowne at lists.slony.info  Fri Jul 27 14:39:13 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Fri Jul 27 14:39:14 2007
Subject: [Slony1-commit] slony1-engine RELEASE
Message-ID: <20070727213913.645702903BF@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine
In directory main.slony.info:/tmp/cvs-serv22237

Modified Files:
      Tag: REL_1_2_STABLE
	RELEASE 
Log Message:
Add release note regarding change to subscription behaviour (e.g. -
shifting update to pg_class.relhasindex).


Index: RELEASE
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/RELEASE,v
retrieving revision 1.1.2.7
retrieving revision 1.1.2.8
diff -C2 -d -r1.1.2.7 -r1.1.2.8
*** RELEASE	9 Jul 2007 19:07:01 -0000	1.1.2.7
--- RELEASE	27 Jul 2007 21:39:11 -0000	1.1.2.8
***************
*** 5,8 ****
--- 5,11 ----
  - Add in tools/mkservice scripts previously added to CVS HEAD
  
+ - During subscription, do UPDATE to pg_class.relhasindex *after* the
+   TRUNCATE because, in 8.2+, TRUNCATE resets this attribute
+ 
  RELEASE 1.2.10
  

From wieck at lists.slony.info  Sun Jul 29 10:27:35 2007
From: wieck at lists.slony.info (Jan Wieck)
Date: Sun Jul 29 10:27:38 2007
Subject: [Slony1-commit] slony1-engine/src/backend slony1_funcs.sql
Message-ID: <20070729172735.588B22903C6@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/backend
In directory main.slony.info:/tmp/cvs-serv4257

Modified Files:
      Tag: REL_1_2_STABLE
	slony1_funcs.sql 
Log Message:
Found another parameter to text casting issue with 8.3.

Jan


Index: slony1_funcs.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/backend/slony1_funcs.sql,v
retrieving revision 1.98.2.17
retrieving revision 1.98.2.18
diff -C2 -d -r1.98.2.17 -r1.98.2.18
*** slony1_funcs.sql	8 Jun 2007 00:08:03 -0000	1.98.2.17
--- slony1_funcs.sql	29 Jul 2007 17:27:33 -0000	1.98.2.18
***************
*** 2548,2555 ****
  	if exists (select true from @NAMESPACE@.sl_event
  			where ev_type = ''ENABLE_SUBSCRIPTION''
! 			and ev_data1 = p_add_id
  			and ev_seqno > (select max(con_seqno) from @NAMESPACE@.sl_confirm
  					where con_origin = ev_origin
! 					and con_received = ev_data3))
  	then
  		raise exception ''Slony-I: set % has subscriptions in progress - cannot merge'',
--- 2548,2555 ----
  	if exists (select true from @NAMESPACE@.sl_event
  			where ev_type = ''ENABLE_SUBSCRIPTION''
! 			and ev_data1 = p_add_id::text
  			and ev_seqno > (select max(con_seqno) from @NAMESPACE@.sl_confirm
  					where con_origin = ev_origin
! 					and con_received::text = ev_data3))
  	then
  		raise exception ''Slony-I: set % has subscriptions in progress - cannot merge'',

From wieck at lists.slony.info  Sun Jul 29 10:29:20 2007
From: wieck at lists.slony.info (Jan Wieck)
Date: Sun Jul 29 10:29:21 2007
Subject: [Slony1-commit] slony1-engine/src/slon remote_worker.c
Message-ID: <20070729172920.96A44290420@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv4314

Modified Files:
      Tag: REL_1_2_STABLE
	remote_worker.c 
Log Message:
Fixed a problem with the setsync tracking in cases where slon does
an internal restart (thereby rereading the pset.ssy_seqno) and ignoring
non-SYNC events because those don't change the sl_setsync table.


Jan


Index: remote_worker.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/remote_worker.c,v
retrieving revision 1.124.2.17
retrieving revision 1.124.2.18
diff -C2 -d -r1.124.2.17 -r1.124.2.18
*** remote_worker.c	20 Jul 2007 19:55:57 -0000	1.124.2.17
--- remote_worker.c	29 Jul 2007 17:29:18 -0000	1.124.2.18
***************
*** 388,395 ****
  						{
  							slon_mkquery(&query1,
! 								"select max(ssy_seqno) from %s.sl_setsync "
  								"  where ssy_setid = %d "
! 								"    and ssy_origin = %d; ",
! 								rtcfg_namespace, pset->set_id, node->no_id);
  							if (query_execute(node, local_dbconn, &query1) < 0)
  								slon_retry();
--- 388,402 ----
  						{
  							slon_mkquery(&query1,
! 								"select max(ssy_seqno) from ("
! 								"select ssy_seqno from %s.sl_setsync "
  								"  where ssy_setid = %d "
! 								"    and ssy_origin = %d "
! 								"union "
! 								"select ev_seqno from %s.sl_event "
! 								"  where ev_origin = %d "
! 								"    and ev_type <> 'SYNC' "
! 								") as S; ",
! 								rtcfg_namespace, pset->set_id, node->no_id,
! 								rtcfg_namespace, node->no_id);
  							if (query_execute(node, local_dbconn, &query1) < 0)
  								slon_retry();

From wieck at lists.slony.info  Sun Jul 29 10:37:36 2007
From: wieck at lists.slony.info (Jan Wieck)
Date: Sun Jul 29 10:37:38 2007
Subject: [Slony1-commit] slony1-engine/src/backend slony1_funcs.sql
Message-ID: <20070729173736.8A06D290C2F@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/backend
In directory main.slony.info:/tmp/cvs-serv4534

Modified Files:
	slony1_funcs.sql 
Log Message:
Found another parameter to text casting issue with 8.3.

Jan


Index: slony1_funcs.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/backend/slony1_funcs.sql,v
retrieving revision 1.115
retrieving revision 1.116
diff -C2 -d -r1.115 -r1.116
*** slony1_funcs.sql	27 Jul 2007 21:35:36 -0000	1.115
--- slony1_funcs.sql	29 Jul 2007 17:37:34 -0000	1.116
***************
*** 2487,2494 ****
  	if exists (select true from @NAMESPACE@.sl_event
  			where ev_type = ''ENABLE_SUBSCRIPTION''
! 			and ev_data1 = p_add_id
  			and ev_seqno > (select max(con_seqno) from @NAMESPACE@.sl_confirm
  					where con_origin = ev_origin
! 					and con_received = ev_data3))
  	then
  		raise exception ''Slony-I: set % has subscriptions in progress - cannot merge'',
--- 2487,2494 ----
  	if exists (select true from @NAMESPACE@.sl_event
  			where ev_type = ''ENABLE_SUBSCRIPTION''
! 			and ev_data1 = p_add_id::text
  			and ev_seqno > (select max(con_seqno) from @NAMESPACE@.sl_confirm
  					where con_origin = ev_origin
! 					and con_received::text = ev_data3))
  	then
  		raise exception ''Slony-I: set % has subscriptions in progress - cannot merge'',

From wieck at lists.slony.info  Sun Jul 29 10:38:25 2007
From: wieck at lists.slony.info (Jan Wieck)
Date: Sun Jul 29 10:38:27 2007
Subject: [Slony1-commit] slony1-engine/src/slon remote_worker.c
Message-ID: <20070729173825.B3461290C1E@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv4576

Modified Files:
	remote_worker.c 
Log Message:
Fixed a problem with the setsync tracking in cases where slon does
an internal restart (thereby rereading the pset.ssy_seqno) and ignoring
non-SYNC events because those don't change the sl_setsync table.


Jan


Index: remote_worker.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/remote_worker.c,v
retrieving revision 1.149
retrieving revision 1.150
diff -C2 -d -r1.149 -r1.150
*** remote_worker.c	20 Jul 2007 20:20:13 -0000	1.149
--- remote_worker.c	29 Jul 2007 17:38:23 -0000	1.150
***************
*** 387,394 ****
  						{
  							slon_mkquery(&query1,
! 								"select max(ssy_seqno) from %s.sl_setsync "
  								"  where ssy_setid = %d "
! 								"    and ssy_origin = %d; ",
! 								rtcfg_namespace, pset->set_id, node->no_id);
  							if (query_execute(node, local_dbconn, &query1) < 0)
  								slon_retry();
--- 387,401 ----
  						{
  							slon_mkquery(&query1,
! 								"select max(ssy_seqno) from ("
! 								"select ssy_seqno from %s.sl_setsync "
  								"  where ssy_setid = %d "
! 								"    and ssy_origin = %d "
! 								"union "
! 								"select ev_seqno from %s.sl_event "
! 								"  where ev_origin = %d "
! 								"    and ev_type <> 'SYNC' "
! 								") as S; ",
! 								rtcfg_namespace, pset->set_id, node->no_id,
! 								rtcfg_namespace, node->no_id);
  							if (query_execute(node, local_dbconn, &query1) < 0)
  								slon_retry();

From wieck at lists.slony.info  Sun Jul 29 13:15:43 2007
From: wieck at lists.slony.info (Jan Wieck)
Date: Sun Jul 29 13:15:45 2007
Subject: [Slony1-commit] slony1-engine/src/backend slony1_funcs.sql
Message-ID: <20070729201543.4B2102903D4@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/backend
In directory main.slony.info:/tmp/cvs-serv8012/src/backend

Modified Files:
	slony1_funcs.sql 
Log Message:
Rewrote rebuildListenEntries() from scratch. The goal here is to suppress
listen entries that would cause events to arrive on cascaded subscribers
on a different path around the data provider for the subscription. 


Jan


Index: slony1_funcs.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/backend/slony1_funcs.sql,v
retrieving revision 1.116
retrieving revision 1.117
diff -C2 -d -r1.116 -r1.117
*** slony1_funcs.sql	29 Jul 2007 17:37:34 -0000	1.116
--- slony1_funcs.sql	29 Jul 2007 20:15:41 -0000	1.117
***************
*** 4675,4710 ****
  as '
  declare
! 	v_receiver record ;
! 	v_provider record ;
! 	v_origin record ;
! 	v_reachable int4[] ;
  begin
  	-- First remove the entire configuration
  	delete from @NAMESPACE@.sl_listen;
  
! 	-- Loop over every possible pair of receiver and provider
! 	for v_receiver in select no_id from @NAMESPACE@.sl_node loop
! 		for v_provider in select pa_server as no_id from @NAMESPACE@.sl_path where pa_client = v_receiver.no_id loop
  
! 			-- Find all nodes that v_provider.no_id can receiver events from without using v_receiver.no_id			
! 			for v_origin in select * from @NAMESPACE@.ReachableFromNode(v_provider.no_id, array[v_receiver.no_id]) as r(no_id) loop
  
! 				-- If v_receiver.no_id subscribes a set from v_provider.no_id, events have to travel the same
! 				-- path as the data. Ignore possible sl_listen that would break that rule.
! 				perform 1 from @NAMESPACE@.sl_subscribe
! 					join @NAMESPACE@.sl_set on sl_set.set_id = sl_subscribe.sub_set
! 		 			where
! 						sub_receiver = v_receiver.no_id and
! 						sub_provider != v_provider.no_id and
! 						set_origin = v_origin.no_id ;
! 				if not found then
! 					insert into @NAMESPACE@.sl_listen (li_receiver, li_provider, li_origin)
! 						values (v_receiver.no_id, v_provider.no_id, v_origin.no_id) ;
! 				end if ;
  
  
! 			end loop ;
  
- 		end loop ;
  	end loop ;
  
--- 4675,4756 ----
  as '
  declare
! 	v_row	record;
  begin
  	-- First remove the entire configuration
  	delete from @NAMESPACE@.sl_listen;
  
! 	-- Second populate the sl_listen configuration with a full
! 	-- network of all possible paths.
! 	insert into @NAMESPACE@.sl_listen
! 				(li_origin, li_provider, li_receiver)
! 			select pa_server, pa_server, pa_client from @NAMESPACE@.sl_path;
! 	while true loop
! 		insert into @NAMESPACE@.sl_listen
! 					(li_origin, li_provider, li_receiver)
! 			select distinct li_origin, pa_server, pa_client
! 				from @NAMESPACE@.sl_listen, @NAMESPACE@.sl_path
! 				where li_receiver = pa_server
! 				  and li_origin <> pa_client
! 			except
! 			select li_origin, li_provider, li_receiver
! 				from @NAMESPACE@.sl_listen;
  
! 		if not found then
! 			exit;
! 		end if;
! 	end loop;
  
! 	-- We now replace specific event-origin,receiver combinations
! 	-- with a configuration that tries to avoid events arriving at
! 	-- a node before the data provider actually has the data ready.
  
+ 	-- Loop over every possible pair of receiver and event origin
+ 	for v_row in select N1.no_id as receiver, N2.no_id as origin
+ 			from @NAMESPACE@.sl_node as N1, @NAMESPACE@.sl_node as N2
+ 			where N1.no_id <> N2.no_id
+ 	loop
+ 		-- 1st choice:
+ 		-- If we use the event origin as a data provider for any
+ 		-- set that originates on that very node, we are a direct
+ 		-- subscriber to that origin and listen there only.
+ 		if exists (select true from @NAMESPACE@.sl_set, @NAMESPACE@.sl_subscribe
+ 				where set_origin = v_row.origin
+ 				  and sub_set = set_id
+ 				  and sub_provider = v_row.origin
+ 				  and sub_receiver = v_row.receiver
+ 				  and sub_active)
+ 		then
+ 			delete from @NAMESPACE@.sl_listen
+ 				where li_origin = v_row.origin
+ 				  and li_receiver = v_row.receiver;
+ 			insert into @NAMESPACE@.sl_listen (li_origin, li_provider, li_receiver)
+ 				values (v_row.origin, v_row.origin, v_row.receiver);
+ 			continue;
+ 		end if;
  
! 		-- 2nd choice:
! 		-- If we are subscribed to any set originating on this
! 		-- event origin, we want to listen on all data providers
! 		-- we use for this origin. We are a cascaded subscriber
! 		-- for sets from this node.
! 		if exists (select true from @NAMESPACE@.sl_set, @NAMESPACE@.sl_subscribe
! 						where set_origin = v_row.origin
! 						  and sub_set = set_id
! 						  and sub_receiver = v_row.receiver
! 						  and sub_active)
! 		then
! 			delete from @NAMESPACE@.sl_listen
! 					where li_origin = v_row.origin
! 					  and li_receiver = v_row.receiver;
! 			insert into @NAMESPACE@.sl_listen (li_origin, li_provider, li_receiver)
! 					select distinct set_origin, sub_provider, v_row.receiver
! 						from @NAMESPACE@.sl_set, @NAMESPACE@.sl_subscribe
! 						where set_origin = v_row.origin
! 						  and sub_set = set_id
! 						  and sub_receiver = v_row.receiver
! 						  and sub_active;
! 			continue;
! 		end if;
  
  	end loop ;
  
***************
*** 4722,4766 ****
  
  -- ----------------------------------------------------------------------
- -- FUNCTION ReachableFromNode (receiver, blacklist)
- --
- -- ----------------------------------------------------------------------
- create or replace function @NAMESPACE@.ReachableFromNode(int4, int4[]) returns setof int4 as '
- declare
- 	v_node alias for $1 ;
- 	v_blacklist alias for $2 ;
- 	v_ignore int4[] ;
- 	v_reachable_edge_last int4[] ;
- 	v_reachable_edge_new int4[] default ''{}'' ;
- 	v_server record ;
- begin
- 	v_reachable_edge_last := array[v_node] ;
- 	v_ignore := v_blacklist || array[v_node] ;
- 	return next v_node ;
- 	while v_reachable_edge_last != ''{}'' loop
- 		v_reachable_edge_new := ''{}'' ;
- 		for v_server in select pa_server as no_id
- 			from @NAMESPACE@.sl_path
- 			where pa_client = ANY(v_reachable_edge_last) and pa_server != ALL(v_ignore)
- 		loop
- 			if v_server.no_id != ALL(v_ignore) then
- 				v_ignore := v_ignore || array[v_server.no_id] ;
- 				v_reachable_edge_new := v_reachable_edge_new || array[v_server.no_id] ;
- 				return next v_server.no_id ;
- 			end if ;
- 		end loop ;
- 		v_reachable_edge_last := v_reachable_edge_new ;
- 	end loop ;
- 	return ;
- end ;
- ' language 'plpgsql';
- 
- comment on function @NAMESPACE@.ReachableFromNode(int4, int4[]) is
- 'ReachableFromNode(receiver, blacklist)
- 
- Find all nodes that <receiver> can receive events from without
- using nodes in <blacklist> as a relay.';
- 
- 
- -- ----------------------------------------------------------------------
  -- FUNCTION generate_sync_event (interval)
  --
--- 4768,4771 ----

From wieck at lists.slony.info  Sun Jul 29 13:15:43 2007
From: wieck at lists.slony.info (Jan Wieck)
Date: Sun Jul 29 13:15:45 2007
Subject: [Slony1-commit] slony1-engine/src/ducttape test_2_pgbench.in
Message-ID: <20070729201543.56BB4290C1E@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/ducttape
In directory main.slony.info:/tmp/cvs-serv8012/src/ducttape

Modified Files:
	test_2_pgbench.in 
Log Message:
Rewrote rebuildListenEntries() from scratch. The goal here is to suppress
listen entries that would cause events to arrive on cascaded subscribers
on a different path around the data provider for the subscription. 


Jan


Index: test_2_pgbench.in
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/ducttape/test_2_pgbench.in,v
retrieving revision 1.3
retrieving revision 1.4
diff -C2 -d -r1.3 -r1.4
*** test_2_pgbench.in	15 May 2007 14:05:15 -0000	1.3
--- test_2_pgbench.in	29 Jul 2007 20:15:41 -0000	1.4
***************
*** 365,414 ****
  kill $slon3_pid 2>/dev/null
  
! echo -n "**** comparing databases ... "
! psql $DB1 -o dump.tmp.1.$$ <<_EOF_
! 	select 'accounts:'::text, aid, bid, abalance, filler
! 			from accounts order by aid;
! 	select 'branches:'::text, bid, bbalance, filler
! 			from branches order by bid;
! 	select 'tellers:'::text, tid, bid, tbalance, filler
! 			from tellers order by tid;
! 	select 'history:'::text, tid, bid, aid, delta, mtime, filler,
! 			"_Slony-I_T1_rowID" from history order by "_Slony-I_T1_rowID";
! _EOF_
! psql $DB2 -o dump.tmp.2.$$ <<_EOF_
! 	select 'accounts:'::text, aid, bid, abalance, filler
! 			from accounts order by aid;
! 	select 'branches:'::text, bid, bbalance, filler
! 			from branches order by bid;
! 	select 'tellers:'::text, tid, bid, tbalance, filler
! 			from tellers order by tid;
! 	select 'history:'::text, tid, bid, aid, delta, mtime, filler,
! 			"_Slony-I_T1_rowID" from history order by "_Slony-I_T1_rowID";
! _EOF_
! psql $DB3 -o dump.tmp.3.$$ <<_EOF_
! 	select 'accounts:'::text, aid, bid, abalance, filler
! 			from accounts order by aid;
! 	select 'branches:'::text, bid, bbalance, filler
! 			from branches order by bid;
! 	select 'tellers:'::text, tid, bid, tbalance, filler
! 			from tellers order by tid;
! 	select 'history:'::text, tid, bid, aid, delta, mtime, filler,
! 			"_Slony-I_T1_rowID" from history order by "_Slony-I_T1_rowID";
! _EOF_
! 
! if diff dump.tmp.1.$$ dump.tmp.2.$$ >test_2.1-2.diff ; then
! 	echo "success - databases 1 and 2 are equal."
! 	rm dump.tmp.2.$$
! 	rm test_2.1-2.diff
! else
! 	echo "FAILED - see test_2.1-2.diff for database differences"
! fi
! echo -n "**** comparing databases ... "
! if diff dump.tmp.1.$$ dump.tmp.3.$$ >test_2.1-3.diff ; then
! 	echo "success - databases 1 and 3 are equal."
! 	rm dump.tmp.3.$$
! 	rm dump.tmp.1.$$
! 	rm test_2.1-3.diff
! else
! 	echo "FAILED - see test_2.1-3.diff for database differences"
! fi
--- 365,368 ----
  kill $slon3_pid 2>/dev/null
  
! ./compare_pgbench_dumps $DB1 $DB2
! ./compare_pgbench_dumps $DB1 $DB3

From cbbrowne at lists.slony.info  Mon Jul 30 15:33:18 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul 30 15:33:20 2007
Subject: [Slony1-commit] slony1-engine RELEASE
Message-ID: <20070730223318.1227F29040F@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine
In directory main.slony.info:/tmp/cvs-serv827

Modified Files:
      Tag: REL_1_2_STABLE
	RELEASE 
Log Message:
Added a test to "testlogship" which attempts to induce the problems
recently experienced where there is a race condition adversely affecting
log shipping when events come along that cause the slon to restart and
reload its config. (That happens with DROP NODE, ACCEPT SET.)

Also updated release notes to correspond.


Index: RELEASE
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/RELEASE,v
retrieving revision 1.1.2.8
retrieving revision 1.1.2.9
diff -C2 -d -r1.1.2.8 -r1.1.2.9
*** RELEASE	27 Jul 2007 21:39:11 -0000	1.1.2.8
--- RELEASE	30 Jul 2007 22:33:15 -0000	1.1.2.9
***************
*** 1,5 ****
  $Id$
  
! RELEASE 1.2.???
  
  - Add in tools/mkservice scripts previously added to CVS HEAD
--- 1,5 ----
  $Id$
  
! RELEASE 1.2.11
  
  - Add in tools/mkservice scripts previously added to CVS HEAD
***************
*** 8,11 ****
--- 8,19 ----
    TRUNCATE because, in 8.2+, TRUNCATE resets this attribute
  
+ - Fixed a problem with the setsync tracking with Log Shipping in cases
+   where slon does an internal restart (thereby rereading the
+   pset.ssy_seqno) and ignoring non-SYNC events because those don't
+   change the sl_setsync table.
+ 
+ - More explicit type casting of text objects for compatibility with
+   PostgreSQL 8.3
+ 
  RELEASE 1.2.10
  

From cbbrowne at lists.slony.info  Mon Jul 30 15:33:18 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul 30 15:33:20 2007
Subject: [Slony1-commit] slony1-engine/tests/testlogship generate_dml.sh
	init_subscribe_set.ik moveset.sh settings.ik
Message-ID: <20070730223318.1DA51290472@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/tests/testlogship
In directory main.slony.info:/tmp/cvs-serv827/tests/testlogship

Modified Files:
      Tag: REL_1_2_STABLE
	generate_dml.sh init_subscribe_set.ik settings.ik 
Added Files:
      Tag: REL_1_2_STABLE
	moveset.sh 
Log Message:
Added a test to "testlogship" which attempts to induce the problems
recently experienced where there is a race condition adversely affecting
log shipping when events come along that cause the slon to restart and
reload its config. (That happens with DROP NODE, ACCEPT SET.)

Also updated release notes to correspond.


Index: settings.ik
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testlogship/settings.ik,v
retrieving revision 1.1.2.1
retrieving revision 1.1.2.2
diff -C2 -d -r1.1.2.1 -r1.1.2.2
*** settings.ik	20 Apr 2007 20:51:09 -0000	1.1.2.1
--- settings.ik	30 Jul 2007 22:33:15 -0000	1.1.2.2
***************
*** 1,6 ****
  NUMCLUSTERS=${NUMCLUSTERS:-"1"}
! NUMNODES=${NUMNODES:-"3"}
  ORIGINNODE=1
  WORKERS=${WORKERS:-"1"}
  ARCHIVE2=true   # Node #2 needs to run log archiving
! LOGSHIP3=true   # Node #3 receives data via log shipping
\ No newline at end of file
--- 1,6 ----
  NUMCLUSTERS=${NUMCLUSTERS:-"1"}
! NUMNODES=${NUMNODES:-"4"}
  ORIGINNODE=1
  WORKERS=${WORKERS:-"1"}
  ARCHIVE2=true   # Node #2 needs to run log archiving
! LOGSHIP3=true   # Node #3 receives data via log shipping

Index: init_subscribe_set.ik
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testlogship/init_subscribe_set.ik,v
retrieving revision 1.1.2.1
retrieving revision 1.1.2.2
diff -C2 -d -r1.1.2.1 -r1.1.2.2
*** init_subscribe_set.ik	20 Apr 2007 20:51:09 -0000	1.1.2.1
--- init_subscribe_set.ik	30 Jul 2007 22:33:15 -0000	1.1.2.2
***************
*** 3,4 ****
--- 3,8 ----
  sleep (seconds = 2);
  echo 'done sleeping...';
+ subscribe set (id = 1, provider = 1, receiver = 4, forward = yes);
+ echo 'sleep a couple of seconds...';
+ sleep (seconds = 2);
+ echo 'done sleeping...';

--- NEW FILE: moveset.sh ---
testname=$1
echo "
  LOCK SET ( ID = 1, ORIGIN = 1 );
  MOVE SET ( ID = 1, OLD ORIGIN = 1, NEW ORIGIN = 4 );
"

Index: generate_dml.sh
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/tests/testlogship/generate_dml.sh,v
retrieving revision 1.1.2.3
retrieving revision 1.1.2.4
diff -C2 -d -r1.1.2.3 -r1.1.2.4
*** generate_dml.sh	13 Jun 2007 15:56:44 -0000	1.1.2.3
--- generate_dml.sh	30 Jul 2007 22:33:15 -0000	1.1.2.4
***************
*** 115,119 ****
  
    wait_for_catchup
!   status "second data load complete - now load files into log shipped node"
    for logfile in `/usr/bin/find ${mktmp}/archive_logs_2 -name "slony1_log_*.sql" -type f | sort`; do
      $pgbindir/psql -h ${HOST3} -p ${PORT3} -d ${DB3} -U ${USER3} -f ${logfile} >> $mktmp/logshipping_output.log 2>> $mktmp/logshipping_errors.log
--- 115,136 ----
  
    wait_for_catchup
! 
!   status "move set to node 4"
! 
!   init_preamble
!   sh ${testname}/moveset.sh ${testname} >> $SCRIPT
!   do_ik
! 
!   status "origin moved"
! 
!   generate_initdata
!   eval db=\$DB4
!   status "loading extra data to node $db"
!   $pgbindir/psql -h $host -p $port -U $user -d $db < $mktmp/generate.data 1> ${mktmp}/even_more_data.log 2> ${mktmp}/even_more_data.log2
! 
!   wait_for_catchup
! 
! 
!   status "final data load complete - now load files into log shipped node"
    for logfile in `/usr/bin/find ${mktmp}/archive_logs_2 -name "slony1_log_*.sql" -type f | sort`; do
      $pgbindir/psql -h ${HOST3} -p ${PORT3} -d ${DB3} -U ${USER3} -f ${logfile} >> $mktmp/logshipping_output.log 2>> $mktmp/logshipping_errors.log

From cbbrowne at lists.slony.info  Mon Jul 30 15:34:35 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Mon Jul 30 15:34:36 2007
Subject: [Slony1-commit] slony1-engine/src/slon confoptions.c
Message-ID: <20070730223435.EBBED29040F@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/slon
In directory main.slony.info:/tmp/cvs-serv1102/src/slon

Modified Files:
	confoptions.c 
Log Message:
Change default logging level from 2 to 0.  The rest of the code has been
revised so that interesting logging takes place at level 0.


Index: confoptions.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/confoptions.c,v
retrieving revision 1.24
retrieving revision 1.25
diff -C2 -d -r1.24 -r1.25
*** confoptions.c	27 Jun 2007 16:20:24 -0000	1.24
--- confoptions.c	30 Jul 2007 22:34:33 -0000	1.25
***************
*** 559,563 ****
  		},
  		&slon_log_level,
! 		2,
  		0,
  		4
--- 559,563 ----
  		},
  		&slon_log_level,
! 		0,
  		0,
  		4

From cbbrowne at lists.slony.info  Tue Jul 31 07:55:36 2007
From: cbbrowne at lists.slony.info (Chris Browne)
Date: Tue Jul 31 07:55:37 2007
Subject: [Slony1-commit] slony1-engine/src/parsestatements
	emptytestresult.expected scanner.c test_sql.expected test_sql.sql
Message-ID: <20070731145536.63403290C29@main.slony.info>

Update of /home/cvsd/slony1/slony1-engine/src/parsestatements
In directory main.slony.info:/tmp/cvs-serv16120

Modified Files:
      Tag: REL_1_2_STABLE
	emptytestresult.expected scanner.c test_sql.expected 
	test_sql.sql 
Log Message:
Fixes to DDL statement parser, along with additional torture tests
provided by Weslee Bilodeau


Index: scanner.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/parsestatements/scanner.c,v
retrieving revision 1.3
retrieving revision 1.3.2.1
diff -C2 -d -r1.3 -r1.3.2.1
*** scanner.c	4 Aug 2006 20:40:19 -0000	1.3
--- scanner.c	31 Jul 2007 14:55:34 -0000	1.3.2.1
***************
*** 12,15 ****
--- 12,18 ----
    int d1start, d1end, d2start, d2end, d1stemp;
    int statements;
+   int nparens;
+   int nbrokets;
+   int nsquigb;
    
    /* Initialize */
***************
*** 22,25 ****
--- 25,31 ----
    d1end = 0;
    state = Q_NORMAL_STATE;
+   nparens = 0;
+   nbrokets = 0;
+   nsquigb = 0;
    
    while (state != Q_DONE) {
***************
*** 27,32 ****
--- 33,71 ----
      switch (cchar) {
      case '\0':
+       STMTS[statements++] = ++cpos;
        state = Q_DONE;
        break;
+ 
+     case '(':
+       if (state == Q_NORMAL_STATE) {
+ 	nparens ++;
+ 	break;
+       }
+     case ')':
+       if (state == Q_NORMAL_STATE) {
+ 	nparens --;
+ 	break;
+       }
+     case '[':
+       if (state == Q_NORMAL_STATE) {
+ 	nbrokets ++;
+ 	break;
+       }
+     case ']':
+       if (state == Q_NORMAL_STATE) {
+ 	nbrokets --;
+ 	break;
+       }
+     case '{':
+       if (state == Q_NORMAL_STATE) {
+ 	nsquigb ++;
+ 	break;
+       }
+     case '}':
+       if (state == Q_NORMAL_STATE) {
+ 	nsquigb --;
+ 	break;
+       }
+ 
      case '/':
        if (state == Q_NORMAL_STATE) {
***************
*** 52,57 ****
  	  break;
  	}
!       } 
! 
        break;
      case '$':
--- 91,95 ----
  	  break;
  	}
!       }
        break;
      case '$':
***************
*** 124,128 ****
        break;
      case '-':
!       if (state == Q_NORMAL_STATE) {
  	state = Q_HOPE_TO_DASH;
  	break;
--- 162,166 ----
        break;
      case '-':
!       if (state == Q_NORMAL_STATE && extended_statement[cpos+1] == '-') {
  	state = Q_HOPE_TO_DASH;
  	break;
***************
*** 152,156 ****
        break;
      case ';':
!       if (state == Q_NORMAL_STATE) {
  	STMTS[statements++] = ++cpos;
  	if (statements >= MAXSTATEMENTS) {
--- 190,194 ----
        break;
      case ';':
!       if ((state == Q_NORMAL_STATE) && (nparens == 0) && (nbrokets == 0) && (nsquigb == 0)) {
  	STMTS[statements++] = ++cpos;
  	if (statements >= MAXSTATEMENTS) {

Index: test_sql.expected
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/parsestatements/test_sql.expected,v
retrieving revision 1.2
retrieving revision 1.2.2.1
diff -C2 -d -r1.2 -r1.2.2.1
*** test_sql.expected	24 Feb 2006 18:48:12 -0000	1.2
--- test_sql.expected	31 Jul 2007 14:55:34 -0000	1.2.2.1
***************
*** 38,41 ****
--- 38,80 ----
  
  
+ -- Here is a rule creation with an embedded semicolon
+ -- "Dmitry Koterov" <dmitry@koterov.ru>
+ 
+ create table "public"."position";
+ 
+ CREATE RULE "position_get_last_id_on_insert2"
+ AS ON INSERT TO "public"."position" DO (SELECT
+ currval('position_position_id_seq'::regclass) AS id;);
+ 
+ -- Added to verify handling of queries tried by
+ -- "Dmitry Koterov" <dmitry@koterov.ru>
+ 
+ CREATE INDEX aaa ON public.bbb USING btree ((-ccc), ddd);
+ 
+ --  Apparently a pair of backslashes fold down into one?
+ -- "Dmitry Koterov" <dmitry@koterov.ru>
+ 
+ CREATE UNIQUE INDEX "i_dictionary_uni_abbr" ON "static"."dictionary"
+ USING btree ((substring(dic_russian, E'^([^(]*[^( ]) *\\('::text)))
+ WHERE (dic_category_id = 26);
+ 
+ -- Some more torturing per Weslee Bilodeau
+ 
+ -- I figure the $_$, $$, etc edge-casees would be another fun one to roll
+ -- into a custom parser.
+ 
+ CREATE FUNCTION test( ) RETURNS text AS $_$ SELECT ';', E'\';\'',
+ '"";""', E'"\';' ; SELECT 'OK'::text ; $_$ LANGUAGE SQL ;
+ 
+ SELECT $_$ hello; this ; - is '\" a '''' test $_$ ;
+ 
+ SELECT $$ $ test ; $ ;  $$ ;
+ 
+ -- All really funky, but perfectly valid.
+ 
+ -- Force a query to be at the end...
+ 
+ create table foo;
+ 
  statement 0
  -------------------------------------------
***************
*** 115,117 ****
      return NULL;
    end;
! $$ language plpgsql;
\ No newline at end of file
--- 154,223 ----
      return NULL;
    end;
! $$ language plpgsql;
! statement 14
! -------------------------------------------
! 
! 
! 
! -- Here is a rule creation with an embedded semicolon
! -- "Dmitry Koterov" <dmitry@koterov.ru>
! 
! create table "public"."position";
! statement 15
! -------------------------------------------
! 
! 
! CREATE RULE "position_get_last_id_on_insert2"
! AS ON INSERT TO "public"."position" DO (SELECT
! currval('position_position_id_seq'::regclass) AS id;);
! statement 16
! -------------------------------------------
! 
! 
! -- Added to verify handling of queries tried by
! -- "Dmitry Koterov" <dmitry@koterov.ru>
! 
! CREATE INDEX aaa ON public.bbb USING btree ((-ccc), ddd);
! statement 17
! -------------------------------------------
! 
! 
! --  Apparently a pair of backslashes fold down into one?
! -- "Dmitry Koterov" <dmitry@koterov.ru>
! 
! CREATE UNIQUE INDEX "i_dictionary_uni_abbr" ON "static"."dictionary"
! USING btree ((substring(dic_russian, E'^([^(]*[^( ]) *\\('::text)))
! WHERE (dic_category_id = 26);
! statement 18
! -------------------------------------------
! 
! 
! -- Some more torturing per Weslee Bilodeau
! 
! -- I figure the $_$, $$, etc edge-casees would be another fun one to roll
! -- into a custom parser.
! 
! CREATE FUNCTION test( ) RETURNS text AS $_$ SELECT ';', E'\';\'',
! '"";""', E'"\';' ; SELECT 'OK'::text ; $_$ LANGUAGE SQL ;
! statement 19
! -------------------------------------------
! 
! 
! SELECT $_$ hello; this ; - is '\" a '''' test $_$ ;
! statement 20
! -------------------------------------------
! 
! 
! SELECT $$ $ test ; $ ;  $$ ;
! statement 21
! -------------------------------------------
! 
! 
! -- All really funky, but perfectly valid.
! 
! -- Force a query to be at the end...
! 
! create table foo;
! statement 22
! -------------------------------------------
!   
\ No newline at end of file

Index: emptytestresult.expected
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/parsestatements/emptytestresult.expected,v
retrieving revision 1.1
retrieving revision 1.1.2.1
diff -C2 -d -r1.1 -r1.1.2.1
Binary files /tmp/cvsEsxAhM and /tmp/cvstVlo4U differ

Index: test_sql.sql
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/parsestatements/test_sql.sql,v
retrieving revision 1.1
retrieving revision 1.1.2.1
diff -C2 -d -r1.1 -r1.1.2.1
*** test_sql.sql	24 Feb 2006 18:33:02 -0000	1.1
--- test_sql.sql	31 Jul 2007 14:55:34 -0000	1.1.2.1
***************
*** 36,37 ****
--- 36,77 ----
    end;
  $$ language plpgsql;
+ 
+ 
+ -- Here is a rule creation with an embedded semicolon
+ -- "Dmitry Koterov" <dmitry@koterov.ru>
+ 
+ create table "public"."position";
+ 
+ CREATE RULE "position_get_last_id_on_insert2"
+ AS ON INSERT TO "public"."position" DO (SELECT
+ currval('position_position_id_seq'::regclass) AS id;);
+ 
+ -- Added to verify handling of queries tried by
+ -- "Dmitry Koterov" <dmitry@koterov.ru>
+ 
+ CREATE INDEX aaa ON public.bbb USING btree ((-ccc), ddd);
+ 
+ --  Apparently a pair of backslashes fold down into one?
+ -- "Dmitry Koterov" <dmitry@koterov.ru>
+ 
+ CREATE UNIQUE INDEX "i_dictionary_uni_abbr" ON "static"."dictionary"
+ USING btree ((substring(dic_russian, E'^([^(]*[^( ]) *\\('::text)))
+ WHERE (dic_category_id = 26);
+ 
+ -- Some more torturing per Weslee Bilodeau
+ 
+ -- I figure the $_$, $$, etc edge-casees would be another fun one to roll
+ -- into a custom parser.
+ 
+ CREATE FUNCTION test( ) RETURNS text AS $_$ SELECT ';', E'\';\'',
+ '"";""', E'"\';' ; SELECT 'OK'::text ; $_$ LANGUAGE SQL ;
+ 
+ SELECT $_$ hello; this ; - is '\" a '''' test $_$ ;
+ 
+ SELECT $$ $ test ; $ ;  $$ ;
+ 
+ -- All really funky, but perfectly valid.
+ 
+ -- Force a query to be at the end...
+ 
+ create table foo;
\ No newline at end of file

