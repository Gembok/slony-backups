From lists at serioustechnology.com  Tue Nov  4 14:22:48 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Tue Nov  4 14:23:04 2008
Subject: [Slony1-general] adding fields to a replicated table
Message-ID: <4910CB38.2080000@serioustechnology.com>

Will it cause a problem if one adds fields to a table that is being 
replicated?

That is, will it break the replication process, or will the replication 
continue to simply replicate the previous set of fields?

-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From drees76 at gmail.com  Tue Nov  4 14:50:13 2008
From: drees76 at gmail.com (David Rees)
Date: Tue Nov  4 14:50:27 2008
Subject: [Slony1-general] adding fields to a replicated table
In-Reply-To: <4910CB38.2080000@serioustechnology.com>
References: <4910CB38.2080000@serioustechnology.com>
Message-ID: <72dbd3150811041450ke1b46c2o5f31291ac3dbd80b@mail.gmail.com>

On Tue, Nov 4, 2008 at 2:22 PM, Geoffrey <lists@serioustechnology.com> wrote:
> Will it cause a problem if one adds fields to a table that is being
> replicated?
>
> That is, will it break the replication process, or will the replication
> continue to simply replicate the previous set of fields?

It should continue to replicate the previous set of fields, but is not
recommended to do so.

-Dave
From ABhat at trustwave.com  Tue Nov  4 14:55:54 2008
From: ABhat at trustwave.com (Anoop Bhat)
Date: Tue Nov  4 15:02:50 2008
Subject: [Slony1-general] adding fields to a replicated table
In-Reply-To: <72dbd3150811041450ke1b46c2o5f31291ac3dbd80b@mail.gmail.com>
Message-ID: <C5362F1A.2BDF%abhat@trustwave.com>

What is the recommended way of adding fields to a replicated table when using altperl scripts?

Anoop Bhat
Systems Administrator
Trustwave
70 W. Madison
Chicago, IL, 60602
O: 312.873.7446
C: 312.925.3271



________________________________
From: David Rees <drees76@gmail.com>
Date: Tue, 4 Nov 2008 16:50:13 -0600
To: <slony1-general@lists.slony.info>
Subject: Re: [Slony1-general] adding fields to a replicated table

On Tue, Nov 4, 2008 at 2:22 PM, Geoffrey <lists@serioustechnology.com> wrote:
> Will it cause a problem if one adds fields to a table that is being
> replicated?
>
> That is, will it break the replication process, or will the replication
> continue to simply replicate the previous set of fields?

It should continue to replicate the previous set of fields, but is not
recommended to do so.

-Dave
_______________________________________________
Slony1-general mailing list
Slony1-general@lists.slony.info
http://lists.slony.info/mailman/listinfo/slony1-general



From jason at buberel.org  Tue Nov  4 15:47:23 2008
From: jason at buberel.org (Jason Buberel)
Date: Tue Nov  4 15:47:40 2008
Subject: [Slony1-general] adding fields to a replicated table
In-Reply-To: <C5362F1A.2BDF%abhat@trustwave.com>
References: <72dbd3150811041450ke1b46c2o5f31291ac3dbd80b@mail.gmail.com>
	<C5362F1A.2BDF%abhat@trustwave.com>
Message-ID: <381af7b40811041547i300dd7c7o57140ee117106451@mail.gmail.com>

Although probably not the recommended process, here is what I've been doing
for a few years now that I've been using Slony in production:

1. Stop all slon daemons on the cluster.
2. Run the SQL patch script that adds the column to the replicated table.
Run it on each node in the cluster.
3. Start slon daemon on master. Wait a minute. Check logs for errors and
such.
4. Start remaining slon daemons for remaining cluster nodes. Watch log files
vigilantly for one hour.
5. Drink beer.

-jason


On Tue, Nov 4, 2008 at 2:55 PM, Anoop Bhat <ABhat@trustwave.com> wrote:

> What is the recommended way of adding fields to a replicated table when
> using altperl scripts?
>
> Anoop Bhat
> Systems Administrator
> Trustwave
> 70 W. Madison
> Chicago, IL, 60602
> O: 312.873.7446
> C: 312.925.3271
>


-- =

Jason L. Buberel
jason@buberel.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20081104/=
b69e729a/attachment.htm
From drees76 at gmail.com  Tue Nov  4 18:02:58 2008
From: drees76 at gmail.com (David Rees)
Date: Tue Nov  4 18:03:17 2008
Subject: [Slony1-general] adding fields to a replicated table
In-Reply-To: <C5362F1A.2BDF%abhat@trustwave.com>
References: <72dbd3150811041450ke1b46c2o5f31291ac3dbd80b@mail.gmail.com>
	<C5362F1A.2BDF%abhat@trustwave.com>
Message-ID: <72dbd3150811041802qfde6352ib0f8ea9234300c49@mail.gmail.com>

On Tue, Nov 4, 2008 at 2:55 PM, Anoop Bhat <ABhat@trustwave.com> wrote:
> What is the recommended way of adding fields to a replicated table when using altperl scripts?

# slonik_execute_script
Usage:
    execute_script [options] set# full_path_to_sql_script_file
    execute_script [options] -c SCRIPT set#

    Executes the contents of a SQL script file on the specified set.
    The script only needs to exist on the machine running the slon
    daemon.

    set#        The set to which this script applies.

    -c SCRIPT   Pass the SQL to be executed via the command line instead
                of as a file.

    -n NUM
    --node=NUM  Override the set origin specified in the configuration
                file.

-Dave
From lists at serioustechnology.com  Wed Nov  5 06:02:41 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Wed Nov  5 06:02:49 2008
Subject: [Slony1-general] adding fields to a replicated table
In-Reply-To: <72dbd3150811041450ke1b46c2o5f31291ac3dbd80b@mail.gmail.com>
References: <4910CB38.2080000@serioustechnology.com>
	<72dbd3150811041450ke1b46c2o5f31291ac3dbd80b@mail.gmail.com>
Message-ID: <4911A781.3060308@serioustechnology.com>

David Rees wrote:
> On Tue, Nov 4, 2008 at 2:22 PM, Geoffrey <lists@serioustechnology.com> wrote:
>> Will it cause a problem if one adds fields to a table that is being
>> replicated?
>>
>> That is, will it break the replication process, or will the replication
>> continue to simply replicate the previous set of fields?
> 
> It should continue to replicate the previous set of fields, but is not
> recommended to do so.

I don't know if it's related or not, but it appears that our slave is 
now out of sync with the master.  It's a two node set up, and it's been 
replicating for some time now.  It's just now that I've gone in and 
compared record counts on some major tables and they are not in sync. 
Further, I can see updates happen to the master node tables but don't 
see them on the slave.

If adding the field didn't cause the problem, any ideas what might have?

-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From scetbon at echo.fr  Wed Nov  5 06:14:05 2008
From: scetbon at echo.fr (Cyril SCETBON)
Date: Wed Nov  5 06:15:21 2008
Subject: [Slony1-general] adding fields to a replicated table
In-Reply-To: <4911A781.3060308@serioustechnology.com>
References: <4910CB38.2080000@serioustechnology.com>	<72dbd3150811041450ke1b46c2o5f31291ac3dbd80b@mail.gmail.com>
	<4911A781.3060308@serioustechnology.com>
Message-ID: <4911AA2D.7060201@echo.fr>

Which type of ALTER did you make ?

Don't forget that there's a special trigger on the source table that 
must be updated too.

Geoffrey wrote:
> David Rees wrote:
>> On Tue, Nov 4, 2008 at 2:22 PM, Geoffrey 
>> <lists@serioustechnology.com> wrote:
>>> Will it cause a problem if one adds fields to a table that is being
>>> replicated?
>>>
>>> That is, will it break the replication process, or will the replication
>>> continue to simply replicate the previous set of fields?
>>
>> It should continue to replicate the previous set of fields, but is not
>> recommended to do so.
>
> I don't know if it's related or not, but it appears that our slave is 
> now out of sync with the master.  It's a two node set up, and it's 
> been replicating for some time now.  It's just now that I've gone in 
> and compared record counts on some major tables and they are not in 
> sync. Further, I can see updates happen to the master node tables but 
> don't see them on the slave.
>
> If adding the field didn't cause the problem, any ideas what might have?
>

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
Cellule bases de donn?es
AUSY pour France T?l?com - OPF/PORTAILS/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C1 - Bureau 202
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From lists at serioustechnology.com  Wed Nov  5 07:08:28 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Wed Nov  5 07:08:37 2008
Subject: [Slony1-general] adding fields to a replicated table
In-Reply-To: <4911AA2D.7060201@echo.fr>
References: <4910CB38.2080000@serioustechnology.com>	<72dbd3150811041450ke1b46c2o5f31291ac3dbd80b@mail.gmail.com>
	<4911A781.3060308@serioustechnology.com> <4911AA2D.7060201@echo.fr>
Message-ID: <4911B6EC.5050704@serioustechnology.com>

Cyril SCETBON wrote:
> Which type of ALTER did you make ?
> 
> Don't forget that there's a special trigger on the source table that 
> must be updated too.

I'm not sure of how the change was made, I didn't make it.  As far as I 
know, all he did was add a new field to one of the tables.  He did not 
modify any slony triggers by hand.

> 
> Geoffrey wrote:
>> David Rees wrote:
>>> On Tue, Nov 4, 2008 at 2:22 PM, Geoffrey 
>>> <lists@serioustechnology.com> wrote:
>>>> Will it cause a problem if one adds fields to a table that is being
>>>> replicated?
>>>>
>>>> That is, will it break the replication process, or will the replication
>>>> continue to simply replicate the previous set of fields?
>>>
>>> It should continue to replicate the previous set of fields, but is not
>>> recommended to do so.
>>
>> I don't know if it's related or not, but it appears that our slave is 
>> now out of sync with the master.  It's a two node set up, and it's 
>> been replicating for some time now.  It's just now that I've gone in 
>> and compared record counts on some major tables and they are not in 
>> sync. Further, I can see updates happen to the master node tables but 
>> don't see them on the slave.
>>
>> If adding the field didn't cause the problem, any ideas what might have?
>>
> 


-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From scetbon at echo.fr  Wed Nov  5 07:22:06 2008
From: scetbon at echo.fr (Cyril SCETBON)
Date: Wed Nov  5 07:22:24 2008
Subject: [Slony1-general] adding fields to a replicated table
In-Reply-To: <4911B6EC.5050704@serioustechnology.com>
References: <4910CB38.2080000@serioustechnology.com>	<72dbd3150811041450ke1b46c2o5f31291ac3dbd80b@mail.gmail.com>	<4911A781.3060308@serioustechnology.com>
	<4911AA2D.7060201@echo.fr> <4911B6EC.5050704@serioustechnology.com>
Message-ID: <4911BA1E.3060602@echo.fr>



Geoffrey wrote:
> Cyril SCETBON wrote:
>> Which type of ALTER did you make ?
>>
>> Don't forget that there's a special trigger on the source table that 
>> must be updated too.
>
> I'm not sure of how the change was made, I didn't make it.  As far as 
> I know, all he did was add a new field to one of the tables.  He did 
> not modify any slony triggers by hand.
Not good. Check in the slon daemons logs to see what's happening.
>
>>
>> Geoffrey wrote:
>>> David Rees wrote:
>>>> On Tue, Nov 4, 2008 at 2:22 PM, Geoffrey 
>>>> <lists@serioustechnology.com> wrote:
>>>>> Will it cause a problem if one adds fields to a table that is being
>>>>> replicated?
>>>>>
>>>>> That is, will it break the replication process, or will the 
>>>>> replication
>>>>> continue to simply replicate the previous set of fields?
>>>>
>>>> It should continue to replicate the previous set of fields, but is not
>>>> recommended to do so.
>>>
>>> I don't know if it's related or not, but it appears that our slave 
>>> is now out of sync with the master.  It's a two node set up, and 
>>> it's been replicating for some time now.  It's just now that I've 
>>> gone in and compared record counts on some major tables and they are 
>>> not in sync. Further, I can see updates happen to the master node 
>>> tables but don't see them on the slave.
>>>
>>> If adding the field didn't cause the problem, any ideas what might 
>>> have?
>>>
>>
>
>

From lists at serioustechnology.com  Wed Nov  5 07:31:10 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Wed Nov  5 07:31:17 2008
Subject: [Slony1-general] adding fields to a replicated table
In-Reply-To: <4911BA1E.3060602@echo.fr>
References: <4910CB38.2080000@serioustechnology.com>	<72dbd3150811041450ke1b46c2o5f31291ac3dbd80b@mail.gmail.com>	<4911A781.3060308@serioustechnology.com>
	<4911AA2D.7060201@echo.fr> <4911B6EC.5050704@serioustechnology.com>
	<4911BA1E.3060602@echo.fr>
Message-ID: <4911BC3E.5010801@serioustechnology.com>

Cyril SCETBON wrote:
> 
> 
> Geoffrey wrote:
>> Cyril SCETBON wrote:
>>> Which type of ALTER did you make ?
>>>
>>> Don't forget that there's a special trigger on the source table that 
>>> must be updated too.
>>
>> I'm not sure of how the change was made, I didn't make it.  As far as 
>> I know, all he did was add a new field to one of the tables.  He did 
>> not modify any slony triggers by hand.
> Not good. Check in the slon daemons logs to see what's happening.

I do see the following regarding the field added:


update only "public"."avlds" set 
ship_date='2008-11-06',ship_time='00:00:00',ship_date2='2008-11-06',ship_time2='00:00:00',appt_date='2008-11-06',appt_time='00:00:00' 
where recid='96593';
" ERROR:  column "loop_flag" of relation "avlds" does not exist
LINE 1: ...appt_date,appt_time,hot_flag,shipment_id,air_flag,loop_flag)...


-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From cbbrowne at ca.afilias.info  Wed Nov  5 07:39:25 2008
From: cbbrowne at ca.afilias.info (cbbrowne)
Date: Wed Nov  5 07:39:31 2008
Subject: [Slony1-general] adding fields to a replicated table
In-Reply-To: <4910CB38.2080000@serioustechnology.com>
References: <4910CB38.2080000@serioustechnology.com>
Message-ID: <4911BE2D.2010604@ca.afilias.info>

Geoffrey wrote:
> Will it cause a problem if one adds fields to a table that is being 
> replicated?
>
> That is, will it break the replication process, or will the 
> replication continue to simply replicate the previous set of fields?
>
There may be cases where replication won't break, but in general, if you 
do not use the slonik "EXECUTE SCRIPT" facility to handle alterations of 
the replicated schema, yes, indeed, you are likely to experience 
problems that will notably include replication "falling over."

There is a trigger on each replicated table which needs to be aware of 
what columns are in the table, and if you ALTER TABLE ADD COLUMN outside 
of "EXECUTE SCRIPT," the trigger will therefore NOT be aware of the 
change, which is likely to cause things to break down.

It is *possible* that repairs might be accomplished by dropping the 
affected tables from replication (SET DROP TABLE), then creating a new 
set, and setting up replication on them again.  It is also entirely 
likely that the best solution will be to re-initialize replication.

-- 
let name="cbbrowne" and tld="ca.afilias.info" in name ^ "@" ^ tld;;
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)

From lists at serioustechnology.com  Wed Nov  5 16:46:47 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Wed Nov  5 16:47:05 2008
Subject: [Slony1-general] replicate views
Message-ID: <49123E77.8010508@serioustechnology.com>

Is it possible to replicate views.  My assumption is that they would 
simply be handled like a table.

-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From drees76 at gmail.com  Wed Nov  5 18:19:40 2008
From: drees76 at gmail.com (David Rees)
Date: Wed Nov  5 18:20:00 2008
Subject: [Slony1-general] replicate views
In-Reply-To: <49123E77.8010508@serioustechnology.com>
References: <49123E77.8010508@serioustechnology.com>
Message-ID: <72dbd3150811051819u1a6ac73ar498ec221d3c4bc0b@mail.gmail.com>

On Wed, Nov 5, 2008 at 4:46 PM, Geoffrey <lists@serioustechnology.com> wrote:
> Is it possible to replicate views.  My assumption is that they would simply
> be handled like a table.

There is no need, since a view has no data. Just make sure your view
gets installed on each node.

-Dave
From lists at serioustechnology.com  Thu Nov  6 06:23:50 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Thu Nov  6 06:24:00 2008
Subject: [Slony1-general] replicate views
In-Reply-To: <72dbd3150811051819u1a6ac73ar498ec221d3c4bc0b@mail.gmail.com>
References: <49123E77.8010508@serioustechnology.com>
	<72dbd3150811051819u1a6ac73ar498ec221d3c4bc0b@mail.gmail.com>
Message-ID: <4912FDF6.5080606@serioustechnology.com>

David Rees wrote:
> On Wed, Nov 5, 2008 at 4:46 PM, Geoffrey <lists@serioustechnology.com> wrote:
>> Is it possible to replicate views.  My assumption is that they would simply
>> be handled like a table.
> 
> There is no need, since a view has no data. Just make sure your view
> gets installed on each node.

Thanks, sorry for posting before thinking.  This is as I expected.

-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From lists at serioustechnology.com  Thu Nov  6 08:11:15 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Thu Nov  6 08:11:24 2008
Subject: [Slony1-general] what changes require the use of execute_script
Message-ID: <49131723.5010204@serioustechnology.com>

Can anyone point me to documentation that outlines what changes require 
the use of 'execute_script?'

For example, I assume it's necessary for:

Adding a new table.
Adding a new field to an existing table.
Adding a view.

Is it necessary when:

Adding a new trigger?
Adding a new function?

Others?

-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From jeff at frostconsultingllc.com  Thu Nov  6 09:16:17 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Thu Nov  6 09:18:24 2008
Subject: [Slony1-general] what changes require the use of execute_script
In-Reply-To: <49131723.5010204@serioustechnology.com>
References: <49131723.5010204@serioustechnology.com>
Message-ID: <Pine.LNX.4.64.0811060912010.21591@discord.home.frostconsultingllc.com>

On Thu, 6 Nov 2008, Geoffrey wrote:

> Can anyone point me to documentation that outlines what changes require the 
> use of 'execute_script?'
>
> For example, I assume it's necessary for:
>
> Adding a new table.
> Adding a new field to an existing table.
> Adding a view.
>
> Is it necessary when:
>
> Adding a new trigger?
> Adding a new function?
>
> Others?

It's not necessary for adding a new table, index, view or function.  You just 
need to make sure you create them on all nodes where they will be used.

You must use it to add a new field to an existing table and to add triggers to 
existing replicated tables.

Check out the documentation here:
http://slony.info/documentation/ddlchanges.html

Especially the section:
15.1. Changes that you might not want to process using EXECUTE SCRIPT

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 916-647-6411	FAX: 916-405-4032
From calarcon at voxgen.com  Thu Nov  6 09:44:22 2008
From: calarcon at voxgen.com (=?iso-8859-1?Q?Carlos_Alarc=F3n?=)
Date: Thu Nov  6 09:49:45 2008
Subject: [Slony1-general] problem doing failover
Message-ID: <BD42407277216649A3B2DCF77A1BAC5701093EC0@mx02srv.london.wavoo.com>

Hi,

I am having the following when traying to do a failover and drop node in a =
2 nodes 3 sets setup:

 =


[root@vox-asterisk02 ~]# ./promote.sh

<stdin>:6: NOTICE:  failedNode: set 1 has no other direct receivers - move =
now

<stdin>:6: NOTICE:  failedNode: set 2 has no other direct receivers - move =
now

<stdin>:6: NOTICE:  failedNode: set 3 has no other direct receivers - move =
now

<stdin>:6: PGRES_FATAL_ERROR select "_monkey_cluster".failedNode2(1,2,1,'45=
','46');  - ERROR:  INSERT has more expressions than target columns

CONTEXT:  SQL statement "INSERT INTO "_monkey_cluster".sl_event (ev_origin,=
 ev_seqno, ev_timestamp, ev_snapshot, ev_type, ev_data1, ev_data2, ev_data3=
, ev_data4) values ( $1 , "pg_catalog".nextval('"_monkey_cluster".sl_event_=
seq'), CURRENT_TIMESTAMP, '0', '0', '0:0:', 'ACCEPT_SET',  $2 ::text,  $3 :=
:text,  $1 ::text,  $4 ::text)"

PL/pgSQL function "failoverset_int" line 35 at SQL statement

SQL statement "SELECT  "_monkey_cluster".failoverSet_int( $1 ,  $2 ,  $3 , =
 $4 )"

PL/pgSQL function "failednode2" line 39 at PERFORM

<stdin>:6: PGRES_FATAL_ERROR select "_monkey_cluster".failedNode2(1,2,2,'45=
','47');  - ERROR:  current transaction is aborted, commands ignored until =
end of transaction block

<stdin>:6: PGRES_FATAL_ERROR select "_monkey_cluster".failedNode2(1,2,3,'45=
','48');  - ERROR:  current transaction is aborted, commands ignored until =
end of transaction block

 =


 =


The cluster setup is the following:

#!/bin/sh

export PATH=3D$PATH:/usr/local/pgsql/bin/

CLUSTER1=3Dmonkey_cluster

DB1=3Dpickmonkey

DB2=3Dpickmonkey2

 =


H1=3D192.168.10.73

H2=3D192.168.10.73

U=3Dpostgres

PASSWORD=3Dpostgres

 =


slonik <<_EOF_

cluster name=3D$CLUSTER1;

node 1 admin conninfo=3D'dbname=3D$DB1 host=3D$H1 user=3D$U password=3D$PAS=
SWORD';

node 2 admin conninfo=3D'dbname=3D$DB2 host=3D$H2 user=3D$U password=3D$PAS=
SWORD';

 =


init cluster (id=3D1, comment=3D'Production');

 =


#TABLE ORDER DATA

create set (id=3D1, origin=3D1, comment=3D'order table');

set add table (set id=3D1, origin=3D1, id=3D1, full qualified name=3D'publi=
c.order_data', comment=3D'Table Order Data');

set add sequence (set id=3D1, origin=3D1, id=3D1, full qualified name=3D'pu=
blic.assrt_order_data_seq', comment=3D'Sequence assrt_order_data_seq');

 =


#TABLE TRANSFER_MISSED_FILES

create set (id=3D2, origin=3D1, comment=3D'Transfer Missed Files table');

set add table (set id=3D2, origin=3D1, id=3D2, full qualified name=3D'publi=
c.transfer_missed_files', comment=3D'Table transfer_missed_files');

set add sequence (set id=3D2, origin=3D1, id=3D2, full qualified name=3D'pu=
blic.assrt_transfer_files_seq', comment=3D'Sequence assrt_transfer_files_se=
q');

 =


#BIG GROUP OF TABLES WITH FKs

create set (id=3D3, origin=3D1, comment=3D'The rest of tables');

set add table (set id=3D3, origin=3D1, id=3D3, full qualified name=3D'publi=
c.address', comment=3D'Table address');

set add table (set id=3D3, origin=3D1, id=3D4, full qualified name=3D'publi=
c.tel_number', comment=3D'Table tel_number');

set add table (set id=3D3, origin=3D1, id=3D5, full qualified name=3D'publi=
c.country', comment=3D'Table country');

set add table (set id=3D3, origin=3D1, id=3D6, full qualified name=3D'publi=
c.customer', comment=3D'Table customer');

set add table (set id=3D3, origin=3D1, id=3D7, full qualified name=3D'publi=
c.zip_code', comment=3D'Table zip_code');

set add table (set id=3D3, origin=3D1, id=3D8, full qualified name=3D'publi=
c.holiday', comment=3D'Table holiday');

set add table (set id=3D3, origin=3D1, id=3D9, full qualified name=3D'publi=
c.depot', comment=3D'Table depot');

set add table (set id=3D3, origin=3D1, id=3D10, full qualified name=3D'publ=
ic.contact_centre', comment=3D'Table contact_centre');

 =


set add sequence (set id=3D3, origin=3D1, id=3D3, full qualified name=3D'pu=
blic.assrt_address_seq', comment=3D'Sequence assrt_address_seq');

set add sequence (set id=3D3, origin=3D1, id=3D4, full qualified name=3D'pu=
blic.assrt_tel_number_seq', comment=3D'Sequence assrt_tel_number_seq');

set add sequence (set id=3D3, origin=3D1, id=3D5, full qualified name=3D'pu=
blic.assrt_country_seq', comment=3D'Sequence assrt_country_seq');

set add sequence (set id=3D3, origin=3D1, id=3D6, full qualified name=3D'pu=
blic.assrt_customer_seq', comment=3D'Sequence assrt_customer_seq');

set add sequence (set id=3D3, origin=3D1, id=3D7, full qualified name=3D'pu=
blic.assrt_zip_code_seq', comment=3D'Sequence assrt_zip_code_seq');

set add sequence (set id=3D3, origin=3D1, id=3D8, full qualified name=3D'pu=
blic.assrt_holiday_seq', comment=3D'Sequence assrt_holiday_seq');

set add sequence (set id=3D3, origin=3D1, id=3D9, full qualified name=3D'pu=
blic.assrt_depot_seq', comment=3D'Sequence assrt_depot_seq');

set add sequence (set id=3D3, origin=3D1, id=3D10, full qualified name=3D'p=
ublic.assrt_contact_centre_seq', comment=3D'Sequence assrt_contact_centre_s=
eq');

 =


store node (id=3D2, comment=3D'Backup', EVENT NODE=3D1);

store path (server=3D1, client=3D2, conninfo=3D'dbname=3D$DB1 host=3D$H1 us=
er=3D$U password=3D$PASSWORD');

store path (server=3D2, client=3D1, conninfo=3D'dbname=3D$DB2 host=3D$H2 us=
er=3D$U password=3D$PASSWORD');

store listen (origin=3D1, provider=3D1, receiver=3D2);

store listen (origin=3D2, provider=3D2, receiver=3D1);

_EOF_

 =


 =


the subscribe script:

#!/bin/sh

export PATH=3D$PATH:/usr/local/pgsql/bin/

CLUSTER1=3Dmonkey_cluster

DB1=3Dpickmonkey

DB2=3Dpickmonkey2

 =


H1=3D192.168.10.73

H2=3D192.168.10.73

U=3Dpostgres

PASSWORD=3Dpostgres

 =


 =


slonik <<_EOF_

 =


cluster name =3D $CLUSTER1;

 =


node 1 admin conninfo =3D 'dbname=3D$DB1 host=3D$H1 user=3D$U password=3D$P=
ASSWORD';

node 2 admin conninfo =3D 'dbname=3D$DB2 host=3D$H2 user=3D$U password=3D$P=
ASSWORD';

 =


subscribe set (id =3D 1, provider =3D 1, receiver =3D 2, forward =3D yes);

subscribe set (id =3D 2, provider =3D 1, receiver =3D 2, forward =3D yes);

subscribe set (id =3D 3, provider =3D 1, receiver =3D 2, forward =3D yes);

_EOF_

 =


and to promote:

 =


#!/bin/bash

#

#promote.sh

 =


export PATH=3D$PATH:/usr/local/pgsql/bin/

CLUSTER1=3Dmonkey_cluster

DB1=3Dpickmonkey

DB2=3Dpickmonkey2

 =


H1=3D192.168.10.73

H2=3D192.168.10.73

U=3Dpostgres

PASSWORD=3Dpostgres

 =


 =


 =


su - postgres -c /usr/local/pgsql/bin/slonik <<_EOF_

cluster name =3D $CLUSTER1;

 =


node 1 admin conninfo =3D 'dbname=3D$DB1 host=3D$H1 user=3D$U password=3D$P=
ASSWORD';

node 2 admin conninfo =3D 'dbname=3D$DB2 host=3D$H2 user=3D$U password=3D$P=
ASSWORD';

 =


failover (id =3D 1, backup node =3D 2);

drop node (id =3D 1, event node =3D 2);

_EOF_

 =


Any idea in what may be wrong?

 =



###########################################################################=
##########
Note:
This message is for the named person's use only.  It may contain confidenti=
al, =

proprietary or legally privileged information. No confidentiality or privil=
ege is =

waived or lost by any mistransmission.  If you receive this message in erro=
r, please
immediately delete it and all copies of it from your system, destroy any ha=
rd copies =

of it and notify the sender.  You must not, directly or indirectly, use, di=
sclose, =

distribute, print, or copy any part of this message if you are not the inte=
nded =

recipient. Vox Generation Limited and any of its subsidiaries each reserve =
the right
to monitor all e-mail communications through its networks. Any views expres=
sed in =

this message are those of the individual sender, except where the message s=
tates =

otherwise and the sender is authorised to state them to be the views of any =

such entity.

Thank You.  =


VoxGen
Manor House =

21 Soho Square =

London W1D 3QP =


---------------------------------------------------------------------------=
-----

VoxGen is a trading name of Vox Generation Limited
Registered in England and Wales: 3937784   VAT Registration 756 2842 09
Registered Address: 90 Fetter Lane, London, EC4A 1JP

---------------------------------------------------------------------------=
-----

############################################################################
Awarded ISO/IEC27001:2005 Certification in 2007.
Awarded ISO9001:2000 Certification in 2006.
Winner - e-Government excellence 2005.
Runner up - European Information Management awards 2004:
 - The Premier Project Award.
 - B2C Commerce Project Award.
 - CRM Project Award.
 =

For more information visit us at www.voxgen.com
 =

###########################################################################

###########################################################################=
##########
This e-mail message has been scanned for Viruses and Content and cleared =

by NetIQ MailMarshal
###########################################################################=
##########
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20081106/=
0420ce06/attachment-0001.htm
From carlos.alarcon at tyven.com  Thu Nov  6 09:50:58 2008
From: carlos.alarcon at tyven.com (Carlos Alarcon)
Date: Thu Nov  6 09:51:09 2008
Subject: [Slony1-general] Problem on Failover
Message-ID: <1488C04358A2473A93B6FA9E1B3307F2@TYVENLAPTOP10>

Hi,

I am having the following when traying to do a failover and drop node in a 2
nodes 3 sets setup:

 =


[root@vox-asterisk02 ~]# ./promote.sh

<stdin>:6: NOTICE:  failedNode: set 1 has no other direct receivers - move
now

<stdin>:6: NOTICE:  failedNode: set 2 has no other direct receivers - move
now

<stdin>:6: NOTICE:  failedNode: set 3 has no other direct receivers - move
now

<stdin>:6: PGRES_FATAL_ERROR select
"_monkey_cluster".failedNode2(1,2,1,'45','46');  - ERROR:  INSERT has more
expressions than target columns

CONTEXT:  SQL statement "INSERT INTO "_monkey_cluster".sl_event (ev_origin,
ev_seqno, ev_timestamp, ev_snapshot, ev_type, ev_data1, ev_data2, ev_data3,
ev_data4) values ( $1 ,
"pg_catalog".nextval('"_monkey_cluster".sl_event_seq'), CURRENT_TIMESTAMP,
'0', '0', '0:0:', 'ACCEPT_SET',  $2 ::text,  $3 ::text,  $1 ::text,  $4
::text)"

PL/pgSQL function "failoverset_int" line 35 at SQL statement

SQL statement "SELECT  "_monkey_cluster".failoverSet_int( $1 ,  $2 ,  $3 ,
$4 )"

PL/pgSQL function "failednode2" line 39 at PERFORM

<stdin>:6: PGRES_FATAL_ERROR select
"_monkey_cluster".failedNode2(1,2,2,'45','47');  - ERROR:  current
transaction is aborted, commands ignored until end of transaction block

<stdin>:6: PGRES_FATAL_ERROR select
"_monkey_cluster".failedNode2(1,2,3,'45','48');  - ERROR:  current
transaction is aborted, commands ignored until end of transaction block

 =


Slony version: 2.0.0. RC1, postgresql-8.3.3

 =


 =


The cluster setup is the following:

#!/bin/sh

export PATH=3D$PATH:/usr/local/pgsql/bin/

CLUSTER1=3Dmonkey_cluster

DB1=3Dpickmonkey

DB2=3Dpickmonkey2

 =


H1=3D192.168.10.73

H2=3D192.168.10.73

U=3Dpostgres

PASSWORD=3Dpostgres

 =


slonik <<_EOF_

cluster name=3D$CLUSTER1;

node 1 admin conninfo=3D'dbname=3D$DB1 host=3D$H1 user=3D$U password=3D$PAS=
SWORD';

node 2 admin conninfo=3D'dbname=3D$DB2 host=3D$H2 user=3D$U password=3D$PAS=
SWORD';

 =


init cluster (id=3D1, comment=3D'Production');

 =


#TABLE ORDER DATA

create set (id=3D1, origin=3D1, comment=3D'order table');

set add table (set id=3D1, origin=3D1, id=3D1, full qualified
name=3D'public.order_data', comment=3D'Table Order Data');

set add sequence (set id=3D1, origin=3D1, id=3D1, full qualified
name=3D'public.assrt_order_data_seq', comment=3D'Sequence
assrt_order_data_seq');

 =


#TABLE TRANSFER_MISSED_FILES

create set (id=3D2, origin=3D1, comment=3D'Transfer Missed Files table');

set add table (set id=3D2, origin=3D1, id=3D2, full qualified
name=3D'public.transfer_missed_files', comment=3D'Table transfer_missed_fil=
es');

set add sequence (set id=3D2, origin=3D1, id=3D2, full qualified
name=3D'public.assrt_transfer_files_seq', comment=3D'Sequence
assrt_transfer_files_seq');

 =


#BIG GROUP OF TABLES WITH FKs

create set (id=3D3, origin=3D1, comment=3D'The rest of tables');

set add table (set id=3D3, origin=3D1, id=3D3, full qualified
name=3D'public.address', comment=3D'Table address');

set add table (set id=3D3, origin=3D1, id=3D4, full qualified
name=3D'public.tel_number', comment=3D'Table tel_number');

set add table (set id=3D3, origin=3D1, id=3D5, full qualified
name=3D'public.country', comment=3D'Table country');

set add table (set id=3D3, origin=3D1, id=3D6, full qualified
name=3D'public.customer', comment=3D'Table customer');

set add table (set id=3D3, origin=3D1, id=3D7, full qualified
name=3D'public.zip_code', comment=3D'Table zip_code');

set add table (set id=3D3, origin=3D1, id=3D8, full qualified
name=3D'public.holiday', comment=3D'Table holiday');

set add table (set id=3D3, origin=3D1, id=3D9, full qualified name=3D'publi=
c.depot',
comment=3D'Table depot');

set add table (set id=3D3, origin=3D1, id=3D10, full qualified
name=3D'public.contact_centre', comment=3D'Table contact_centre');

 =


set add sequence (set id=3D3, origin=3D1, id=3D3, full qualified
name=3D'public.assrt_address_seq', comment=3D'Sequence assrt_address_seq');

set add sequence (set id=3D3, origin=3D1, id=3D4, full qualified
name=3D'public.assrt_tel_number_seq', comment=3D'Sequence
assrt_tel_number_seq');

set add sequence (set id=3D3, origin=3D1, id=3D5, full qualified
name=3D'public.assrt_country_seq', comment=3D'Sequence assrt_country_seq');

set add sequence (set id=3D3, origin=3D1, id=3D6, full qualified
name=3D'public.assrt_customer_seq', comment=3D'Sequence assrt_customer_seq'=
);

set add sequence (set id=3D3, origin=3D1, id=3D7, full qualified
name=3D'public.assrt_zip_code_seq', comment=3D'Sequence assrt_zip_code_seq'=
);

set add sequence (set id=3D3, origin=3D1, id=3D8, full qualified
name=3D'public.assrt_holiday_seq', comment=3D'Sequence assrt_holiday_seq');

set add sequence (set id=3D3, origin=3D1, id=3D9, full qualified
name=3D'public.assrt_depot_seq', comment=3D'Sequence assrt_depot_seq');

set add sequence (set id=3D3, origin=3D1, id=3D10, full qualified
name=3D'public.assrt_contact_centre_seq', comment=3D'Sequence
assrt_contact_centre_seq');

 =


store node (id=3D2, comment=3D'Backup', EVENT NODE=3D1);

store path (server=3D1, client=3D2, conninfo=3D'dbname=3D$DB1 host=3D$H1 us=
er=3D$U
password=3D$PASSWORD');

store path (server=3D2, client=3D1, conninfo=3D'dbname=3D$DB2 host=3D$H2 us=
er=3D$U
password=3D$PASSWORD');

store listen (origin=3D1, provider=3D1, receiver=3D2);

store listen (origin=3D2, provider=3D2, receiver=3D1);

_EOF_

 =


 =


the subscribe script:

#!/bin/sh

export PATH=3D$PATH:/usr/local/pgsql/bin/

CLUSTER1=3Dmonkey_cluster

DB1=3Dpickmonkey

DB2=3Dpickmonkey2

 =


H1=3D192.168.10.73

H2=3D192.168.10.73

U=3Dpostgres

PASSWORD=3Dpostgres

 =


 =


slonik <<_EOF_

 =


cluster name =3D $CLUSTER1;

 =


node 1 admin conninfo =3D 'dbname=3D$DB1 host=3D$H1 user=3D$U password=3D$P=
ASSWORD';

node 2 admin conninfo =3D 'dbname=3D$DB2 host=3D$H2 user=3D$U password=3D$P=
ASSWORD';

 =


subscribe set (id =3D 1, provider =3D 1, receiver =3D 2, forward =3D yes);

subscribe set (id =3D 2, provider =3D 1, receiver =3D 2, forward =3D yes);

subscribe set (id =3D 3, provider =3D 1, receiver =3D 2, forward =3D yes);

_EOF_

 =


and to promote:

 =


#!/bin/bash

#

#promote.sh

 =


export PATH=3D$PATH:/usr/local/pgsql/bin/

CLUSTER1=3Dmonkey_cluster

DB1=3Dpickmonkey

DB2=3Dpickmonkey2

 =


H1=3D192.168.10.73

H2=3D192.168.10.73

U=3Dpostgres

PASSWORD=3Dpostgres

 =


 =


 =


su - postgres -c /usr/local/pgsql/bin/slonik <<_EOF_

cluster name =3D $CLUSTER1;

 =


node 1 admin conninfo =3D 'dbname=3D$DB1 host=3D$H1 user=3D$U password=3D$P=
ASSWORD';

node 2 admin conninfo =3D 'dbname=3D$DB2 host=3D$H2 user=3D$U password=3D$P=
ASSWORD';

 =


failover (id =3D 1, backup node =3D 2);

drop node (id =3D 1, event node =3D 2);

_EOF_

 =


Any idea in what may be wrong?

 =


 =


 =


 =


-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20081106/=
321b14c8/attachment-0001.htm
From ABhat at trustwave.com  Thu Nov  6 12:13:05 2008
From: ABhat at trustwave.com (Anoop Bhat)
Date: Thu Nov  6 12:13:27 2008
Subject: [Slony1-general] Sl_status
Message-ID: <C538ABF1.2D0E%abhat@trustwave.com>

Hi,

I learned from cbrowne that I can query sl_status to find out the status of the replication.

Within a minute or so, the origin's sl_status for the cluster I created looked like this

 st_origin | st_received | st_last_event |      st_last_event_ts      | st_last_received |    st_last_received_ts     | st_last_received_event_ts  | st_lag_num_events |   st_lag_time
-----------+-------------+---------------+----------------------------+------------------+----------------------------+----------------------------+-------------------+-----------------
         1 |           2 |            35 | 2008-11-06 20:02:24.943084 |               35 | 2008-11-06 14:07:11.002322 | 2008-11-06 20:02:24.943084 |                 0 | 00:00:06.259891


st_last_event and st_last_received grew.

However, I'm not sure what's being replicated and if it's going into the right tables in the slave db.

The db's are called vul and vul_slave. On vul_slave, what can I check on to see if it's gotten any data.

I used the slony docs this time to set it up just to make sure it was done right.

I noticed this by the way on http://www.slony.info/documentation/firstdb.html

# subscribe set to second node (1= set ID, 2= node ID)
$ slonik_subscribe_set  2 | slonik

Is that command missing an option?

Thanks

Anoop

From glynastill at yahoo.co.uk  Fri Nov  7 05:25:22 2008
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Fri Nov  7 05:25:27 2008
Subject: [Slony1-general] Sl_status
In-Reply-To: <C538ABF1.2D0E%abhat@trustwave.com>
Message-ID: <210559.25254.qm@web23607.mail.ird.yahoo.com>

--- On Thu, 6/11/08, Anoop Bhat <ABhat@trustwave.com> wrote:

> Hi,
> 
> I learned from cbrowne that I can query sl_status to find
> out the status of the replication.
> 
> Within a minute or so, the origin's sl_status for the
> cluster I created looked like this
> 
>  st_origin | st_received | st_last_event |     
> st_last_event_ts      | st_last_received |   
> st_last_received_ts     | st_last_received_event_ts  |
> st_lag_num_events |   st_lag_time
> -----------+-------------+---------------+----------------------------+------------------+----------------------------+----------------------------+-------------------+-----------------
>          1 |           2 |            35 | 2008-11-06
> 20:02:24.943084 |               35 | 2008-11-06
> 14:07:11.002322 | 2008-11-06 20:02:24.943084 |              
>   0 | 00:00:06.259891
> 
> 
> st_last_event and st_last_received grew.
> 

Are the slons running? And if so looking in the logs is a good start.

> However, I'm not sure what's being replicated and
> if it's going into the right tables in the slave db.
> 
> The db's are called vul and vul_slave. On vul_slave,
> what can I check on to see if it's gotten any data.
> 

Make a change to a replicated table, then go check it on the slave.



      
From giamcw at fourierlab.com.sg  Fri Nov  7 02:05:04 2008
From: giamcw at fourierlab.com.sg (wernergiam)
Date: Fri Nov  7 06:19:20 2008
Subject: [Slony1-general] help needed to install slony on solaris
Message-ID: <20377714.post@talk.nabble.com>


i'm trying to install slony on a solaris 10 machine. however, i encounter a
error from gcc with the error message
ld: fatal: library -lpgport: not found

Does anybody able to help me on this. btw, i did not build postgres from
source, it comes with solaris 10 distribution.
-- 
View this message in context: http://www.nabble.com/help-needed-to-install-slony-on-solaris-tp20377714p20377714.html
Sent from the Slony-I -- General mailing list archive at Nabble.com.

From ABhat at trustwave.com  Fri Nov  7 15:07:58 2008
From: ABhat at trustwave.com (Anoop Bhat)
Date: Fri Nov  7 15:09:06 2008
Subject: [Slony1-general] Sl_status
In-Reply-To: <210559.25254.qm@web23607.mail.ird.yahoo.com>
Message-ID: <C53A266E.2DA4%abhat@trustwave.com>

Yup. The slon daemons are running on the slave itself.

root     18692     1  0 14:23 pts/1    00:00:00 /usr/bin//slon -s 1000 -d2 vul_repl_11062008 host=crdmaster dbname=vul user=crd port=5432
root     18694 18692  0 14:23 pts/1    00:00:00 /usr/bin//slon -s 1000 -d2 vul_repl_11062008 host=crdmaster dbname=vul user=crd port=5432
root     18702     1  0 14:23 pts/1    00:00:00 /usr/bin/perl /usr/local/bin/slon_watchdog --config=vul_slontools.conf node1 30
root     18745     1  0 14:24 pts/1    00:00:00 /usr/bin//slon -s 1000 -d2 vul_repl_11062008 host=172.31.6.70 dbname=vul_slave user=crd port=5432
root     18748 18745  0 14:24 pts/1    00:00:00 /usr/bin//slon -s 1000 -d2 vul_repl_11062008 host=172.31.6.70 dbname=vul_slave user=crd port=5432
root     18759     1  0 14:24 pts/1    00:00:00 /usr/bin/perl /usr/local/bin/slon_watchdog --config=vul_slontools.conf node2 30

The log files show stuff like this

2008-11-06 14:22:55 CST DEBUG2 localListenThread: Received event 2,125 SYNC
2008-11-06 14:23:01 CST DEBUG2 remoteListenThread_1: queue event 1,125 SYNC
2008-11-06 14:23:01 CST DEBUG2 remoteWorkerThread_1: Received event 1,125 SYNC
2008-11-06 14:23:01 CST DEBUG2 remoteWorkerThread_1: SYNC 125 processing
2008-11-06 14:23:01 CST DEBUG2 remoteWorkerThread_1: syncing set 1 with 0 table(s) from provider 1
2008-11-06 14:23:01 CST DEBUG2 remoteWorkerThread_1: current local log_status is 0
2008-11-06 14:23:01 CST DEBUG2 remoteWorkerThread_1_1: current remote log_status = 0
2008-11-06 14:23:01 CST DEBUG2 remoteHelperThread_1_1: 0.048 seconds delay for first row
2008-11-06 14:23:01 CST DEBUG2 remoteHelperThread_1_1: 0.095 seconds until close cursor
2008-11-06 14:23:01 CST DEBUG2 remoteHelperThread_1_1: inserts=0 updates=0 deletes=0
2008-11-06 14:23:01 CST DEBUG2 remoteWorkerThread_1: new sl_rowid_seq value: 1000000000000000
2008-11-06 14:23:01 CST DEBUG2 remoteWorkerThread_1: SYNC 125 done in 0.193 seconds
2008-11-06 14:23:01 CST DEBUG2 remoteWorkerThread_1: forward confirm 2,125 received by 1
2008-11-06 14:23:01 CST DEBUG2 syncThread: new sl_action_seq 1 - SYNC 126
2008-11-06 14:23:05 CST DEBUG2 localListenThread: Received event 2,126 SYNC
2008-11-06 14:23:11 CST DEBUG2 syncThread: new sl_action_seq 1 - SYNC 127
2008-11-06 14:23:12 CST DEBUG2 remoteListenThread_1: queue event 1,126 SYNC
2008-11-06 14:23:12 CST DEBUG2 remoteWorkerThread_1: Received event 1,126 SYNC
2008-11-06 14:23:12 CST DEBUG2 remoteWorkerThread_1: SYNC 126 processing
2008-11-06 14:23:12 CST DEBUG2 remoteWorkerThread_1: syncing set 1 with 0 table(s) from provider 1
2008-11-06 14:23:12 CST DEBUG2 remoteWorkerThread_1: current local log_status is 0
2008-11-06 14:23:12 CST DEBUG2 remoteWorkerThread_1_1: current remote log_status = 0
2008-11-06 14:23:12 CST DEBUG2 remoteHelperThread_1_1: 0.048 seconds delay for first row
2008-11-06 14:23:12 CST DEBUG2 remoteHelperThread_1_1: 0.095 seconds until close cursor
2008-11-06 14:23:12 CST DEBUG2 remoteHelperThread_1_1: inserts=0 updates=0 deletes=0
2008-11-06 14:23:12 CST DEBUG2 remoteWorkerThread_1: new sl_rowid_seq value: 1000000000000000
2008-11-06 14:23:12 CST DEBUG2 remoteWorkerThread_1: SYNC 126 done in 0.194 seconds
2008-11-06 14:23:12 CST DEBUG2 remoteWorkerThread_1: forward confirm 2,126 received by 1
2008-11-06 14:23:15 CST DEBUG2 localListenThread: Received event 2,127 SYNC
2008-11-06 14:23:21 CST DEBUG2 syncThread: new sl_action_seq 1 - SYNC 128
2008-11-06 14:23:23 CST DEBUG2 remoteListenThread_1: queue event 1,127 SYNC
2008-11-06 14:23:23 CST DEBUG2 remoteWorkerThread_1: Received event 1,127 SYNC
2008-11-06 14:23:23 CST DEBUG2 remoteWorkerThread_1: SYNC 127 processing
2008-11-06 14:23:23 CST DEBUG2 remoteWorkerThread_1: syncing set 1 with 0 table(s) from provider 1
2008-11-06 14:23:23 CST DEBUG2 remoteWorkerThread_1: current local log_status is 0
2008-11-06 14:23:23 CST DEBUG2 remoteWorkerThread_1_1: current remote log_status = 0
2008-11-06 14:23:23 CST DEBUG2 remoteHelperThread_1_1: 0.048 seconds delay for first row
2008-11-06 14:23:23 CST DEBUG2 remoteHelperThread_1_1: 0.095 seconds until close cursor
2008-11-06 14:23:23 CST DEBUG2 remoteHelperThread_1_1: inserts=0 updates=0 deletes=0
2008-11-06 14:23:23 CST DEBUG2 remoteWorkerThread_1: new sl_rowid_seq value: 1000000000000000
2008-11-06 14:23:23 CST DEBUG2 remoteWorkerThread_1: SYNC 127 done in 0.194 seconds
2008-11-06 14:23:23 CST DEBUG2 remoteWorkerThread_1: forward confirm 2,128 received by 1
2008-11-06 14:23:25 CST DEBUG2 localListenThread: Received event 2,128 SYNC

This just keeps on going.

Currently, there are 0 rows in any of the tables on the slave. I'm contemplating abandoning the scripts on the slave and running it from the master. Or dropping the altperl scripts all together and just doing the slonik commands manually.

________________________________
From: Glyn Astill <glynastill@yahoo.co.uk>
Reply-To: <glynastill@yahoo.co.uk>
Date: Fri, 7 Nov 2008 07:25:22 -0600
To: <slony1-general@lists.slony.info>, Anoop Bhat <ABhat@trustwave.com>
Subject: Re: [Slony1-general] Sl_status

--- On Thu, 6/11/08, Anoop Bhat <ABhat@trustwave.com> wrote:

> Hi,
>
> I learned from cbrowne that I can query sl_status to find
> out the status of the replication.
>
> Within a minute or so, the origin's sl_status for the
> cluster I created looked like this
>
>  st_origin | st_received | st_last_event |
> st_last_event_ts      | st_last_received |
> st_last_received_ts     | st_last_received_event_ts  |
> st_lag_num_events |   st_lag_time
> -----------+-------------+---------------+----------------------------+------------------+----------------------------+----------------------------+-------------------+-----------------
>          1 |           2 |            35 | 2008-11-06
> 20:02:24.943084 |               35 | 2008-11-06
> 14:07:11.002322 | 2008-11-06 20:02:24.943084 |
>   0 | 00:00:06.259891
>
>
> st_last_event and st_last_received grew.
>

Are the slons running? And if so looking in the logs is a good start.

> However, I'm not sure what's being replicated and
> if it's going into the right tables in the slave db.
>
> The db's are called vul and vul_slave. On vul_slave,
> what can I check on to see if it's gotten any data.
>

Make a change to a replicated table, then go check it on the slave.







From lists at serioustechnology.com  Mon Nov 10 17:39:28 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Mon Nov 10 17:39:46 2008
Subject: [Slony1-general] truncate failed???
Message-ID: <4918E250.1010103@serioustechnology.com>

I've received the message:

NOTICE:  truncate of "public"."foo" failed - doing delete

When first initializing slony on a slave where all the tables are empty. 
  Why would the truncate fail on an empty table?

-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From jeff at frostconsultingllc.com  Mon Nov 10 17:42:08 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Mon Nov 10 17:42:33 2008
Subject: [Slony1-general] truncate failed???
In-Reply-To: <4918E250.1010103@serioustechnology.com>
References: <4918E250.1010103@serioustechnology.com>
Message-ID: <Pine.LNX.4.64.0811101741190.18987@discord.home.frostconsultingllc.com>

On Mon, 10 Nov 2008, Geoffrey wrote:

> I've received the message:
>
> NOTICE:  truncate of "public"."foo" failed - doing delete
>
> When first initializing slony on a slave where all the tables are empty.  Why 
> would the truncate fail on an empty table?

Because of foreign key references from other tables.  From the docs:

TRUNCATE cannot be used on a table that has foreign-key references from other 
tables, unless all such tables are also truncated in the same command. 
Checking validity in such cases would require table scans, and the whole point 
is not to do one.

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 916-647-6411	FAX: 916-405-4032
From lists at serioustechnology.com  Tue Nov 11 05:09:25 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Tue Nov 11 05:09:28 2008
Subject: [Slony1-general] best way to verify slony is properly syncing
Message-ID: <49198405.9070803@serioustechnology.com>

I'm looking for suggestions as to the best way to verify that my single 
slave is in sync with my master.  We've had a couple of situations (self 
induced) where we've created problems for slony and therefore would like 
to provide a warm and fuzzy feeling that slony is current.

I've considered simply doing a couple of 'select count(*)' against 
various tables and comparing the results between the master and slave, 
but this seems to be a bit of a hatchet job.

I seem to recall there are is some statistical data in a slony table, 
but I can't for the life of me locate that discussion.

Thanks for any assistance.

-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From bnichols at ca.afilias.info  Tue Nov 11 05:59:12 2008
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Tue Nov 11 05:59:16 2008
Subject: [Slony1-general] best way to verify slony is properly syncing
In-Reply-To: <49198405.9070803@serioustechnology.com>
References: <49198405.9070803@serioustechnology.com>
Message-ID: <1226411952.16085.81.camel@bnicholson-desktop>

On Tue, 2008-11-11 at 08:09 -0500, Geoffrey wrote:
> I'm looking for suggestions as to the best way to verify that my single 
> slave is in sync with my master.  We've had a couple of situations (self 
> induced) where we've created problems for slony and therefore would like 
> to provide a warm and fuzzy feeling that slony is current.
> 
> I've considered simply doing a couple of 'select count(*)' against 
> various tables and comparing the results between the master and slave, 
> but this seems to be a bit of a hatchet job.
> 
> I seem to recall there are is some statistical data in a slony table, 
> but I can't for the life of me locate that discussion.

Look at the sl_status view on the provider.  It's in the Slony created
schema.

-- 
?Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.

From troy at troywolf.com  Tue Nov 11 14:36:31 2008
From: troy at troywolf.com (Troy Wolf)
Date: Tue Nov 11 14:36:48 2008
Subject: [Slony1-general] Re: best way to verify slony is properly syncing
Message-ID: <e0d7c3f50811111436p5baf6c05gb911fad5f1293267@mail.gmail.com>

>
> I'm looking for suggestions as to the best way to verify that my single
> slave is in sync with my master.  We've had a couple of situations (self
> induced) where we've created problems for slony and therefore would like
> to provide a warm and fuzzy feeling that slony is current.
>

I thought I was clever and built a script that selects the most recent
timestamp from the event tables on both and compares to see that they are
within 10 seconds. It took me about 45 days to learn the hard way that this
is not enough.

So I got stupid-brute-force. I created a cron job that updates a value in a
slony'd table's column every minute to the current_timestamp. My "health"
check simply queries the subscriber's value for this column to see if it is
within the last 2 minutes.  For me, I had an appropriate table of
"parameters" where I could just create a "slony_ts" parameter and update its
value. You may not have this, so maybe you'd create a special table just for
this purpose.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20081111/=
fd4ece49/attachment.htm
From cbbrowne at ca.afilias.info  Tue Nov 11 14:53:17 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Nov 11 14:53:33 2008
Subject: [Slony1-general] Re: best way to verify slony is properly syncing
In-Reply-To: <e0d7c3f50811111436p5baf6c05gb911fad5f1293267@mail.gmail.com>
	(Troy Wolf's message of "Tue, 11 Nov 2008 16:36:31 -0600")
References: <e0d7c3f50811111436p5baf6c05gb911fad5f1293267@mail.gmail.com>
Message-ID: <8763mtub6q.fsf@dba2.int.libertyrms.com>

"Troy Wolf" <troy@troywolf.com> writes:
>           I'm looking for suggestions as to the best way to verify that my single
>      slave is in sync with my master. ?We've had a couple of situations (self
>      induced) where we've created problems for slony and therefore would like
>      to provide a warm and fuzzy feeling that slony is current.
>      
>
> I thought I was clever and built a script that selects the most recent timestamp from the event tables on both and compares to see that they are
> within 10 seconds. It took me about 45 days to learn the hard way that this is not enough.
>
> So I got stupid-brute-force. I created a cron job that updates a value in a slony'd table's column every minute to the current_timestamp. My
> "health" check simply queries the subscriber's value for this column to see if it is within the last 2 minutes. ?For me, I had an appropriate
> table of "parameters" where I could just create a "slony_ts" parameter and update its value. You may not have this, so maybe you'd create a
> special table just for this purpose.

There is value to both approaches:

 - Checking sl_status to see if Slony-I thinks it's behind will work
   fairly well both when things are working well, and when your
   underlying system *isn't* busy (e.g. - when it's not doing any
   "real work."

 - There is also value to having an "end-to-end" test that looks for
   some application data.

   We have a "transaction table" which is normally updated quite
   frequently, 24 hours a day.  Looking at the youngest transaction in
   that table is a pretty good test; if there's no new-looking data,
   then there's probably a problem with the *application*, even if
   replication's working fine.
-- 
(reverse (concatenate 'string "ofni.secnanifxunil" "@" "enworbbc"))
http://linuxfinances.info/info/spiritual.html
The  meta-Turing test counts  a thing  as intelligent  if it  seeks to
apply Turing tests to objects of its own creation.
From smith.not.western at gmail.com  Tue Nov 11 18:37:06 2008
From: smith.not.western at gmail.com (Mike C)
Date: Tue Nov 11 18:37:25 2008
Subject: [Slony1-general] slony 2.0 RC2 cleanupThread problem
Message-ID: <bd0eabd0811111837l491f575eleb1729be2d481903@mail.gmail.com>

Hello,

I'm running postgres 8.3.3 and slony 2.0 rc2 on three servers (1
master, 2 slaves).

I keep seeing this error from all 3 servers:

Nov 12 02:26:49 database12 slon[4893]: [227-1] 2008-11-12 02:26:49 UTC
FATAL  cleanupThread: "select "_sample".cleanupEvent('10
minutes'::interval, 'false'::boolean); " -
Nov 12 02:26:49 database12 slon[4893]: [227-2]  ERROR:  query has no
destination for result data
Nov 12 02:26:49 database12 slon[4893]: [227-3] HINT:  If you want to
discard the results of a SELECT, use PERFORM instead.
Nov 12 02:26:49 database12 slon[4893]: [227-4] CONTEXT:  PL/pgSQL
function "logswitch_finish" line 42 at SQL statement
Nov 12 02:26:49 database12 slon[4893]: [227-5] PL/pgSQL function
"cleanupevent" line 99 at assignment
Nov 12 02:26:49 database12 slon[4514]: [5-1] 2008-11-12 02:26:49 UTC
INFO   slon: retry requested
Nov 12 02:26:49 database12 slon[4514]: [6-1] 2008-11-12 02:26:49 UTC
INFO   slon: notify worker process to shutdown
Nov 12 02:26:49 database12 slon[4893]: [228-1] 2008-11-12 02:26:49 UTC
INFO   syncThread: thread done
Nov 12 02:26:49 database12 slon[4893]: [229-1] 2008-11-12 02:26:49 UTC
INFO   remoteListenThread_3: disconnecting from 'dbname=sample
host=1.2.3.4 user=slony port=5432'
Nov 12 02:26:49 database12 slon[4893]: [230-1] 2008-11-12 02:26:49 UTC
INFO   remoteListenThread_1: disconnecting from 'dbname=sample
host=12.3.5 user=slony port=5432'
Nov 12 02:26:49 database12 slon[4893]: [231-1] 2008-11-12 02:26:49 UTC
INFO   localListenThread: thread done
Nov 12 02:26:49 database12 slon[4893]: [232-1] 2008-11-12 02:26:49 UTC
INFO   main: scheduler mainloop returned
Nov 12 02:26:49 database12 slon[4893]: [233-1] 2008-11-12 02:26:49 UTC
CONFIG main: wait for remote threads
Nov 12 02:26:49 database12 slon[4893]: [234-1] 2008-11-12 02:26:49 UTC
CONFIG remoteWorkerThread_1: update provider configuration
Nov 12 02:26:49 database12 slon[4893]: [235-1] 2008-11-12 02:26:49 UTC
CONFIG remoteWorkerThread_1: helper thread for provider 1 terminated
Nov 12 02:26:49 database12 slon[4893]: [236-1] 2008-11-12 02:26:49 UTC
CONFIG remoteWorkerThread_1: disconnecting from data provider 1
Nov 12 02:26:49 database12 slon[4893]: [237-1] 2008-11-12 02:26:49 UTC
INFO   remoteWorkerThread_1: thread done
Nov 12 02:26:49 database12 slon[4893]: [238-1] 2008-11-12 02:26:49 UTC
CONFIG remoteWorkerThread_3: update provider configuration
Nov 12 02:26:49 database12 slon[4893]: [239-1] 2008-11-12 02:26:49 UTC
INFO   remoteWorkerThread_3: thread done
Nov 12 02:26:49 database12 slon[4893]: [240-1] 2008-11-12 02:26:49 UTC
CONFIG main: done
Nov 12 02:26:49 database12 slon[4514]: [7-1] 2008-11-12 02:26:49 UTC
CONFIG slon: child terminated status: 0; pid: 4893, current worker
pid: 4893

Is this a known issue? Any workarounds for it?

Cheers,

Mike
From Tony.Fernandez at vocalocity.com  Wed Nov 12 14:52:07 2008
From: Tony.Fernandez at vocalocity.com (Tony Fernandez)
Date: Wed Nov 12 15:01:01 2008
Subject: [Slony1-general] ERROR:  incompatible library
Message-ID: <925169557BAB6947A70CB145F894A75B70ABEE@mail-41ps.atlarge.net>

Hello lists,

 

I am trying to run Slony on a Master Postgres 8.1.11 replicating to a
Slave same version and 2nd Slave Postgres 8.3.4.

The purpose is to update Postgres in production by steps, first slaves
then switchover to upgrade the master that will not be master when
upgraded.

 

I am getting the following error:

 

<stdin>:14: PGRES_FATAL_ERROR load '$libdir/xxid';  - ERROR:
incompatible library "/usr/lib/pgsql/xxid.so": missing magic block

HINT:  Extension libraries are required to use the PG_MODULE_MAGIC
macro.

<stdin>:14: Error: the extension for the xxid data type cannot be loaded
in database 'dbname=hdap host=10.0.100.234 port=6543 user=myuser
password=mp'

 

 

Is this mean that Slony can not replicate into a newer postgres version?

If it does, then how do I fix this problem?

 

Thanks for your help,

 

Tony Fernandez

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20081112/433f5094/attachment.htm
From carlos.alarcon at tyven.com  Thu Nov 13 01:05:58 2008
From: carlos.alarcon at tyven.com (Carlos Alarcon)
Date: Thu Nov 13 01:06:33 2008
Subject: [Slony1-general] Problem on Failover 
In-Reply-To: <1488C04358A2473A93B6FA9E1B3307F2@TYVENLAPTOP10>
References: <1488C04358A2473A93B6FA9E1B3307F2@TYVENLAPTOP10>
Message-ID: <D2A1A42732934718A41CE39B8BBEA746@TYVENLAPTOP10>

Hi I am repeating the email but reordering Info just in case it was not
clear:

 =


Slony version: 2.0.0. RC1, postgresql-8.3.3

I am having the following when trying to do a failover and drop node in a 2
nodes setup (failover from 1, master into 2 slave):

[root@vox-asterisk02 ~]# ./promote.sh

<stdin>:6: NOTICE:  failedNode: set 1 has no other direct receivers - move
now

<stdin>:6: NOTICE:  failedNode: set 2 has no other direct receivers - move
now

<stdin>:6: NOTICE:  failedNode: set 3 has no other direct receivers - move
now

<stdin>:6: PGRES_FATAL_ERROR select
"_monkey_cluster".failedNode2(1,2,1,'45','46');  - ERROR:  INSERT has more
expressions than target columns

CONTEXT:  SQL statement "INSERT INTO "_monkey_cluster".sl_event (ev_origin,
ev_seqno, ev_timestamp, ev_snapshot, ev_type, ev_data1, ev_data2, ev_data3,
ev_data4) values ( $1 ,
"pg_catalog".nextval('"_monkey_cluster".sl_event_seq'), CURRENT_TIMESTAMP,
'0', '0', '0:0:', 'ACCEPT_SET',  $2 ::text,  $3 ::text,  $1 ::text,  $4
::text)"

PL/pgSQL function "failoverset_int" line 35 at SQL statement

SQL statement "SELECT  "_monkey_cluster".failoverSet_int( $1 ,  $2 ,  $3 ,
$4 )"

PL/pgSQL function "failednode2" line 39 at PERFORM

<stdin>:6: PGRES_FATAL_ERROR select
"_monkey_cluster".failedNode2(1,2,2,'45','47');  - ERROR:  current
transaction is aborted, commands ignored until end of transaction block

<stdin>:6: PGRES_FATAL_ERROR select
"_monkey_cluster".failedNode2(1,2,3,'45','48');  - ERROR:  current
transaction is aborted, commands ignored until end of transaction block

 =


The cluster setup is the following:

#!/bin/sh

export PATH=3D$PATH:/usr/local/pgsql/bin/

CLUSTER1=3Dmonkey_cluster

DB1=3Dpickmonkey

DB2=3Dpickmonkey2

 =


H1=3D192.168.10.73

H2=3D192.168.10.73

U=3Dpostgres

PASSWORD=3Dpostgres

 =


slonik <<_EOF_

cluster name=3D$CLUSTER1;

node 1 admin conninfo=3D'dbname=3D$DB1 host=3D$H1 user=3D$U password=3D$PAS=
SWORD';

node 2 admin conninfo=3D'dbname=3D$DB2 host=3D$H2 user=3D$U password=3D$PAS=
SWORD';

 =


init cluster (id=3D1, comment=3D'Production');

 =


#TABLE ORDER DATA

create set (id=3D1, origin=3D1, comment=3D'order table');

set add table (set id=3D1, origin=3D1, id=3D1, full qualified
name=3D'public.order_data', comment=3D'Table Order Data');

set add sequence (set id=3D1, origin=3D1, id=3D1, full qualified
name=3D'public.assrt_order_data_seq', comment=3D'Sequence
assrt_order_data_seq');

 =


#TABLE TRANSFER_MISSED_FILES

create set (id=3D2, origin=3D1, comment=3D'Transfer Missed Files table');

set add table (set id=3D2, origin=3D1, id=3D2, full qualified
name=3D'public.transfer_missed_files', comment=3D'Table transfer_missed_fil=
es');

set add sequence (set id=3D2, origin=3D1, id=3D2, full qualified
name=3D'public.assrt_transfer_files_seq', comment=3D'Sequence
assrt_transfer_files_seq');

 =


#BIG GROUP OF TABLES WITH FKs

create set (id=3D3, origin=3D1, comment=3D'The rest of tables');

set add table (set id=3D3, origin=3D1, id=3D3, full qualified
name=3D'public.address', comment=3D'Table address');

set add table (set id=3D3, origin=3D1, id=3D4, full qualified
name=3D'public.tel_number', comment=3D'Table tel_number');

set add table (set id=3D3, origin=3D1, id=3D5, full qualified
name=3D'public.country', comment=3D'Table country');

set add table (set id=3D3, origin=3D1, id=3D6, full qualified
name=3D'public.customer', comment=3D'Table customer');

set add table (set id=3D3, origin=3D1, id=3D7, full qualified
name=3D'public.zip_code', comment=3D'Table zip_code');

set add table (set id=3D3, origin=3D1, id=3D8, full qualified
name=3D'public.holiday', comment=3D'Table holiday');

set add table (set id=3D3, origin=3D1, id=3D9, full qualified name=3D'publi=
c.depot',
comment=3D'Table depot');

set add table (set id=3D3, origin=3D1, id=3D10, full qualified
name=3D'public.contact_centre', comment=3D'Table contact_centre');

 =


set add sequence (set id=3D3, origin=3D1, id=3D3, full qualified
name=3D'public.assrt_address_seq', comment=3D'Sequence assrt_address_seq');

set add sequence (set id=3D3, origin=3D1, id=3D4, full qualified
name=3D'public.assrt_tel_number_seq', comment=3D'Sequence
assrt_tel_number_seq');

set add sequence (set id=3D3, origin=3D1, id=3D5, full qualified
name=3D'public.assrt_country_seq', comment=3D'Sequence assrt_country_seq');

set add sequence (set id=3D3, origin=3D1, id=3D6, full qualified
name=3D'public.assrt_customer_seq', comment=3D'Sequence assrt_customer_seq'=
);

set add sequence (set id=3D3, origin=3D1, id=3D7, full qualified
name=3D'public.assrt_zip_code_seq', comment=3D'Sequence assrt_zip_code_seq'=
);

set add sequence (set id=3D3, origin=3D1, id=3D8, full qualified
name=3D'public.assrt_holiday_seq', comment=3D'Sequence assrt_holiday_seq');

set add sequence (set id=3D3, origin=3D1, id=3D9, full qualified
name=3D'public.assrt_depot_seq', comment=3D'Sequence assrt_depot_seq');

set add sequence (set id=3D3, origin=3D1, id=3D10, full qualified
name=3D'public.assrt_contact_centre_seq', comment=3D'Sequence
assrt_contact_centre_seq');

 =


store node (id=3D2, comment=3D'Backup', EVENT NODE=3D1);

store path (server=3D1, client=3D2, conninfo=3D'dbname=3D$DB1 host=3D$H1 us=
er=3D$U
password=3D$PASSWORD');

store path (server=3D2, client=3D1, conninfo=3D'dbname=3D$DB2 host=3D$H2 us=
er=3D$U
password=3D$PASSWORD');

store listen (origin=3D1, provider=3D1, receiver=3D2);

store listen (origin=3D2, provider=3D2, receiver=3D1);

_EOF_

 =


 =


the subscribe script:

#!/bin/sh

export PATH=3D$PATH:/usr/local/pgsql/bin/

CLUSTER1=3Dmonkey_cluster

DB1=3Dpickmonkey

DB2=3Dpickmonkey2

 =


H1=3D192.168.10.73

H2=3D192.168.10.73

U=3Dpostgres

PASSWORD=3Dpostgres

 =


 =


slonik <<_EOF_

 =


cluster name =3D $CLUSTER1;

 =


node 1 admin conninfo =3D 'dbname=3D$DB1 host=3D$H1 user=3D$U password=3D$P=
ASSWORD';

node 2 admin conninfo =3D 'dbname=3D$DB2 host=3D$H2 user=3D$U password=3D$P=
ASSWORD';

 =


subscribe set (id =3D 1, provider =3D 1, receiver =3D 2, forward =3D yes);

subscribe set (id =3D 2, provider =3D 1, receiver =3D 2, forward =3D yes);

subscribe set (id =3D 3, provider =3D 1, receiver =3D 2, forward =3D yes);

_EOF_

 =


and to promote:

 =


#!/bin/bash

#

#promote.sh

 =


export PATH=3D$PATH:/usr/local/pgsql/bin/

CLUSTER1=3Dmonkey_cluster

DB1=3Dpickmonkey

DB2=3Dpickmonkey2

 =


H1=3D192.168.10.73

H2=3D192.168.10.73

U=3Dpostgres

PASSWORD=3Dpostgres

 =


 =


 =


su - postgres -c /usr/local/pgsql/bin/slonik <<_EOF_

cluster name =3D $CLUSTER1;

 =


node 1 admin conninfo =3D 'dbname=3D$DB1 host=3D$H1 user=3D$U password=3D$P=
ASSWORD';

node 2 admin conninfo =3D 'dbname=3D$DB2 host=3D$H2 user=3D$U password=3D$P=
ASSWORD';

 =


failover (id =3D 1, backup node =3D 2);

drop node (id =3D 1, event node =3D 2);

_EOF_

 =


As far as I can see Postgres  is complaining about we are trying to insert
more values into .sl_event than the fields we tell postgress we wanna
filled. sl_event has even more fields than those.

Any Idea of what can be wrong?

 =


 =


 =


 =


 =


 =


-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20081113/=
48776768/attachment-0001.htm
From glynastill at yahoo.co.uk  Thu Nov 13 01:53:04 2008
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Thu Nov 13 01:53:35 2008
Subject: [Slony1-general] ERROR:  incompatible library
In-Reply-To: <925169557BAB6947A70CB145F894A75B70ABEE@mail-41ps.atlarge.net>
Message-ID: <561916.65311.qm@web23606.mail.ird.yahoo.com>


--- On Wed, 12/11/08, Tony Fernandez <Tony.Fernandez@vocalocity.com> wrote:

> Date: Wednesday, 12 November, 2008, 10:52 PM
> Hello lists,
> 
>  
> 
> I am trying to run Slony on a Master Postgres 8.1.11
> replicating to a
> Slave same version and 2nd Slave Postgres 8.3.4.

> 
> I am getting the following error:
> 
>  
> 
> <stdin>:14: PGRES_FATAL_ERROR load
> '$libdir/xxid';  - ERROR:
> incompatible library "/usr/lib/pgsql/xxid.so":
> missing magic block
> 
> HINT:  Extension libraries are required to use the
> PG_MODULE_MAGIC
> macro.
> 
> <stdin>:14: Error: the extension for the xxid data
> type cannot be loaded
> in database 'dbname=hdap host=10.0.100.234 port=6543
> user=myuser
> password=mp'

I think you've proabably built slony against one version of postgres and then tried to use it with another. You must build against 8.1.11 and then separately for 8.3.4, using the same version of slony ofcourse.


      
From k.mironov at drweb.com  Thu Nov 13 02:50:11 2008
From: k.mironov at drweb.com (kosm)
Date: Thu Nov 13 02:50:44 2008
Subject: [Slony1-general] Slony crash: realloc() - Cannot allocate memory
Message-ID: <20478497.post@talk.nabble.com>


Hello. Help me please. Slony crashed in the morning with error allocate
memory.
OS: FreeBSD 6.2
Hardware: Memory 4Gb, I try tuning shared memory from 16Mb up to 2Gb
PgSQL: Database size more 120Gb, shared_buffers = 16MB (increase up to
512Mb)

I do not know what to do, all has tried.

--- cutted more 71000 events queue
2008-11-13 12:55:39 MSK DEBUG2 remoteListenThread_2: queue event 2,1742400
SYNC
2008-11-13 12:55:39 MSK DEBUG2 remoteListenThread_2: queue event 2,1742401
SYNC
2008-11-13 12:55:39 MSK DEBUG2 remoteListenThread_2: queue event 2,1742402
SYNC
2008-11-13 12:55:39 MSK DEBUG2 remoteListenThread_2: queue event 2,1742403
SYNC
2008-11-13 12:55:39 MSK DEBUG2 remoteListenThread_2: queue event 2,1742404
SYNC
2008-11-13 12:55:39 MSK DEBUG2 remoteListenThread_2: queue event 2,1742405
SYNC
2008-11-13 12:55:39 MSK DEBUG2 remoteListenThread_2: queue event 2,1742406
SYNC
2008-11-13 12:55:39 MSK DEBUG2 remoteListenThread_2: queue event 2,1742407
SYNC
2008-11-13 12:55:39 MSK DEBUG2 remoteListenThread_2: queue event 2,1742408
SYNC
2008-11-13 12:55:40 MSK DEBUG2 localListenThread: Received event 1,734640
SYNC
2008-11-13 12:55:41 MSK FATAL  dstring_addchar: realloc() - Cannot allocate
memory
2008-11-13 12:55:41 MSK DEBUG2 slon_abort() from pid=84874
2008-11-13 12:55:41 MSK DEBUG1 slon: shutdown requested
2008-11-13 12:55:41 MSK DEBUG2 slon: notify worker process to shutdown

-- 
View this message in context: http://www.nabble.com/Slony-crash%3A-realloc%28%29---Cannot-allocate-memory-tp20478497p20478497.html
Sent from the Slony-I -- General mailing list archive at Nabble.com.

From tgl at sss.pgh.pa.us  Thu Nov 13 05:07:48 2008
From: tgl at sss.pgh.pa.us (Tom Lane)
Date: Thu Nov 13 05:07:52 2008
Subject: [Slony1-general] Re: [HACKERS] ERROR: incompatible library 
In-Reply-To: <925169557BAB6947A70CB145F894A75B70ABEE@mail-41ps.atlarge.net> 
References: <925169557BAB6947A70CB145F894A75B70ABEE@mail-41ps.atlarge.net>
Message-ID: <3608.1226581668@sss.pgh.pa.us>

"Tony Fernandez" <Tony.Fernandez@vocalocity.com> writes:
> I am getting the following error:

> <stdin>:14: PGRES_FATAL_ERROR load '$libdir/xxid';  - ERROR:
> incompatible library "/usr/lib/pgsql/xxid.so": missing magic block

You need a version of xxid.so that matches your server version, on
each server.

It might well also be that you need a newer version of Slony --- I would
not expect an 8.1-vintage release of Slony to work on 8.3.

			regards, tom lane
From romero.cl at gmail.com  Fri Nov 14 08:18:21 2008
From: romero.cl at gmail.com (Daniel Romero)
Date: Fri Nov 14 08:18:29 2008
Subject: [Slony1-general] Slony only Synchonizing
Message-ID: <79d095f60811140818q3dd0d3f2ue2413f17a2dbd8a2@mail.gmail.com>

Hi.

I have 3 nodes, 1 main and 2 direct replicas.

I can see my querys in the main node log, but node 2 and 3 are not receiving
any querys, only synch or "slony internal" querys.


Any ideas?


NODE 2 LOG EXAMPLE
LOG:  statement: start transaction;set transaction isolation level
serializable;select last_value from "_romeroCLT".sl_action_seq;
LOG:  statement: rollback transaction;
LOG:  statement: start transaction; set transaction isolation level
serializable;
LOG:  statement: select ev_seqno, ev_timestamp,        ev_minxid, ev_maxxid,
ev_xip,        ev_type,        ev_data1, ev_data2, ev_data3,
ev_data4,        ev_data5, ev_data6, ev_data7, ev_data8 from
"_romeroCLT".sl_event where  ev_origin =3D '2'        and ev_seqno > '33'
order by ev_seqno
LOG:  statement: commit transaction
LOG:  statement: start transaction; set transaction isolation level
serializable;
LOG:  statement: select ev_seqno, ev_timestamp,        ev_minxid, ev_maxxid,
ev_xip,        ev_type,        ev_data1, ev_data2, ev_data3,
ev_data4,        ev_data5, ev_data6, ev_data7, ev_data8 from
"_romeroCLT".sl_event where  ev_origin =3D '2'        and ev_seqno > '34'
order by ev_seqno
LOG:  statement: rollback transaction;
LOG:  statement: start transaction;set transaction isolation level
serializable;select last_value from "_romeroCLT".sl_action_seq;
LOG:  statement: rollback transaction;
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20081114/=
791aa750/attachment.htm
From jennifer.spencer at stanford.edu  Fri Nov 14 12:51:13 2008
From: jennifer.spencer at stanford.edu (Jennifer Spencer)
Date: Fri Nov 14 12:51:27 2008
Subject: [Slony1-general] Slony only Synchonizing
In-Reply-To: <79d095f60811140818q3dd0d3f2ue2413f17a2dbd8a2@mail.gmail.com>
References: <79d095f60811140818q3dd0d3f2ue2413f17a2dbd8a2@mail.gmail.com>
Message-ID: <491DE4C1.1080303@stanford.edu>

It appears that you are only doing for "select" statements.  Are you expecting "select" to be done on 
your replicas?

Slony replicates data, not queries that only display existing data.

If you are doing inserts, updates or deletes of data on your main node, you should expect to see those 
changes on nodes 2 & 3.  Are you seeing any insert/update/delete activity done on node 1 showing up on 
nodes 2 & 3?

-Jennifer Spencer

Daniel Romero wrote:
> Hi.
> 
> I have 3 nodes, 1 main and 2 direct replicas.
> 
> I can see my querys in the main node log, but node 2 and 3 are not receiving
> any querys, only synch or "slony internal" querys.
> 
> 
> Any ideas?
> 
> 
> NODE 2 LOG EXAMPLE
> LOG:  statement: start transaction;set transaction isolation level
> serializable;select last_value from "_romeroCLT".sl_action_seq;
> LOG:  statement: rollback transaction;
> LOG:  statement: start transaction; set transaction isolation level
> serializable;
> LOG:  statement: select ev_seqno, ev_timestamp,        ev_minxid, ev_maxxid,
> ev_xip,        ev_type,        ev_data1, ev_data2, ev_data3,
> ev_data4,        ev_data5, ev_data6, ev_data7, ev_data8 from
> "_romeroCLT".sl_event where  ev_origin = '2'        and ev_seqno > '33'
> order by ev_seqno
> LOG:  statement: commit transaction
> LOG:  statement: start transaction; set transaction isolation level
> serializable;
> LOG:  statement: select ev_seqno, ev_timestamp,        ev_minxid, ev_maxxid,
> ev_xip,        ev_type,        ev_data1, ev_data2, ev_data3,
> ev_data4,        ev_data5, ev_data6, ev_data7, ev_data8 from
> "_romeroCLT".sl_event where  ev_origin = '2'        and ev_seqno > '34'
> order by ev_seqno
> LOG:  statement: rollback transaction;
> LOG:  statement: start transaction;set transaction isolation level
> serializable;select last_value from "_romeroCLT".sl_action_seq;
> LOG:  statement: rollback transaction;
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
From romero.cl at gmail.com  Mon Nov 17 07:29:12 2008
From: romero.cl at gmail.com (Daniel Romero)
Date: Mon Nov 17 07:29:20 2008
Subject: [Slony1-general] Slony only Synchonizing
In-Reply-To: <491DE4C1.1080303@stanford.edu>
References: <79d095f60811140818q3dd0d3f2ue2413f17a2dbd8a2@mail.gmail.com>
	<491DE4C1.1080303@stanford.edu>
Message-ID: <79d095f60811170729m2068fa69mebae3d7ea9cd6eb6@mail.gmail.com>

Hi.

Problem solved.

Cause: slonik_init_cluster is not generating the "STORE PATH" commands. Ej:
store path (server =3D 1, client =3D 2, conninfo=3D'dbname=3Dromero
host=3D192.168.xxx.194 user=3Dpostgres');

Solution: create a new missingCommand.sh script as follow:

#!/bin/sh

slonik <<_EOF_

cluster name =3D romeroCLT;
 node 1 admin conninfo=3D'host=3D192.168.xxx.194 dbname=3Dromero user=3Dpos=
tgres
port=3D5432';
 node 2 admin conninfo=3D'host=3D192.168.xxx.195 dbname=3Dromero user=3Dpos=
tgres
port=3D5432';
 node 3 admin conninfo=3D'host=3D192.168.xxx.196 dbname=3Dromero user=3Dpos=
tgres
port=3D5432';

# STORE PATH
  echo 'Next: configure paths for each node/origin';

  store path (server =3D 1, client =3D 2, conninfo=3D'dbname=3Dromero
host=3D192.168.xxx.194 user=3Dpostgres');
  store path (server =3D 1, client =3D 3, conninfo=3D'dbname=3Dromero
host=3D192.168.xxx.194 user=3Dpostgres');

  echo 'Replication nodes prepared';
  echo 'Please start a slon replication daemon for each node';

_EOF_

-- =

Regards,
Daniel Romero P.
NICLabs (www.niclabs.cl)

2008/11/14 Jennifer Spencer <jennifer.spencer@stanford.edu>

> It appears that you are only doing for "select" statements.  Are you
> expecting "select" to be done on your replicas?
>
> Slony replicates data, not queries that only display existing data.
>
> If you are doing inserts, updates or deletes of data on your main node, y=
ou
> should expect to see those changes on nodes 2 & 3.  Are you seeing any
> insert/update/delete activity done on node 1 showing up on nodes 2 & 3?
>
> -Jennifer Spencer
>
> Daniel Romero wrote:
>
>> Hi.
>>
>> I have 3 nodes, 1 main and 2 direct replicas.
>>
>> I can see my querys in the main node log, but node 2 and 3 are not
>> receiving
>> any querys, only synch or "slony internal" querys.
>>
>>
>> Any ideas?
>>
>>
>> NODE 2 LOG EXAMPLE
>> LOG:  statement: start transaction;set transaction isolation level
>> serializable;select last_value from "_romeroCLT".sl_action_seq;
>> LOG:  statement: rollback transaction;
>> LOG:  statement: start transaction; set transaction isolation level
>> serializable;
>> LOG:  statement: select ev_seqno, ev_timestamp,        ev_minxid,
>> ev_maxxid,
>> ev_xip,        ev_type,        ev_data1, ev_data2, ev_data3,
>> ev_data4,        ev_data5, ev_data6, ev_data7, ev_data8 from
>> "_romeroCLT".sl_event where  ev_origin =3D '2'        and ev_seqno > '33'
>> order by ev_seqno
>> LOG:  statement: commit transaction
>> LOG:  statement: start transaction; set transaction isolation level
>> serializable;
>> LOG:  statement: select ev_seqno, ev_timestamp,        ev_minxid,
>> ev_maxxid,
>> ev_xip,        ev_type,        ev_data1, ev_data2, ev_data3,
>> ev_data4,        ev_data5, ev_data6, ev_data7, ev_data8 from
>> "_romeroCLT".sl_event where  ev_origin =3D '2'        and ev_seqno > '34'
>> order by ev_seqno
>> LOG:  statement: rollback transaction;
>> LOG:  statement: start transaction;set transaction isolation level
>> serializable;select last_value from "_romeroCLT".sl_action_seq;
>> LOG:  statement: rollback transaction;
>>
>>
>>
>> ------------------------------------------------------------------------
>>
>> _______________________________________________
>> Slony1-general mailing list
>> Slony1-general@lists.slony.info
>> http://lists.slony.info/mailman/listinfo/slony1-general
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20081117/=
e474aa40/attachment.htm
From lists at serioustechnology.com  Tue Nov 18 07:29:26 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Tue Nov 18 07:29:32 2008
Subject: [Slony1-general] What mechanism actually causes replication?
In-Reply-To: <60r6bamglb.fsf@dba2.int.libertyrms.com>
References: <48496043.8060201@serioustechnology.com>
	<60r6bamglb.fsf@dba2.int.libertyrms.com>
Message-ID: <4922DF56.9020801@serioustechnology.com>

I am revisiting this issue as it seems I may have left something out of 
my slony solution.  Note from below we are trying to set the slony 
triggers to 'fire always' so that we can take advantage of 
session_replication_role.

That being said, I'm back to trying to figure out how I can be sure that 
I set the slony triggers to 'fire always' at the 'right time' so as to 
insure our replication is working.

As I understand it, we need the creation of the slony triggers and the 
setting of those triggers to 'fire always' to reside in the same 
transaction.

I hope that all makes sense, and I apologize for revisting this old 
issue.  I thought that I had addressed this concern in my scripts, but 
apparently that is not the case.

Thanks for any insight/assistance.


Christopher Browne wrote:
> Geoffrey <lists@serioustechnology.com> writes:
>> I can't seem to figure out what 'mechanism' actually causes
>> replication. That may be a too simplistic view of the whole process,
>> but the bottom line is, I have to make sure that our manipulation of
>> the 'session_replication_role' is going to properly address the issue
>> of insuring slony continues to replicate our data.
>>
>> Is it the '_pro_cluster_logtrigger_1' trigger in the NODE 1 Database
>> that is responsible for the actual replication process?
>>
>> That is, if I do the following:
>>
>> ALTER TABLE foo ENABLE ALWAYS TRIGGER _pro_cluster_logtrigger_1;
>>
>> I'm assuming that the replication will not be interrupted as this
>> trigger will always fire regardless of the 'session_replication_role'
>> setting.
>>
>> Another way of putting it is, is it the '*_logtrigger_1' trigger that
>> is added to replicated tables responsible (directly or indirectly) for
>> the actual replication of data.
>>
>> I say 'directly or indirectly' as I see that this trigger runs the
>> procedure _pro_cluster.logtrigger, and without looking into that
>> procedure mechanism, it's possible that it has a cascading effect that
>> ultimately effects the replication of data.
>>
>> Please understand, I realize our current approach is not the best
>> solution, but, I don't set the priorities and replication is higher on
>> the list, then changing the way our application works.
> 
> In a sense, it's *ALL* a big indirection.
> 
> Slony-I started by implementing an event management system, to get
> events propagating between the nodes.
> 
> Once you've got that, replicating data is a convenient side-effect
> :-).
> 
> Having replication working requires several things cooperating...
> 
> - The "logtrigger" triggers running on the origin collect data into
>   sl_log_*.
> 
> - You need to have a slon working against the origin, marking off SYNC
>   events every so often, which allows us to do incremental processing
>   of replication data.
> 
> - The slon process connected to the subscriber listens for SYNC
>   events, which tell it "Hey, we may have some new data for you!"
>   SYNC information allows the subscriber to identify which data to
>   look for in sl_log_*.
> 
> At the end of all that, you have replication.


-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From lists at serioustechnology.com  Tue Nov 18 07:32:58 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Tue Nov 18 07:33:03 2008
Subject: [Slony1-general] sl_status what does it mean?
Message-ID: <4922E02A.6000903@serioustechnology.com>

Can someone tell me what is meant by the following data from sl_status?

  st_origin | st_received | st_last_event |      st_last_event_ts      | 
st_last_received |    st_last_received_ts    | st_last_received_event_ts 
  | st_lag_num_events | st_lag_time
-----------+-------------+---------------+----------------------------+------------------+---------------------------+----------------------------+-------------------+-------------
          1 |           2 |         73226 | 11/18/2008 09:52:03.588658 | 
            73226 | 11/18/2008 09:54:45.17624 | 11/18/2008 
09:52:03.588658 |                 0 | @ 2.25 secs
(1 row)

That is, 'st_origin' == 1.  Does 1 indicate a particular status?  Same 
for 'st_received', what does the value 2 tell me?

Is 2.25 secs st_lag_time good?

Thanks for any info.

-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From jpfletch at ca.afilias.info  Tue Nov 18 08:59:29 2008
From: jpfletch at ca.afilias.info (JP Fletcher)
Date: Tue Nov 18 08:59:01 2008
Subject: [Slony1-general] sl_status what does it mean?
In-Reply-To: <4922E02A.6000903@serioustechnology.com>
References: <4922E02A.6000903@serioustechnology.com>
Message-ID: <4922F471.40203@ca.afilias.info>

The last event originating on node 1 was 73226.  The last event 
originating on node 1 that was received by node 2 was 73226.  Describe 
the view sl_status, and you'll see the way the lagtime is calculated.

Geoffrey wrote:
> Can someone tell me what is meant by the following data from sl_status?
>
>  st_origin | st_received | st_last_event |      st_last_event_ts      
> | st_last_received |    st_last_received_ts    | 
> st_last_received_event_ts  | st_lag_num_events | st_lag_time
> -----------+-------------+---------------+----------------------------+------------------+---------------------------+----------------------------+-------------------+------------- 
>
>          1 |           2 |         73226 | 11/18/2008 09:52:03.588658 
> |            73226 | 11/18/2008 09:54:45.17624 | 11/18/2008 
> 09:52:03.588658 |                 0 | @ 2.25 secs
> (1 row)
>
> That is, 'st_origin' == 1.  Does 1 indicate a particular status?  Same 
> for 'st_received', what does the value 2 tell me?
>
> Is 2.25 secs st_lag_time good?
>
> Thanks for any info.
>


-- 
JP Fletcher
Database Administrator
Afilias Canada
voice: 416.646.3304 ext. 4123
fax: 416.646.3305
mobile: 416.561.4763
jpfletch@ca.afilias.info


From stephane.schildknecht at postgresqlfr.org  Tue Nov 18 09:13:22 2008
From: stephane.schildknecht at postgresqlfr.org (=?ISO-8859-15?Q?=22St=E9phane_A=2E_Schildknecht=22?=)
Date: Tue Nov 18 09:14:02 2008
Subject: [Slony1-general] sl_status what does it mean?
In-Reply-To: <4922E02A.6000903@serioustechnology.com>
References: <4922E02A.6000903@serioustechnology.com>
Message-ID: <4922F7B2.4060300@postgresqlfr.org>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Geoffrey a ?crit :
> Can someone tell me what is meant by the following data from sl_status?
> 
>  st_origin | st_received | st_last_event |      st_last_event_ts      |
> st_last_received |    st_last_received_ts    | st_last_received_event_ts
>  | st_lag_num_events | st_lag_time
> -----------+-------------+---------------+----------------------------+------------------+---------------------------+----------------------------+-------------------+-------------
> 
>          1 |           2 |         73226 | 11/18/2008 09:52:03.588658 |
>            73226 | 11/18/2008 09:54:45.17624 | 11/18/2008
> 09:52:03.588658 |                 0 | @ 2.25 secs
> (1 row)
> 
> That is, 'st_origin' == 1.  Does 1 indicate a particular status?  Same
> for 'st_received', what does the value 2 tell me?
> 
> Is 2.25 secs st_lag_time good?
> 
> Thanks for any info.
> 

st_origin is the node that produced the sync event.
st_received is the node that received it.
st_last_event is the number of the last produced event (on st_origin).
st_last_event_ts is the timestamp when st_last_event was produced.
st_last_received is the number of the last sync st_received did receive (i.e.
the event it confirmed), event originated on st_origin.
st_last_received_ts is time of confirmation on receiver
st_last_received_event_ts is time of event received
st_lag_num_events is the difference between st_last_event and st_last_received.
st_lag_time is the difference between current time and st_last_event_ts.

Everything may be deduced from the vue definition :

SELECT e.ev_origin AS st_origin, c.con_received AS st_received, e.ev_seqno AS
st_last_event, e.ev_timestamp AS st_last_event_ts, c.con_seqno AS
st_last_received, c.con_timestamp AS st_last_received_ts, ce.ev_timestamp AS
st_last_received_event_ts, e.ev_seqno - c.con_seqno AS st_lag_num_events, now()
- - ce.ev_timestamp::timestamp with time zone AS st_lag_time
   FROM _rep.sl_event e, _rep.sl_confirm c, _rep.sl_event ce
  WHERE e.ev_origin = c.con_origin AND ce.ev_origin = e.ev_origin AND
ce.ev_seqno = c.con_seqno AND ((e.ev_origin, e.ev_seqno) IN ( SELECT
sl_event.ev_origin, max(sl_event.ev_seqno) AS max
           FROM _rep.sl_event
          WHERE sl_event.ev_origin = _rep.getlocalnodeid('_rep'::name)
          GROUP BY sl_event.ev_origin)) AND ((c.con_origin, c.con_received,
c.con_seqno) IN ( SELECT sl_confirm.con_origin, sl_confirm.con_received,
max(sl_confirm.con_seqno) AS max
           FROM _rep.sl_confirm
          WHERE sl_confirm.con_origin = _rep.getlocalnodeid('_rep'::name)
          GROUP BY sl_confirm.con_origin, sl_confirm.con_received));

Regards,
- --
St?phane Schildknecht
PostgreSQLFr - http://www.postgresql.fr
Dalibo - http://www.dalibo.com
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFJIveBA+REPKWGI0ERAjeEAJ0crNwk3fNpRIrqtq/zvoD9lBjZgQCgwTkK
afh/2nVdhO9uI9z5wjnfjaU=
=EOEw
-----END PGP SIGNATURE-----
From cbbrowne at ca.afilias.info  Tue Nov 18 12:08:48 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Nov 18 12:09:00 2008
Subject: [Slony1-general] What mechanism actually causes replication?
In-Reply-To: <4922DF56.9020801@serioustechnology.com> (Geoffrey's message of
	"Tue, 18 Nov 2008 10:29:26 -0500")
References: <48496043.8060201@serioustechnology.com>
	<60r6bamglb.fsf@dba2.int.libertyrms.com>
	<4922DF56.9020801@serioustechnology.com>
Message-ID: <87prksu78v.fsf@dba2.int.libertyrms.com>

Geoffrey <lists@serioustechnology.com> writes:
> I am revisiting this issue as it seems I may have left something out
> of my slony solution.  Note from below we are trying to set the slony
> triggers to 'fire always' so that we can take advantage of
> session_replication_role.

Note that this is only the case with Slony-I version 2.0, which hasn't
yet been officially released.  (We've had rc2; I should "bake" rc3
this afternoon so we can hopefully finalize 2.0.0 next week...)

With versions 1.0, 1.1, 1.2 (and sub-versions under that), it is
necessary to handle the "fire always" triggers via the slonik STORE
TRIGGER command (which disappears in v2.0).

So, if you're using the earlier versions of Slony-I, then
session_replication_role isn't of any use; it didn't exist then, so
isn't used in the earlier versions.

> That being said, I'm back to trying to figure out how I can be sure
> that I set the slony triggers to 'fire always' at the 'right time' so
> as to insure our replication is working.

> As I understand it, we need the creation of the slony triggers and the
> setting of those triggers to 'fire always' to reside in the same
> transaction.

Hmm.  Slony creates *its own* triggers inside the relevant
transaction, but that shouldn't be your concern (except insofar as
you'd expect it to handle its own internals properly!).

How you establish your own triggers is a function of more than just
the matter of in which transaction the triggers are created; it is
also affected by any other relevant initialization.

For instance, we have a custom trigger (well, several :-)) for
managing invalidation of an application cache; whenever updates take
place to relevant objects on the replica, the trigger causes the
management process to remove the invalidated data from the cache.

Whenever we "boot up" the cache manager, there's a brief period when
it's not totally consistent.  To get consistency, the initialization
process looks like:

    begin;
    truncate cache_manager_table, cache_contents;
    commit;

(Actually, Ops don't usually do it quite that way, but this *would* be
a good way to do it...)

If whatever it is that your triggers are managing has some more
sophisticated state, then your process to "make it consistent" may be
more complex.

If the "make it consistent" process is looking exceedingly
expensive/complex, then that may be a sign that you're doing something
not-entirely-wise.

But note that in that "initialization" process, I didn't do anything
about defining the triggers.  For our purposes, having an out-of-date
cache for a few minutes isn't disastrous.  

- On the one hand, the condition is unlikely to ever be noticed during
  the interim period during which it's a *little* broken.  

- And on the other hand, truncating the cached data cleans it up
  perfectly well.

Your milage may vary.  Mind you, if it varies by a LOT, I'd question
whether triggers are a good choice for the application.

Oracle Magazine had a pretty good article recently on the use and
abuse of triggers.  It has some good good questions worth asking one's
self.
<http://www.oracle.com/technology/oramag/oracle/08-sep/o58asktom.html>

"Some people, when confronted with a problem, think 'I know, I'll use
 regular expressions.'  Now they have two problems."
        -- Jamie Zawinski, on comp.lang.emacs

That is the traditional attribution of that quote.  I have also heard
it used as:
  'I know, I'll use sed.'  Now they have two problems.

I think it works pretty well for:
  'I know, I'll use triggers.'  Now they have two problems.

:-)
-- 
"cbbrowne","@","acm.org"
http://cbbrowne.com/info/advocacy.html
Send  messages calling for fonts  not  available to the  recipient(s).
This can (in the case of Zmail) totally disable the user's machine and
mail system for up to a whole day in some circumstances.
-- from the Symbolics Guidelines for Sending Mail
From cbbrowne at ca.afilias.info  Tue Nov 18 12:19:51 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Nov 18 12:20:03 2008
Subject: [Slony1-general] sl_status what does it mean?
In-Reply-To: <4922E02A.6000903@serioustechnology.com> (Geoffrey's message of
	"Tue, 18 Nov 2008 10:32:58 -0500")
References: <4922E02A.6000903@serioustechnology.com>
Message-ID: <87k5b0u6qg.fsf@dba2.int.libertyrms.com>

Geoffrey <lists@serioustechnology.com> writes:
> Can someone tell me what is meant by the following data from sl_status?
>
>  st_origin | st_received | st_last_event |      st_last_event_ts
> | st_last_received |    st_last_received_ts    |
> st_last_received_event_ts | st_lag_num_events | st_lag_time
> -----------+-------------+---------------+----------------------------+------------------+---------------------------+----------------------------+-------------------+-------------
>          1 |           2 |         73226 | 11/18/2008 09:52:03.588658
> |          73226 | 11/18/2008 09:54:45.17624 | 11/18/2008
> 09:52:03.588658 |                 0 | @ 2.25 secs
> (1 row)
>
> That is, 'st_origin' == 1.  Does 1 indicate a particular status?  Same
> for 'st_received', what does the value 2 tell me?
>
> Is 2.25 secs st_lag_time good?
>
> Thanks for any info.

As per the documentation...


   This view shows the local nodes last event sequence number and how
   far all remote nodes have processed events.

- st_origin is the ID of the origin node for events, and will always
  be the node ID of the node where this query is being run.

- st_received is the ID of the subscriber node.

- st_last_event indicates what is the last event processed on the
  subscriber.

- st_last_event_ts indicates the date that event was generated (which
  will be somewhat in the past)

You can look in src/backend/slony1_funcs.sql to see more details about
how the data is derived.

If the subscriber is lagging by 0 events (as is the case in the
example), then the subscriber is clearly keeping up well.

st_lag_time indicates how far back events are lagging, and it is quite
likely that 2.25s is pretty reasonable.  There are three scenarios
that seem interesting, offhand:

1.  If updates are going in on the origin more or less continually,
then lag time will likely be pretty low, as long as replication is
keeping up.

2.  If the origin sees long periods where there are no updates, lag
time could get pretty high, but you may still be in a position of
having no "lagging events."

That's what I see in your example.

3.  It could be that there's a lot of load, and that replication is
lagging behind.  In *that* case, you'll see the event number lag go up
(e.g. - st_lag_num_events), as well as lag time (st_lag_time).

That's not what I see in your example.
-- 
select 'cbbrowne' || '@' || 'linuxfinances.info';
http://www3.sympatico.ca/cbbrowne/sgml.html
"How should I know if it  works?  That's what beta testers are for.  I
only  coded  it."   (Attributed  to  Linus Torvalds,  somewhere  in  a
posting)
From lists at serioustechnology.com  Tue Nov 18 12:40:58 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Tue Nov 18 12:41:12 2008
Subject: [Slony1-general] What mechanism actually causes replication?
In-Reply-To: <87prksu78v.fsf@dba2.int.libertyrms.com>
References: <48496043.8060201@serioustechnology.com>	<60r6bamglb.fsf@dba2.int.libertyrms.com>	<4922DF56.9020801@serioustechnology.com>
	<87prksu78v.fsf@dba2.int.libertyrms.com>
Message-ID: <4923285A.8080705@serioustechnology.com>

Christopher Browne wrote:
> Geoffrey <lists@serioustechnology.com> writes:
>> I am revisiting this issue as it seems I may have left something out
>> of my slony solution.  Note from below we are trying to set the slony
>> triggers to 'fire always' so that we can take advantage of
>> session_replication_role.
> 
> Note that this is only the case with Slony-I version 2.0, which hasn't
> yet been officially released.  (We've had rc2; I should "bake" rc3
> this afternoon so we can hopefully finalize 2.0.0 next week...)
> 
> With versions 1.0, 1.1, 1.2 (and sub-versions under that), it is
> necessary to handle the "fire always" triggers via the slonik STORE
> TRIGGER command (which disappears in v2.0).
> 
> So, if you're using the earlier versions of Slony-I, then
> session_replication_role isn't of any use; it didn't exist then, so
> isn't used in the earlier versions.

So, I'm confused, but that's easy to do.  Are you saying that in the 
version of slony we are using (1.2.14), that session_replication_role 
does not exist, and therefore by trying to use that functionality within 
our code, we are not accomplishing what we are trying to do?

The underlying issue here is that we have a process that transfers data 
from many databases to a master database on a regular basis.  In order 
to accomplish this, this process does:

  $rvalue = session_role ($conn[$x], "session","replica");

With the intent of turning off all triggers except for those that are 
set to 'enable always'?

-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From dba at richyen.com  Tue Nov 18 14:04:55 2008
From: dba at richyen.com (Richard Yen)
Date: Tue Nov 18 14:05:25 2008
Subject: [Slony1-general] Do finishTableAfterCopy and ANALYZE need to be
	serialized with data copy?
Message-ID: <77A47D34-7021-4A12-8D56-4ECA8E3BB565@richyen.com>

Hello,

This might be moot with the coming release of Slony 2.0.0, but I was  
wondering if there are any thoughts about the following question:

Do the finishTableAfterCopy() and ANALYZE of each table need to happen  
in serial with the data copy from stdin?  i.e., can we create a new  
thread that will do these two things while slon proceeds to copy the  
data of the next table?

I raise this question because for large data sets, I think the  
copy_set process time could be improved by 30-40% if we can split  
these two stages.  I have some large tables that take 30 min or so to  
copy, then another 15-20 min to finishTableAfterCopy() and ANALYZE.

Thought I'd throw this out to get some feedback, before I go and  
mangle code...any thoughts?
--Richard
From cbbrowne at ca.afilias.info  Tue Nov 18 14:08:22 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Nov 18 14:08:36 2008
Subject: [Slony1-general] What mechanism actually causes replication?
In-Reply-To: <4923285A.8080705@serioustechnology.com> (Geoffrey's message of
	"Tue, 18 Nov 2008 15:40:58 -0500")
References: <48496043.8060201@serioustechnology.com>
	<60r6bamglb.fsf@dba2.int.libertyrms.com>
	<4922DF56.9020801@serioustechnology.com>
	<87prksu78v.fsf@dba2.int.libertyrms.com>
	<4923285A.8080705@serioustechnology.com>
Message-ID: <87d4gsu1pl.fsf@dba2.int.libertyrms.com>

Geoffrey <lists@serioustechnology.com> writes:
> Christopher Browne wrote:
>> Geoffrey <lists@serioustechnology.com> writes:
>>> I am revisiting this issue as it seems I may have left something out
>>> of my slony solution.  Note from below we are trying to set the slony
>>> triggers to 'fire always' so that we can take advantage of
>>> session_replication_role.
>>
>> Note that this is only the case with Slony-I version 2.0, which hasn't
>> yet been officially released.  (We've had rc2; I should "bake" rc3
>> this afternoon so we can hopefully finalize 2.0.0 next week...)
>>
>> With versions 1.0, 1.1, 1.2 (and sub-versions under that), it is
>> necessary to handle the "fire always" triggers via the slonik STORE
>> TRIGGER command (which disappears in v2.0).
>>
>> So, if you're using the earlier versions of Slony-I, then
>> session_replication_role isn't of any use; it didn't exist then, so
>> isn't used in the earlier versions.
>
> So, I'm confused, but that's easy to do.  Are you saying that in the
> version of slony we are using (1.2.14), that session_replication_role
> does not exist, and therefore by trying to use that functionality
> within our code, we are not accomplishing what we are trying to do?

That's nearly it.

In the version of Slony that you are using, *Slony* does not use
session_replication_role, whether it exists in the PostgreSQL build or
not.

Everything that that you said following "therefore" is still true :-).

> The underlying issue here is that we have a process that transfers
> data from many databases to a master database on a regular basis.  In
> order to accomplish this, this process does:
>
>  $rvalue = session_role ($conn[$x], "session","replica");
>
> With the intent of turning off all triggers except for those that are
> set to 'enable always'?

This is what we might call a "temporal" confusion :-).

At present, when running Slony-I 1.2.anything,
session_replication_role is not used by Slony-I; it uses a pretty
gross hack to turn off triggers.  

Specifically, extracting from the function alterTableForReplication():

		-- ----
		-- Disable all existing triggers
		-- ----
		update "pg_catalog".pg_trigger
				set tgrelid = v_tab_row.indexrelid
				where tgrelid = v_tab_row.tab_reloid
				and not exists (
						select true from @NAMESPACE@.sl_table TAB,
								@NAMESPACE@.sl_trigger TRIG
								where TAB.tab_reloid = tgrelid
								and TAB.tab_id = TRIG.trig_tabid
								and TRIG.trig_tgname = tgname
					);

If you have a process that uses session_role to do something similar,
then your process will conflict with what Slony 1.2.14 (or earlier)
does.

What I'd expect to happen is that Slony will "hide" most triggers, as
shown, *irrespective* of what is done with session_role.

That's not "nice" behaviour, which is why Jan added the whole
"session_role" notion to PostgreSQL 8.3.

But Slony-I 1.2.14 doesn't use the nice new PostgreSQL feature,
because it needs to retain compatibility with versions 7.4, 8.0, 8.1,
and 8.2, which don't have session_role.

Slony-I version 2.0 will "play more nicely" as it uses session_role.
And I hope to have it released on Monday.  So, temporally, that answer
doesn't exist yet, but hopefully, next week, it becomes a new reality
:-).
-- 
(format nil "~S@~S" "cbbrowne" "linuxfinances.info")
http://cbbrowne.com/info/nonrdbms.html
"64-bit integers aren't silly.   For instance Bill Gates, of Microsoft
fame, is now worth more than  $4 billion.  You can't represent his net
worth in 32 bits in dollars, let alone cents."  -- Charlie Price
From cbbrowne at ca.afilias.info  Tue Nov 18 14:22:34 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Nov 18 14:22:49 2008
Subject: [Slony1-general] Do finishTableAfterCopy and ANALYZE need to be
	serialized with data copy?
In-Reply-To: <77A47D34-7021-4A12-8D56-4ECA8E3BB565@richyen.com> (Richard Yen's
	message of "Tue, 18 Nov 2008 14:04:55 -0800")
References: <77A47D34-7021-4A12-8D56-4ECA8E3BB565@richyen.com>
Message-ID: <8763mku11x.fsf@dba2.int.libertyrms.com>

Richard Yen <dba@richyen.com> writes:
> This might be moot with the coming release of Slony 2.0.0, but I was
> wondering if there are any thoughts about the following question:
>
> Do the finishTableAfterCopy() and ANALYZE of each table need to happen
> in serial with the data copy from stdin?  i.e., can we create a new
> thread that will do these two things while slon proceeds to copy the
> data of the next table?
>
> I raise this question because for large data sets, I think the
> copy_set process time could be improved by 30-40% if we can split
> these two stages.  I have some large tables that take 30 min or so to
> copy, then another 15-20 min to finishTableAfterCopy() and ANALYZE.
>
> Thought I'd throw this out to get some feedback, before I go and
> mangle code...any thoughts?

I don't think the point is moot; no, indeed, there is considerable
value to this idea.

Jan and I have been bouncing this one around for a while.  We took the
idea further in concept (if not the implementation!); the further
thought is to do this two steps cleverer than you describe...

  Step 1.  Allow as many extra connections as the administrator
  requests.

       Thus, we have a "number_of_finish_connections" parameter (which
       presumably has a better name than that), and throw the
       finishTableAfterCopy()/ANALYZE requests to a "connection pool."

       I'd expect this to have diminishing returns, and that the
       useful maximum would be around 4.

  Step 2.  Order the requests so as to maximize parallelism.

       Thus, we subscribe to tables in reverse order of their
       estimated size (pg_class.relpages should be a reasonable
       approximation).

       This means that we tend to push the bigger tables onto the
       "reindex queue" as early as possible in the subscription
       process.

Haven't had the Round Tuits to get to it; if you could provide the
beginnings of it, that would make it easier to find the (hopefully
fewer, if effort is shared!) hours of implementation effort.
-- 
select 'cbbrowne' || '@' || 'cbbrowne.com';
http://linuxdatabases.info/info/internet.html
As of next Monday, MACLISP will no longer support list structure.
Please downgrade your programs.
From kgorman at hi5.com  Tue Nov 18 14:48:28 2008
From: kgorman at hi5.com (Kenny Gorman)
Date: Tue Nov 18 14:48:47 2008
Subject: [Slony1-general] Do finishTableAfterCopy and ANALYZE need to be
	serialized with data copy?
In-Reply-To: <8763mku11x.fsf@dba2.int.libertyrms.com>
References: <77A47D34-7021-4A12-8D56-4ECA8E3BB565@richyen.com>
	<8763mku11x.fsf@dba2.int.libertyrms.com>
Message-ID: <1F66C91C-B4C5-4FAD-BE74-FF70186D1CFA@hi5.com>

> Richard Yen <dba@richyen.com> writes:
>> This might be moot with the coming release of Slony 2.0.0, but I was
>> wondering if there are any thoughts about the following question:
>>
>> Do the finishTableAfterCopy() and ANALYZE of each table need to  
>> happen
>> in serial with the data copy from stdin?  i.e., can we create a new
>> thread that will do these two things while slon proceeds to copy the
>> data of the next table?
>>
>> I raise this question because for large data sets, I think the
>> copy_set process time could be improved by 30-40% if we can split
>> these two stages.  I have some large tables that take 30 min or so to
>> copy, then another 15-20 min to finishTableAfterCopy() and ANALYZE.
>>
>>

> On Nov 18, 2008, at 2:22 PM, Christopher Browne wrote:
>>  Step 2.  Order the requests so as to maximize parallelism.
>>
>>       Thus, we subscribe to tables in reverse order of their
>>       estimated size (pg_class.relpages should be a reasonable
>>       approximation).
>>
>>       This means that we tend to push the bigger tables onto the
>>       "reindex queue" as early as possible in the subscription
>>       process.

We have this same request.  Essentially in our case we may or may not  
have anything reading the slave right away.  So simply providing an  
option of skipping the analyze would be nice.  This way we can have a  
separate process analyze as we feel appropriate (or auto).

Of course it would be very nice to be able to specify a level of  
parallelism for the COPY processes to run in as well. In many cases  
there is no benefit to running everything in serial.  By randomizing  
the tables being COPY'd, you stand a reasonable chance of all  
processes having about the same amount of work to do and the fastest  
completion time.  Of course you could employ a more elaborate  
algorithm based on size and get better balancing.

thx
Kenny Gorman
www.hi5.com
From cbbrowne at ca.afilias.info  Tue Nov 18 16:21:08 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Nov 18 16:21:27 2008
Subject: [Slony1-general] Do finishTableAfterCopy and ANALYZE need to be
	serialized with data copy?
In-Reply-To: <1F66C91C-B4C5-4FAD-BE74-FF70186D1CFA@hi5.com> (Kenny Gorman's
	message of "Tue, 18 Nov 2008 14:48:28 -0800")
References: <77A47D34-7021-4A12-8D56-4ECA8E3BB565@richyen.com>
	<8763mku11x.fsf@dba2.int.libertyrms.com>
	<1F66C91C-B4C5-4FAD-BE74-FF70186D1CFA@hi5.com>
Message-ID: <87od0csgzv.fsf@dba2.int.libertyrms.com>

Kenny Gorman <kgorman@hi5.com> writes:
> We have this same request.  Essentially in our case we may or may not
> have anything reading the slave right away.  So simply providing an
> option of skipping the analyze would be nice.  This way we can have a
> separate process analyze as we feel appropriate (or auto).

The ANALYZE is a complete red herring, here; if you've got a many-hour
subscription, it's not ANALYZE that is costly, it's the REINDEX.

> Of course it would be very nice to be able to specify a level of
> parallelism for the COPY processes to run in as well. In many cases
> there is no benefit to running everything in serial.  By randomizing
> the tables being COPY'd, you stand a reasonable chance of all
> processes having about the same amount of work to do and the fastest
> completion time.  Of course you could employ a more elaborate
> algorithm based on size and get better balancing.

We have frequently seen cases where the REINDEX takes longer, for
large tables, than the COPY, and I suspect that's frequently the case,
which implies that the "big win" comes from parallelizing index
regens.

I *love* seeing heuristics where random selection is the "winning
strategy," but I don't believe that this is the case here.  We can be
reasonably certain that the large tables are the ones that will take
longer to REINDEX, and that they are the ones that should be "queued
up" first.

This part of the patch is not elaborate; it changes just one line of
code:

RCS file: /home/cvsd/slony1/slony1-engine/src/slon/remote_worker.c,v
retrieving revision 1.176
diff -c -u -r1.176 remote_worker.c
cvs diff: conflicting specifications of output style
--- src/slon/remote_worker.c	29 Aug 2008 21:06:45 -0000	1.176
+++ src/slon/remote_worker.c	19 Nov 2008 00:19:55 -0000
@@ -2635,7 +2635,7 @@
 						"where T.tab_set = %d "
 						"    and T.tab_reloid = PGC.oid "
 						"    and PGC.relnamespace = PGN.oid "
-						"order by tab_id; ",
+						"order by PGC.relpages desc; ",
 						rtcfg_namespace,
 						rtcfg_namespace,
 						rtcfg_namespace,
-- 
(format nil "~S@~S" "cbbrowne" "linuxfinances.info")
http://www3.sympatico.ca/cbbrowne/rdbms.html
As of next Tuesday, ITS will be flushed in favor of TRSDOS 2.1.
Please kill yourself.
From dba at richyen.com  Tue Nov 18 16:25:33 2008
From: dba at richyen.com (Richard Yen)
Date: Tue Nov 18 16:25:53 2008
Subject: [Slony1-general] Do finishTableAfterCopy and ANALYZE need to be
	serialized with data copy?
In-Reply-To: <8763mku11x.fsf@dba2.int.libertyrms.com>
References: <77A47D34-7021-4A12-8D56-4ECA8E3BB565@richyen.com>
	<8763mku11x.fsf@dba2.int.libertyrms.com>
Message-ID: <D057B842-8052-406A-9468-C2500D19A9B4@richyen.com>

> Haven't had the Round Tuits to get to it; if you could provide the
> beginnings of it, that would make it easier to find the (hopefully
> fewer, if effort is shared!) hours of implementation effort.

Sounds great!  I'll try get to work on this and post whatever working  
changes I make.

--Richard
From kgorman at hi5.com  Tue Nov 18 16:36:52 2008
From: kgorman at hi5.com (Kenny Gorman)
Date: Tue Nov 18 16:37:15 2008
Subject: [Slony1-general] Do finishTableAfterCopy and ANALYZE need to be
	serialized with data copy?
In-Reply-To: <87od0csgzv.fsf@dba2.int.libertyrms.com>
References: <77A47D34-7021-4A12-8D56-4ECA8E3BB565@richyen.com>
	<8763mku11x.fsf@dba2.int.libertyrms.com>
	<1F66C91C-B4C5-4FAD-BE74-FF70186D1CFA@hi5.com>
	<87od0csgzv.fsf@dba2.int.libertyrms.com>
Message-ID: <EA12E702-86C8-479A-9FB8-503C7E8721EC@hi5.com>


On Nov 18, 2008, at 4:21 PM, Christopher Browne wrote:
>
> I *love* seeing heuristics where random selection is the "winning
> strategy," but I don't believe that this is the case here.  We can be
> reasonably certain that the large tables are the ones that will take
> longer to REINDEX, and that they are the ones that should be "queued
> up" first.

I was referring to making sure that each parallel process has about  
the same amount of work to do, and finishes at about the same time.   
Ordering by size won't do it unless you assign each worker process in  
round robin against the ordered set.  Perhaps thats your plan.

thx
Kenny Gorman
www.hi5.com
From lists at serioustechnology.com  Wed Nov 19 04:59:01 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Wed Nov 19 04:59:37 2008
Subject: [Slony1-general] What mechanism actually causes replication?
In-Reply-To: <87d4gsu1pl.fsf@dba2.int.libertyrms.com>
References: <48496043.8060201@serioustechnology.com>	<60r6bamglb.fsf@dba2.int.libertyrms.com>	<4922DF56.9020801@serioustechnology.com>	<87prksu78v.fsf@dba2.int.libertyrms.com>	<4923285A.8080705@serioustechnology.com>
	<87d4gsu1pl.fsf@dba2.int.libertyrms.com>
Message-ID: <49240D95.6020602@serioustechnology.com>

Christopher Browne wrote:
> Geoffrey <lists@serioustechnology.com> writes:

>> So, I'm confused, but that's easy to do.  Are you saying that in the
>> version of slony we are using (1.2.14), that session_replication_role
>> does not exist, and therefore by trying to use that functionality
>> within our code, we are not accomplishing what we are trying to do?
> 
> That's nearly it.
> 
> In the version of Slony that you are using, *Slony* does not use
> session_replication_role, whether it exists in the PostgreSQL build or
> not.

I'm not thinking straight here.  It doesn't really matter if Slony uses 
session_replication_role or not.  All we want to insure is that the 
Slony triggers that are in our 'producer' still fire when we turn off 
all the other triggers in our databases.

The key issue is how do we insure that the slony triggers are created 
and set to 'enable always' in the same transaction.

It would be possible, but a burden to set up slony and set the triggers 
manually to 'enable always' while restricting access to the databases. 
The optimal solution is to be able to set up slony and get replication 
running while our databases are active.  In particular, when we have a 
process running that routinely turns off all triggers (hence the need to 
set the slony triggers to 'enable always').

-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From JanWieck at Yahoo.com  Wed Nov 19 05:39:49 2008
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Wed Nov 19 05:39:56 2008
Subject: [Slony1-general] Set 2 not found in runtime configuration
In-Reply-To: <69CB30F4-B218-45F1-931F-A525EF021CA5@evryx.com>
References: <FB2CA7F7-92C8-4C3C-9A0E-6BBF98A44024@evryx.com>
	<69CB30F4-B218-45F1-931F-A525EF021CA5@evryx.com>
Message-ID: <49241725.7080208@Yahoo.com>

On 10/27/2008 2:04 PM, Michael Lorenz wrote:
> OK, so blowing away all of the records in sl_event *did* get  
> replication started again.
> 
> However, as I said in the original post, this is not something I want  
> to try in production.  Can anyone provide any information as to how to  
> get Slony back on track when replication gets messed up as I described  
> below?  Of particular use would be how to identify problem sl_event  
> records (if doing that is the best way).

The best way is not to mess it up like that.

The docs have been wrong about how to wait for a SUBSCRIBE SET. The 
trick is that subscribing to a set involves an event that is not 
generated by any slonik script, but by the sets Origin when it receives 
the SUBSCRIBE_SET event. That is the event to wait for. Another annoying 
detail is that WAIT FOR EVENT has a default timeout, and since 
subscribing can take a while, timeouts are bad. So assuming that set 1 
has Origin 1 and direct subscriber 2 with cascaded subscriber 3, the 
proper sequence of slonik commands to subscribe and merge another set is 
this:

     SUBSCRIBE SET (ID = 999, PROVIDER = 1, RECEIVER = 2);
     WAIT FOR EVENT (ORIGIN = 2, CONFIRMED = 1, WAIT ON = 1,
                     TIMEOUT = 0);
     SYNC (ID = 1);
     WAIT FOR EVENT (ORIGIN = 1, CONFIRMED = 2, WAIT ON = 1,
                     TIMEOUT = 0);

     SUBSCRIBE SET (ID = 999, PROVIDER = 2, RECEIVER = 3);
     WAIT FOR EVENT (ORIGIN = 3, CONFIRMED = 1, WAIT ON = 1,
                     TIMEOUT = 0);
     SYNC (ID=1);
     WAIT FOR EVENT (ORIGIN = 1, CONFIRMED = 3, WAIT ON = 1,
                     TIMEOUT = 0);
     MERGE SET ( ID = 1, ADD ID = 999, ORIGIN = 1 );

The WAIT after the SUBSCRIBE must wait until the SUBSCRIBE_SET has been 
processed by the Origin of the set, which means that the 
ENABLE_SUBSCRIPTION event has been created by the Origin. The following 
SYNC and WAIT then generate another event on the Origin which is known 
to slonik, and which it waits for to be processed by the new subscriber. 
When that is done, the subscriber not only has done the subscription 
itself but also the initial SYNC after that.


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From mark.hagger at m-spatial.com  Thu Nov 20 01:34:56 2008
From: mark.hagger at m-spatial.com (Mark Hagger)
Date: Thu Nov 20 01:35:26 2008
Subject: [Slony1-general] replication for multiple databases
Message-ID: <1227173696.22193.146.camel@giga.cambridge.m-spatial.com>

Apologies if this has been answered in the lists before, but I can't
seem to find any place or site that lets me directly search the archives
(a brute force "read the entire archives by hand" doesn't greatly appeal
to me...), google searches haven't really turned up anything useful
either.

If I want to replicate multiple databases from hostA to hostB does
anyone have any opinions/thoughts on using multiple clusters vs a single
cluster?  Somehow both approaches feel wrong in some way, but those
appear to be the 2 choices.

Regards,

Mark



________________________________________________________________________
This email has been scanned for all known viruses by the MessageLabs SkyScan service.
From JanWieck at Yahoo.com  Wed Nov 19 23:04:15 2008
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Thu Nov 20 04:52:08 2008
Subject: [Slony1-general] replication for multiple databases
In-Reply-To: <1227173696.22193.146.camel@giga.cambridge.m-spatial.com>
References: <1227173696.22193.146.camel@giga.cambridge.m-spatial.com>
Message-ID: <49250BEF.2040007@Yahoo.com>

On 11/20/2008 4:34 AM, Mark Hagger wrote:
> Apologies if this has been answered in the lists before, but I can't
> seem to find any place or site that lets me directly search the archives
> (a brute force "read the entire archives by hand" doesn't greatly appeal
> to me...), google searches haven't really turned up anything useful
> either.
> 
> If I want to replicate multiple databases from hostA to hostB does
> anyone have any opinions/thoughts on using multiple clusters vs a single
> cluster?  Somehow both approaches feel wrong in some way, but those
> appear to be the 2 choices.

I would tend to do it in separate clusters.

Even if they never exchange any data, all nodes in one cluster must have 
possible event paths to each other. Which means that the nodes exchange 
events for no reason at all, which leads to some unnecessary confirm 
traffic. Also, if one set of databases gets screwed up and they are a 
separate cluster, one can simply drop both databases and recreate a new 
cluster. If it all is one big cluster, one at least has to properly drop 
those nodes.

The only advantage of building one cluster seems to be that one hosts 
sl_status view may reveal that everything is humming fine.


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From dba at richyen.com  Thu Nov 20 17:00:59 2008
From: dba at richyen.com (Richard Yen)
Date: Thu Nov 20 17:01:21 2008
Subject: [Slony1-general] okay to drop listen entries?
Message-ID: <9D805E75-CF98-4B69-AD75-29441EF14DE6@richyen.com>

Hi,

Wondering if it's okay to drop listen entries (in an effort to sculpt  
my cluster).  I have a very small cluster that needs to replicate  
quickly, but there are 15 or so nodes, so all the cross talk across  
the network (sync_interval == 500) is generating a lot of load.

I know that in the past, STORE PATH was modified to imply a STORE  
LISTEN as well.  As a result, it looks like the sl_listen table  
contains entries for nodes that the local node doesn't need to listen  
to.  Furthermore, since the data set is very small (on the order of <  
100MB), we don't anticipate ever needing to fail over or switch  
provider.

Would doing DROP LISTEN on the "unnecessary" nodes create any  
undesirable side effects?

Thought I'd ask before trying to set up a development cluster of 4+  
machines...

Thanks for any tips!
--Richard
From skelton at apple.com  Fri Nov 21 09:48:34 2008
From: skelton at apple.com (Bruce Skelton)
Date: Fri Nov 21 09:48:44 2008
Subject: [Slony1-general] DONE/ERROR in log
Message-ID: <37B5404E-9AEE-4565-830D-16EB79281EC2@apple.com>

Do I need to be concerned about these entries in the log for the  
subscribing node.

2008-11-21 09:46:40 PST DEBUG4 remoteHelperThread_1_1: change helper  
thread status
2008-11-21 09:46:40 PST DEBUG4 remoteHelperThread_1_1: send DONE/ERROR  
line to worker
2008-11-21 09:46:40 PST DEBUG3 remoteHelperThread_1_1: waiting for  
workgroup to finish

The DONE/ERROR is what concerns me.

Bruce Skelton
Software Engineering Operations
cell     = 408.425.3658
office = 408.974.0049


-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20081121/05481df3/attachment.htm
From ajs at crankycanuck.ca  Fri Nov 21 10:07:17 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Fri Nov 21 10:07:28 2008
Subject: [Slony1-general] DONE/ERROR in log
In-Reply-To: <37B5404E-9AEE-4565-830D-16EB79281EC2@apple.com>
References: <37B5404E-9AEE-4565-830D-16EB79281EC2@apple.com>
Message-ID: <20081121180716.GC20618@shinkuro.com>

On Fri, Nov 21, 2008 at 09:48:34AM -0800, Bruce Skelton wrote:
> Do I need to be concerned about these entries in the log for the  
> subscribing node.
>
> 2008-11-21 09:46:40 PST DEBUG4 remoteHelperThread_1_1: change helper  
> thread status
> 2008-11-21 09:46:40 PST DEBUG4 remoteHelperThread_1_1: send DONE/ERROR  
> line to worker
> 2008-11-21 09:46:40 PST DEBUG3 remoteHelperThread_1_1: waiting for  
> workgroup to finish
>
> The DONE/ERROR is what concerns me.

DEBUG4 is pretty high.  I don't see an actual ERROR line here, so I
wouldn't be concerned.

A


-- 
Andrew Sullivan
ajs@crankycanuck.ca
From bnichols at ca.afilias.info  Fri Nov 21 11:40:33 2008
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Fri Nov 21 11:40:45 2008
Subject: [Slony1-general] okay to drop listen entries?
In-Reply-To: <9D805E75-CF98-4B69-AD75-29441EF14DE6@richyen.com>
References: <9D805E75-CF98-4B69-AD75-29441EF14DE6@richyen.com>
Message-ID: <1227296433.18990.79.camel@bnicholson-desktop>

On Thu, 2008-11-20 at 17:00 -0800, Richard Yen wrote:
> Hi,
> 
> Wondering if it's okay to drop listen entries (in an effort to sculpt  
> my cluster).  I have a very small cluster that needs to replicate  
> quickly, but there are 15 or so nodes, so all the cross talk across  
> the network (sync_interval == 500) is generating a lot of load.
> 
> I know that in the past, STORE PATH was modified to imply a STORE  
> LISTEN as well.  As a result, it looks like the sl_listen table  
> contains entries for nodes that the local node doesn't need to listen  
> to.  Furthermore, since the data set is very small (on the order of <  
> 100MB), we don't anticipate ever needing to fail over or switch  
> provider.
> 
> Would doing DROP LISTEN on the "unnecessary" nodes create any  
> undesirable side effects?

You should drop the uneeded paths.  The listen entries will be reshaped
accordingly.

-- 
?Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.

From cbbrowne at ca.afilias.info  Fri Nov 21 14:32:52 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri Nov 21 14:33:08 2008
Subject: [Slony1-general] DONE/ERROR in log
In-Reply-To: <37B5404E-9AEE-4565-830D-16EB79281EC2@apple.com> (Bruce Skelton's
	message of "Fri, 21 Nov 2008 09:48:34 -0800")
References: <37B5404E-9AEE-4565-830D-16EB79281EC2@apple.com>
Message-ID: <87tza0r9pn.fsf@dba2.int.libertyrms.com>

Bruce Skelton <skelton@apple.com> writes:
> Do I need to be concerned about these entries in the log for the subscribing node.
>
>
>
> 2008-11-21 09:46:40 PST DEBUG4 remoteHelperThread_1_1: change helper thread status
>
> 2008-11-21 09:46:40 PST DEBUG4 remoteHelperThread_1_1: send DONE/ERROR line to worker
>
> 2008-11-21 09:46:40 PST DEBUG3 remoteHelperThread_1_1: waiting for workgroup to finish
>
> ?
>
> The DONE/ERROR is what concerns me.

It is of type "DEBUG", so it is not indicating an error condition with
replication.

I think you probably have your debug levels turned up a little too
high; if you're seeing those messages, you'll be filling a lot of disk
space with logs...
-- 
output = ("cbbrowne" "@" "linuxfinances.info")
http://linuxdatabases.info/info/emacs.html
Next year in L5.
From cbbrowne at ca.afilias.info  Fri Nov 21 14:34:17 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri Nov 21 14:34:33 2008
Subject: [Slony1-general] okay to drop listen entries?
In-Reply-To: <1227296433.18990.79.camel@bnicholson-desktop> (Brad Nicholson's
	message of "Fri, 21 Nov 2008 14:40:33 -0500")
References: <9D805E75-CF98-4B69-AD75-29441EF14DE6@richyen.com>
	<1227296433.18990.79.camel@bnicholson-desktop>
Message-ID: <87prkor9na.fsf@dba2.int.libertyrms.com>

Brad Nicholson <bnichols@ca.afilias.info> writes:
> On Thu, 2008-11-20 at 17:00 -0800, Richard Yen wrote:
>> Hi,
>> 
>> Wondering if it's okay to drop listen entries (in an effort to sculpt  
>> my cluster).  I have a very small cluster that needs to replicate  
>> quickly, but there are 15 or so nodes, so all the cross talk across  
>> the network (sync_interval == 500) is generating a lot of load.
>> 
>> I know that in the past, STORE PATH was modified to imply a STORE  
>> LISTEN as well.  As a result, it looks like the sl_listen table  
>> contains entries for nodes that the local node doesn't need to listen  
>> to.  Furthermore, since the data set is very small (on the order of <  
>> 100MB), we don't anticipate ever needing to fail over or switch  
>> provider.
>> 
>> Would doing DROP LISTEN on the "unnecessary" nodes create any  
>> undesirable side effects?
>
> You should drop the uneeded paths.  The listen entries will be reshaped
> accordingly.

I mirror Brad's sentiment.

If you drop unnecessary paths (e.g. - run DROP PATH), *that* is the
better way to reduce the number of listen entries.
-- 
(reverse (concatenate 'string "ofni.sailifa.ac" "@" "enworbbc"))
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)
From dba at richyen.com  Fri Nov 21 15:59:44 2008
From: dba at richyen.com (Richard Yen)
Date: Fri Nov 21 16:00:07 2008
Subject: [Slony1-general] okay to drop listen entries?
In-Reply-To: <87prkor9na.fsf@dba2.int.libertyrms.com>
References: <9D805E75-CF98-4B69-AD75-29441EF14DE6@richyen.com>
	<1227296433.18990.79.camel@bnicholson-desktop>
	<87prkor9na.fsf@dba2.int.libertyrms.com>
Message-ID: <0825F7BB-ECD7-408E-83B4-68B18C5A5CDF@richyen.com>

>> You should drop the uneeded paths.  The listen entries will be  
>> reshaped
>> accordingly.
>
> I mirror Brad's sentiment.
>
> If you drop unnecessary paths (e.g. - run DROP PATH), *that* is the
> better way to reduce the number of listen entries.

Thanks for the tip!  All the machines in my cluster are breathing  
easier now--lower network traffic and less load on CPUs...

--Richard
From cbbrowne at ca.afilias.info  Mon Nov 24 19:53:56 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Nov 24 19:54:21 2008
Subject: [Slony1-general] Version 2.0.0 released
Message-ID: <87hc5wpijv.fsf@dba2.int.libertyrms.com>

We are pleased to make a new major release of Slony-I available,
version 2.0.0.

It incorporates numerous enhancements and bug fixes contributed over
the last year or so.

A *major* change is that it is only compatible with PostgreSQL 8.3 and
newer versions.  Several changes were introduced in 8.3 which allow
Slony-I to work in a much "cleaner" fashion.  It now interacts with
triggers and foreign keys in a clean way, which means you may now use
pg_dump against any replica node; replicas no longer have "corrupted"
system catalogues.

There are also numerous other enhancements; see the file RELEASE-2.0
in the release for more details.

Please visit http://slony.info to find the sources.
-- 
let name="cbbrowne" and tld="linuxfinances.info" in name ^ "@" ^ tld;;
http://www3.sympatico.ca/cbbrowne/advocacy.html
I think  it may be  possible to simplify  and condense the  content of
this thread somewhat:
 "GX is an ex-API.  It is no longer supported" - The Rest of Us
 "No it isn't.  It's just pining for the fjords!" - Lawson
-- Michael Paquette
From z-saito at guitar.ocn.ne.jp  Tue Nov 25 05:43:20 2008
From: z-saito at guitar.ocn.ne.jp (Hiroshi Saito)
Date: Tue Nov 25 05:43:25 2008
Subject: [Slony1-general] Version 2.0.0 released
References: <87hc5wpijv.fsf@dba2.int.libertyrms.com>
Message-ID: <592835A1F9DD41CE8C76DDD7BC707C8E@HIRO57887DE653>

Hi.

I proposed some problem solutions at the time of RC. =

However, One has leaked and the present release is a problem. =


1. Make error...

$ make
make[1]: Entering directory `/home/HIROSHI/slony1-2.0.0/src'
make[2]: Entering directory `/home/HIROSHI/slony1-2.0.0/src/parsestatements'
./test-scanner < /dev/null > emptytestresult.log
cmp ./emptytestresult.log emptytestresult.expected.win32
./test-scanner < ./test_sql.sql > test_sql.log
cmp ./test_sql.log ./test_sql.expected.win32
./test_sql.log ./test_sql.expected.win32 differ: char 2038, line 62
make[2]: *** [test] Error 1
make[2]: Leaving directory `/home/HIROSHI/slony1-2.0.0/src/parsestatements'
make[1]: *** [all] Error 2
make[1]: Leaving directory `/home/HIROSHI/slony1-2.0.0/src'
make: *** [all] Error 2

2. problem "#define HAVE_GETACTIVESNAPSHOT 1" on  pg8.3.5 =


I think that it is inadequate. ..

-----config/acx_libpq.m4-----
AC_EGREP_HEADER(GetActiveSnapshot,
        utils/snapmgr.h,
        [AC_MSG_RESULT(yes)
        AC_DEFINE(HAVE_GETACTIVESNAPSHOT)],
        AC_MSG_RESULT(no)
)

3. archive is not bz2 but a mere tar file.
http://main.slony.info/downloads/2.0/source/slony1-2.0.0.tar.bz2

P.S)
It seems that information had stopped in me?_? =


Regards,
Hiroshi Saito

----- Original Message ----- =

From: "Christopher Browne" <cbbrowne@ca.afilias.info>
To: "slony" <slony1-general@lists.slony.info>
Sent: Tuesday, November 25, 2008 12:53 PM
Subject: [Slony1-general] Version 2.0.0 released


> We are pleased to make a new major release of Slony-I available,
> version 2.0.0.
> =

> It incorporates numerous enhancements and bug fixes contributed over
> the last year or so.
> =

> A *major* change is that it is only compatible with PostgreSQL 8.3 and
> newer versions.  Several changes were introduced in 8.3 which allow
> Slony-I to work in a much "cleaner" fashion.  It now interacts with
> triggers and foreign keys in a clean way, which means you may now use
> pg_dump against any replica node; replicas no longer have "corrupted"
> system catalogues.
> =

> There are also numerous other enhancements; see the file RELEASE-2.0
> in the release for more details.
> =

> Please visit http://slony.info to find the sources.
> -- =

> let name=3D"cbbrowne" and tld=3D"linuxfinances.info" in name ^ "@" ^ tld;;
> http://www3.sympatico.ca/cbbrowne/advocacy.html
> I think  it may be  possible to simplify  and condense the  content of
> this thread somewhat:
> "GX is an ex-API.  It is no longer supported" - The Rest of Us
> "No it isn't.  It's just pining for the fjords!" - Lawson
> -- Michael Paquette
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
-------------- next part --------------
A non-text attachment was scrubbed...
Name: win32_patch
Type: application/octet-stream
Size: 1209 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20081125=
/22f66dd1/win32_patch.obj
-------------- next part --------------
make[1]: Entering directory `/home/HIROSHI/slony1-2.0.0/src'
make[2]: Entering directory `/home/HIROSHI/slony1-2.0.0/src/parsestatements'
./test-scanner < /dev/null > emptytestresult.log
cmp ./emptytestresult.log emptytestresult.expected.win32
./test-scanner < ./test_sql.sql > test_sql.log
cmp ./test_sql.log ./test_sql.expected.win32
./test-scanner < ./cstylecomments.sql > cstylecomments.log
cmp ./cstylecomments.log ./cstylecomments.expected.win32
make[2]: Leaving directory `/home/HIROSHI/slony1-2.0.0/src/parsestatements'
make[2]: Entering directory `/home/HIROSHI/slony1-2.0.0/src/slon'
sed -e 's;FILEDESC;"Slony replication engine";' -e 's;VFT_APP;VFT_APP;' -e =
's;SLVERSION;SLONY_I_VERSION_STRING_DEC ,'`date '+%y%j' | sed 's/^0*//'`';'=
 ../../src/slon/port/win32ver.rc.in > win32ver.rc
windres -i win32ver.rc -o win32ver.o --include-dir=3D../..
rm -f win32ver.rc
gcc -g -O2 -Wall -Wmissing-prototypes -Wmissing-declarations  -I../.. -I../=
../src/slon -o slon.exe slon.o runtime_config.o local_listen.o remote_liste=
n.o remote_worker.o sync_thread.o cleanup_thread.o scheduler.o dbutils.o co=
nf-file.o confoptions.o misc.o ../parsestatements/scanner.o port/pipe.o por=
t/win32service.o win32ver.o  -lpgport -L/usr/local/pgsql/lib -L/usr/local/p=
gsql/lib -lpq  -lpthreadgc2 -lwsock32
make[2]: Leaving directory `/home/HIROSHI/slony1-2.0.0/src/slon'
make[2]: Entering directory `/home/HIROSHI/slony1-2.0.0/src/slonik'
sed -e 's;FILEDESC;"Slony command interpreter";' -e 's;VFT_APP;VFT_APP;' -e=
 's;SLVERSION;SLONY_I_VERSION_STRING_DEC ,'`date '+%y%j' | sed 's/^0*//'`';=
' ../../src/slon/port/win32ver.rc.in > win32ver.rc
windres -i win32ver.rc -o win32ver.o --include-dir=3D../..
rm -f win32ver.rc
gcc -g -O2 -Wall -Wmissing-prototypes -Wmissing-declarations -I../.. -DPGSH=
ARE=3D"\"/usr/local/pgsql/share\""  slonik.o dbutil.o parser.o win32ver.o .=
./parsestatements/scanner.o -lpgport -L/usr/local/pgsql/lib -L/usr/local/pg=
sql/lib -lpq  -o slonik.exe
make[2]: Leaving directory `/home/HIROSHI/slony1-2.0.0/src/slonik'
make[2]: Entering directory `/home/HIROSHI/slony1-2.0.0/src/backend'
gcc -g -O2 -Wall -Wmissing-prototypes -Wmissing-declarations -I../..  -I/us=
r/local/pgsql/include -I/usr/local/pgsql/include/server  -I/usr/local/pgsql=
/include/server/port/win32  -c -o slony1_funcs.o slony1_funcs.c
In file included from C:/MinGW/local/pgsql/include/server/utils/snapmgr.h:1=
6,
                 from slony1_funcs.c:32:
C:/MinGW/local/pgsql/include/server/utils/snapshot.h:20: error: redefinitio=
n of typedef 'Snapshot'
C:/MinGW/local/pgsql/include/server/utils/tqual.h:28: error: previous decla=
ration of 'Snapshot' was here
C:/MinGW/local/pgsql/include/server/utils/snapshot.h:31: error: redefinitio=
n of typedef 'SnapshotSatisfiesFunc'
C:/MinGW/local/pgsql/include/server/utils/tqual.h:31: error: previous decla=
ration of 'SnapshotSatisfiesFunc' was here
C:/MinGW/local/pgsql/include/server/utils/snapshot.h:34: error: redefinitio=
n of `struct SnapshotData'
C:/MinGW/local/pgsql/include/server/utils/snapshot.h:63: error: redefinitio=
n of typedef 'SnapshotData'
C:/MinGW/local/pgsql/include/server/utils/tqual.h:60: error: previous decla=
ration of 'SnapshotData' was here
C:/MinGW/local/pgsql/include/server/utils/snapshot.h:71: error: redeclarati=
on of enumerator `HeapTupleMayBeUpdated'
C:/MinGW/local/pgsql/include/server/utils/tqual.h:112: error: previous defi=
nition of 'HeapTupleMayBeUpdated' was here
C:/MinGW/local/pgsql/include/server/utils/snapshot.h:72: error: redeclarati=
on of enumerator `HeapTupleInvisible'
C:/MinGW/local/pgsql/include/server/utils/tqual.h:113: error: previous defi=
nition of 'HeapTupleInvisible' was here
C:/MinGW/local/pgsql/include/server/utils/snapshot.h:73: error: redeclarati=
on of enumerator `HeapTupleSelfUpdated'
C:/MinGW/local/pgsql/include/server/utils/tqual.h:114: error: previous defi=
nition of 'HeapTupleSelfUpdated' was here
C:/MinGW/local/pgsql/include/server/utils/snapshot.h:74: error: redeclarati=
on of enumerator `HeapTupleUpdated'
C:/MinGW/local/pgsql/include/server/utils/tqual.h:115: error: previous defi=
nition of 'HeapTupleUpdated' was here
C:/MinGW/local/pgsql/include/server/utils/snapshot.h:76: error: redeclarati=
on of enumerator `HeapTupleBeingUpdated'
C:/MinGW/local/pgsql/include/server/utils/tqual.h:117: error: previous defi=
nition of 'HeapTupleBeingUpdated' was here
C:/MinGW/local/pgsql/include/server/utils/snapshot.h:76: error: conflicting=
 types for 'HTSU_Result'
C:/MinGW/local/pgsql/include/server/utils/tqual.h:117: error: previous decl=
aration of 'HTSU_Result' was here
make[2]: *** [slony1_funcs.o] Error 1
make[2]: Leaving directory `/home/HIROSHI/slony1-2.0.0/src/backend'
make[1]: *** [all] Error 2
make[1]: Leaving directory `/home/HIROSHI/slony1-2.0.0/src'
make: *** [all] Error 2
From salmanb at quietcaresystems.com  Tue Nov 25 09:27:47 2008
From: salmanb at quietcaresystems.com (salman)
Date: Tue Nov 25 09:27:57 2008
Subject: [Slony1-general] slony upgrade error: "could not open file
	/usr/share/slony1_funcs.sql"
Message-ID: <492C3593.9000507@quietcaresystems.com>

Hello,

While attempting to upgrade to 2.0, I'm getting this error when running 
slonik_update_nodes. Can I simply symlink the first .sql (see below) 
file into usr/share to get around this?

I see the file at the following locations:
/usr/src/slony1-2.0.0/src/backend/slony1_funcs.sql (md5: 
5c47555b5e2ae556ed6958a4d5f9bfa2)
/usr/local/postgresql/8.3.1/share/slony1_funcs.sql (md5: 
538bc6f60dda20fcde704a673f89afbe)

pg_config output is as follows:
BINDIR = /usr/local/postgresql/8.3.1/bin
DOCDIR = /usr/local/postgresql/8.3.1/doc
INCLUDEDIR = /usr/local/postgresql/8.3.1/include
PKGINCLUDEDIR = /usr/local/postgresql/8.3.1/include
INCLUDEDIR-SERVER = /usr/local/postgresql/8.3.1/include/server
LIBDIR = /usr/local/postgresql/8.3.1/lib
PKGLIBDIR = /usr/local/postgresql/8.3.1/lib
LOCALEDIR =
MANDIR = /usr/local/postgresql/8.3.1/man
SHAREDIR = /usr/local/postgresql/8.3.1/share
SYSCONFDIR = /usr/local/postgresql/8.3.1/etc
PGXS = /usr/local/postgresql/8.3.1/lib/pgxs/src/makefiles/pgxs.mk
CONFIGURE = '--prefix=/usr/local/postgresql/8.3.1' '--with-python' 
'--with-perl' '--enable-thread-safety' '--enable-depend' '--with-openssl'
CC = gcc
CPPFLAGS = -D_GNU_SOURCE
CFLAGS = -O2 -Wall -Wmissing-prototypes -Wpointer-arith -Winline 
-Wdeclaration-after-statement -Wendif-labels -fno-strict-aliasing -fwrapv
CFLAGS_SL = -fpic
LDFLAGS = -Wl,-rpath,'/usr/local/postgresql/8.3.1/lib'
LDFLAGS_SL =
LIBS = -lpgport -lssl -lcrypto -lz -lreadline -ltermcap -lcrypt -ldl -lm
VERSION = PostgreSQL 8.3.1

slony config string:
./configure --prefix=/usr --sysconfdir=/etc/slony --with-perltools 
--with-pgconfigdir=/usr/local/postgresql/current/bin/

-salman
From salmanb at quietcaresystems.com  Tue Nov 25 15:42:39 2008
From: salmanb at quietcaresystems.com (salman)
Date: Tue Nov 25 15:42:58 2008
Subject: [Slony1-general] Re: slony upgrade error: "could not open file
	/usr/share/slony1_funcs.sql"
In-Reply-To: <492C3593.9000507@quietcaresystems.com>
References: <492C3593.9000507@quietcaresystems.com>
Message-ID: <492C8D6F.7070304@quietcaresystems.com>

salman wrote:
> Hello,
>
> While attempting to upgrade to 2.0, I'm getting this error when 
> running slonik_update_nodes. Can I simply symlink the first .sql (see 
> below) file into usr/share to get around this?
>
> I see the file at the following locations:
> /usr/src/slony1-2.0.0/src/backend/slony1_funcs.sql (md5: 
> 5c47555b5e2ae556ed6958a4d5f9bfa2)
> /usr/local/postgresql/8.3.1/share/slony1_funcs.sql (md5: 
> 538bc6f60dda20fcde704a673f89afbe)
>
> pg_config output is as follows:
> BINDIR = /usr/local/postgresql/8.3.1/bin
> DOCDIR = /usr/local/postgresql/8.3.1/doc
> INCLUDEDIR = /usr/local/postgresql/8.3.1/include
> PKGINCLUDEDIR = /usr/local/postgresql/8.3.1/include
> INCLUDEDIR-SERVER = /usr/local/postgresql/8.3.1/include/server
> LIBDIR = /usr/local/postgresql/8.3.1/lib
> PKGLIBDIR = /usr/local/postgresql/8.3.1/lib
> LOCALEDIR =
> MANDIR = /usr/local/postgresql/8.3.1/man
> SHAREDIR = /usr/local/postgresql/8.3.1/share
> SYSCONFDIR = /usr/local/postgresql/8.3.1/etc
> PGXS = /usr/local/postgresql/8.3.1/lib/pgxs/src/makefiles/pgxs.mk
> CONFIGURE = '--prefix=/usr/local/postgresql/8.3.1' '--with-python' 
> '--with-perl' '--enable-thread-safety' '--enable-depend' '--with-openssl'
> CC = gcc
> CPPFLAGS = -D_GNU_SOURCE
> CFLAGS = -O2 -Wall -Wmissing-prototypes -Wpointer-arith -Winline 
> -Wdeclaration-after-statement -Wendif-labels -fno-strict-aliasing -fwrapv
> CFLAGS_SL = -fpic
> LDFLAGS = -Wl,-rpath,'/usr/local/postgresql/8.3.1/lib'
> LDFLAGS_SL =
> LIBS = -lpgport -lssl -lcrypto -lz -lreadline -ltermcap -lcrypt -ldl -lm
> VERSION = PostgreSQL 8.3.1
>
> slony config string:
> ./configure --prefix=/usr --sysconfdir=/etc/slony --with-perltools 
> --with-pgconfigdir=/usr/local/postgresql/current/bin/
>
> -salman
>


Had to roll back to the previous version of slony as the attempted 
broken update was causing app errors on inserts. Just got around to 
trying the upgrade, again and ran into the same issue. For now I've just 
uninstalled slony and then did a re-init on the slave. However, even 
with that I ran into the following problems:

1) slonik was looking for slony1_funcs.sql file in usr/share instead of 
$PGSHAREDIR -- fixed by copying the .sql files in src/backend to 
usr/share/ and $PGSHAREDIR by hand.

2) slon_start wouldn't actually start a slon_daemon but also wouldn't 
show any error messages. Looking at the log file, I discovered that 
slon_start was attempting to start slon with the -d flag but was not 
passing any value. Fixed by adding $DEBUGLEVEL="0" into my slon_tools.conf

3) slon_watchdog would not start due to a missing ';' at the end of line 
46. Fixed by editing the file.

This is all on RHEL 5.1 and postgres-8.3.1

-salman
From remuscat at gmail.com  Thu Nov 27 02:33:51 2008
From: remuscat at gmail.com (=?ISO-8859-1?Q?Ren=E9-Etienne_Muscat?=)
Date: Thu Nov 27 02:34:25 2008
Subject: [Slony1-general] Slow Replication on a single cluster.
Message-ID: <46d2bc8f0811270233p5d966531m49255c1a366ffab9@mail.gmail.com>

Hi everyone, I have a problem with slony replicating slowly on a particular
cluster.
This problem came up after slony replication had stopped for a weekend and
this particular cluster (replication set) had a backlog of about 3million
rows (about 1.2million on sl_log1 and 1.8million on sl_log2).
After resuming slony replication (it had a problem with a table locks), all
the replication sets resumed normally (inserting over 15,000 rows per
batch), except for this particular set.
When I examined the log for this set on the slave, I saw a lot of SYNC
events, but few fetch/delivery events, and the inserts are just about
350rows each time.
I also noted that it was giving a lot of log switch failures ("log switch to
sl_log_1 still in progress - sl_log_2 not truncated").
I first tried stopping all replication and starting replication on this
problematic set, but still replication was slow (lots of SYNC events but
very few fetch/delivery events).
I also tried to resolve the issue by stopping all replication and vacuuming
the sl_logs, without any success.
Does anyone know why this is happening? Is this normal? Can I do somthing to
speed this up?

Rene
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20081127/=
da37a25a/attachment.htm
From dariusz.klimas at indigo.pl  Thu Nov 27 04:36:28 2008
From: dariusz.klimas at indigo.pl (darekk)
Date: Thu Nov 27 06:26:27 2008
Subject: [Slony1-general] slon_start and message: slony is already running
Message-ID: <20718552.post@talk.nabble.com>


hello.


i have a problem with launch slony-I on my linux ( debian ) servers.

when i make:

root@gazeta:/var/run/slony1# su - slony
slony@gazeta:~$ slon_start --config /etc/slony1/targeo-mobi.conf node2
Slon is already running for the 'replication_targeo_mobi' cluster.

and this message is on master and slave.
the log file for replication_targeo_mobi is not created by slony, and when i
list processes, the process for replication_targeo_mobi does not  exists

someone may have some idea of what may be a problem? 

the postgresql version 8.1.13
the slony-I version 1.2.1


Thanks,
Darek Klimas

-- 
View this message in context: http://www.nabble.com/slon_start-and-message%3A-slony-is-already-running-tp20718552p20718552.html
Sent from the Slony-I -- General mailing list archive at Nabble.com.

From msteben at autorevenue.com  Fri Nov 28 12:29:38 2008
From: msteben at autorevenue.com (Mark Steben)
Date: Fri Nov 28 12:28:59 2008
Subject: [Slony1-general] 32 BIT vs 64 BIT architecture
Message-ID: <DD68606B759A4E04AFD46BB8345E0903@dei26g028534>

Good afternoon

Quick question:  We have a master db server running linux redhat 32 bit
architecture.  Postgres version: 8.2

We plan to have a slave db server running linux redhat 64 bit architecture.
Also postgres version 8.2.

Can this work with Slony 1?

Thanks for your time 

Committed to Creating @utoEnthusiasts. Please provide us with your feedback.

________________________________

Mark Steben?Database Administrator? @utoRevenueT
95 Ashley Ave. West Springfield, MA., 01089 
413-243-4800 x1512 (Phone) ? 413-732-1824 (Fax)
A Division of Dominion Enterprises

 
 
 
 
 


From jeff at frostconsultingllc.com  Fri Nov 28 12:43:03 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Fri Nov 28 12:44:42 2008
Subject: [Slony1-general] 32 BIT vs 64 BIT architecture
In-Reply-To: <DD68606B759A4E04AFD46BB8345E0903@dei26g028534>
References: <DD68606B759A4E04AFD46BB8345E0903@dei26g028534>
Message-ID: <493057D7.1050107@frostconsultingllc.com>

Mark Steben wrote:
> Good afternoon
>
> Quick question:  We have a master db server running linux redhat 32 bit
> architecture.  Postgres version: 8.2
>
> We plan to have a slave db server running linux redhat 64 bit architecture.
> Also postgres version 8.2.
>
> Can this work with Slony 1?
>   
Mark, yes, this will work fine with Slony1.  You can also use a
different version of postgres on the various nodes allowing an upgrade
path that provides less downtime than the traditional dump/restore method.

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 916-647-6411	FAX: 916-405-4032

