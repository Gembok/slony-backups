From karl at denninger.net  Sun Aug  1 10:55:09 2010
From: karl at denninger.net (Karl Denninger)
Date: Sun, 01 Aug 2010 12:55:09 -0500
Subject: [Slony1-general] Eek Part II - No,
 SSL was not the entire problem (Replication COPY fails repeatedly)
Message-ID: <4C55B4FD.7040904@denninger.net>

So last night, if you remember my previous missive, I thought I had
found the issue with a big table copy having to do with Postgresql's SQL
support and went to bed with it running with SSL off.

Well, I was wrong, as I was treated to this morning after the thing ran
for more than four hours - probably about the amount of time required to
actually complete the job.  (It actually failed TWICE and restarted
overnight.)

Aug  1 06:32:25 dbms TICKER[77422]: [153-1] CONFIG remoteWorkerThread_3:
copy table "public"."images"
Aug  1 06:32:25 dbms TICKER[77422]: [154-1] CONFIG remoteWorkerThread_3:
Begin COPY of table "public"."images"
Aug  1 10:09:08 dbms TICKER[77422]: [155-1] ERROR  remoteWorkerThread_3:
copy from stdin on local node - PGRES_FATAL_ERROR server closed the
connection unexpectedly
Aug  1 10:09:08 dbms TICKER[77422]: [155-2]     This probably means the
server terminated abnormally
Aug  1 10:09:08 dbms TICKER[77422]: [155-3]     before or while
processing the request.
Aug  1 10:09:08 dbms TICKER[77422]: [156-1] WARN   remoteWorkerThread_3:
data copy for set 1 failed 1 times - sleep 15 seconds
Aug  1 10:09:08 dbms TICKER[77422]: [157] ERROR  remoteWorkerThread_3:
"rollback transaction" PGRES_FATAL_ERROR
Aug  1 10:09:08 dbms TICKER[72097]: [5-1] INFO   slon: retry requested
Aug  1 10:09:08 dbms TICKER[72097]: [6-1] INFO   slon: notify worker
process to shutdown

The problem is that I really don't have anything untoward in the
postgres log file this time, except for:

Aug  1 11:09:11 tickerforum postgres[39981]: [6-1] LOG:  unexpected EOF
on client connection
Aug  1 11:09:11 tickerforum postgres[38657]: [6-1] LOG:  unexpected EOF
on client connection
Aug  1 11:09:11 tickerforum postgres[39585]: [6-1] LOG:  unexpected EOF
on client connection
Aug  1 11:09:11 tickerforum postgres[39816]: [6-1] LOG:  unexpected EOF
on client connection
Aug  1 11:09:11 tickerforum postgres[39191]: [6-1] LOG:  unexpected EOF
on client connection

Those APPEAR, from the process IDs, to be the IDs of the SLONs that were
running at the time from the other side, implying that the server didn't
barf, SLONY did and dropped the connection without first saying goodbye.

The problem is that there is literally nothing in the SLON log above or
in the Postgres log implying a problem until the dump.

I had a core dump with a coincident time stamp too on slon, but it was
on the MASTER (not the receiver machine!) and the backtrace was invalid
and thus useless (stack smashed?)  If I'm understanding how the process
works correctly from my perusal of the code that doesn't make any sense
since the client SLON is the one that "pulls" the data in this case, and
thus the server SLONs shouldn't be involved in the transfer itself.

Version 2.0.4, Postgres 8.4.4, OS is FreeBSD 8.0/amd64.

Note that this table is quite large (~30GB) and contains BYTEA fields,
with some instances of those fields being very large (megabyte-size
elements are not unusual.)  There are no known problems with the data
integrity and the application with the master copy is running fine. A
manual copy of pg_dump of the table in question ("scp'd" over and then
loaded with "psql test-database <file") loads perfectly fine on the
replication target machine, so I'm quite comfortable with the data in
the table itself being fine.

-- Karl

-------------- next part --------------
A non-text attachment was scrubbed...
Name: karl.vcf
Type: text/x-vcard
Size: 124 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20100801/09532e09/attachment.vcf 

From neetinkumar at srishtisoft.com  Mon Aug  2 23:24:56 2010
From: neetinkumar at srishtisoft.com (Neetin Kumar)
Date: Tue, 03 Aug 2010 11:54:56 +0530
Subject: [Slony1-general] Reg:- Database size in postgres
Message-ID: <4C57B638.9010609@srishtisoft.com>

Hi,

I am new to postgres My database actual size is 2 GB after replication 
its become 47 GB i tried to run VACUUM but i am not able to do so 
because getting error :No space left on disk.

Please suggest me what to do.

Can I remove pg_xlog files its size become 2.4 GB.

If yes how can i remove the log files.

Thanks,
Neetin

From stephane.schildknecht at postgresql.fr  Tue Aug  3 06:11:42 2010
From: stephane.schildknecht at postgresql.fr (=?ISO-8859-15?Q?=22St=E9phane_A=2E_Schildknecht=22?=)
Date: Tue, 03 Aug 2010 15:11:42 +0200
Subject: [Slony1-general] Eek Part II - No,
 SSL was not the entire problem (Replication COPY fails repeatedly)
In-Reply-To: <4C55B4FD.7040904@denninger.net>
References: <4C55B4FD.7040904@denninger.net>
Message-ID: <4C58158E.9070003@postgresql.fr>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Le 01/08/2010 19:55, Karl Denninger a ?crit :
> So last night, if you remember my previous missive, I thought I had
> found the issue with a big table copy having to do with Postgresql's SQL
> support and went to bed with it running with SSL off.
> 
> Well, I was wrong, as I was treated to this morning after the thing ran
> for more than four hours - probably about the amount of time required to
> actually complete the job.  (It actually failed TWICE and restarted
> overnight.)
> 
> Aug  1 06:32:25 dbms TICKER[77422]: [153-1] CONFIG remoteWorkerThread_3:
> copy table "public"."images"
> Aug  1 06:32:25 dbms TICKER[77422]: [154-1] CONFIG remoteWorkerThread_3:
> Begin COPY of table "public"."images"
> Aug  1 10:09:08 dbms TICKER[77422]: [155-1] ERROR  remoteWorkerThread_3:
> copy from stdin on local node - PGRES_FATAL_ERROR server closed the
> connection unexpectedly
> Aug  1 10:09:08 dbms TICKER[77422]: [155-2]     This probably means the
> server terminated abnormally
> Aug  1 10:09:08 dbms TICKER[77422]: [155-3]     before or while
> processing the request.
> Aug  1 10:09:08 dbms TICKER[77422]: [156-1] WARN   remoteWorkerThread_3:
> data copy for set 1 failed 1 times - sleep 15 seconds
> Aug  1 10:09:08 dbms TICKER[77422]: [157] ERROR  remoteWorkerThread_3:
> "rollback transaction" PGRES_FATAL_ERROR
> Aug  1 10:09:08 dbms TICKER[72097]: [5-1] INFO   slon: retry requested
> Aug  1 10:09:08 dbms TICKER[72097]: [6-1] INFO   slon: notify worker
> process to shutdown
> 
> The problem is that I really don't have anything untoward in the
> postgres log file this time, except for:
> 
> Aug  1 11:09:11 tickerforum postgres[39981]: [6-1] LOG:  unexpected EOF
> on client connection
> Aug  1 11:09:11 tickerforum postgres[38657]: [6-1] LOG:  unexpected EOF
> on client connection
> Aug  1 11:09:11 tickerforum postgres[39585]: [6-1] LOG:  unexpected EOF
> on client connection
> Aug  1 11:09:11 tickerforum postgres[39816]: [6-1] LOG:  unexpected EOF
> on client connection
> Aug  1 11:09:11 tickerforum postgres[39191]: [6-1] LOG:  unexpected EOF
> on client connection
> 
> Those APPEAR, from the process IDs, to be the IDs of the SLONs that were
> running at the time from the other side, implying that the server didn't
> barf, SLONY did and dropped the connection without first saying goodbye.

Could there be a timeout somewhere in your network that releases connection it
sees as stalled ?

> 
> The problem is that there is literally nothing in the SLON log above or
> in the Postgres log implying a problem until the dump.
> 
> I had a core dump with a coincident time stamp too on slon, but it was
> on the MASTER (not the receiver machine!) and the backtrace was invalid
> and thus useless (stack smashed?)  If I'm understanding how the process
> works correctly from my perusal of the code that doesn't make any sense
> since the client SLON is the one that "pulls" the data in this case, and
> thus the server SLONs shouldn't be involved in the transfer itself.
> 
> Version 2.0.4, Postgres 8.4.4, OS is FreeBSD 8.0/amd64.
> 
> Note that this table is quite large (~30GB) and contains BYTEA fields,
> with some instances of those fields being very large (megabyte-size
> elements are not unusual.)  There are no known problems with the data
> integrity and the application with the master copy is running fine. A
> manual copy of pg_dump of the table in question ("scp'd" over and then
> loaded with "psql test-database <file") loads perfectly fine on the
> replication target machine, so I'm quite comfortable with the data in
> the table itself being fine.
> 
> -- Karl
> 
> 
> 
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


- -- 
St?phane Schildknecht
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkxYFY4ACgkQA+REPKWGI0GgiACgiuvkq+dntp7hXK/yIL1dJXU+
Y1IAnReg0UFd6Nh4Z6aH2B3pryGeXmH+
=KdmK
-----END PGP SIGNATURE-----

From ssinger at ca.afilias.info  Tue Aug  3 06:15:23 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Tue, 03 Aug 2010 09:15:23 -0400
Subject: [Slony1-general] [slony-general] moving tables to another schema
In-Reply-To: <AANLkTinOGdhMRHf-tjCGqMpHJK9u-ZBfwcpadnbE=1Za@mail.gmail.com>
References: <AANLkTinOGdhMRHf-tjCGqMpHJK9u-ZBfwcpadnbE=1Za@mail.gmail.com>
Message-ID: <4C58166B.1080101@ca.afilias.info>

Jaime Casanova wrote:
> Hi,
> 
> I want to move some replicated tables to a new schema, so i execute
> "ALTER TABLE SET SCHEMA new_schema" via the SLONIK EXECUTE SCRIPT
> command and the result was:
> - on origin: everything is ok, table moved and sl_table fixed
> - on subscriber: table was moved but sl_table still says that the
> table is in public (i guess i can update sl_table manually but i
> prefer it happens automagically)
> 
> this was on pg 8.4 with slony 1.2.20
> 
> I also tried to rename the schema via the SLONIK EXECUTE SCRIPT
> command and on subscriber the schema wasn't renamed.

I think this is a bug.

The function _ at CLUSTERNAME@.updateRelname adjustst the sl_table to 
reflect the name in the catalog.  It is being called by 
ddlScript_complete() which only runs on the event node of an execute 
script.  I think we really want to call this function from 
ddlScript_complete_int() that gets called on both nodes.

You could call updateRelname directly but I don't see how that is any 
better than doing the update yourself.




-- 
Steve Singer
Afilias Canada
Data Services Developer
416-673-1142

From ajs at crankycanuck.ca  Tue Aug  3 08:22:05 2010
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Tue, 3 Aug 2010 11:22:05 -0400
Subject: [Slony1-general] Reg:- Database size in postgres
In-Reply-To: <4C57B638.9010609@srishtisoft.com>
References: <4C57B638.9010609@srishtisoft.com>
Message-ID: <20100803152204.GA32722@shinkuro.com>

On Tue, Aug 03, 2010 at 11:54:56AM +0530, Neetin Kumar wrote:

> I am new to postgres My database actual size is 2 GB after replication 
> its become 47 GB i tried to run VACUUM but i am not able to do so 
> because getting error :No space left on disk.

You need more disk.  You can solve this by shutting postgres down,
moving some of the files to another filesystem, and symlinking them
back into their previous location.  Also, look for log files
(human-readable log files) or something else that you can safely cut
down to get yourself more room.

> Can I remove pg_xlog files its size become 2.4 GB.

No, lordy, no.  That's the transaction log.  If you remove it you will
destroy the database.

A big question is how your database got so big.  Are you quite sure
you're not getting a lot of errors (which leave dead tuples around)?

A
-- 
Andrew Sullivan
ajs at crankycanuck.ca

From cbbrowne at ca.afilias.info  Wed Aug  4 11:17:18 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed, 04 Aug 2010 14:17:18 -0400
Subject: [Slony1-general] slon memory usage
In-Reply-To: <4C4F1DDD.5070307@ca.afilias.info> (Steve Singer's message of
	"Tue, 27 Jul 2010 13:56:45 -0400")
References: <4C4F1DDD.5070307@ca.afilias.info>
Message-ID: <87lj8m4501.fsf@cbbrowne.afilias-int.info>

Steve Singer <ssinger at ca.afilias.info> writes:
> I see a few choices
>
> 1) We can have slon explicitly request a more reasonable thread stack 
> size before it creates threads (pthreads has API calls for this).  I'm 
> not 100% sure what the best value for this would be for all platforms 
> but slon tends to be pretty good about not storing large values on the stack
>
> 2) We can document this and tell sysadmins/DBA's that are concerned 
> about the slon memory footprint to use their OS's facilities (ie ulimit 
> -s before invoking slon) to adjust how much stack each thread.
>
> The argument for 1 is that the slony development team has a better sense 
> of how much stack memory slon threads take, and we might even discover 
> that different threads types of stack memory requirements (I doubt the 
> different slony thread types will very much in stack usage)
>
> The argument for 2 is that the OS is already providing facilities to 
> tune this and we should leave it tunable through those.
>
> Thoughts?

I agree with your reasonings for both 1 and 2...

I'll throw in another consideration that generally favours 2.

There are folks that run slon under Windows, which may have
substantially different behaviour.  I don't know how memory tuning works
there, and we might easily do a Unix-centric thing here that would break
Windows porting.
-- 
let name="cbbrowne" and tld="ca.afilias.info" in String.concat "@" [name;tld];;
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From cbbrowne at ca.afilias.info  Wed Aug  4 11:24:38 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed, 04 Aug 2010 14:24:38 -0400
Subject: [Slony1-general] Aieeee!  Problem with 2.0.4
In-Reply-To: <4C550D9A.1080305@denninger.net> (Karl Denninger's message of
	"Sun, 01 Aug 2010 01:00:58 -0500")
References: <4C54F5D3.2060703@denninger.net> <4C550D9A.1080305@denninger.net>
Message-ID: <87hbja44nt.fsf@cbbrowne.afilias-int.info>

Karl Denninger <karl at denninger.net> writes:
> This isn't SLONY's issue, but it's definitely a problem.  I'll report it
> over on the Postgres list in the morning...

I'll note this in the FAQ.
-- 
let name="cbbrowne" and tld="ca.afilias.info" in String.concat "@" [name;tld];;
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From raghuchennuru at gmail.com  Thu Aug  5 03:31:09 2010
From: raghuchennuru at gmail.com (raghu ram)
Date: Thu, 5 Aug 2010 16:01:09 +0530
Subject: [Slony1-general] WARN :: remoteWorker_event: event xxxx ignored -
	unknown origin --- slony log's
Message-ID: <AANLkTikx=2k_S7pEf7Tq1gAL_XXFbsGpOkZZ9d_5P+M5@mail.gmail.com>

Hi Slony guru's,


We had a replication setup like

                                Master --> slave
                                                 master --> slave

Slony log's saying below warings:

2010-08-05 03:01:39 PDT WARN   remoteWorker_event: event 2,334 ignored -
unknown origin
2010-08-05 03:01:39 PDT WARN   remoteWorker_event: event 2,335 ignored -
unknown origin
2010-08-05 03:01:39 PDT WARN   remoteWorker_event: event 2,336 ignored -
unknown origin
2010-08-05 03:01:39 PDT WARN   remoteWorker_event: event 2,337 ignored -
unknown origin
2010-08-05 03:01:39 PDT WARN   remoteWorker_event: event 2,338 ignored -
unknown origin
2010-08-05 03:01:39 PDT WARN   remoteWorker_event: event 2,339 ignored -
unknown origin
2010-08-05 03:01:39 PDT WARN   remoteWorker_event: event 2,340 ignored -
unknown origin
2010-08-05 03:01:39 PDT WARN   remoteWorker_event: event 2,341 ignored -
unknown origin

As per slony documentation say's that... "Probably happens if events arrive
before the STORE_NODE event that tells that the new node now exists"..


Could you please let me know, How to avoid those problems in the replication
setup


Regards
Raghu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20100805/e2dcc190/attachment.htm 

From ulas.albayrak at gmail.com  Fri Aug  6 00:57:08 2010
From: ulas.albayrak at gmail.com (Ulas Albayrak)
Date: Fri, 6 Aug 2010 09:57:08 +0200
Subject: [Slony1-general] uninstall slony
Message-ID: <AANLkTinA7pz7OaQNboyO=ja7_Pfash22_mKd9GsvUTVM@mail.gmail.com>

Hi,

I recently installed slony-I 1.2-21 from source on a FreeBSD machine
but now I need to remove it to install a different version. My
question is how do I do this? During install I ran the "gmake install"
command which to my knowledge copied a number of scripts and files to
different places throughout the system. Will these be removed when
uninstalling?

-- 
Ulas Albayrak
ulas.albayrak at gmail.com

From devrim at gunduz.org  Fri Aug  6 01:34:30 2010
From: devrim at gunduz.org (Devrim =?ISO-8859-1?Q?G=DCND=DCZ?=)
Date: Fri, 06 Aug 2010 11:34:30 +0300
Subject: [Slony1-general] uninstall slony
In-Reply-To: <AANLkTinA7pz7OaQNboyO=ja7_Pfash22_mKd9GsvUTVM@mail.gmail.com>
References: <AANLkTinA7pz7OaQNboyO=ja7_Pfash22_mKd9GsvUTVM@mail.gmail.com>
Message-ID: <1281083670.2807.36.camel@hp-laptop2.gunduz.org>

On Fri, 2010-08-06 at 09:57 +0200, Ulas Albayrak wrote:
> 
> I recently installed slony-I 1.2-21 from source on a FreeBSD machine
> but now I need to remove it to install a different version.

You don't need to remove old version. slonik_update_nodes is your friend
here.

-- 
Devrim G?ND?Z
PostgreSQL Dan??man?/Consultant, Red Hat Certified Engineer
PostgreSQL RPM Repository: http://yum.pgrpms.org
Community: devrim~PostgreSQL.org, devrim.gunduz~linux.org.tr
http://www.gunduz.org  Twitter: http://twitter.com/devrimgunduz
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 198 bytes
Desc: This is a digitally signed message part
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20100806/50b24c9d/attachment.pgp 

From ulas.albayrak at gmail.com  Fri Aug  6 02:47:46 2010
From: ulas.albayrak at gmail.com (Ulas Albayrak)
Date: Fri, 6 Aug 2010 11:47:46 +0200
Subject: [Slony1-general] uninstall slony
In-Reply-To: <1281083670.2807.36.camel@hp-laptop2.gunduz.org>
References: <AANLkTinA7pz7OaQNboyO=ja7_Pfash22_mKd9GsvUTVM@mail.gmail.com>
	<1281083670.2807.36.camel@hp-laptop2.gunduz.org>
Message-ID: <AANLkTingdvYGxdd1gAqmbcjP1Kzi0NEBAjnoKJyKNSTJ@mail.gmail.com>

>
> You don't need to remove old version. slonik_update_nodes is your friend
> here.

The thing is I need to downgrade and I thought "slonik_update_nodes"
was just for upgrading? The reason I need to downgrade (to Slony-I
1.2-15) is because my system complains when I try to initialize the
nodes, saying
"<stdin>:39: loading of file
/usr/local/share/postgresql//slony1_funcs.sql: PGRES_FATAL_ERROR
ERROR:  Slonik version: 1.2.21 != Slony-I version in PG build 1.2.15".
How should I proceed?

-- 
Ulas Albayrak
ulas.albayrak at gmail.com

From devrim at gunduz.org  Fri Aug  6 02:52:52 2010
From: devrim at gunduz.org (Devrim =?ISO-8859-1?Q?G=DCND=DCZ?=)
Date: Fri, 06 Aug 2010 12:52:52 +0300
Subject: [Slony1-general] uninstall slony
In-Reply-To: <AANLkTingdvYGxdd1gAqmbcjP1Kzi0NEBAjnoKJyKNSTJ@mail.gmail.com>
References: <AANLkTinA7pz7OaQNboyO=ja7_Pfash22_mKd9GsvUTVM@mail.gmail.com>
	<1281083670.2807.36.camel@hp-laptop2.gunduz.org>
	<AANLkTingdvYGxdd1gAqmbcjP1Kzi0NEBAjnoKJyKNSTJ@mail.gmail.com>
Message-ID: <1281088372.2807.66.camel@hp-laptop2.gunduz.org>

On Fri, 2010-08-06 at 11:47 +0200, Ulas Albayrak wrote:
> "<stdin>:39: loading of file
> /usr/local/share/postgresql//slony1_funcs.sql: PGRES_FATAL_ERROR
> ERROR:  Slonik version: 1.2.21 != Slony-I version in PG build 1.2.15".
> How should I proceed? 

Upgrade the other node ;)

Is the other node Debian? If so, I'd build slony-I 1.2.21 from sources
on the other one. 1.2.15 has various bugs as compared to 1.2.21.

-- 
Devrim G?ND?Z
PostgreSQL Dan??man?/Consultant, Red Hat Certified Engineer
PostgreSQL RPM Repository: http://yum.pgrpms.org
Community: devrim~PostgreSQL.org, devrim.gunduz~linux.org.tr
http://www.gunduz.org  Twitter: http://twitter.com/devrimgunduz
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 198 bytes
Desc: This is a digitally signed message part
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20100806/a9a95cf1/attachment.pgp 

From stephane.schildknecht at postgresql.fr  Fri Aug  6 02:53:38 2010
From: stephane.schildknecht at postgresql.fr (=?ISO-8859-15?Q?=22St=E9phane_A=2E_Schildknecht=22?=)
Date: Fri, 06 Aug 2010 11:53:38 +0200
Subject: [Slony1-general] uninstall slony
In-Reply-To: <AANLkTingdvYGxdd1gAqmbcjP1Kzi0NEBAjnoKJyKNSTJ@mail.gmail.com>
References: <AANLkTinA7pz7OaQNboyO=ja7_Pfash22_mKd9GsvUTVM@mail.gmail.com>	<1281083670.2807.36.camel@hp-laptop2.gunduz.org>
	<AANLkTingdvYGxdd1gAqmbcjP1Kzi0NEBAjnoKJyKNSTJ@mail.gmail.com>
Message-ID: <4C5BDBA2.8020904@postgresql.fr>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Le 06/08/2010 11:47, Ulas Albayrak a ?crit :
>>
>> You don't need to remove old version. slonik_update_nodes is your friend
>> here.
> 
> The thing is I need to downgrade and I thought "slonik_update_nodes"
> was just for upgrading? The reason I need to downgrade (to Slony-I
> 1.2-15) is because my system complains when I try to initialize the
> nodes, saying
> "<stdin>:39: loading of file
> /usr/local/share/postgresql//slony1_funcs.sql: PGRES_FATAL_ERROR
> ERROR:  Slonik version: 1.2.21 != Slony-I version in PG build 1.2.15".
> How should I proceed?
> 

Could'nt it be that you did not compile and install the new version of Slony on
every node of the replication cluster ?

- -- 
St?phane Schildknecht
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkxb26IACgkQA+REPKWGI0G6GACgzq5VV2uF3z/6FSerCe4zk6rA
dZYAoMCy/ZtrAHR+jYJ2+CpslTwidqLX
=YKkV
-----END PGP SIGNATURE-----

From ulas.albayrak at gmail.com  Fri Aug  6 03:01:15 2010
From: ulas.albayrak at gmail.com (Ulas Albayrak)
Date: Fri, 6 Aug 2010 12:01:15 +0200
Subject: [Slony1-general] uninstall slony
In-Reply-To: <1281088372.2807.66.camel@hp-laptop2.gunduz.org>
References: <AANLkTinA7pz7OaQNboyO=ja7_Pfash22_mKd9GsvUTVM@mail.gmail.com>
	<1281083670.2807.36.camel@hp-laptop2.gunduz.org>
	<AANLkTingdvYGxdd1gAqmbcjP1Kzi0NEBAjnoKJyKNSTJ@mail.gmail.com>
	<1281088372.2807.66.camel@hp-laptop2.gunduz.org>
Message-ID: <AANLkTinvkbuS5SWZGmiQ8kTA6TJ+h3jt7cirgWi4sq-X@mail.gmail.com>

>Upgrade the other node ;)
>
>Is the other node Debian? If so, I'd build slony-I 1.2.21 from sources
>on the other one. 1.2.15 has various bugs as compared to 1.2.21.

Well, if so, I should probably try that. Yes, the other system is
running Debian Lenny and I installed Slony-I with aptitude, but I'll
uninstall Slony on the Debian system and try to get release 1.2-21
installed. Thanks for your help!

-- 
Ulas Albayrak
ulas.albayrak at gmail.com

From ulas.albayrak at gmail.com  Fri Aug  6 03:22:44 2010
From: ulas.albayrak at gmail.com (Ulas Albayrak)
Date: Fri, 6 Aug 2010 12:22:44 +0200
Subject: [Slony1-general] uninstall slony
In-Reply-To: <AANLkTinvkbuS5SWZGmiQ8kTA6TJ+h3jt7cirgWi4sq-X@mail.gmail.com>
References: <AANLkTinA7pz7OaQNboyO=ja7_Pfash22_mKd9GsvUTVM@mail.gmail.com>
	<1281083670.2807.36.camel@hp-laptop2.gunduz.org>
	<AANLkTingdvYGxdd1gAqmbcjP1Kzi0NEBAjnoKJyKNSTJ@mail.gmail.com>
	<1281088372.2807.66.camel@hp-laptop2.gunduz.org>
	<AANLkTinvkbuS5SWZGmiQ8kTA6TJ+h3jt7cirgWi4sq-X@mail.gmail.com>
Message-ID: <AANLkTik8LFwDH7vzPNobm10-mVTwkd6J=mPwFLNFxKO9@mail.gmail.com>

After trying working on upgrading for a bit I realized that the error message
"<stdin>:39: loading of file
/usr/local/share/postgresql//slony1_funcs.sql: PGRES_FATAL_ERROR
ERROR:  Slonik version: 1.2.21 != Slony-I version in PG build 1.2.15"
refers to a discrepancy between the version of Slony-I in slonik and
the one in the local postgresql build, something that probably won't
be helped by me upgrading slony-I in the other node. So I guess I'm
back to square one. I need to downgrade Slony- on the FreeBSD machine
(or possibly upgrade the slony version in the Postgresql build, if
that's even possible). Any ideas?

2010/8/6 Ulas Albayrak <ulas.albayrak at gmail.com>:
>>Upgrade the other node ;)
>>
>>Is the other node Debian? If so, I'd build slony-I 1.2.21 from sources
>>on the other one. 1.2.15 has various bugs as compared to 1.2.21.
>
> Well, if so, I should probably try that. Yes, the other system is
> running Debian Lenny and I installed Slony-I with aptitude, but I'll
> uninstall Slony on the Debian system and try to get release 1.2-21
> installed. Thanks for your help!
>
> --
> Ulas Albayrak
> ulas.albayrak at gmail.com
>



-- 
Ulas Albayrak
ulas.albayrak at gmail.com

From devrim at gunduz.org  Fri Aug  6 03:31:04 2010
From: devrim at gunduz.org (Devrim =?ISO-8859-1?Q?G=DCND=DCZ?=)
Date: Fri, 06 Aug 2010 13:31:04 +0300
Subject: [Slony1-general] uninstall slony
In-Reply-To: <AANLkTik8LFwDH7vzPNobm10-mVTwkd6J=mPwFLNFxKO9@mail.gmail.com>
References: <AANLkTinA7pz7OaQNboyO=ja7_Pfash22_mKd9GsvUTVM@mail.gmail.com>
	<1281083670.2807.36.camel@hp-laptop2.gunduz.org>
	<AANLkTingdvYGxdd1gAqmbcjP1Kzi0NEBAjnoKJyKNSTJ@mail.gmail.com>
	<1281088372.2807.66.camel@hp-laptop2.gunduz.org>
	<AANLkTinvkbuS5SWZGmiQ8kTA6TJ+h3jt7cirgWi4sq-X@mail.gmail.com>
	<AANLkTik8LFwDH7vzPNobm10-mVTwkd6J=mPwFLNFxKO9@mail.gmail.com>
Message-ID: <1281090664.2807.78.camel@hp-laptop2.gunduz.org>

On Fri, 2010-08-06 at 12:22 +0200, Ulas Albayrak wrote:
> After trying working on upgrading for a bit I realized that the error
> message
> "<stdin>:39: loading of file
> /usr/local/share/postgresql//slony1_funcs.sql: PGRES_FATAL_ERROR
> ERROR:  Slonik version: 1.2.21 != Slony-I version in PG build 1.2.15"
> refers to a discrepancy between the version of Slony-I in slonik and
> the one in the local postgresql build, something that probably won't
> be helped by me upgrading slony-I in the other node. S 

You are still calling the .sql file which is installed by aptitude.
--
Devrim G?ND?Z
PostgreSQL Dan??man?/Consultant, Red Hat Certified Engineer
PostgreSQL RPM Repository: http://yum.pgrpms.org
Community: devrim~PostgreSQL.org, devrim.gunduz~linux.org.tr
http://www.gunduz.org  Twitter: http://twitter.com/devrimgunduz
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 198 bytes
Desc: This is a digitally signed message part
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20100806/71be2393/attachment.pgp 

From ulas.albayrak at gmail.com  Fri Aug  6 03:48:42 2010
From: ulas.albayrak at gmail.com (Ulas Albayrak)
Date: Fri, 6 Aug 2010 12:48:42 +0200
Subject: [Slony1-general] uninstall slony
In-Reply-To: <1281090664.2807.78.camel@hp-laptop2.gunduz.org>
References: <AANLkTinA7pz7OaQNboyO=ja7_Pfash22_mKd9GsvUTVM@mail.gmail.com>
	<1281083670.2807.36.camel@hp-laptop2.gunduz.org>
	<AANLkTingdvYGxdd1gAqmbcjP1Kzi0NEBAjnoKJyKNSTJ@mail.gmail.com>
	<1281088372.2807.66.camel@hp-laptop2.gunduz.org>
	<AANLkTinvkbuS5SWZGmiQ8kTA6TJ+h3jt7cirgWi4sq-X@mail.gmail.com>
	<AANLkTik8LFwDH7vzPNobm10-mVTwkd6J=mPwFLNFxKO9@mail.gmail.com>
	<1281090664.2807.78.camel@hp-laptop2.gunduz.org>
Message-ID: <AANLkTinXKYY+wghHzf66yLoDykGtSPFhoKsmpKc+vWm=@mail.gmail.com>

>2010/8/6 Devrim G?ND?Z <devrim at gunduz.org>:
>
> You are still calling the .sql file which is installed by aptitude.
>

Excuse me if this question seems stupid, but which .sql file? Where
does it reside? Also, I installed Slony-I on the FreeBSD machine from
source, not with a package manager.

-- 
Ulas Albayrak
ulas.albayrak at gmail.com

From devrim at gunduz.org  Fri Aug  6 04:00:01 2010
From: devrim at gunduz.org (Devrim =?ISO-8859-1?Q?G=DCND=DCZ?=)
Date: Fri, 06 Aug 2010 14:00:01 +0300
Subject: [Slony1-general] uninstall slony
In-Reply-To: <AANLkTinXKYY+wghHzf66yLoDykGtSPFhoKsmpKc+vWm=@mail.gmail.com>
References: <AANLkTinA7pz7OaQNboyO=ja7_Pfash22_mKd9GsvUTVM@mail.gmail.com>
	<1281083670.2807.36.camel@hp-laptop2.gunduz.org>
	<AANLkTingdvYGxdd1gAqmbcjP1Kzi0NEBAjnoKJyKNSTJ@mail.gmail.com>
	<1281088372.2807.66.camel@hp-laptop2.gunduz.org>
	<AANLkTinvkbuS5SWZGmiQ8kTA6TJ+h3jt7cirgWi4sq-X@mail.gmail.com>
	<AANLkTik8LFwDH7vzPNobm10-mVTwkd6J=mPwFLNFxKO9@mail.gmail.com>
	<1281090664.2807.78.camel@hp-laptop2.gunduz.org>
	<AANLkTinXKYY+wghHzf66yLoDykGtSPFhoKsmpKc+vWm=@mail.gmail.com>
Message-ID: <1281092401.2807.80.camel@hp-laptop2.gunduz.org>


On Fri, 2010-08-06 at 12:48 +0200, Ulas Albayrak wrote:

> Excuse me if this question seems stupid, but which .sql file? Where
> does it reside? Also, I installed Slony-I on the FreeBSD machine from
> source, not with a package manager. 

The error message you are seeing is coming from Debian. Did you remove
1.2.15? Probably 1.1.15 is still under $PATH, and Slony-I is trying to
use that one. I'd remove 1.1.15 first, add 1.2.21 to $PATH, and retry.

Regards,
-- 
Devrim G?ND?Z
PostgreSQL Dan??man?/Consultant, Red Hat Certified Engineer
PostgreSQL RPM Repository: http://yum.pgrpms.org
Community: devrim~PostgreSQL.org, devrim.gunduz~linux.org.tr
http://www.gunduz.org  Twitter: http://twitter.com/devrimgunduz
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 198 bytes
Desc: This is a digitally signed message part
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20100806/e4f2fedd/attachment.pgp 

From fharids at hotmail.com  Fri Aug  6 07:23:25 2010
From: fharids at hotmail.com (Fharid Salomon Fernandez)
Date: Fri, 6 Aug 2010 14:23:25 +0000
Subject: [Slony1-general] How To Define Replications Sets Properly
In-Reply-To: <mailman.12.1281103487.4687.slony1-general@lists.slony.info>
References: <mailman.12.1281103487.4687.slony1-general@lists.slony.info>
Message-ID: <COL119-W3178DC8282BEA6B7F62187AC910@phx.gbl>


Hello, i'm new using this slony-I replication system, and i have little doubts about defining the replications sets.
In the slony-i documentation it says that i have to group those tables that are related via foreign key constraints in one set, so the objetive
here is to have varoius sets from one database, the problem is that , i have a large database  where all the tables are related, for example
i have some tables for the human resources module, those tables are related (employees, location, etc) and some of those tables are related to
tables from other modules (sales, accounts, etc), so it means that i can't separate the tables in diferent sets because some of them act like bridges
relating all the tables from the database, and I have to define one big set with all the tables??? ....
please what can i do in order to have the correct number of replication sets from my database.
 		 	   		  

From community at chronicdb.com  Fri Aug  6 12:32:21 2010
From: community at chronicdb.com (ChronicDB Community Team)
Date: Fri, 06 Aug 2010 12:32:21 -0700
Subject: [Slony1-general] How To Define Replications Sets Properly
In-Reply-To: <COL119-W3178DC8282BEA6B7F62187AC910@phx.gbl>
References: <mailman.12.1281103487.4687.slony1-general@lists.slony.info>
	<COL119-W3178DC8282BEA6B7F62187AC910@phx.gbl>
Message-ID: <1281123141.3317.61.camel@localhost>

Hello Fharid,

For whatever it's worth, this is one example where replication with
ChronicDB is easier to setup: you wouldn't have to explicitly define
such sets, as ChronicDB automatically discovers and handles them.

On Fri, 2010-08-06 at 14:23 +0000, Fharid Salomon Fernandez wrote:
> Hello, i'm new using this slony-I replication system, and i have little doubts about defining the replications sets.
> In the slony-i documentation it says that i have to group those tables that are related via foreign key constraints in one set, so the objetive
> here is to have varoius sets from one database, the problem is that , i have a large database  where all the tables are related, for example
> i have some tables for the human resources module, those tables are related (employees, location, etc) and some of those tables are related to
> tables from other modules (sales, accounts, etc), so it means that i can't separate the tables in diferent sets because some of them act like bridges
> relating all the tables from the database, and I have to define one big set with all the tables??? ....
> please what can i do in order to have the correct number of replication sets from my database.
>  		 	   		  
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


From ssinger at ca.afilias.info  Fri Aug  6 12:54:12 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 06 Aug 2010 15:54:12 -0400
Subject: [Slony1-general] How To Define Replications Sets Properly
In-Reply-To: <COL119-W3178DC8282BEA6B7F62187AC910@phx.gbl>
References: <mailman.12.1281103487.4687.slony1-general@lists.slony.info>
	<COL119-W3178DC8282BEA6B7F62187AC910@phx.gbl>
Message-ID: <4C5C6864.8000305@ca.afilias.info>

Fharid Salomon Fernandez wrote:
> Hello, i'm new using this slony-I replication system, and i have little doubts about defining the replications sets.
> In the slony-i documentation it says that i have to group those tables that are related via foreign key constraints in one set, so the objetive
> here is to have varoius sets from one database, the problem is that , i have a large database  where all the tables are related, for example
> i have some tables for the human resources module, those tables are related (employees, location, etc) and some of those tables are related to
> tables from other modules (sales, accounts, etc), so it means that i can't separate the tables in diferent sets because some of them act like bridges
> relating all the tables from the database, and I have to define one big set with all the tables??? ....
> please what can i do in order to have the correct number of replication sets from my database.
>  		 	


There isn't anything wrong with having all off your tables in one 
replication set.  In fact, that is a very common way of deploying slony.

    		
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


-- 
Steve Singer
Afilias Canada
Data Services Developer
416-673-1142

From cbbrowne at ca.afilias.info  Fri Aug  6 13:20:34 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri, 06 Aug 2010 16:20:34 -0400
Subject: [Slony1-general] uninstall slony
In-Reply-To: <AANLkTik8LFwDH7vzPNobm10-mVTwkd6J=mPwFLNFxKO9@mail.gmail.com>
	(Ulas Albayrak's message of "Fri, 6 Aug 2010 12:22:44 +0200")
References: <AANLkTinA7pz7OaQNboyO=ja7_Pfash22_mKd9GsvUTVM@mail.gmail.com>
	<1281083670.2807.36.camel@hp-laptop2.gunduz.org>
	<AANLkTingdvYGxdd1gAqmbcjP1Kzi0NEBAjnoKJyKNSTJ@mail.gmail.com>
	<1281088372.2807.66.camel@hp-laptop2.gunduz.org>
	<AANLkTinvkbuS5SWZGmiQ8kTA6TJ+h3jt7cirgWi4sq-X@mail.gmail.com>
	<AANLkTik8LFwDH7vzPNobm10-mVTwkd6J=mPwFLNFxKO9@mail.gmail.com>
Message-ID: <87tyn7ze5p.fsf@cbbrowne.afilias-int.info>

Ulas Albayrak <ulas.albayrak at gmail.com> writes:
> After trying working on upgrading for a bit I realized that the error message
> "<stdin>:39: loading of file
> /usr/local/share/postgresql//slony1_funcs.sql: PGRES_FATAL_ERROR
> ERROR:  Slonik version: 1.2.21 != Slony-I version in PG build 1.2.15"
> refers to a discrepancy between the version of Slony-I in slonik and
> the one in the local postgresql build, something that probably won't
> be helped by me upgrading slony-I in the other node. So I guess I'm
> back to square one. I need to downgrade Slony- on the FreeBSD machine
> (or possibly upgrade the slony version in the Postgresql build, if
> that's even possible). Any ideas?

The SQL files (slony1_funcs.sql, notably) only forcibly need to be on
the node(s) where Slonik gets run, as Slonik reads them locally.

But the binary functions (e.g. - code for logging trigger activity) have
got to be installed/upgraded on each and every node, as that is certain
to get loaded locally.

In practice, the latter, when combined with the potential for
catastrophe if the SQL code stored in files is out of sync between nodes
(where the SQL *COULD* get run, though it isn't necessarily ACTUALLY
run) pretty much mandates installing everything on every node.
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From fharids at hotmail.com  Fri Aug  6 13:53:27 2010
From: fharids at hotmail.com (Fharid Salomon Fernandez)
Date: Fri, 6 Aug 2010 20:53:27 +0000
Subject: [Slony1-general] FW:  How To Define Replications Sets Properly
In-Reply-To: <4C5C6864.8000305@ca.afilias.info>
References: <mailman.12.1281103487.4687.slony1-general@lists.slony.info>
	<COL119-W3178DC8282BEA6B7F62187AC910@phx.gbl>,
	<4C5C6864.8000305@ca.afilias.info>
Message-ID: <COL119-W88FE0FF942D812FCD4BB7AC910@phx.gbl>


Thanks For your answers, well i was thinking that to, 
but the thing is that when you put all the tables in one replication set
when the set needs to lock itself, my whole database is going to be locked ?
 		 	   		  

From scott.marlowe at gmail.com  Fri Aug  6 14:01:20 2010
From: scott.marlowe at gmail.com (Scott Marlowe)
Date: Fri, 6 Aug 2010 15:01:20 -0600
Subject: [Slony1-general] FW: How To Define Replications Sets Properly
In-Reply-To: <COL119-W88FE0FF942D812FCD4BB7AC910@phx.gbl>
References: <mailman.12.1281103487.4687.slony1-general@lists.slony.info>
	<COL119-W3178DC8282BEA6B7F62187AC910@phx.gbl>
	<4C5C6864.8000305@ca.afilias.info>
	<COL119-W88FE0FF942D812FCD4BB7AC910@phx.gbl>
Message-ID: <AANLkTinSOBJhLn5+SOVnFNmLW-3tn-gtHVuzqyk4YWH=@mail.gmail.com>

On Fri, Aug 6, 2010 at 2:53 PM, Fharid Salomon Fernandez
<fharids at hotmail.com> wrote:
>
> Thanks For your answers, well i was thinking that to,
> but the thing is that when you put all the tables in one replication set
> when the set needs to lock itself, my whole database is going to be locked ?

Yes, and this can be a problem if you have 50,000 tables.  I've found
that with ~1000 tables I do ok, but we do all our slony / schema
modifications during maintenance windows with the application offline
anyway (and autovacuum shut down as well) because interactions between
long running slony - schema changes, autovacuum, and our application
result in priority inversion issues that make the whole system grind
to a halt waiting for autovacuum's much slower work to finish, which
of course takes hours on some tables.

We can reduce schema change times to minutes by taking the app offline
and turning off autovac while we work.

We've tried just turnning off autovac and running schema updates
through slony while still live and it's been a disaster.  We're better
off dropping replication, making schema changes, and restarting
replication in that instance.  But a new subscription takes hours and
during that time we have no slony slaves to take over should the
master fail.

From ssinger at ca.afilias.info  Fri Aug  6 14:08:20 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Fri, 06 Aug 2010 17:08:20 -0400
Subject: [Slony1-general] FW:  How To Define Replications Sets Properly
In-Reply-To: <COL119-W88FE0FF942D812FCD4BB7AC910@phx.gbl>
References: <mailman.12.1281103487.4687.slony1-general@lists.slony.info>	<COL119-W3178DC8282BEA6B7F62187AC910@phx.gbl>,
	<4C5C6864.8000305@ca.afilias.info>
	<COL119-W88FE0FF942D812FCD4BB7AC910@phx.gbl>
Message-ID: <4C5C79C4.1060509@ca.afilias.info>

Fharid Salomon Fernandez wrote:
> Thanks For your answers, well i was thinking that to, 
> but the thing is that when you put all the tables in one replication set
> when the set needs to lock itself, my whole database is going to be locked ?
>  


You didn't mention which version of slony your using.

Also in which circumstances are you concerned about locking the tables?

Be aware that with Slony 1.2 ALL replicated tables get locked with every 
EXECUTE SCRIPT call even if they are in different sets.  With Slony 
version 2.0.x EXECUTE SCRIPT doesn't lock any tables (note bug 
http://www.slony.info/bugzilla/show_bug.cgi?id=137 it is possible the 
solution to that might introduce a bit more locking)

Another instance where slony locks things is move set, if your foreign 
key relationships are as you describe this is exactly why you want them 
in one set.  You don't want a situation where some tables are moved at a 
different time than other related tables.



		 	   		
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


-- 
Steve Singer
Afilias Canada
Data Services Developer
416-673-1142

From fharids at hotmail.com  Fri Aug  6 14:20:36 2010
From: fharids at hotmail.com (Fharid Salomon Fernandez)
Date: Fri, 6 Aug 2010 21:20:36 +0000
Subject: [Slony1-general] FW:  How To Define Replications Sets Properly
In-Reply-To: <4C5C79C4.1060509@ca.afilias.info>
References: <mailman.12.1281103487.4687.slony1-general@lists.slony.info>
	<COL119-W3178DC8282BEA6B7F62187AC910@phx.gbl>,
	<4C5C6864.8000305@ca.afilias.info>
	<COL119-W88FE0FF942D812FCD4BB7AC910@phx.gbl>,
	<4C5C79C4.1060509@ca.afilias.info>
Message-ID: <COL119-W4175BA9BD9F3ED3EAC3A6DAC910@phx.gbl>




OH, maybe i was cheking an old documentation source, so theres no problem putting all my tables in one set,
unless they were more than 10000 :D, here we have like 300 tables so theres no problem.
thank you very much
----------------------------------------
> Date: Fri, 6 Aug 2010 17:08:20 -0400
> From: ssinger at ca.afilias.info
> To: fharids at hotmail.com
> CC: slony1-general at lists.slony.info
> Subject: Re: [Slony1-general] FW: How To Define Replications Sets Properly
>
> Fharid Salomon Fernandez wrote:
> > Thanks For your answers, well i was thinking that to,
> > but the thing is that when you put all the tables in one replication set
> > when the set needs to lock itself, my whole database is going to be locked ?
> >
>
>
> You didn't mention which version of slony your using.
>
> Also in which circumstances are you concerned about locking the tables?
>
> Be aware that with Slony 1.2 ALL replicated tables get locked with every
> EXECUTE SCRIPT call even if they are in different sets. With Slony
> version 2.0.x EXECUTE SCRIPT doesn't lock any tables (note bug
> http://www.slony.info/bugzilla/show_bug.cgi?id=137 it is possible the
> solution to that might introduce a bit more locking)
>
> Another instance where slony locks things is move set, if your foreign
> key relationships are as you describe this is exactly why you want them
> in one set. You don't want a situation where some tables are moved at a
> different time than other related tables.
>
>
>
>
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general at lists.slony.info
> > http://lists.slony.info/mailman/listinfo/slony1-general
>
>
> --
> Steve Singer
> Afilias Canada
> Data Services Developer
> 416-673-1142
 		 	   		  

From cbbrowne at ca.afilias.info  Fri Aug  6 14:57:34 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri, 06 Aug 2010 17:57:34 -0400
Subject: [Slony1-general] FW:  How To Define Replications Sets Properly
In-Reply-To: <COL119-W4175BA9BD9F3ED3EAC3A6DAC910@phx.gbl> (Fharid Salomon
	Fernandez's message of "Fri, 6 Aug 2010 21:20:36 +0000")
References: <mailman.12.1281103487.4687.slony1-general@lists.slony.info>
	<COL119-W3178DC8282BEA6B7F62187AC910@phx.gbl>
	<4C5C6864.8000305@ca.afilias.info>
	<COL119-W88FE0FF942D812FCD4BB7AC910@phx.gbl>
	<4C5C79C4.1060509@ca.afilias.info>
	<COL119-W4175BA9BD9F3ED3EAC3A6DAC910@phx.gbl>
Message-ID: <87pqxvz9o1.fsf@cbbrowne.afilias-int.info>

Fharid Salomon Fernandez <fharids at hotmail.com> writes:
> OH, maybe i was cheking an old documentation source, so theres no
> problem putting all my tables in one set, unless they were more than
> 10000 :D, here we have like 300 tables so theres no problem.  thank
> you very much

300 tables shouldn't be a huge problem.  Adding them to replication is
likely to take minutes, not hours.  Thousands of tables are troublesome
because they need to be managed individually any time:
 - There's a new subscription
   Tho that doesn't *too* much affect providers...
 - Any time EXECUTE SCRIPT is run (pre 2.0)
   As each table will have replication triggers removed and re-added
 - Any time origin gets moved
   As tables will have triggers added+removed on former/new origins

But 300's not likely to present much of a problem.
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From ulas.albayrak at gmail.com  Wed Aug 11 02:21:04 2010
From: ulas.albayrak at gmail.com (Ulas Albayrak)
Date: Wed, 11 Aug 2010 11:21:04 +0200
Subject: [Slony1-general] slonik switchover script
Message-ID: <AANLkTimD4ctfEresHzpNS-2hHasq8qByQuvjeiwMTRvw@mail.gmail.com>

Hi,

I have two Postgres db's running Slony-I and I need to perform a
switchover. I read the documentation on the homepage but still have
some questions on the matter. My question is do I have to wait for the
events to be done both when locking AND moving sets or only the
latter, i.e. should the script be written as:

[CODE:]
        lock set (id = 1, origin = 1);
        move set (id = 1, old origin = 1, new origin = 2);
        wait for event (origin = 1, confirmed = 2);

        lock set (id = 2, origin = 1);
        move set (id = 2, old origin = 1, new origin = 2);
        wait for event (origin = 1, confirmed = 2);

        lock set (id = 3, origin = 1);
        move set (id = 3, old origin = 1, new origin = 2);
        wait for event (origin = 1, confirmed = 2);
[END CODE:]

or should it look like

[CODE:]
        lock set (id = 1, origin = 1);
        wait for event (origin = 1, confirmed = 2);
        move set (id = 1, old origin = 1, new origin = 2);
        wait for event (origin = 1, confirmed = 2);

        lock set (id = 2, origin = 1);
        wait for event (origin = 1, confirmed = 2);
        move set (id = 2, old origin = 1, new origin = 2);
        wait for event (origin = 1, confirmed = 2);

        lock set (id = 3, origin = 1);
        wait for event (origin = 1, confirmed = 2);
        move set (id = 3, old origin = 1, new origin = 2);
        wait for event (origin = 1, confirmed = 2);
[END CODE:]

Kind regards /Ulas Albayrak

From noh019 at naver.com  Wed Aug 11 01:21:28 2010
From: noh019 at naver.com (=?EUC-KR?B?s+vH9ryu?=)
Date: Wed, 11 Aug 2010 17:21:28 +0900
Subject: [Slony1-general] =?euc-kr?q?how_can_we_overcome_error_messages_?=
	=?euc-kr?q?=22No_admin_conninfo_provided_for_node_-1=22=3F=3F?=
Message-ID: <6cf8f040ace9be2df026790b72d4c2ed@tweb35-2.nm>

hi..
 
1
##################################################
we test EnterpriseDB Replication (slony) node1/node2.
we test Controlled Switchover node1/node2...
(it will be node1 master-->slave, node2 slave ---> master)
 
$ cat switchovernode2.sk
--------------------------------------------
#!/u01/PostgresPlus/8.4AS/bin/slonik
#file switchovernode2.sk
cluster name = testcluster;
node 1 admin conninfo = 'service=192.168.2.61-slonik';
node 2 admin conninfo = 'service=192.168.2.71-slonik';
 
lock set (id=1, origin=1);
move set (id=1, old origin=1, new origin=2);
wait for event (origin=1, confirmed=2); &lt;##### This is issue...
--------------------------------------------
$
$ chmod ugo+x switchovernode2.sk
$
$ ./switchovernode2.sk
./switchovernode2.sk:9: Error: No admin conninfo provided for node -1
$
$
$ 
 
2
##################################################
so, we test 
 
1>
$ cat switchovernode2test1.sk
--------------------------------------------
#!/u01/PostgresPlus/8.4AS/bin/slonik
#file switchovernode2test1.sk
cluster name = testcluster;
node 1 admin conninfo = 'service=192.168.2.61-slonik';
node 2 admin conninfo = 'service=192.168.2.71-slonik';
 
lock set (id=1, origin=1);
move set (id=1, old origin=1, new origin=2);
--------------------------------------------
$
$ ./switchovernode2test1.sk
 &lt;--- OK, no error message, and "switchover ok"
$
$ -- remove wait for event
 
2>
$ cat switchovernode2test2.sk
--------------------------------------------
#!/u01/PostgresPlus/8.4AS/bin/slonik
#file switchovernode2test2.sk
cluster name = testcluster;
node 1 admin conninfo = 'service=192.168.2.61-slonik';
node 2 admin conninfo = 'service=192.168.2.71-slonik';
 
lock set (id=1, origin=1);
move set (id=1, old origin=1, new origin=2);
wait for event (origin=1, confirmed=2, wait on=2); &lt;=== add """wait on = 2""
--------------------------------------------
$ ./switchovernode2test2.sk
 &lt;--- OK, no error message, and "switchover ok"
$
$ -- === add """wait on = 2""
3
##################################################
1>
Could you teach me,
 how can we overcome the error messages when executing switchovernode2.sk.....
 "./switchovernode2.sk:8: Error: No admin conninfo provided for node -1"
 
2>
Could you teach me,
 Can I use "switchovernode2test1.sk" or "switchovernode2test2.sk" ???
 
Thanks...
 
 
 
 
 
 
 
 
 
 noh019?? ???
 ?????.
 
 
 
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20100811/45f0be68/attachment.htm 

From melvin6925 at yahoo.com  Wed Aug 11 06:32:49 2010
From: melvin6925 at yahoo.com (Melvin Davidson)
Date: Wed, 11 Aug 2010 06:32:49 -0700 (PDT)
Subject: [Slony1-general] how can we overcome error messages "No admin
	conninfo provided for node -1"??
In-Reply-To: <6cf8f040ace9be2df026790b72d4c2ed@tweb35-2.nm>
Message-ID: <239673.68583.qm@web53007.mail.re2.yahoo.com>

For admin conninfo, you only specified the server. You also need to specify the
Database, port(if not standard 5432, slonik user (and possibly password)
eg:
node 1 admin conninfo='dbname=$MASTERDBNAME host=$MASTERHOST port=$PGPORT user=$REPLICATIONUSER password=$PASSWORD';

Melvin Davidson 

--- On Wed, 8/11/10, ??? <noh019 at naver.com> wrote:

From: ??? <noh019 at naver.com>
Subject: [Slony1-general] how can we overcome error messages "No admin conninfo provided for node -1"??
To: slony1-general at lists.slony.info
Date: Wednesday, August 11, 2010, 3:21 AM

#yiv928436694 P {margin-top:2px;margin-bottom:2px;}hi..
?
1
##################################################
we test EnterpriseDB? Replication (slony)? node1/node2.
we test? Controlled Switchover?? node1/node2...
(it? will be??????? node1? master-->slave,?????? node2? slave ---> master)
?
$ cat switchovernode2.sk
--------------------------------------------
#!/u01/PostgresPlus/8.4AS/bin/slonik
#file switchovernode2.sk
cluster name = testcluster;
node 1 admin conninfo = 'service=192.168.2.61-slonik';
node 2 admin conninfo = 'service=192.168.2.71-slonik';
?



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20100811/12ee6f62/attachment.htm 

From fharids at hotmail.com  Thu Aug 12 20:07:33 2010
From: fharids at hotmail.com (Fharid Salomon Fernandez)
Date: Fri, 13 Aug 2010 03:07:33 +0000
Subject: [Slony1-general] Where to get altperl scripts
Message-ID: <COL119-W97F22A2FA6E13C2C0BD98AC980@phx.gbl>


hello there, i read about some scripts that helps you administrating slony-I replication, (the altperl scripts )
they are suposed to be in some directory in my computer after the instalation of slony-I , but i couldn't find them
i couldn't even found any slony directory :S please can you tell me where can i find that directory and those scripts?
i'm sure i have installed slony-I right because i've already used slony to replicate some example tables i have here 

thanksss :)

 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20100813/527579a0/attachment.htm 

From jaime at 2ndquadrant.com  Thu Aug 12 22:34:04 2010
From: jaime at 2ndquadrant.com (Jaime Casanova)
Date: Fri, 13 Aug 2010 00:34:04 -0500
Subject: [Slony1-general] Drop Node command works,
	but leaves crumbs behind.
In-Reply-To: <4BE8839D.8070708@consistentstate.com>
References: <4BE8839D.8070708@consistentstate.com>
Message-ID: <AANLkTinaYXJZ7VgfHZvZvNCtNaFzbDo2vcqJfY0N18rK@mail.gmail.com>

On Mon, May 10, 2010 at 5:07 PM, Brian Fehrle
<brianf at consistentstate.com> wrote:
> Hi all,
> ? ?I've been running into a problem with dropping a node from the slony
> cluster, in which the slony system catalogs aren't getting fully cleaned
> up upon the dropping of the node.
>
> ? ?I have a three node cluster, one master and two slaves. I have a
> script that will generate the slonik command that will drop one of the
> slaves (in this case node three) from the slony cluster and it executes
> without problem. However, after preforming the drop node a few dozen
> times, there have been several instances in which the data in
> _slony.sl_status still refers to a third node, and the st_lag_num_events
> climb and climb (since there's no node to sync with, it will never drop
> to 0).
>

I have this same problem right now with slony 1.2.20
what could i do to recover? STORE NODE?

-- 
Jaime Casanova? ? ? ?? www.2ndQuadrant.com
Soporte y capacitaci?n de PostgreSQL

From brianf at consistentstate.com  Fri Aug 13 07:56:11 2010
From: brianf at consistentstate.com (Brian Fehrle)
Date: Fri, 13 Aug 2010 08:56:11 -0600
Subject: [Slony1-general] Drop Node command works,
	but leaves crumbs behind.
In-Reply-To: <AANLkTinaYXJZ7VgfHZvZvNCtNaFzbDo2vcqJfY0N18rK@mail.gmail.com>
References: <4BE8839D.8070708@consistentstate.com>
	<AANLkTinaYXJZ7VgfHZvZvNCtNaFzbDo2vcqJfY0N18rK@mail.gmail.com>
Message-ID: <4C655D0B.4070505@consistentstate.com>

I never did find a way to prevent this from happening, however I found 
what I believe to be a safe way to fix it after it happens.

http://slony.info/documentation/function.cleanupevent-interval-boolean.html

Running this function on the clusters with the "crumbs" left over will 
clean them out. I believe that this gets executed automatically during 
the drop node process, but for whatever reason it doesn't always clean 
everything up (possibly a race condition between the dropped node 
confirming the last event and the cleanupevent() execution).

Example sql statement"
" select  _slonyclustername.cleanupevent() "

I did multiple tests of a script I wrote that did a whole drop sequence 
which included this cleanup event, and each time everything went 
smoothly, slony replication continued to work without problem.

- Brian Fehrle

Jaime Casanova wrote:
> On Mon, May 10, 2010 at 5:07 PM, Brian Fehrle
> <brianf at consistentstate.com> wrote:
>   
>> Hi all,
>>    I've been running into a problem with dropping a node from the slony
>> cluster, in which the slony system catalogs aren't getting fully cleaned
>> up upon the dropping of the node.
>>
>>    I have a three node cluster, one master and two slaves. I have a
>> script that will generate the slonik command that will drop one of the
>> slaves (in this case node three) from the slony cluster and it executes
>> without problem. However, after preforming the drop node a few dozen
>> times, there have been several instances in which the data in
>> _slony.sl_status still refers to a third node, and the st_lag_num_events
>> climb and climb (since there's no node to sync with, it will never drop
>> to 0).
>>
>>     
>
> I have this same problem right now with slony 1.2.20
> what could i do to recover? STORE NODE?
>
>   


From cbbrowne at ca.afilias.info  Fri Aug 13 08:05:39 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri, 13 Aug 2010 11:05:39 -0400
Subject: [Slony1-general] Where to get altperl scripts
In-Reply-To: <COL119-W97F22A2FA6E13C2C0BD98AC980@phx.gbl> (Fharid Salomon
	Fernandez's message of "Fri, 13 Aug 2010 03:07:33 +0000")
References: <COL119-W97F22A2FA6E13C2C0BD98AC980@phx.gbl>
Message-ID: <87iq3e5z98.fsf@cbbrowne.afilias-int.info>

Fharid Salomon Fernandez <fharids at hotmail.com> writes:
> hello there, i read about some scripts that helps you administrating slony-I
> replication, (the altperl scripts )
> they are suposed to be in some directory in my computer after the instalation
> of slony-I , but i couldn't find them
> i couldn't even found any slony directory :S please can you tell me where can i
> find that directory and those scripts?
> i'm sure i have installed slony-I right because i've already used slony to
> replicate some example tables i have here

In the source code, they're found in the directory: tools/altperl.

So, supposing I pull a tarball:

{/tmp}  ls -l ~/Downloads/cbbrowne-slony1-engine-REL_2_0_0-0-ge4e2068.tar.gz
-rw-r--r-- 1 cbbrowne cbbrowne 1032841 Aug 13 11:00 /home/cbbrowne/Downloads/cbbrowne-slony1-engine-REL_2_0_0-0-ge4e2068.tar.gz

Then, extract it:
{/tmp}  tar xfz ~/Downloads/cbbrowne-slony1-engine-REL_2_0_0-0-ge4e2068.tar.gz                                         
{/tmp}  cd cbbrowne-slony1-engine-e4e2068                                                                              
{cbbrowne-slony1-engine-e4e2068}  ls                                                                                   
aclocal.m4   configure     doc             INSTALL             makefiles       redhat       SAMPLE          src    TODO
config       configure.ac  GNUmakefile.in  Makefile            README          RELEASE      share           suse   tools
config.h.in  COPYRIGHT     HISTORY-1.1     Makefile.global.in  README.Unicode  RELEASE-2.0  slony1.spec.in  tests  UPGRADING
{cbbrowne-slony1-engine-e4e2068}  cd tools/altperl                                                                     
{altperl}  ls                                                                                                          
Makefile                     slonik_drop_sequence.pl   slonik_merge_sets.pl      slonik_uninstall_nodes.pl  slon-tools.pm
old-apache-rotatelogs.patch  slonik_drop_set.pl        slonik_move_set.pl        slonik_unsubscribe_set.pl  slon_watchdog2.pl
README                       slonik_drop_table.pl      slonik_print_preamble.pl  slonik_update_nodes.pl     slon_watchdog.pl
slonik_build_env.pl          slonik_execute_script.pl  slonik_restart_node.pl    slon_kill.pl               slony_show_configuration.pl
slonik_create_set.pl         slonik_failover.pl        slonik_store_node.pl      slon_start.pl              ToDo
slonik_drop_node.pl          slonik_init_cluster.pl    slonik_subscribe_set.pl   slon_tools.conf-sample
{altperl}

The Makefile has configuration indicating where they should get
installed; this is controlled at configure time via the directive
"--with-perltools=<dir>"
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From JanWieck at Yahoo.com  Sun Aug 15 09:56:27 2010
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sun, 15 Aug 2010 12:56:27 -0400
Subject: [Slony1-general] Eek Part II - No,
 SSL was not the entire problem (Replication COPY fails repeatedly)
In-Reply-To: <4C58158E.9070003@postgresql.fr>
References: <4C55B4FD.7040904@denninger.net> <4C58158E.9070003@postgresql.fr>
Message-ID: <4C681C3B.3000600@Yahoo.com>

On 8/3/2010 9:11 AM, St?phane A. Schildknecht wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> Le 01/08/2010 19:55, Karl Denninger a ?crit :
>> So last night, if you remember my previous missive, I thought I had
>> found the issue with a big table copy having to do with Postgresql's SQL
>> support and went to bed with it running with SSL off.
>> 
>> Well, I was wrong, as I was treated to this morning after the thing ran
>> for more than four hours - probably about the amount of time required to
>> actually complete the job.  (It actually failed TWICE and restarted
>> overnight.)
>> 
>> Aug  1 06:32:25 dbms TICKER[77422]: [153-1] CONFIG remoteWorkerThread_3:
>> copy table "public"."images"
>> Aug  1 06:32:25 dbms TICKER[77422]: [154-1] CONFIG remoteWorkerThread_3:
>> Begin COPY of table "public"."images"
>> Aug  1 10:09:08 dbms TICKER[77422]: [155-1] ERROR  remoteWorkerThread_3:
>> copy from stdin on local node - PGRES_FATAL_ERROR server closed the
>> connection unexpectedly
>> Aug  1 10:09:08 dbms TICKER[77422]: [155-2]     This probably means the
>> server terminated abnormally
>> Aug  1 10:09:08 dbms TICKER[77422]: [155-3]     before or while
>> processing the request.
>> Aug  1 10:09:08 dbms TICKER[77422]: [156-1] WARN   remoteWorkerThread_3:
>> data copy for set 1 failed 1 times - sleep 15 seconds
>> Aug  1 10:09:08 dbms TICKER[77422]: [157] ERROR  remoteWorkerThread_3:
>> "rollback transaction" PGRES_FATAL_ERROR
>> Aug  1 10:09:08 dbms TICKER[72097]: [5-1] INFO   slon: retry requested
>> Aug  1 10:09:08 dbms TICKER[72097]: [6-1] INFO   slon: notify worker
>> process to shutdown
>> 
>> The problem is that I really don't have anything untoward in the
>> postgres log file this time, except for:
>> 
>> Aug  1 11:09:11 tickerforum postgres[39981]: [6-1] LOG:  unexpected EOF
>> on client connection
>> Aug  1 11:09:11 tickerforum postgres[38657]: [6-1] LOG:  unexpected EOF
>> on client connection
>> Aug  1 11:09:11 tickerforum postgres[39585]: [6-1] LOG:  unexpected EOF
>> on client connection
>> Aug  1 11:09:11 tickerforum postgres[39816]: [6-1] LOG:  unexpected EOF
>> on client connection
>> Aug  1 11:09:11 tickerforum postgres[39191]: [6-1] LOG:  unexpected EOF
>> on client connection
>> 
>> Those APPEAR, from the process IDs, to be the IDs of the SLONs that were
>> running at the time from the other side, implying that the server didn't
>> barf, SLONY did and dropped the connection without first saying goodbye.
> 
> Could there be a timeout somewhere in your network that releases connection it
> sees as stalled ?

Agreed, that looks very much like a network issue, losing or resetting 
connections. Both, Slony and Postgres think that the other end closed 
unexpectedly.


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From JanWieck at Yahoo.com  Sun Aug 15 11:18:51 2010
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sun, 15 Aug 2010 14:18:51 -0400
Subject: [Slony1-general] slonik switchover script
In-Reply-To: <AANLkTimD4ctfEresHzpNS-2hHasq8qByQuvjeiwMTRvw@mail.gmail.com>
References: <AANLkTimD4ctfEresHzpNS-2hHasq8qByQuvjeiwMTRvw@mail.gmail.com>
Message-ID: <4C682F8B.9000004@Yahoo.com>

On 8/11/2010 5:21 AM, Ulas Albayrak wrote:
> Hi,
> 
> I have two Postgres db's running Slony-I and I need to perform a
> switchover. I read the documentation on the homepage but still have
> some questions on the matter. My question is do I have to wait for the
> events to be done both when locking AND moving sets or only the
> latter, i.e. should the script be written as:

I don't think you need to wait for anything but the last move set, in 
order to know when the move is complete and node 2 has assumed the role 
of origin.


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From sivakumar.mailinglist at gmail.com  Mon Aug 16 08:53:49 2010
From: sivakumar.mailinglist at gmail.com (sivakumar krishnamurthy)
Date: Mon, 16 Aug 2010 21:23:49 +0530
Subject: [Slony1-general] Update the column with same value
Message-ID: <AANLkTi=XCVYxCYWe8jmHi+Sz5_GDKDmgmVUTAGOVFXi0@mail.gmail.com>

Hackers,
   Is there any specific reason to generate an UPDATE query (in LogTrigger)
when both the old and new value are the same?
Can't we ignore the replication of this particular row silently?

I am referring to the following comment in slony1_funcs.c

/*
                 * It can happen that the only UPDATE an application does is
to set a
                 * column to the same value again. In that case, we'd end up
here with
                 * no columns in the SET clause yet. We add the first key
column here
                 * with it's old value to simulate the same for the
replication
                 * engine.
                 */

Thanks,
Sivakumar.K
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20100816/7f4ebb51/attachment.htm 

From cbbrowne at ca.afilias.info  Mon Aug 16 09:24:13 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon, 16 Aug 2010 12:24:13 -0400
Subject: [Slony1-general] Update the column with same value
In-Reply-To: <AANLkTi=XCVYxCYWe8jmHi+Sz5_GDKDmgmVUTAGOVFXi0@mail.gmail.com>
	(sivakumar krishnamurthy's message of "Mon, 16 Aug 2010 21:23:49
	+0530")
References: <AANLkTi=XCVYxCYWe8jmHi+Sz5_GDKDmgmVUTAGOVFXi0@mail.gmail.com>
Message-ID: <87k4nqh6fm.fsf@cbbrowne.afilias-int.info>

sivakumar krishnamurthy <sivakumar.mailinglist at gmail.com> writes:
> Hackers,
> ?? Is there any specific reason to generate an UPDATE query (in LogTrigger)
> when both the old and new value are the same?
> Can't we ignore the replication of this particular row silently?
>
> I am referring to the following comment in slony1_funcs.c
>
> /*
> ???????????????? * It can happen that the only UPDATE an application does is to
> set a
> ???????????????? * column to the same value again. In that case, we'd end up
> here with
> ???????????????? * no columns in the SET clause yet. We add the first key
> column here
> ???????????????? * with it's old value to simulate the same for the replication
> ???????????????? * engine.
> ???????????????? */

Triggers on the table may still need to fire; they certainly did, on the
origin, and they may also need to, on subscribers.

How would you propose to configure a determination that sometimes the
tuple can be ignored silently, and sometimes the update still needs to
take place?
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From greg at endpoint.com  Mon Aug 16 10:12:08 2010
From: greg at endpoint.com (Greg Sabino Mullane)
Date: Mon, 16 Aug 2010 13:12:08 -0400
Subject: [Slony1-general] Update the column with same value
In-Reply-To: <87k4nqh6fm.fsf@cbbrowne.afilias-int.info>
References: <AANLkTi=XCVYxCYWe8jmHi+Sz5_GDKDmgmVUTAGOVFXi0@mail.gmail.com>
	<87k4nqh6fm.fsf@cbbrowne.afilias-int.info>
Message-ID: <20100816171208.GH9227@core.home>

> Triggers on the table may still need to fire; they certainly did, on the
> origin, and they may also need to, on subscribers.
> 
> How would you propose to configure a determination that sometimes the
> tuple can be ignored silently, and sometimes the update still needs to
> take place?

(Surely triggers firing is the exception not the rule for subscribers).

As a first-shot proposal, I'd have a config to set this at the Slony 
global level, defaulting to the current behavior, and allowing people 
to turn on this optimization with the understanding that replica 
triggers will NOT fire reliably if this is turned on.

-- 
Greg Sabino Mullane greg at endpoint.com
End Point Corporation
PGP Key: 0x14964AC8
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 163 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20100816/5be67db0/attachment.pgp 

From scott.marlowe at gmail.com  Mon Aug 16 10:25:32 2010
From: scott.marlowe at gmail.com (Scott Marlowe)
Date: Mon, 16 Aug 2010 11:25:32 -0600
Subject: [Slony1-general] Update the column with same value
In-Reply-To: <20100816171208.GH9227@core.home>
References: <AANLkTi=XCVYxCYWe8jmHi+Sz5_GDKDmgmVUTAGOVFXi0@mail.gmail.com>
	<87k4nqh6fm.fsf@cbbrowne.afilias-int.info>
	<20100816171208.GH9227@core.home>
Message-ID: <AANLkTinA86dwiRnBBf-0kKfeCbYO_nxds-07zqSgNBLQ@mail.gmail.com>

On Mon, Aug 16, 2010 at 11:12 AM, Greg Sabino Mullane <greg at endpoint.com> wrote:
>> Triggers on the table may still need to fire; they certainly did, on the
>> origin, and they may also need to, on subscribers.
>>
>> How would you propose to configure a determination that sometimes the
>> tuple can be ignored silently, and sometimes the update still needs to
>> take place?
>
> (Surely triggers firing is the exception not the rule for subscribers).
>
> As a first-shot proposal, I'd have a config to set this at the Slony
> global level, defaulting to the current behavior, and allowing people
> to turn on this optimization with the understanding that replica
> triggers will NOT fire reliably if this is turned on.

Seems like added (and possibly dangerous) complexity to overcome a
problem most people don't have.

From sivakumar.mailinglist at gmail.com  Mon Aug 16 23:13:13 2010
From: sivakumar.mailinglist at gmail.com (sivakumar krishnamurthy)
Date: Tue, 17 Aug 2010 11:43:13 +0530
Subject: [Slony1-general] Update the column with same value
In-Reply-To: <87k4nqh6fm.fsf@cbbrowne.afilias-int.info>
References: <AANLkTi=XCVYxCYWe8jmHi+Sz5_GDKDmgmVUTAGOVFXi0@mail.gmail.com>
	<87k4nqh6fm.fsf@cbbrowne.afilias-int.info>
Message-ID: <AANLkTimn0f-J=U1fcDjh7VK0vi054iUfQG_EaBHqYT4c@mail.gmail.com>

Triggers on the table may still need to fire; they certainly did, on the
> origin, and they may also need to, on subscribers.
>

Mine might be a naive question however why do we need a query like below if
both the old and new values are same in the UPDATE statement to be executed
on slaves.
UPDATE tbl set key='x' where key='x'.
This unnecessarily causes additional table and index bloat on the
subscribers.

Thanks,
Sivakumar.K
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20100817/6eef3fa8/attachment.htm 

From scott.marlowe at gmail.com  Mon Aug 16 23:21:27 2010
From: scott.marlowe at gmail.com (Scott Marlowe)
Date: Tue, 17 Aug 2010 00:21:27 -0600
Subject: [Slony1-general] Update the column with same value
In-Reply-To: <87k4nqh6fm.fsf@cbbrowne.afilias-int.info>
References: <AANLkTi=XCVYxCYWe8jmHi+Sz5_GDKDmgmVUTAGOVFXi0@mail.gmail.com>
	<87k4nqh6fm.fsf@cbbrowne.afilias-int.info>
Message-ID: <AANLkTikVXvSeQPCOqrymccVO+ALQfA7nd=Dkd2QiqZ38@mail.gmail.com>

On Mon, Aug 16, 2010 at 10:24 AM, Christopher Browne
<cbbrowne at ca.afilias.info> wrote:
> Triggers on the table may still need to fire; they certainly did, on the
> origin, and they may also need to, on subscribers.

Aren't all triggers disabled on slaves in slony (except slony
triggers) by default?

-- 
To understand recursion, one must first understand recursion.

From cbbrowne at ca.afilias.info  Tue Aug 17 08:18:37 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue, 17 Aug 2010 11:18:37 -0400
Subject: [Slony1-general] Update the column with same value
In-Reply-To: <AANLkTikVXvSeQPCOqrymccVO+ALQfA7nd=Dkd2QiqZ38@mail.gmail.com>
	(Scott Marlowe's message of "Tue, 17 Aug 2010 00:21:27 -0600")
References: <AANLkTi=XCVYxCYWe8jmHi+Sz5_GDKDmgmVUTAGOVFXi0@mail.gmail.com>
	<87k4nqh6fm.fsf@cbbrowne.afilias-int.info>
	<AANLkTikVXvSeQPCOqrymccVO+ALQfA7nd=Dkd2QiqZ38@mail.gmail.com>
Message-ID: <87bp91gtde.fsf@cbbrowne.afilias-int.info>

Scott Marlowe <scott.marlowe at gmail.com> writes:
> On Mon, Aug 16, 2010 at 10:24 AM, Christopher Browne
> <cbbrowne at ca.afilias.info> wrote:
>> Triggers on the table may still need to fire; they certainly did, on the
>> origin, and they may also need to, on subscribers.
>
> Aren't all triggers disabled on slaves in slony (except slony
> triggers) by default?

By default, yes.

But that's not the same thing as saying they *must* be disabled.

I know we (Afilias) have cases, normally for managing cached objects,
where we expressly add such triggers.

Note that in such cases, the old tuples, on the origin node, all get
wiped out in favor of new tuples which happen to have the same values as
the old tuples.

Example:

Foo is a table with 65536 tuples, none of them dead.

test at localhost->  update foo set id = id;
UPDATE 65536
test at localhost->  update foo set id = id;
UPDATE 65536
test at localhost->  update foo set id = id;
UPDATE 65536
test at localhost->  update foo set id = id;
UPDATE 65536
test at localhost->  vacuum verbose foo;
INFO:  vacuuming "public.foo"
INFO:  scanned index "foo_pkey" to remove 262056 row versions
DETAIL:  CPU 0.00s/0.02u sec elapsed 0.02 sec.
[more elided that's not terribly interesting]
INFO:  "foo": found 65564 removable, 65536 nonremovable row versions in 1450 out of 1450 pages
DETAIL:  0 dead row versions cannot be removed yet.
There were 40 unused item pointers.
0 pages are entirely empty.

The changes *actually got applied* to the original tuples on the origin
node.  Nothing to do with replication.  I don't see any huge problem in
this getting applied to subscribers.

It's definitely more work (from a coding perspective) to *not* log such
updates.  And if we were to do so, you'd lose the ability to decide to
use those updates for something (e.g. - cache management) on subscribers
without needing to do something to alter the source table on the origin.

There are legitimate arguments for both approaches.  I favour "just
apply the changes," which shouldn't simply quash dissent, but I'm
disinclined to change approaches, barring rather wider discussion of the
matter.
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From JanWieck at Yahoo.com  Tue Aug 17 10:09:19 2010
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Tue, 17 Aug 2010 13:09:19 -0400
Subject: [Slony1-general] Update the column with same value
In-Reply-To: <AANLkTimn0f-J=U1fcDjh7VK0vi054iUfQG_EaBHqYT4c@mail.gmail.com>
References: <AANLkTi=XCVYxCYWe8jmHi+Sz5_GDKDmgmVUTAGOVFXi0@mail.gmail.com>	<87k4nqh6fm.fsf@cbbrowne.afilias-int.info>
	<AANLkTimn0f-J=U1fcDjh7VK0vi054iUfQG_EaBHqYT4c@mail.gmail.com>
Message-ID: <4C6AC23F.8090002@Yahoo.com>

On 8/17/2010 2:13 AM, sivakumar krishnamurthy wrote:
> 
> 
>     Triggers on the table may still need to fire; they certainly did, on the
>     origin, and they may also need to, on subscribers.
> 
> 
> Mine might be a naive question however why do we need a query like below 
> if both the old and new values are same in the UPDATE statement to be 
> executed on slaves.
> UPDATE tbl set key='x' where key='x'.
> This unnecessarily causes additional table and index bloat on the 
> subscribers.

Something on the origin did something similar. It updated a row and that 
update caused no single value in the row to change. As pointed out, the 
resulting update on the subscriber is done so that eventual triggers 
there will fire.

We can add a configuration option, suppressing those updates, to the 2.1 
todo list. In the meantime, if that happens that much that it causes 
problems for you, it may be better to fix your application. Because your 
origin must suffer the same bloat.


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From JanWieck at Yahoo.com  Tue Aug 17 10:14:14 2010
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Tue, 17 Aug 2010 13:14:14 -0400
Subject: [Slony1-general] Update the column with same value
In-Reply-To: <AANLkTikVXvSeQPCOqrymccVO+ALQfA7nd=Dkd2QiqZ38@mail.gmail.com>
References: <AANLkTi=XCVYxCYWe8jmHi+Sz5_GDKDmgmVUTAGOVFXi0@mail.gmail.com>	<87k4nqh6fm.fsf@cbbrowne.afilias-int.info>
	<AANLkTikVXvSeQPCOqrymccVO+ALQfA7nd=Dkd2QiqZ38@mail.gmail.com>
Message-ID: <4C6AC366.4030508@Yahoo.com>

On 8/17/2010 2:21 AM, Scott Marlowe wrote:
> On Mon, Aug 16, 2010 at 10:24 AM, Christopher Browne
> <cbbrowne at ca.afilias.info> wrote:
>> Triggers on the table may still need to fire; they certainly did, on the
>> origin, and they may also need to, on subscribers.
> 
> Aren't all triggers disabled on slaves in slony (except slony
> triggers) by default?
> 

In 1.2 they are, unless you have told Slony via STORE TRIGGER not to do so.

In 2.0 you can control that on the subscriber with native PostgreSQL 
configuration options.

ALTER TABLE DISABLE/ENABLE [ REPLICA | ALWAYS ] TRIGGER


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From sivakumar.mailinglist at gmail.com  Tue Aug 17 20:56:04 2010
From: sivakumar.mailinglist at gmail.com (sivakumar krishnamurthy)
Date: Wed, 18 Aug 2010 09:26:04 +0530
Subject: [Slony1-general] Update the column with same value
In-Reply-To: <4C6AC23F.8090002@Yahoo.com>
References: <AANLkTi=XCVYxCYWe8jmHi+Sz5_GDKDmgmVUTAGOVFXi0@mail.gmail.com>
	<87k4nqh6fm.fsf@cbbrowne.afilias-int.info>
	<AANLkTimn0f-J=U1fcDjh7VK0vi054iUfQG_EaBHqYT4c@mail.gmail.com>
	<4C6AC23F.8090002@Yahoo.com>
Message-ID: <AANLkTinnqUV-AtgvVrxoEFbwCuUrp+oNSNnCvZp48iBH@mail.gmail.com>

>
> Something on the origin did something similar. It updated a row and that
> update caused no single value in the row to change. As pointed out, the
> resulting update on the subscriber is done so that eventual triggers there
> will fire.
>
> We can add a configuration option, suppressing those updates, to the 2.1
> todo list. In the meantime, if that happens that much that it causes
> problems for you, it may be better to fix your application. Because your
> origin must suffer the same bloat.
>

True the master is also going to suffer the same bloat and it makes sense to
fix my application first.


Thanks,
Sivakumar.K
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20100818/5fe7dfe2/attachment.htm 

From stephane.schildknecht at postgresql.fr  Wed Aug 18 02:14:27 2010
From: stephane.schildknecht at postgresql.fr (=?ISO-8859-15?Q?=22St=E9phane_A=2E_Schildknecht=22?=)
Date: Wed, 18 Aug 2010 11:14:27 +0200
Subject: [Slony1-general] Known bug I missed ?
Message-ID: <4C6BA473.4020009@postgresql.fr>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi,

I tried to do a move set between two nodes, and I got something strange... All
my nodes became read only, having write-denying triggers sets on all tables.
At first glance, I could not see any error in slon logs.
In PG'log on the old master, I can see : LOG:  duration: 4262.644 ms
statement: select "_cluster".moveSet(1, 1);
Nothing on the supposed new master.

I'm using slony 1.2.16 on postgreSQL 8.3, so I wanted to know if that was a
known bug which may have been corrected since then, or if I should investigate
more deeply.

I'm aware I have to update slon, and knowing this could be the cause of the
misfunction discovered will certainly help updating :-)

Thnaks in advance.

Best regards,
- -- 
St?phane Schildknecht
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkxrpHIACgkQA+REPKWGI0GswACgiVpqWmtU1egdd4K1WJHrBi6O
jZwAn2gNvqBjj+8Rn9ik9wVZIwrg0DBo
=+8fi
-----END PGP SIGNATURE-----

From msteben at autorevenue.com  Wed Aug 18 13:12:24 2010
From: msteben at autorevenue.com (Mark Steben)
Date: Wed, 18 Aug 2010 16:12:24 -0400
Subject: [Slony1-general] recommendations for removing bloat
Message-ID: <20100818201239.B40AC290C1E@main.slony.info>

Hello, 

We are running a Linux Redhat system and running a postgres 8.3.7 
Database.  We are also running slony 1.2.21 with a simple 1 master -1 slave
Configuration.  We wish to delete older inactive data from our largest
table, the end result will be dropping from 380 million rows and 2.9 million
Pages to 290 million rows.  When I perform a vacuum full in test, the table
size Reduces to 2.2 million pages.  I would like this to be the end result,
The problem is the vacuum full took nearly 36 hours to run.  I've also read
The cautions about long running transactions being a potential problem to
Slony.  

In test, I have successfully run the delete to remove the rows and
Currently have the table with the removed rows but the bloated page size.
My questions are:
  1. What better method other than VACUUM FULL is there to rid myself of
      The bloat and,
  2. How can I make this method play nice with slony?

Thank you for your time,
 

Mark Steben?|?Database Administrator?
@utoRevenue? - "Keeping Customers Close"?
95D Ashley Ave, West Springfield, MA 01089 
413.243.4800 x1512 (Phone) |413.732-1824 (Fax) 
@utoRevenue is a registered trademark and a division of Dominion
Enterprises?
?




From peter.geoghegan86 at gmail.com  Wed Aug 18 13:35:47 2010
From: peter.geoghegan86 at gmail.com (Peter Geoghegan)
Date: Wed, 18 Aug 2010 21:35:47 +0100
Subject: [Slony1-general] recommendations for removing bloat
In-Reply-To: <20100818201239.B40AC290C1E@main.slony.info>
References: <20100818201239.B40AC290C1E@main.slony.info>
Message-ID: <AANLkTimnBB0pi4fTFJcPsF22-K2Rhhe_AbS=qK1xmyL7@mail.gmail.com>

Hello,

I think you should read the following article about VACUUM FULL before
embarking on this:

http://it.toolbox.com/blogs/database-soup/getting-rid-of-vacuum-full-feedback-needed-33959

-- 
Regards,
Peter Geoghegan

From ajs at crankycanuck.ca  Wed Aug 18 13:39:11 2010
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Wed, 18 Aug 2010 16:39:11 -0400
Subject: [Slony1-general] recommendations for removing bloat
In-Reply-To: <20100818201239.B40AC290C1E@main.slony.info>
References: <20100818201239.B40AC290C1E@main.slony.info>
Message-ID: <20100818203911.GA94188@shinkuro.com>

On Wed, Aug 18, 2010 at 04:12:24PM -0400, Mark Steben wrote:
> table, the end result will be dropping from 380 million rows and 2.9 million
> Pages to 290 million rows.  When I perform a vacuum full in test, the table
> size Reduces to 2.2 million pages.  I would like this to be the end result,

Are you suggesting that the table will get that much smaller and never grow?

A

-- 
Andrew Sullivan
ajs at crankycanuck.ca

From cbbrowne at ca.afilias.info  Wed Aug 18 15:15:46 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed, 18 Aug 2010 18:15:46 -0400
Subject: [Slony1-general] recommendations for removing bloat
In-Reply-To: <20100818201239.B40AC290C1E@main.slony.info> (Mark Steben's
	message of "Wed, 18 Aug 2010 16:12:24 -0400")
References: <20100818201239.B40AC290C1E@main.slony.info>
Message-ID: <87y6c3ftyl.fsf@cbbrowne.afilias-int.info>

"Mark Steben" <msteben at autorevenue.com> writes:
> We are running a Linux Redhat system and running a postgres 8.3.7 
> Database.  We are also running slony 1.2.21 with a simple 1 master -1 slave
> Configuration.  We wish to delete older inactive data from our largest
> table, the end result will be dropping from 380 million rows and 2.9 million
> Pages to 290 million rows.  When I perform a vacuum full in test, the table
> size Reduces to 2.2 million pages.  I would like this to be the end result,
> The problem is the vacuum full took nearly 36 hours to run.  I've also read
> The cautions about long running transactions being a potential problem to
> Slony.  
>
> In test, I have successfully run the delete to remove the rows and
> Currently have the table with the removed rows but the bloated page size.
> My questions are:
>   1. What better method other than VACUUM FULL is there to rid myself of
>       The bloat and,
>   2. How can I make this method play nice with slony?
>
> Thank you for your time,

CLUSTER is usually the relevant alternative to VACUUM FULL.  It has the
demerit that it doubles the size of the data, but it essentially
simultaneously does a reindex on all tables, so you're not left (as is
the case after VACUUM FULL) with a "clean" table, but indexes that are
in pretty bad shape.

It'll still run similarly long to VACUUM FULL.

By the way, I'm going to assume that the table undergoing this
maintenance is one which the application isn't presently adding to.  

If it is, then there's not much of a Slony-I issue - the CLUSTER/VACUUM
FULL will lock the table, blocking your application from doing work, so
that Slony-I won't have any work to do during that period.  :-) But I
suspect this isn't the case; a 36 hour outage seems more than
allowable...

If you've got a 36 hour transaction running, and the application *is*
active, then you'll surely want Slony-I to have a *way* fewer SYNCs, as
the larger the set of those, the more data just can't get cleared out,
and the worse performance is likely to get.

It would seem helpful to increase the sync timeout intervals:

{~}    slon -h
2010-08-18 18:05:57 EDTCONFIG main: slon version 2.1.0 starting up
usage: slon [options] clustername conninfo

Options:
    -h                    print usage message and exit
    -v                    print version and exit
    -d <debuglevel>       verbosity of logging (1..4)
    -s <milliseconds>     SYNC check interval (default 10000)
    -t <milliseconds>     SYNC interval timeout (default 60000)
    -o <milliseconds>     desired subscriber SYNC processing time
    -g <num>              maximum SYNC group size (default 6)
    -c <num>              how often to vacuum in cleanup cycles
    -p <filename>         slon pid file
    -f <filename>         slon configuration file
    -a <directory>        directory to store SYNC archive files
    -x <command>          program to run after writing archive file
    -q <num>              Terminate when this node reaches # of SYNCs
    -r <num>              # of syncs for -q option
    -l <interval>         this node should lag providers by this interval

In particular, the two values you'd fiddle with are the "-s" and "-t"
ones.

The default is to consider generating a SYNC every 10 seconds (-s
10000); I'd suggest increasing that to once a minute, or more, so that
there's not a glut of tens of thousands of SYNCs being looked at
continually.  The "-t" value needs to be higher than the "-s" value.

If you set "-s 180000 -t 180000", then there'll be a SYNC every 3
minutes, and, after 36 hours, that adds to just 720 SYNCs to be
reconsidering, which isn't over-gigantic.

You may want to simply open a psql session and type "BEGIN;", and leave
it open for a while, and watch to see if there are any of the tables
that bloat up notably heavily.  

pg_listener is the "usual suspect", and the fact that the above config
change reduces the number of SYNCs, and the number of times event
requests are raised, should diminish the bloat of dead tuples there.
It'll bloat a bit, but by cutting down on SYNCs, it won't be zillions of
dead tuples waiting for that VACUUM FULL/CLUSTER to end.
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From cbbrowne at gmail.com  Wed Aug 18 18:40:08 2010
From: cbbrowne at gmail.com (Christopher Browne)
Date: Wed, 18 Aug 2010 21:40:08 -0400
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
Message-ID: <AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>

On Wed, Aug 18, 2010 at 7:39 PM, Selena Deckelmann
<selenamarie at gmail.com> wrote:
> Hi!
>
> Steve & Chris, please meet Robert! ?Robert hacks on stuff for
> Canonical, and is interested in handling DDL replication more nicely.
>
> In particular, this is something that is concerning:
>
> "Note: Actually, as of version 1.1.5 and later, this is NOT TRUE. The
> danger of someone making DDL changes that crosses replication sets
> seems sufficiently palpable that slon has been changed to lock ALL
> replicated tables, whether they are in the specified replication set
> or not."
>
> So -- questions are:
>
> * Can we reasonably disable this and restrict locking to a particular
> replication set, allowing savvy DBAs to employ the footgun when they
> really need it?
> * Is there an even more awesome possibility of extending Slony
> (possibly funded!) to manage locks more politely, and only lock
> relations that actually need to be locked?
>
> And I may have mis-stated Robert's questions, so I leave it to him to
> correct whatever I got wrong.

In version 2, the locking is exceedingly less restricting, to the
point of there being a possible problem :-(.
<http://bugs.slony.info/bugzilla/show_bug.cgi?id=137>

Steve, Jan Wieck, and I have been chatting about this over the last
couple weeks, which is where the comments on that bug #137 have come
from. ?(And thus, there couldn't be a more ideal time for extra eyes
to be in on the conversation.)

Where Jan's leaning comes in the comment here:
------
To fix this, slonik needs to issue LOCK TABLE statements right after "begin;".
That way, it will wait until all conflicting transactions have committed before
generating its own snapshot.

We need new syntax to add this information to the EXECUTE SCRIPT command and it
will be the responsibility of the user to provide the list of tables to lock.
------

So, in 1.2, things are "too locked down," in 2.0, things are
"insufficiently locked down" (which I should observe we *THOUGHT* was
a feature, not noticing this particular downside), and it's a pretty
good time for there to be a conversation about how to handle this in
what's probably version 2.1.

I suggest taking this conversation over to the mailing list, probably
slony1-general (http://lists.slony.info/mailman/listinfo).

The "magical answer" would be to have an oracle (a computer science
notion of a possibly-nonexistent machine that can answer particular
questions) that would tell us what tables need to be locked in order
to run the DDL. ?Unfortunately, since the DDL might include stored
procedures that can run arbitrary dynamic statements, this would need
to be a Magical Oracle indeed.

At any rate, this is a fine conversation to hold, and who does the
work is rather less important than that there be a meaningful
discussion, ideally, on the mailing list, as that gets the right sorts
of eyes on it.
--
http://linuxfinances.info/info/linuxdistributions.html

From JanWieck at Yahoo.com  Thu Aug 19 11:21:15 2010
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Thu, 19 Aug 2010 14:21:15 -0400
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>
Message-ID: <4C6D761B.40505@Yahoo.com>

On 8/18/2010 9:40 PM, Christopher Browne wrote:
> Where Jan's leaning comes in the comment here:
> ------
> To fix this, slonik needs to issue LOCK TABLE statements right after "begin;".
> That way, it will wait until all conflicting transactions have committed before
> generating its own snapshot.
> 
> We need new syntax to add this information to the EXECUTE SCRIPT command and it
> will be the responsibility of the user to provide the list of tables to lock.

An alternative to this would be to have EXECUTE SCRIPT parse the DDL 
script a little deeper, executing all LOCK TABLE statements at the 
beginning, before creating the SYNC that contains all DML before the DDL.

This way we would not need to change the EXECUTE SCRIPT syntax at all.


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From selenamarie at gmail.com  Thu Aug 19 11:14:36 2010
From: selenamarie at gmail.com (Selena Deckelmann)
Date: Thu, 19 Aug 2010 11:14:36 -0700
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <4C6D761B.40505@Yahoo.com>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>
	<4C6D761B.40505@Yahoo.com>
Message-ID: <AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>

On Thu, Aug 19, 2010 at 11:21 AM, Jan Wieck <JanWieck at yahoo.com> wrote:
> On 8/18/2010 9:40 PM, Christopher Browne wrote:
>> Where Jan's leaning comes in the comment here:
>> ------
>> To fix this, slonik needs to issue LOCK TABLE statements right after "begin;".
>> That way, it will wait until all conflicting transactions have committed before
>> generating its own snapshot.
>>
>> We need new syntax to add this information to the EXECUTE SCRIPT command and it
>> will be the responsibility of the user to provide the list of tables to lock.
>
> An alternative to this would be to have EXECUTE SCRIPT parse the DDL
> script a little deeper, executing all LOCK TABLE statements at the
> beginning, before creating the SYNC that contains all DML before the DDL.
>
> This way we would not need to change the EXECUTE SCRIPT syntax at all.

That was the suggestion I was going to make!

Its sort of the inverse of how the executor treats EXPLAIN.. maybe? :)

-selena


-- 
http://chesnok.com/daily - me

From cbbrowne at ca.afilias.info  Thu Aug 19 11:58:04 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu, 19 Aug 2010 14:58:04 -0400
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>
	(Selena Deckelmann's message of "Thu, 19 Aug 2010 11:14:36 -0700")
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>
	<4C6D761B.40505@Yahoo.com>
	<AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>
Message-ID: <8762z6mnur.fsf@cbbrowne.afilias-int.info>

Selena Deckelmann <selenamarie at gmail.com> writes:
> On Thu, Aug 19, 2010 at 11:21 AM, Jan Wieck <JanWieck at yahoo.com> wrote:
>> On 8/18/2010 9:40 PM, Christopher Browne wrote:
>>> Where Jan's leaning comes in the comment here:
>>> ------
>>> To fix this, slonik needs to issue LOCK TABLE statements right after "begin;".
>>> That way, it will wait until all conflicting transactions have committed before
>>> generating its own snapshot.
>>>
>>> We need new syntax to add this information to the EXECUTE SCRIPT command and it
>>> will be the responsibility of the user to provide the list of tables to lock.
>>
>> An alternative to this would be to have EXECUTE SCRIPT parse the DDL
>> script a little deeper, executing all LOCK TABLE statements at the
>> beginning, before creating the SYNC that contains all DML before the DDL.
>>
>> This way we would not need to change the EXECUTE SCRIPT syntax at
>> all.

True enough, and it can always be handled (from a DBA's perspective) as
a single statement:

LOCK [optional TABLE] [optional ONLY] t1,t2,t3,t4,...t99;

The "simplest" rule would be that if the DDL begins with
"[Ll][Oo][Cc][Kk]", then the first statement gets pulled off and
executed first.

It's not *much* of an extension of that (e.g. - more complicated, but
not hideously so) to notice all leading LOCK statements.  (e.g. - as
soon as we find a statement that isn't a LOCK, we're done).

It doesn't require a new parser, as the one already implemented in
src/parsestatements already does the heavy lifting.  We just need to
match individual statements against LOCK.

> That was the suggestion I was going to make!
>
> Its sort of the inverse of how the executor treats EXPLAIN.. maybe? :)
>
> -selena

To Selena's comments, this isn't a panacea; unlike EXPLAIN, this doesn't
involve any deep parsing of the statements.  The parsing that we do (see
http://git.postgresql.org/gitweb?p=slony1-engine.git;a=tree;f=src/parsestatements)
is merely to split apart the SQL statements.  

The parser doesn't know anything deeper than:
 - comments
 - the several quoting styles ('', "", $dollar$ dollar quoting $dollar$)
 - we use ";" to terminate statements

It doesn't go into the PG backend to parse semantics, so we can't
automatically infer what tables need to be locked.  That's because
statements may include:

  a) Stored procedures, which make such analysis look like the Halting
     Problem, but, to *really* kill the idea,

  b) There may be statements that may reference data not available to
     the parser.  (For a truly mean case, someone might call a stored
     function that does an RPC call to get a list of tables to process
     *from a remote server*.  A parser can't do anything about that!)

At any rate, I don't think it's too scary to extend the DDL code to
partition the DDL into two sets of statements:
  - Prefix section, consisting  of LOCK statements
  - The rest of the DDL

Actually, that suggests to me a *bit* more sophisticated semantics...

EXECUTE SCRIPT works two ways:

  1.  If the DDL begins with LOCK statements, then EXECUTE SCRIPT begins
  by locking those tables specified in the LOCK statements.

  2.  If the DDL begins without any LOCK statements, then EXECUTE SCRIPT
  assumes that *ALL* tables should be locked.

Thus:

 - If you're a smart DBA, who knows what tables need to be locked, you
   can specify them, as in case #1, leaving other tables unlocked, so
   concurrent updates can continue unabated.

 - If you didn't know what to lock, and didn't bother lock anything,
   Slony-I protects the data from error by automatically demanding locks
   on all the tables.

I'd be uncomfortable with the default being to "lock nothing," which
*could* be an option #3.
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From bnichols at ca.afilias.info  Thu Aug 19 12:27:43 2010
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Thu, 19 Aug 2010 15:27:43 -0400
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <8762z6mnur.fsf@cbbrowne.afilias-int.info>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>	<4C6D761B.40505@Yahoo.com>	<AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>
	<8762z6mnur.fsf@cbbrowne.afilias-int.info>
Message-ID: <4C6D85AF.1080003@ca.afilias.info>

  On 10-08-19 02:58 PM, Christopher Browne wrote:
> Actually, that suggests to me a *bit* more sophisticated semantics...
>
> EXECUTE SCRIPT works two ways:
>
>    1.  If the DDL begins with LOCK statements, then EXECUTE SCRIPT begins
>    by locking those tables specified in the LOCK statements.
>
>    2.  If the DDL begins without any LOCK statements, then EXECUTE SCRIPT
>    assumes that *ALL* tables should be locked.
>

+1 on the idea, -1 on the implementation.  I've never been a fan of 
magic values that implicitly takes a different code path based on the 
values detected like this.

I would much rather see an extra parameter added to the EXECUTE SCRIPT  
where you could specify a separate file containing the locks.  If you 
provide it, Slony uses those, if you don't, it uses it's default 
locking.  I think this is cleaner from the users perspective.
> Thus:
>
>   - If you're a smart DBA, who knows what tables need to be locked, you
>     can specify them, as in case #1, leaving other tables unlocked, so
>     concurrent updates can continue unabated.
>
>   - If you didn't know what to lock, and didn't bother lock anything,
>     Slony-I protects the data from error by automatically demanding locks
>     on all the tables.
>
> I'd be uncomfortable with the default being to "lock nothing," which
> *could* be an option #3.

Agreed - default of lock nothing is really bad and will end up with lots 
of people breaking their replication sets.


-- 
Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.



From scott.marlowe at gmail.com  Thu Aug 19 12:28:02 2010
From: scott.marlowe at gmail.com (Scott Marlowe)
Date: Thu, 19 Aug 2010 13:28:02 -0600
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <8762z6mnur.fsf@cbbrowne.afilias-int.info>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>
	<4C6D761B.40505@Yahoo.com>
	<AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>
	<8762z6mnur.fsf@cbbrowne.afilias-int.info>
Message-ID: <AANLkTi=sm=bhhOp1gzV-HEOJucOuUKXvMhP=F+cpdLyL@mail.gmail.com>

On Thu, Aug 19, 2010 at 12:58 PM, Christopher Browne
<cbbrowne at ca.afilias.info> wrote:

Just a data point to add here.  When I had 50k+ objects on my source
database, only 1k or so of which were under slony replication and in
the same set, each lock table issued by slony 1.2.x would take about
45 to 60 seconds.  I'd watch what was going on in pg_stat_activity and
see lots of references to all the tables that were NOT in the
replication set going by in whatever function it was slony was using
to lock its tables.  This meant that doing ddl on the source database
took about 60*1000 seconds or around 16 hours.

Moving those extra 50k+ objects to a destination slony member removed
the long wait and now ddl changes now happen in seconds, or at most
minutes.

From cbbrowne at ca.afilias.info  Thu Aug 19 14:29:09 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu, 19 Aug 2010 17:29:09 -0400
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <4C6D85AF.1080003@ca.afilias.info> (Brad Nicholson's message of
	"Thu, 19 Aug 2010 15:27:43 -0400")
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>
	<4C6D761B.40505@Yahoo.com>
	<AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>
	<8762z6mnur.fsf@cbbrowne.afilias-int.info>
	<4C6D85AF.1080003@ca.afilias.info>
Message-ID: <87zkwil2ai.fsf@cbbrowne.afilias-int.info>

Brad Nicholson <bnichols at ca.afilias.info> writes:
>  On 10-08-19 02:58 PM, Christopher Browne wrote:
>> Actually, that suggests to me a *bit* more sophisticated semantics...
>>
>> EXECUTE SCRIPT works two ways:
>>
>>    1.  If the DDL begins with LOCK statements, then EXECUTE SCRIPT begins
>>    by locking those tables specified in the LOCK statements.
>>
>>    2.  If the DDL begins without any LOCK statements, then EXECUTE SCRIPT
>>    assumes that *ALL* tables should be locked.
>>
>
> +1 on the idea, -1 on the implementation.  I've never been a fan of
> magic values that implicitly takes a different code path based on the
> values detected like this.
>
> I would much rather see an extra parameter added to the EXECUTE SCRIPT
> where you could specify a separate file containing the locks.  If you
> provide it, Slony uses those, if you don't, it uses it's default
> locking.  I think this is cleaner from the users perspective.

Here are a couple approaches to specify the locking, which includes, I
think, what you suggest:

  3.  An extra parameter to EXECUTE SCRIPT is a quoted comma-separated
      list of the IDs (as in sl_table.tab_id) of tables to be locked.

      execute script (set id=1, filename='/tmp/ddl-script.sql',
                      event node=3, tables to lock='1,2,17,29,35');

      While this is somewhat nice in the sense that we can validate (and
      raise errors, if invalid) that the tables being locked are
      legitimate ones, the table IDs aren't the most obvious thing in
      the world to look up.

  4.  An extra parameter to EXECUTE SCRIPT indicates the filename of
      a file containing the LOCK TABLE requests.

      execute script (set id=1, filename='/tmp/ddl-script.sql', 
                      event node=3, lockfile='/tmp/locks.sql');

      I think this is more or less what you're suggesting, and it seems
      fine to me.  

I think I like "#4" the best of any of the options, thus far.  I'm not
sure Jan/Steve have seen them, so it's premature to treat it as
"decided."

>> Thus:
>>
>>   - If you're a smart DBA, who knows what tables need to be locked, you
>>     can specify them, as in case #1, leaving other tables unlocked, so
>>     concurrent updates can continue unabated.
>>
>>   - If you didn't know what to lock, and didn't bother lock anything,
>>     Slony-I protects the data from error by automatically demanding locks
>>     on all the tables.
>>
>> I'd be uncomfortable with the default being to "lock nothing," which
>> *could* be an option #3.
>
> Agreed - default of lock nothing is really bad and will end up with
> lots of people breaking their replication sets.

I'm pretty ok with *that* "magic behaviour" (e.g. - "specify nothing,
and Slony will lock everything.")
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From selenamarie at gmail.com  Thu Aug 19 14:33:45 2010
From: selenamarie at gmail.com (Selena Deckelmann)
Date: Thu, 19 Aug 2010 14:33:45 -0700
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <87zkwil2ai.fsf@cbbrowne.afilias-int.info>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>
	<4C6D761B.40505@Yahoo.com>
	<AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>
	<8762z6mnur.fsf@cbbrowne.afilias-int.info>
	<4C6D85AF.1080003@ca.afilias.info>
	<87zkwil2ai.fsf@cbbrowne.afilias-int.info>
Message-ID: <AANLkTikK+BTUWb_ZmfU8xMfRkvGvi7Nhnp86VS-E5yS6@mail.gmail.com>

Hi!

On Thu, Aug 19, 2010 at 2:29 PM, Christopher Browne
<cbbrowne at ca.afilias.info> wrote:

> ?3. ?An extra parameter to EXECUTE SCRIPT is a quoted comma-separated
> ? ? ?list of the IDs (as in sl_table.tab_id) of tables to be locked.
>
> ? ? ?execute script (set id=1, filename='/tmp/ddl-script.sql',
> ? ? ? ? ? ? ? ? ? ? ?event node=3, tables to lock='1,2,17,29,35');
>
> ? ? ?While this is somewhat nice in the sense that we can validate (and
> ? ? ?raise errors, if invalid) that the tables being locked are
> ? ? ?legitimate ones, the table IDs aren't the most obvious thing in
> ? ? ?the world to look up.
>
> ?4. ?An extra parameter to EXECUTE SCRIPT indicates the filename of
> ? ? ?a file containing the LOCK TABLE requests.
>
> ? ? ?execute script (set id=1, filename='/tmp/ddl-script.sql',
> ? ? ? ? ? ? ? ? ? ? ?event node=3, lockfile='/tmp/locks.sql');
>
> ? ? ?I think this is more or less what you're suggesting, and it seems
> ? ? ?fine to me.
>
> I think I like "#4" the best of any of the options, thus far. ?I'm not
> sure Jan/Steve have seen them, so it's premature to treat it as
> "decided."

+1 to option 4. That seems like the most humane option.

It would be lovely if there was a way to get a list of potential locks
required by a script run, without actually taking the locks.

-selena

-- 
http://chesnok.com/daily - me

From guy.helmer at palisadesystems.com  Thu Aug 19 14:45:39 2010
From: guy.helmer at palisadesystems.com (Guy Helmer)
Date: Thu, 19 Aug 2010 16:45:39 -0500
Subject: [Slony1-general] Rapid-fire updates to table missed by slony
Message-ID: <6B66C950-980F-4608-844D-1A02A95C92CB@palisadesystems.com>

I'm seeing something odd occasionally on a fairly new slony1 (1.2.20) replication set involving one slave.  At times, the application inserts a record to a particular table, updates the record several times, and then deletes the record, sometimes in a fairly quick succession (but not always).

When I run the test-slony-state script, sometimes I find that the replication is failing, and when I look deeper, I find that Slony is having trouble replicating the changes to this table because of rows in the slave table that shouldn't be there.  After I manually remove the conflicting rows, Slony is then able to finish the backlogged replication.

Is there anything in particular I should look for in the log file prior to this problem?

Guy

--------
This message has been scanned by ComplianceSafe, powered by Palisade's PacketSure.

From cbbrowne at ca.afilias.info  Thu Aug 19 14:51:14 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu, 19 Aug 2010 17:51:14 -0400
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <AANLkTikK+BTUWb_ZmfU8xMfRkvGvi7Nhnp86VS-E5yS6@mail.gmail.com>
	(Selena Deckelmann's message of "Thu, 19 Aug 2010 14:33:45 -0700")
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>
	<4C6D761B.40505@Yahoo.com>
	<AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>
	<8762z6mnur.fsf@cbbrowne.afilias-int.info>
	<4C6D85AF.1080003@ca.afilias.info>
	<87zkwil2ai.fsf@cbbrowne.afilias-int.info>
	<AANLkTikK+BTUWb_ZmfU8xMfRkvGvi7Nhnp86VS-E5yS6@mail.gmail.com>
Message-ID: <87vd76l19p.fsf@cbbrowne.afilias-int.info>

Selena Deckelmann <selenamarie at gmail.com> writes:
> It would be lovely if there was a way to get a list of potential locks
> required by a script run, without actually taking the locks.

Automatically, not so much.  To get the actual set of locks, it's pretty
much necessary to run the queries, which means that *before* you know
what locks to demand to run your queries, you *first* need to run the
queries to find the list of locks, which is the wrong order....

Fortunately, you may an excellent approximation (which should be good
enough for any but rather perverse situations) by doing a QA run (not in
production!) as follows:

   ---> You specify a blank file for /tmp/locks.sql, making sure
        everything doesn't automagically lock.

   ---> You add the following query into the end of /tmp/ddl-script.sql:

         select pid, mode, granted, locktype, relation into
         public.keep_locks from pg_locks where pid = pg_backend_pid();

That leaves "breadcrumbs" of what tables got locked, which can be
queried later, to come up with a lock list.

oxrsdb=# select nspname, relname, l.* from pg_class c, pg_namespace n, public.keep_locks l where c.oid = relation and n.oid = c.relnamespace;
  nspname   |        relname        |  pid  |        mode         | granted | locktype | relation
------------+-----------------------+-------+---------------------+---------+----------+----------
 public     | keep_locks            | 23459 | AccessExclusiveLock | t       | relation |   163662
 pg_catalog | pg_locks              | 23459 | AccessShareLock     | t       | relation |    10969
 pg_toast   | pg_toast_163662       | 23459 | ShareLock           | t       | relation |   163665
 pg_toast   | pg_toast_163662_index | 23459 | AccessExclusiveLock | t       | relation |   163667
(4 rows)

If there are crucial differences between the data QA and production,
then the list *could* be wrong, due to the DDL behaving differently.
That's an argument for realistic test environments, not for not doing
this.

More interpretation of that may give a more precise query; perhaps all
we need to worry about are the AccessExclusiveLock locks.  Need to think
about that more.
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From stuart at stuartbishop.net  Thu Aug 19 23:57:40 2010
From: stuart at stuartbishop.net (Stuart Bishop)
Date: Fri, 20 Aug 2010 13:57:40 +0700
Subject: [Slony1-general] Slony & Locking
In-Reply-To: <AANLkTik_VpFm4ctdTxvnai=W0pMQa7r5NFRvY0YK+zxf@mail.gmail.com>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTik_ebW=bMNiiR_-4EBuWdky1AvqEjB=oJ1EH3tN@mail.gmail.com>
	<BLU0-SMTP3474A1A93EADFC648FEA54AC9E0@phx.gbl>
	<AANLkTik_VpFm4ctdTxvnai=W0pMQa7r5NFRvY0YK+zxf@mail.gmail.com>
Message-ID: <AANLkTimkk3iN=gJUfPfvErbHL5_=wqU-dYmySys1b3f2@mail.gmail.com>

> Robert Collins wrote
>
>> To provide a little more context here; we take up to an hour to
>> gracefully quiesce all our DB clients, apply a DDL change, and bring
>> our systems back up. Thats a lot of downtime for something that we'd,
>> in principle, like to do when code changes are ready; because it takes
>> so long (vs say, 5-10 seconds) we need to schedule downtime weeks in
>> advance, and that pushes complexity into our development process as
>> well because we have to choose between several week latency, large
>> branches, or having two trunks (the one with the next rollout schema,
>> and the one with the current schema).
>
> I think you first need to figure out what slony version your going to be
> using. ?If you're using 2.0.x then you are not in bad shape. ? If you are
> using 1.2 then I think your efforts are better spent thinking about what can
> get you onto 2.0.

We just finished getting ourselves to 1.2.21 (from 1.2.15) as a step
in our Ubuntu 10.04 LTS (Lucid) and PostgreSQL 8.4 upgrades. Once we
are on Lucid, we can look at 2.0. Back at the dawn of time when this
process started, 2.0 wasn't stable enough for me and would have
involved back porting Debian experimental packages to both Lucid and
Ubuntu 8.04 LTS (Hardy).

> With 2.0.x ?you can do DDL changes to tables via execute script without any
> slony introduced locking. ?The caveat being that if your application is
> performing insert/update/delete operations on the tables your DDL is
> changing then you might be in trouble (see the bug # Chris referenced for
> details)

We previously had much worse locking problems we eventually fixed by
migrating one of our replication sets to separate hardware - Slony 1.2
locking all tables rather than just the tables in the replication set
I was messing with caused me great trauma (much more than just letting
me shoot myself in the foot if I was silly enough to mess with tables
I hadn't told slony I was messing with).


> Slony 2.0.x has no safeguard to prevent/detect this situation, for 2.1 we
> would like to introduce something to either detect the conflict or at least
> make it more obvious to the DBA but this hasn't been thought of yet.

So the problem with needing locks on busy tables is they might never
be granted. A busy table will always have several connections with
open transactions that have read from it, and the exclusive lock will
never be granted because there are always conflicting locks in the
way. I suspect this needs extensions to PostgreSQL, so we can request
an exclusive lock in such a way that requests for other locks are
blocked. This isn't a slony issue even - the same issue applies when I
ALTER TABLE in an busy non-replicated environment.

As a work around, maybe there should be some way for my application to
detect that Slony wants to open some locks and block? If slony grabbed
an exclusive advisory lock before grabbing its exclusive table locks,
and released it when the table locks are granted, my application could
simply attempt at the start of the transaction to grab the same
exclusive advisory lock and release it straight away.

I do like the idea (later in this thread) of me explicitly listing
which resources to lock. Pulled from the top of the DDL or specified
separately is fine by me.

If you want to make my life easier let me specify the DDL inline in
the slonik script rather than needing a separate file. Oh - and an
option to only echo DDL to stdout if it failed (my daily staging
rebuild logs are very noisy). And a pony.


-- 
Stuart Bishop <stuart at stuartbishop.net>
http://www.stuartbishop.net/

From byerley at spray.se  Fri Aug 20 06:07:24 2010
From: byerley at spray.se (=?iso-8859-1?Q?Henrik_Nystr=F6m?=)
Date: Fri, 20 Aug 2010 06:07:24 -0700
Subject: [Slony1-general] Replicate to different table name
Message-ID: <56C12845A0A9476D82FA1E58079DEDA2@mail2world.com>

Hi,

I'm new to slony and have a need that I can't find answer to if it's
possible.

What I have is 3 databases for logs on different servers (for different
products) where all databases and tables are named the same.

Can I change the destination table name for replication with slony?
In that the table "logs" are replicated to "logs_prodX" for each product
database.

from (server1) logdb.logs  to  logdb.logs_prod1
from (server2) logdb.logs  to  logdb.logs_prod2
from (server3) logdb.logs  to  logdb.logs_prod3

If it's possible could you please point me in the right direction.

/Henrik





<P><p><font face="Arial, Helvetica, sans-serif" size="2" style="font-size:13.5px">_______________________________________________________________<BR>Hitta k?rleken med hj?lp av v?rt matchningstest - <a href="http://spray.matchaffinity.se/?mtcmk=614114">Klicka h?r!</a></font>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20100820/22fd58cb/attachment-0001.htm 

From bnichols at ca.afilias.info  Fri Aug 20 06:41:32 2010
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Fri, 20 Aug 2010 09:41:32 -0400
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <87zkwil2ai.fsf@cbbrowne.afilias-int.info>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>	<4C6D761B.40505@Yahoo.com>	<AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>	<8762z6mnur.fsf@cbbrowne.afilias-int.info>	<4C6D85AF.1080003@ca.afilias.info>
	<87zkwil2ai.fsf@cbbrowne.afilias-int.info>
Message-ID: <4C6E860C.5030206@ca.afilias.info>

  On 10-08-19 05:29 PM, Christopher Browne wrote:
> Brad Nicholson<bnichols at ca.afilias.info>  writes:
>>   On 10-08-19 02:58 PM, Christopher Browne wrote:
>>> Actually, that suggests to me a *bit* more sophisticated semantics...
>>>
>>> EXECUTE SCRIPT works two ways:
>>>
>>>     1.  If the DDL begins with LOCK statements, then EXECUTE SCRIPT begins
>>>     by locking those tables specified in the LOCK statements.
>>>
>>>     2.  If the DDL begins without any LOCK statements, then EXECUTE SCRIPT
>>>     assumes that *ALL* tables should be locked.
>>>
>> +1 on the idea, -1 on the implementation.  I've never been a fan of
>> magic values that implicitly takes a different code path based on the
>> values detected like this.
>>
>> I would much rather see an extra parameter added to the EXECUTE SCRIPT
>> where you could specify a separate file containing the locks.  If you
>> provide it, Slony uses those, if you don't, it uses it's default
>> locking.  I think this is cleaner from the users perspective.
> Here are a couple approaches to specify the locking, which includes, I
> think, what you suggest:
>
>    3.  An extra parameter to EXECUTE SCRIPT is a quoted comma-separated
>        list of the IDs (as in sl_table.tab_id) of tables to be locked.
>
>        execute script (set id=1, filename='/tmp/ddl-script.sql',
>                        event node=3, tables to lock='1,2,17,29,35');
>
>        While this is somewhat nice in the sense that we can validate (and
>        raise errors, if invalid) that the tables being locked are
>        legitimate ones, the table IDs aren't the most obvious thing in
>        the world to look up.
>

If you ever need to lock tables that are not replicated, this approach 
won't work.

>    4.  An extra parameter to EXECUTE SCRIPT indicates the filename of
>        a file containing the LOCK TABLE requests.
>
>        execute script (set id=1, filename='/tmp/ddl-script.sql',
>                        event node=3, lockfile='/tmp/locks.sql');
>
>        I think this is more or less what you're suggesting, and it seems
>        fine to me.
>
> I think I like "#4" the best of any of the options, thus far.  I'm not
> sure Jan/Steve have seen them, so it's premature to treat it as
> "decided."
>

I like #4 as well.

-- 
Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.



From cbbrowne at ca.afilias.info  Fri Aug 20 08:20:26 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri, 20 Aug 2010 11:20:26 -0400
Subject: [Slony1-general] Replicate to different table name
In-Reply-To: <56C12845A0A9476D82FA1E58079DEDA2@mail2world.com> ("Henrik
	=?utf-8?Q?Nystr=C3=B6m=22's?= message of "Fri,
	20 Aug 2010 06:07:24 -0700")
References: <56C12845A0A9476D82FA1E58079DEDA2@mail2world.com>
Message-ID: <87r5htl39h.fsf@cbbrowne.afilias-int.info>

Henrik Nystr?m <byerley at spray.se> writes:
> I'm new to slony and have a need that I can't find answer to if it's possible.
>
> What I have is 3 databases for logs on different servers (for different
> products) where all databases and tables are named the same.
>
> Can I change the destination table name for replication with slony?
> In that the table "logs" are replicated to "logs_prodX" for each product
> database.
>
> from (server1) logdb.logs  to  logdb.logs_prod1
> from (server2) logdb.logs  to  logdb.logs_prod2
> from (server3) logdb.logs  to  logdb.logs_prod3
>
> If it's possible could you please point me in the right direction.

This is an idea about which developers have mused for some time now, but
it's not something that we've figured out how to implement.  

The name of the table is acquired from what is stored in sl_table on the
*provider* node.  Thus, if you fiddle with the contents of sl_table on
the provider, changing the table name (sl_table.tab_relname), then that
could do what you're looking for.

FYI, there's also a non-zero probability that I'm wrong there, and the
slon asks the *subscriber* for the table name.  If so, that's rather a
lot better, as it allows the cluster to remain comparatively stable in
the wake of this change.  Change the shape of the subscriptions and you
don't mess up that node 1 thinks it's "logdb.logs", node 2 thinks it's
"logdb.logs_prod1", and node 3 thinks it's "server1.logs_prod1".

How to configure it is the challenge, and how to manage name names
consistently if subscriptions get shifted around, is something nobody's
really figured out how to do.
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From greg at endpoint.com  Fri Aug 20 08:25:42 2010
From: greg at endpoint.com (Greg Sabino Mullane)
Date: Fri, 20 Aug 2010 11:25:42 -0400
Subject: [Slony1-general] Replicate to different table name
In-Reply-To: <56C12845A0A9476D82FA1E58079DEDA2@mail2world.com>
References: <56C12845A0A9476D82FA1E58079DEDA2@mail2world.com>
Message-ID: <20100820152542.GV9227@core.home>

> I'm new to slony and have a need that I can't find answer to if it's
> possible.
...
> Can I change the destination table name for replication with slony?
> In that the table "logs" are replicated to "logs_prodX" for each product
> database.
> 
> from (server1) logdb.logs  to  logdb.logs_prod1
> from (server2) logdb.logs  to  logdb.logs_prod2
> from (server3) logdb.logs  to  logdb.logs_prod3

Not possible. What you could do it create table logdb.logs_prod1 on 
server1, and then wrap it in a view named logdb.logs. Slony would see 
the underlying logs_prod1 table, but everyone else would simply see 
the view (with rules as needed if you want to insert without worrying 
about the real name)

-- 
Greg Sabino Mullane greg at endpoint.com
End Point Corporation
PGP Key: 0x14964AC8
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 163 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20100820/3f792ad6/attachment.pgp 

From vivek at khera.org  Fri Aug 20 08:30:36 2010
From: vivek at khera.org (Vick Khera)
Date: Fri, 20 Aug 2010 11:30:36 -0400
Subject: [Slony1-general] Rapid-fire updates to table missed by slony
In-Reply-To: <6B66C950-980F-4608-844D-1A02A95C92CB@palisadesystems.com>
References: <6B66C950-980F-4608-844D-1A02A95C92CB@palisadesystems.com>
Message-ID: <AANLkTimsCp7q9RGu3m6v2mtq9iAZKUrTafY6911X5vH8@mail.gmail.com>

On Thu, Aug 19, 2010 at 5:45 PM, Guy Helmer
<guy.helmer at palisadesystems.com> wrote:
> I'm seeing something odd occasionally on a fairly new slony1 (1.2.20) replication set involving one slave. ?At times, the application inserts a record to a particular table, updates the record several times, and then deletes the record, sometimes in a fairly quick succession (but not always).
>

FWIW, I have similar use cases and never observe any failure in the
synchronization.  Have you had any hardware failures?

From cbbrowne at ca.afilias.info  Fri Aug 20 08:44:34 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri, 20 Aug 2010 11:44:34 -0400
Subject: [Slony1-general] Slony & Locking
In-Reply-To: <AANLkTimkk3iN=gJUfPfvErbHL5_=wqU-dYmySys1b3f2@mail.gmail.com>
	(Stuart Bishop's message of "Fri, 20 Aug 2010 13:57:40 +0700")
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTik_ebW=bMNiiR_-4EBuWdky1AvqEjB=oJ1EH3tN@mail.gmail.com>
	<BLU0-SMTP3474A1A93EADFC648FEA54AC9E0@phx.gbl>
	<AANLkTik_VpFm4ctdTxvnai=W0pMQa7r5NFRvY0YK+zxf@mail.gmail.com>
	<AANLkTimkk3iN=gJUfPfvErbHL5_=wqU-dYmySys1b3f2@mail.gmail.com>
Message-ID: <87mxshl259.fsf@cbbrowne.afilias-int.info>

Stuart Bishop <stuart at stuartbishop.net> writes:
> As a work around, maybe there should be some way for my application to
> detect that Slony wants to open some locks and block? If slony grabbed
> an exclusive advisory lock before grabbing its exclusive table locks,
> and released it when the table locks are granted, my application could
> simply attempt at the start of the transaction to grab the same
> exclusive advisory lock and release it straight away.

That's an interesting thought.

I'll need to muse on it more.

The alternative I was thinking of was to write a stored function to use
in the "Lock section" of EXECUTE SCRIPT that would allow:
   SELECT claim_locks_with_extreme_prejudice(tab_schema, tab_name);

It would do something like the following (which isn't quite valid code)

 create function claim_locks_with_extreme_prejudice(tab_schema, tab_name)
 declare
    c_oid oid;
    c_gotit boolean;
 begin
    loop
        begin
            execute 'lock table ' || tab_schema || '.' || 'tab_name;';
            c_gotit := 't';
            return 't';
        exception
            when 'COULD_NOT_OBTAIN_LOCK';
            c_gotit := 'f';
            select c.oid into c_oid from pg_class c, pg_namespace n 
              where c.relname = tab_name and n.nspname = tab_schema
                    and n.oid = c.relnamespace;
            perform pg_terminate_backend(pid) from 
               (select pid from pg_locks where relation = c_oid and
                granted) as arnold;
        end;
        if c_gotit = 't' then
           exit;
        end if;
    end loop;
 end;

This function takes an exclusive lock on the requested table,
terminating any competing backends that get in its way.  Perhaps it's
unfriendly, but if you've declared an outage to your organization, then
it's not "out there" to say:

  - I declared my intentions and my needs
  - Y'all aren't following directions
  - If this takes a *long* time, then there will be greater
    inconveniences
  - You're terminated...

> I do like the idea (later in this thread) of me explicitly listing
> which resources to lock. Pulled from the top of the DDL or specified
> separately is fine by me.
>
> If you want to make my life easier let me specify the DDL inline in
> the slonik script rather than needing a separate file. Oh - and an
> option to only echo DDL to stdout if it failed (my daily staging
> rebuild logs are very noisy). And a pony.

Upthread, Brad Nicholson commended making the DDL separate, and I pretty
much agree.  It's logically quite separate from the main DDL.

As for echoing to STDOUT only on error, that may be what already
happens, unless I mussed with it (which may have happened ;-)).  I'm not
sure just now.  I'm not sure I like the idea of adding an option for
this; I prefer slonik to remain comparatively simple.  But it's not
purely about my preferences :-).

Feel free to raise bugs on the Bugzilla instance at slony.info.  That
doesn't necessarily mean they'll be accepted and fixed as requested, but
you'll certainly have better luck having things not be missed from some
corner of an email message if they're tracked somewhere that has status
:-).
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From bnichols at ca.afilias.info  Fri Aug 20 10:21:16 2010
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Fri, 20 Aug 2010 13:21:16 -0400
Subject: [Slony1-general] Slony & Locking
In-Reply-To: <87mxshl259.fsf@cbbrowne.afilias-int.info>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>	<AANLkTik_ebW=bMNiiR_-4EBuWdky1AvqEjB=oJ1EH3tN@mail.gmail.com>	<BLU0-SMTP3474A1A93EADFC648FEA54AC9E0@phx.gbl>	<AANLkTik_VpFm4ctdTxvnai=W0pMQa7r5NFRvY0YK+zxf@mail.gmail.com>	<AANLkTimkk3iN=gJUfPfvErbHL5_=wqU-dYmySys1b3f2@mail.gmail.com>
	<87mxshl259.fsf@cbbrowne.afilias-int.info>
Message-ID: <4C6EB98C.5040505@ca.afilias.info>

  On 10-08-20 11:44 AM, Christopher Browne wrote:
> Stuart Bishop<stuart at stuartbishop.net>  writes:
>> As a work around, maybe there should be some way for my application to
>> detect that Slony wants to open some locks and block? If slony grabbed
>> an exclusive advisory lock before grabbing its exclusive table locks,
>> and released it when the table locks are granted, my application could
>> simply attempt at the start of the transaction to grab the same
>> exclusive advisory lock and release it straight away.
> That's an interesting thought.
>
> I'll need to muse on it more.
>
> The alternative I was thinking of was to write a stored function to use
> in the "Lock section" of EXECUTE SCRIPT that would allow:
>     SELECT claim_locks_with_extreme_prejudice(tab_schema, tab_name);
>
> It would do something like the following (which isn't quite valid code)
>
>   create function claim_locks_with_extreme_prejudice(tab_schema, tab_name)
>   declare
>      c_oid oid;
>      c_gotit boolean;
>   begin
>      loop
>          begin
>              execute 'lock table ' || tab_schema || '.' || 'tab_name;';
>              c_gotit := 't';
>              return 't';
>          exception
>              when 'COULD_NOT_OBTAIN_LOCK';
>              c_gotit := 'f';
>              select c.oid into c_oid from pg_class c, pg_namespace n
>                where c.relname = tab_name and n.nspname = tab_schema
>                      and n.oid = c.relnamespace;
>              perform pg_terminate_backend(pid) from
>                 (select pid from pg_locks where relation = c_oid and
>                  granted) as arnold;
>          end;
>          if c_gotit = 't' then
>             exit;
>          end if;
>      end loop;
>   end;
>
> This function takes an exclusive lock on the requested table,
> terminating any competing backends that get in its way.  Perhaps it's
> unfriendly, but if you've declared an outage to your organization, then
> it's not "out there" to say:
>

Maybe this is getting a bit parameter happy, but adding a FORCE option 
would give control to the operator allowing both.

It also touches on another case I was going to bring up - autovacuum.  
Even in a maintenance window, autovacuum may kick off an process tables, 
which can get in the way of DDL.  A way to automatically terminate the 
vacuums would be nice

>    - I declared my intentions and my needs
>    - Y'all aren't following directions
>    - If this takes a *long* time, then there will be greater
>      inconveniences
>    - You're terminated...
>

This would have to be 8.4 and greater though, and you need 
pg_terminate_backend to reliably get rid of connections.  
pg_cancel_backend is too soft of a touch, and lots of times it can't 
interrupt backends in a timely fashion.


-- 
Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.



From JanWieck at Yahoo.com  Fri Aug 20 00:31:54 2010
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Fri, 20 Aug 2010 03:31:54 -0400
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <AANLkTikK+BTUWb_ZmfU8xMfRkvGvi7Nhnp86VS-E5yS6@mail.gmail.com>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>	<4C6D761B.40505@Yahoo.com>	<AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>	<8762z6mnur.fsf@cbbrowne.afilias-int.info>	<4C6D85AF.1080003@ca.afilias.info>	<87zkwil2ai.fsf@cbbrowne.afilias-int.info>
	<AANLkTikK+BTUWb_ZmfU8xMfRkvGvi7Nhnp86VS-E5yS6@mail.gmail.com>
Message-ID: <4C6E2F6A.2040308@Yahoo.com>

On 8/19/2010 5:33 PM, Selena Deckelmann wrote:
> Hi!
> 
> On Thu, Aug 19, 2010 at 2:29 PM, Christopher Browne
> <cbbrowne at ca.afilias.info> wrote:
> 
>>  3.  An extra parameter to EXECUTE SCRIPT is a quoted comma-separated
>>      list of the IDs (as in sl_table.tab_id) of tables to be locked.
>>
>>      execute script (set id=1, filename='/tmp/ddl-script.sql',
>>                      event node=3, tables to lock='1,2,17,29,35');
>>
>>      While this is somewhat nice in the sense that we can validate (and
>>      raise errors, if invalid) that the tables being locked are
>>      legitimate ones, the table IDs aren't the most obvious thing in
>>      the world to look up.
>>
>>  4.  An extra parameter to EXECUTE SCRIPT indicates the filename of
>>      a file containing the LOCK TABLE requests.
>>
>>      execute script (set id=1, filename='/tmp/ddl-script.sql',
>>                      event node=3, lockfile='/tmp/locks.sql');
>>
>>      I think this is more or less what you're suggesting, and it seems
>>      fine to me.
>>
>> I think I like "#4" the best of any of the options, thus far.  I'm not
>> sure Jan/Steve have seen them, so it's premature to treat it as
>> "decided."
> 
> +1 to option 4. That seems like the most humane option.

Agreed, although I find "lockfile" a particularly bad choice for the 
syntax.

And for clarification, the default is to lock all tables in all sets, 
not ALL TABLES.


Jan


-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From community at chronicdb.com  Fri Aug 20 12:06:54 2010
From: community at chronicdb.com (ChronicDB Community Team)
Date: Fri, 20 Aug 2010 12:06:54 -0700
Subject: [Slony1-general] Slony & Locking
In-Reply-To: <87mxshl259.fsf@cbbrowne.afilias-int.info>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTik_ebW=bMNiiR_-4EBuWdky1AvqEjB=oJ1EH3tN@mail.gmail.com>
	<BLU0-SMTP3474A1A93EADFC648FEA54AC9E0@phx.gbl>
	<AANLkTik_VpFm4ctdTxvnai=W0pMQa7r5NFRvY0YK+zxf@mail.gmail.com>
	<AANLkTimkk3iN=gJUfPfvErbHL5_=wqU-dYmySys1b3f2@mail.gmail.com>
	<87mxshl259.fsf@cbbrowne.afilias-int.info>
Message-ID: <1282331214.15518.40.camel@localhost>

Hello,

We thought it may be helpful if we were to suggest looking at the
locking problem from a different angle. We see two main problems with
DDL schema changes.

On Fri, 2010-08-20 at 11:44 -0400, Christopher Browne wrote:
> Stuart Bishop <stuart at stuartbishop.net> writes:
> blocked. This isn't a slony issue even - the same issue applies when I
> ALTER TABLE in an busy non-replicated environment.

The first problem is that, as mentioned, an ALTER TABLE statement blocks
indefinitely a table. This is a known limitation of many database
management systems.

> > As a work around, maybe there should be some way for my application to
> > detect that Slony wants to open some locks and block? If slony grabbed
> > an exclusive advisory lock before grabbing its exclusive table locks,
> > and released it when the table locks are granted, my application could
> > simply attempt at the start of the transaction to grab the same
> > exclusive advisory lock and release it straight away.

At the table-lock level, this may be effective in many cases.

If this is looked at from a higher-level, a valuable requirement might
be to offer a solution that guarantees no active database connection is
blocked indefinitely. In other words, not to focus strictly on
addressing table locks.

> This function takes an exclusive lock on the requested table,
> terminating any competing backends that get in its way.  Perhaps it's
> unfriendly, but if you've declared an outage to your organization, then
> it's not "out there" to say:
> 
>   - I declared my intentions and my needs
>   - Y'all aren't following directions
>   - If this takes a *long* time, then there will be greater
>     inconveniences
>   - You're terminated...

Indeed, the problem is that there is no guarantee as to when the schema
change will complete. This is equivalent to downtime and is an expensive
solution. Terminating competing backends that attempt to acquire locks
does not solve the problem. However, it shouldn't be unreasonable to
declare the intention to update without downtime.


The second problem we see is that this approach requires defining a
switch-over point from which the old version of the application the
database serves will no longer work. In other words, it requires
coordination for updating both the database and client instances of the
application, which may be difficult to achieve. As already pointed out,
one effectively needs to declare an outage to their organization.

A more effective solution might be to allow both the old version and the
new version of the application to both work simultaneously, and manage
to allow the old version of the application to work without errors. This
could be achieved by rewriting live the queries issued by the old
version of the application to meet the semantics of the new schema.


We would like to describe the solution proposed by ChronicDB. We
envision a replication system that offers:
- Declaring an intention to update without downtime
- The guarantee no database connection will ever be unresponsive for
more than a user-configurable time period (e.g. less than 3 seconds).
- The capability of allowing the old version and the new version of the
application can run concurrently, indefinitely.

We would welcome feedback in improving this solution, in adding more
features, and in making it more accessible to PostgreSQL users. More
technical details can be found at:

http://chronicdb.com/technical_strengths




From ajs at crankycanuck.ca  Fri Aug 20 13:02:03 2010
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Fri, 20 Aug 2010 16:02:03 -0400
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <4C6E860C.5030206@ca.afilias.info>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>
	<4C6D761B.40505@Yahoo.com>
	<AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>
	<8762z6mnur.fsf@cbbrowne.afilias-int.info>
	<4C6D85AF.1080003@ca.afilias.info>
	<87zkwil2ai.fsf@cbbrowne.afilias-int.info>
	<4C6E860C.5030206@ca.afilias.info>
Message-ID: <20100820200202.GQ96071@shinkuro.com>

On Fri, Aug 20, 2010 at 09:41:32AM -0400, Brad Nicholson wrote:
>   On 10-08-19 05:29 PM, Christopher Browne wrote:
> >    4.  An extra parameter to EXECUTE SCRIPT indicates the filename of
> >        a file containing the LOCK TABLE requests.
> 
> I like #4 as well.

Me three.

Ay

-- 
Andrew Sullivan
ajs at crankycanuck.ca

From greg at endpoint.com  Fri Aug 20 13:35:17 2010
From: greg at endpoint.com (Greg Sabino Mullane)
Date: Fri, 20 Aug 2010 16:35:17 -0400
Subject: [Slony1-general] sl_nodelock worries
Message-ID: <20100820203516.GZ9227@core.home>

I just found a case where Slony was refusing to startup because 
of entries in the sl_nodelock table. Further investigation 
showed that an entry in sl_nodelock.nl_backendpid matched up 
to a *non* Slony backend[1] in Postgres (definitely non-Slony as 
it was an application level username and not 'postgres') Is Slony 
relying solely on the pid number here? I'm guessing that something 
killed Slony, and then some other process used that pid and was 
holding on to it when Slony was attempted to restart (which was a 
few hours later). Any other theories of what might have happened?

-- 
Greg Sabino Mullane greg at endpoint.com
End Point Corporation
PGP Key: 0x14964AC8
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 163 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20100820/7ad810ae/attachment.pgp 

From cbbrowne at ca.afilias.info  Fri Aug 20 14:28:11 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri, 20 Aug 2010 17:28:11 -0400
Subject: [Slony1-general] sl_nodelock worries
In-Reply-To: <20100820203516.GZ9227@core.home> (Greg Sabino Mullane's message
	of "Fri, 20 Aug 2010 16:35:17 -0400")
References: <20100820203516.GZ9227@core.home>
Message-ID: <87bp8xkm8k.fsf@cbbrowne.afilias-int.info>

Greg Sabino Mullane <greg at endpoint.com> writes:
> I just found a case where Slony was refusing to startup because of
> entries in the sl_nodelock table. Further investigation showed that an
> entry in sl_nodelock.nl_backendpid matched up to a *non* Slony
> backend[1] in Postgres (definitely non-Slony as it was an application
> level username and not 'postgres') Is Slony relying solely on the pid
> number here? I'm guessing that something killed Slony, and then some
> other process used that pid and was holding on to it when Slony was
> attempted to restart (which was a few hours later). Any other theories
> of what might have happened?

Hmm.  Yes, Slony is relying on the pid.  It's not checking for the user
name or such, as that's really not something it can determine.  You
could use different users, if you so wished.

Is it possible that there were a large number of processes generated
during those hours?  It isn't unusual for there to be ~32K entries in
the process table on Linux or such, so if something's spawning a lot of
processes, it wouldn't be difficult to have a duplicate after a few
hours.  Something forking processes per second would roll through a 32K
table in a little less than an hour.

Note that the *crucial* entry in sl_nodelock is the one with "nl_conncnt
= 0", as that's the one that is established to manage the local node,
and that's what'll cause the node to fall over.
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From JanWieck at Yahoo.com  Fri Aug 20 03:41:07 2010
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Fri, 20 Aug 2010 06:41:07 -0400
Subject: [Slony1-general] Slony & Locking
In-Reply-To: <1282331214.15518.40.camel@localhost>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>	<AANLkTik_ebW=bMNiiR_-4EBuWdky1AvqEjB=oJ1EH3tN@mail.gmail.com>	<BLU0-SMTP3474A1A93EADFC648FEA54AC9E0@phx.gbl>	<AANLkTik_VpFm4ctdTxvnai=W0pMQa7r5NFRvY0YK+zxf@mail.gmail.com>	<AANLkTimkk3iN=gJUfPfvErbHL5_=wqU-dYmySys1b3f2@mail.gmail.com>	<87mxshl259.fsf@cbbrowne.afilias-int.info>
	<1282331214.15518.40.camel@localhost>
Message-ID: <4C6E5BC3.4020106@Yahoo.com>

On 8/20/2010 3:06 PM, ChronicDB Community Team wrote:

> We would like to describe the solution proposed by ChronicDB. We
> envision a replication system that offers:
> - Declaring an intention to update without downtime
> - The guarantee no database connection will ever be unresponsive for
> more than a user-configurable time period (e.g. less than 3 seconds).
> - The capability of allowing the old version and the new version of the
> application can run concurrently, indefinitely.

Proposed?

Is there actually a technical design concept out there for the community 
to study and discuss?


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From cbbrowne at ca.afilias.info  Fri Aug 20 15:11:44 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri, 20 Aug 2010 18:11:44 -0400
Subject: [Slony1-general] Slony & Locking
In-Reply-To: <1282331214.15518.40.camel@localhost> (ChronicDB Community Team's
	message of "Fri, 20 Aug 2010 12:06:54 -0700")
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTik_ebW=bMNiiR_-4EBuWdky1AvqEjB=oJ1EH3tN@mail.gmail.com>
	<BLU0-SMTP3474A1A93EADFC648FEA54AC9E0@phx.gbl>
	<AANLkTik_VpFm4ctdTxvnai=W0pMQa7r5NFRvY0YK+zxf@mail.gmail.com>
	<AANLkTimkk3iN=gJUfPfvErbHL5_=wqU-dYmySys1b3f2@mail.gmail.com>
	<87mxshl259.fsf@cbbrowne.afilias-int.info>
	<1282331214.15518.40.camel@localhost>
Message-ID: <877hjlkk7z.fsf@cbbrowne.afilias-int.info>

ChronicDB Community Team <community at chronicdb.com> writes:
> We would welcome feedback in improving this solution, in adding more
> features, and in making it more accessible to PostgreSQL users. More
> technical details can be found at:
> http://chronicdb.com/technical_strengths

It's rather rude to side-track discussions on how to improve Slony-I on
our mailing list.

If you have suggestions as to how we might improve the locking behaviour
of Slony-I in ways that may be included into our code and documentation,
feel free to contribute.

If, however, you're interested in making your proprietary solution more
featureful, it is probably apropos to arrange to engage staff and/or
consultants to work on that.
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From stuart at stuartbishop.net  Fri Aug 20 22:10:34 2010
From: stuart at stuartbishop.net (Stuart Bishop)
Date: Sat, 21 Aug 2010 12:10:34 +0700
Subject: [Slony1-general] Slony & Locking
In-Reply-To: <87mxshl259.fsf@cbbrowne.afilias-int.info>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTik_ebW=bMNiiR_-4EBuWdky1AvqEjB=oJ1EH3tN@mail.gmail.com>
	<BLU0-SMTP3474A1A93EADFC648FEA54AC9E0@phx.gbl>
	<AANLkTik_VpFm4ctdTxvnai=W0pMQa7r5NFRvY0YK+zxf@mail.gmail.com>
	<AANLkTimkk3iN=gJUfPfvErbHL5_=wqU-dYmySys1b3f2@mail.gmail.com>
	<87mxshl259.fsf@cbbrowne.afilias-int.info>
Message-ID: <AANLkTinsK2j9kASODF12PoPUTFiDoShnZLxY40R9KbJE@mail.gmail.com>

On Fri, Aug 20, 2010 at 10:44 PM, Christopher Browne
<cbbrowne at ca.afilias.info> wrote:
> Stuart Bishop <stuart at stuartbishop.net> writes:
>> As a work around, maybe there should be some way for my application to
>> detect that Slony wants to open some locks and block? If slony grabbed
>> an exclusive advisory lock before grabbing its exclusive table locks,
>> and released it when the table locks are granted, my application could
>> simply attempt at the start of the transaction to grab the same
>> exclusive advisory lock and release it straight away.
>
> That's an interesting thought.
>
> I'll need to muse on it more.
>
> The alternative I was thinking of was to write a stored function to use
> in the "Lock section" of EXECUTE SCRIPT that would allow:
> ? SELECT claim_locks_with_extreme_prejudice(tab_schema, tab_name);
>
> It would do something like the following (which isn't quite valid code)
>
> ?create function claim_locks_with_extreme_prejudice(tab_schema, tab_name)

I think both would be needed to avoid scheduling outages. With the
lock approach, if my application cooperates and am careful with my
DDL, I can turn my scheduled downtime into a 20 second hiccup.
Terminating non-cooperating processes, such as autovacuum or that
pesky backup cronjob you forgot to disable, will ensure that what you
benchmarked as a 20 second hiccup on staging remains a 20 second
hiccup on production (when it counts). The advisory lock approach
makes it purely opt-in. I'd store the advisory lock number used as a
column on sl_set, default NULL,

(For the web application, we use the PostgreSQL statement timeout to
ensure transactions don't take more than 10 seconds, plus 10 seconds
DDL time == 20 seconds pause in their web requests and no error
messages == quick enough that users will not notice or blame their ISP
instead of us :-D )

If PostgreSQL grew a more aggressive locking mode, you wouldn't need
your application to cooperate at all - it would just block when slony
needs its locks. But that is at least 12 months and one volunteer
away.

> This function takes an exclusive lock on the requested table,
> terminating any competing backends that get in its way. ?Perhaps it's
> unfriendly, but if you've declared an outage to your organization, then
> it's not "out there" to say:

Just put in a check to not terminate other slony connections or you
might blow your own foot off :-) And a timeout - I'll like to give my
existing connections a few seconds grace before they are executed.


-- 
Stuart Bishop <stuart at stuartbishop.net>
http://www.stuartbishop.net/

From ssinger at ca.afilias.info  Mon Aug 23 06:55:07 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Mon, 23 Aug 2010 09:55:07 -0400
Subject: [Slony1-general] Slony & Locking
In-Reply-To: <AANLkTimkk3iN=gJUfPfvErbHL5_=wqU-dYmySys1b3f2@mail.gmail.com>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>	<AANLkTik_ebW=bMNiiR_-4EBuWdky1AvqEjB=oJ1EH3tN@mail.gmail.com>	<BLU0-SMTP3474A1A93EADFC648FEA54AC9E0@phx.gbl>	<AANLkTik_VpFm4ctdTxvnai=W0pMQa7r5NFRvY0YK+zxf@mail.gmail.com>
	<AANLkTimkk3iN=gJUfPfvErbHL5_=wqU-dYmySys1b3f2@mail.gmail.com>
Message-ID: <4C727DBB.3080607@ca.afilias.info>

Stuart Bishop wrote:
>> Robert Collins wrote
>>
> So the problem with needing locks on busy tables is they might never
> be granted. A busy table will always have several connections with
> open transactions that have read from it, and the exclusive lock will
> never be granted because there are always conflicting locks in the
> way. I suspect this needs extensions to PostgreSQL, so we can request
> an exclusive lock in such a way that requests for other locks are
> blocked. This isn't a slony issue even - the same issue applies when I
> ALTER TABLE in an busy non-replicated environment.
> 

It is more of an issue with needing a lock that has already been granted 
to another connection.  Say t1 (your application) needs locks on tables 
a and b, and t2 (your DDL script) needs locks on tables b and a.

t1: locks a
t2: locks b
t1: tries to lock b, it has to wait for t2
t2: tries to lock a but it has to wait for t1.

Sometimes postgres can detect these deadlocks but it can't always, in 
theory the lock dependency cycles can be rather complex.

The discussion elsewhere in the thread on solving this with query 
timeouts for application transactions sounds like it would work when 
combined with the 'lock file' option to execute script discussed.




> 
> If you want to make my life easier let me specify the DDL inline in
> the slonik script rather than needing a separate file. Oh - and an
> option to only echo DDL to stdout if it failed (my daily staging
> rebuild logs are very noisy). And a pony.
> 

The DDL echoing sounds do-able open a bug in the slony bugzilla for it.

I would also find SQL inline to the slonik script useful.  Open a bug 
for that as well but I'm not sure (without looking into it) how easy it 
will be to get the slonik parser to properly accept inline SQL.





-- 
Steve Singer
Afilias Canada
Data Services Developer
416-673-1142

From dba at richyen.com  Mon Aug 23 12:23:29 2010
From: dba at richyen.com (Richard Yen)
Date: Mon, 23 Aug 2010 12:23:29 -0700
Subject: [Slony1-general] logshipping files stop generating after DROP NODE?
Message-ID: <AF415126-2CDD-440F-A106-EC5D82A91FB2@richyen.com>

Hi everyone,

Wondering why the following would happen (running slony 2.0.3 on postgres 8.4.2 in a CentOS 2.6.18 box):

I have 1 provider (nodeid=5) and 3 subscribers (nodeids 2,3,4).  Sorry, long story, but it just happened that way that the nodeIDs are the way they are.

Node 2 generates the logshipping files (started with `slon -a <blah> ...`) and has been running for well over 6 months now, I think.  When I went to do a dump/reload on node 4 today, node 2 stopped generating files when I performed the DROP NODE for node 2.

In the logs for Node 2, I find the following:
> Aug 23 10:52:32 shipper_db slon[17121]: [1747401-1] 2010-08-23 10:52:32 PDT WARN   serialization problem updating sl_archive_counter: restarting slon
> Aug 23 10:52:32 shipper_db slon[17121]: [1747402-1] 2010-08-23 10:52:32 PDT CONFIG disableNode: no_id=3
> Aug 23 10:52:32 shipper_db slon[17121]: [1747403-1] 2010-08-23 10:52:32 PDT CONFIG storeListen: li_origin=4 li_receiver=2 li_provider=4
> Aug 23 10:52:32 shipper_db slon[17121]: [1747404-1] 2010-08-23 10:52:32 PDT CONFIG storeListen: li_origin=4 li_receiver=2 li_provider=5
> Aug 23 10:52:32 shipper_db slon[17121]: [1747405-1] 2010-08-23 10:52:32 PDT CONFIG storeListen: li_origin=6 li_receiver=2 li_provider=4
> Aug 23 10:52:32 shipper_db slon[17121]: [1747406-1] 2010-08-23 10:52:32 PDT CONFIG storeListen: li_origin=6 li_receiver=2 li_provider=5
> Aug 23 10:52:32 shipper_db slon[17121]: [1747407-1] 2010-08-23 10:52:32 PDT INFO   localListenThread: got restart notification
> Aug 23 10:52:32 shipper_db slon[17121]: [1747408-1] 2010-08-23 10:52:32 PDT CONFIG storeListen: li_origin=5 li_receiver=2 li_provider=5
> Aug 23 10:52:32 shipper_db slon[17121]: [1747409-1] 2010-08-23 10:52:32 PDT CONFIG remoteWorkerThread_5: update provider configuration
> Aug 23 10:52:32 shipper_db slon[25593]: [5-1] 2010-08-23 10:52:32 PDT INFO   slon: restart requested
> Aug 23 10:52:32 shipper_db slon[17121]: [1747410-1] 2010-08-23 10:52:32 PDT CONFIG remoteWorkerThread_5: added active set 1 to provider 5
> Aug 23 10:52:32 shipper_db slon[25593]: [6-1] 2010-08-23 10:52:32 PDT INFO   slon: notify worker process to shutdown
> Aug 23 10:52:32 shipper_db slon[17121]: [1747411-1] 2010-08-23 10:52:32 PDT INFO   remoteListenThread_4: disconnecting from 'dbname=tii host=db5.xxx.xxxxxxx.com port=5432
> Aug 23 10:52:32 shipper_db slon[17121]: [1747411-2]  user=slony password=xxxxxxx'
> Aug 23 10:52:32 shipper_db slon[17121]: [1747412-1] 2010-08-23 10:52:32 PDT CONFIG remoteWorkerThread_4: update provider configuration
> Aug 23 10:52:32 shipper_db slon[17121]: [1747413-1] 2010-08-23 10:52:32 PDT INFO   remoteWorkerThread_4: thread done
> Aug 23 10:52:32 shipper_db slon[17121]: [1747414-1] 2010-08-23 10:52:32 PDT DEBUG1 cleanupThread: thread done
> Aug 23 10:52:32 shipper_db slon[17121]: [1747415-1] 2010-08-23 10:52:32 PDT INFO   remoteListenThread_5: disconnecting from 'dbname=tii host=db6.xxx.xxxxxxx.com port=5432
> Aug 23 10:52:32 shipper_db slon[17121]: [1747415-2]  user=slony password=xxxxxxx'
> Aug 23 10:52:32 shipper_db slon[17121]: [1747416-1] 2010-08-23 10:52:32 PDT INFO   remoteListenThread_3: disconnecting from 'dbname=tii host=db4.xxx.xxxxxxx.com port=5432
> Aug 23 10:52:32 shipper_db slon[17121]: [1747416-2]  user=slony password=xxxxxxx'
> Aug 23 10:52:32 shipper_db slon[17121]: [1747417-1] 2010-08-23 10:52:32 PDT INFO   syncThread: thread done
> Aug 23 10:52:32 shipper_db slon[17121]: [1747418-1] 2010-08-23 10:52:32 PDT CONFIG remoteWorkerThread_5: update provider configuration
> Aug 23 10:52:32 shipper_db slon[17121]: [1747419-1] 2010-08-23 10:52:32 PDT CONFIG remoteWorkerThread_3: update provider configuration
> Aug 23 10:52:32 shipper_db slon[17121]: [1747420-1] 2010-08-23 10:52:32 PDT DEBUG1 remoteListenThread_4: thread done
> Aug 23 10:52:32 shipper_db slon[17121]: [1747421-1] 2010-08-23 10:52:32 PDT DEBUG1 remoteListenThread_5: thread done
> Aug 23 10:52:32 shipper_db slon[17121]: [1747422-1] 2010-08-23 10:52:32 PDT DEBUG1 remoteListenThread_3: thread done
> Aug 23 10:52:32 shipper_db slon[17121]: [1747423-1] 2010-08-23 10:52:32 PDT INFO   remoteWorkerThread_3: thread done
> Aug 23 10:52:32 shipper_db slon[17121]: [1747424-1] 2010-08-23 10:52:32 PDT CONFIG remoteWorkerThread_5: helper thread for provider 5 terminated
> Aug 23 10:52:32 shipper_db slon[17121]: [1747425-1] 2010-08-23 10:52:32 PDT CONFIG remoteWorkerThread_5: disconnecting from data provider 5
> Aug 23 10:52:32 shipper_db slon[17121]: [1747426-1] 2010-08-23 10:52:32 PDT INFO   remoteWorkerThread_5: thread done
> Aug 23 10:52:32 shipper_db slon[17121]: [1747427-1] 2010-08-23 10:52:32 PDT INFO   main: scheduler mainloop returned
> Aug 23 10:52:32 shipper_db slon[17121]: [1747428-1] 2010-08-23 10:52:32 PDT CONFIG main: wait for remote threads
> Aug 23 10:52:32 shipper_db slon[17121]: [1747429-1] 2010-08-23 10:52:32 PDT CONFIG main: done
> Aug 23 10:52:32 shipper_db slon[25593]: [7-1] 2010-08-23 10:52:32 PDT CONFIG slon: child terminated status: 0; pid: 17121, current worker pid: 17121
> Aug 23 10:52:32 shipper_db slon[25593]: [1-1] 2010-08-23 10:52:32 PDT CONFIG main: slon version 2.0.3 starting up
> Aug 23 10:52:32 shipper_db slon[25593]: [2-1] 2010-08-23 10:52:32 PDT INFO   slon: watchdog process started
> Aug 23 10:52:32 shipper_db slon[25593]: [3-1] 2010-08-23 10:52:32 PDT CONFIG slon: watchdog ready - pid = 25593

Once I did an ADD NODE to put Node 3 back in as a subscriber, Node 2 generated 2 logfiles and now it's not generating anymore.  Perhaps this is because no new events are being generated from Node 3 while the COPY SET is finishing up.  Also, these ten logfiles were empty:

> ------------------------------------------------------------------
> -- Slony-I log shipping archive
> -- Node 3, Event 5000000004
> ------------------------------------------------------------------
> set session_replication_role to replica;
> start transaction;
> select "_slony_schema".archiveTracking_offline('13801039', '2010-08-23 11:44:31.541321');
> -- end of log archiving header
> ------------------------------------------------------------------
> -- start of Slony-I data
> ------------------------------------------------------------------
> 
> ------------------------------------------------------------------
> -- End Of Archive Log
> ------------------------------------------------------------------
> commit;
> vacuum analyze "_slony_schema".sl_archive_tracking;


Would anyone be able to explain why dropping a subscriber from replication cause another subscriber to stop generating logfiles?  Or, for that matter, why the actions on another subscriber affects logshipping?

Regards,
--Richard

From ssinger at ca.afilias.info  Mon Aug 23 12:42:53 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Mon, 23 Aug 2010 15:42:53 -0400
Subject: [Slony1-general] Rapid-fire updates to table missed by slony
In-Reply-To: <6B66C950-980F-4608-844D-1A02A95C92CB@palisadesystems.com>
References: <6B66C950-980F-4608-844D-1A02A95C92CB@palisadesystems.com>
Message-ID: <4C72CF3D.2000007@ca.afilias.info>

Guy Helmer wrote:
> I'm seeing something odd occasionally on a fairly new slony1 (1.2.20) replication set involving one slave.  At times, the application inserts a record to a particular table, updates the record several times, and then deletes the record, sometimes in a fairly quick succession (but not always).
> 
> When I run the test-slony-state script, sometimes I find that the replication is failing, and when I look deeper, I find that Slony is having trouble replicating the changes to this table because of rows in the slave table that shouldn't be there.  After I manually remove the conflicting rows, Slony is then able to finish the backlogged replication.
> 
> Is there anything in particular I should look for in the log file prior to this problem?


Shortly after the problem happens your going to want to look at sl_log_1 
  sl_log_2 and sl_event to figure out what was going on.

You want to find the what sync the delete should have been part of, and 
what sync the failing insert was part of and try to figure out why the 
delete wasn't applied to the slave by the time it tried the insert.

You would also want to look at the logs slon generates to see if that 
sync did get applied and look in sl_confirm to verify that.


Honestly I am somewhat suspect that something else isn't going on I find 
your description somewhat hard reconcile with how things work.





> 
> Guy
> 
> --------
> This message has been scanned by ComplianceSafe, powered by Palisade's PacketSure.
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


-- 
Steve Singer
Afilias Canada
Data Services Developer
416-673-1142

From ssinger at ca.afilias.info  Mon Aug 23 12:50:08 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Mon, 23 Aug 2010 15:50:08 -0400
Subject: [Slony1-general] Known bug I missed ?
In-Reply-To: <4C6BA473.4020009@postgresql.fr>
References: <4C6BA473.4020009@postgresql.fr>
Message-ID: <4C72D0F0.9090203@ca.afilias.info>

St?phane A. Schildknecht wrote:

What you describe might not be a bug.

What should happen in a move set (at a high level) is

1. Slonik contacts the origin and executes moveSet()
2. moveSet() sets all the tables to read only
3. moveSet() creates a MOVE_SET event
4. moveSet() exists -- this is what you see in the log
5. The MOVE_SET event travels to subscribers through replication paths 
and these subscribers reconfigure themselves.  The new origin will 
reconfigure itself when it receives the MOVE_SET command as well.

The set isn't 'moved' until the move set command is confirmed by all nodes.




> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> Hi,
> 
> I tried to do a move set between two nodes, and I got something strange... All
> my nodes became read only, having write-denying triggers sets on all tables.
> At first glance, I could not see any error in slon logs.
> In PG'log on the old master, I can see : LOG:  duration: 4262.644 ms
> statement: select "_cluster".moveSet(1, 1);
> Nothing on the supposed new master.
> 
> I'm using slony 1.2.16 on postgreSQL 8.3, so I wanted to know if that was a
> known bug which may have been corrected since then, or if I should investigate
> more deeply.
> 
> I'm aware I have to update slon, and knowing this could be the cause of the
> misfunction discovered will certainly help updating :-)
> 
> Thnaks in advance.
> 
> Best regards,
> - -- 
> St?phane Schildknecht
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.10 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
> 
> iEYEARECAAYFAkxrpHIACgkQA+REPKWGI0GswACgiVpqWmtU1egdd4K1WJHrBi6O
> jZwAn2gNvqBjj+8Rn9ik9wVZIwrg0DBo
> =+8fi
> -----END PGP SIGNATURE-----
> _______________________________________________
> Slony1-general mailing list
> Slony1-general at lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


-- 
Steve Singer
Afilias Canada
Data Services Developer
416-673-1142

From dba at richyen.com  Mon Aug 23 13:02:08 2010
From: dba at richyen.com (Richard Yen)
Date: Mon, 23 Aug 2010 13:02:08 -0700
Subject: [Slony1-general] logshipping files stop generating after DROP
	NODE?
In-Reply-To: <AF415126-2CDD-440F-A106-EC5D82A91FB2@richyen.com>
References: <AF415126-2CDD-440F-A106-EC5D82A91FB2@richyen.com>
Message-ID: <D6FA2C36-CD2D-47D3-B080-B83B4D1991EF@richyen.com>

I think I have discovered more details regarding what happened.

After issuing DROP NODE, the master node (Node 5) was asked to restart, but it couldn't fully restart because of lock contention:

> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6960-1] 2010-08-23 10:52:31 PDT INFO   remoteWorkerThread_3: thread done
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6961-1] 2010-08-23 10:52:31 PDT INFO   localListenThread: got restart notification
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[5541]: [5-1] 2010-08-23 10:52:31 PDT INFO   slon: restart requested
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[5541]: [6-1] 2010-08-23 10:52:31 PDT INFO   slon: notify worker process to shutdown
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6962-1] 2010-08-23 10:52:31 PDT INFO   remoteListenThread_2: disconnecting from 'dbname=tii host=shipper_db.xxx.xxxxxxx.com port=5432
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6962-2]  user=slony password=xxxxxxx'
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6963-1] 2010-08-23 10:52:31 PDT INFO   main: scheduler mainloop returned
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6964-1] 2010-08-23 10:52:31 PDT CONFIG main: wait for remote threads
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6965-1] 2010-08-23 10:52:31 PDT INFO   syncThread: thread done
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6966-1] 2010-08-23 10:52:31 PDT DEBUG1 cleanupThread: thread done
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6967-1] 2010-08-23 10:52:31 PDT DEBUG1 remoteListenThread_2: thread done
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6968-1] 2010-08-23 10:52:31 PDT INFO   remoteListenThread_4: disconnecting from 'dbname=tii host=db5.xxx.xxxxxxx.com port=5432
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6968-2]  user=slony password=xxxxxxx'
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6969-1] 2010-08-23 10:52:31 PDT DEBUG1 remoteListenThread_4: thread done
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6970-1] 2010-08-23 10:52:31 PDT CONFIG remoteWorkerThread_4: update provider configuration
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6971-1] 2010-08-23 10:52:31 PDT INFO   remoteWorkerThread_4: thread done
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6972-1] 2010-08-23 10:52:31 PDT INFO   remoteListenThread_3: disconnecting from 'dbname=tii host=db4.xxx.xxxxxxx.com port=5432
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6972-2]  user=slony password=xxxxxxx'
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6973-1] 2010-08-23 10:52:31 PDT DEBUG1 remoteListenThread_3: thread done
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6974-1] 2010-08-23 10:52:31 PDT CONFIG remoteWorkerThread_2: update provider configuration
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6975-1] 2010-08-23 10:52:31 PDT INFO   remoteWorkerThread_2: thread done
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11953]: [6976-1] 2010-08-23 10:52:31 PDT CONFIG main: done
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[5541]: [7-1] 2010-08-23 10:52:31 PDT CONFIG slon: child terminated status: 0; pid: 11953, current worker pid: 11953
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[5541]: [1-1] 2010-08-23 10:52:31 PDT CONFIG main: slon version 2.0.3 starting up
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[5541]: [2-1] 2010-08-23 10:52:31 PDT INFO   slon: watchdog process started
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[5541]: [3-1] 2010-08-23 10:52:31 PDT CONFIG slon: watchdog ready - pid = 5541
> <snip (loading of config params)>
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[5541]: [4-1] 2010-08-23 10:52:31 PDT CONFIG slon: worker process created - pid = 19013
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [31-1] 2010-08-23 10:52:31 PDT CONFIG main: local node id = 5
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [32-1] 2010-08-23 10:52:31 PDT INFO   main: main process started
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [33-1] 2010-08-23 10:52:31 PDT CONFIG main: launching sched_start_mainloop
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [34-1] 2010-08-23 10:52:31 PDT CONFIG main: loading current cluster configuration
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [35-1] 2010-08-23 10:52:31 PDT CONFIG storeNode: no_id=2 no_comment='Node 2 - Base tii - Host shipper_db.xxx.xxxxxxx.com - Cluster
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [35-2]  slony_schema'
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [36-1] 2010-08-23 10:52:31 PDT CONFIG storeNode: no_id=4 no_comment='Node 4 - Base tii - Host db5.xxx.xxxxxxx.com - Cluster
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [36-2]  slony_schema'
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [37-1] 2010-08-23 10:52:31 PDT CONFIG storeNode: no_id=6 no_comment='<event pending>'
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [38-1] 2010-08-23 10:52:31 PDT CONFIG storePath: pa_server=2 pa_client=5 pa_conninfo="dbname=tii host=shipper_db.xxx.xxxxxxx.com
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [38-2]  port=5432 user=slony password=xxxxxxx" pa_connretry=10
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [39-1] 2010-08-23 10:52:31 PDT CONFIG storePath: pa_server=4 pa_client=5 pa_conninfo="dbname=tii host=db5.xxx.xxxxxxx.com
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [39-2]  port=5432 user=slony password=xxxxxxx" pa_connretry=10
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [40-1] 2010-08-23 10:52:31 PDT CONFIG storeListen: li_origin=2 li_receiver=5 li_provider=2
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [41-1] 2010-08-23 10:52:31 PDT CONFIG storeListen: li_origin=4 li_receiver=5 li_provider=4
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [42-1] 2010-08-23 10:52:31 PDT CONFIG storeListen: li_origin=4 li_receiver=5 li_provider=2
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [43-1] 2010-08-23 10:52:31 PDT CONFIG storeListen: li_origin=2 li_receiver=5 li_provider=4
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [44-1] 2010-08-23 10:52:31 PDT CONFIG storeSet: set_id=1 set_origin=5 set_comment='Tables in tii'
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [45-1] 2010-08-23 10:52:31 PDT CONFIG main: last local event sequence = 5037905941
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [46-1] 2010-08-23 10:52:31 PDT CONFIG main: configuration complete - starting threads
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [47-1] 2010-08-23 10:52:31 PDT INFO   localListenThread: thread starts
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11946]: [3034324-1] 2010-08-23 10:52:31 PDT DEBUG1 calc sync size - last time: 1 last length: 1000 ideal: 60 proposed size: 3
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11946]: [3034325-1] 2010-08-23 10:52:31 PDT DEBUG1 about to monitor_subscriber_query - pulling big actionid list for 5
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[11946]: [3034326-1] 2010-08-23 10:52:31 PDT INFO   remoteWorkerThread_5: syncing set 1 with 199 table(s) from provider 5
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [48-1] 2010-08-23 10:52:31 PDT CONFIG version for "dbname=tii host=db6.xxx.xxxxxxx.com port=5432 user=slony password=xxxxxxx"
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [48-2]  is 80402
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [49-1] 2010-08-23 10:52:31 PDT DEBUG1 local_listen "dbname=tii host=db6.xxx.xxxxxxx.com port=5432 user=slony
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [49-2]  password=xxxxxxx": backend pid = 14119
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [50-1] 2010-08-23 10:52:31 PDT FATAL  localListenThread: "select "_slony_schema".cleanupNodelock(); insert into "_slony_schema".sl_nodelock
> Aug 23 10:52:31 master-db.xxx.xxxxxxx.com slon[19013]: [50-2]  values (    5, 0, "pg_catalog".pg_backend_pid()); " - ERROR:  duplicate key value violates unique constraint "sl_nodelock-pkey"

Any ideas why we would reach this state?

Regards,
--Richard

From JanWieck at Yahoo.com  Mon Aug 23 15:41:16 2010
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Mon, 23 Aug 2010 18:41:16 -0400
Subject: [Slony1-general] Known bug I missed ?
In-Reply-To: <4C72D0F0.9090203@ca.afilias.info>
References: <4C6BA473.4020009@postgresql.fr> <4C72D0F0.9090203@ca.afilias.info>
Message-ID: <4C72F90C.5030903@Yahoo.com>

On 8/23/2010 3:50 PM, Steve Singer wrote:
> St?phane A. Schildknecht wrote:
> 
> What you describe might not be a bug.
> 
> What should happen in a move set (at a high level) is
> 
> 1. Slonik contacts the origin and executes moveSet()
> 2. moveSet() sets all the tables to read only

The tables were already read only prior to that. moveSet() only replaces 
the lockedSet trigger with the denyAccess trigger.


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From stephane.schildknecht at postgresql.fr  Tue Aug 24 01:34:32 2010
From: stephane.schildknecht at postgresql.fr (=?ISO-8859-15?Q?=22St=E9phane_A=2E_Schildknecht=22?=)
Date: Tue, 24 Aug 2010 10:34:32 +0200
Subject: [Slony1-general] Known bug I missed ?
In-Reply-To: <4C72D0F0.9090203@ca.afilias.info>
References: <4C6BA473.4020009@postgresql.fr> <4C72D0F0.9090203@ca.afilias.info>
Message-ID: <4C738418.4050004@postgresql.fr>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Le 23/08/2010 21:50, Steve Singer a ?crit :
> St?phane A. Schildknecht wrote:
> 
> What you describe might not be a bug.
> 
> What should happen in a move set (at a high level) is
> 
> 1. Slonik contacts the origin and executes moveSet()
> 2. moveSet() sets all the tables to read only
> 3. moveSet() creates a MOVE_SET event
> 4. moveSet() exists -- this is what you see in the log
> 5. The MOVE_SET event travels to subscribers through replication paths
> and these subscribers reconfigure themselves.  The new origin will
> reconfigure itself when it receives the MOVE_SET command as well.
> 
> The set isn't 'moved' until the move set command is confirmed by all nodes.

Hi Steve,

Thanks for your answer.

What really surprised me, is that I've already done such moves, and it was
always really quick. That time, after a couple of minutes, the situation still
remains with all tables in read-only on every nodes.
Maybe I should have waited for a longer piece of time...

Best regards,
St?phane Schildknecht
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkxzhBgACgkQA+REPKWGI0FZTACg3dkmEjthJPrYAFe9eBaJToyj
QecAn05VclS7a4ToT+FnzXzfCzdUqyA7
=OwH6
-----END PGP SIGNATURE-----

From ssinger at ca.afilias.info  Tue Aug 24 12:35:16 2010
From: ssinger at ca.afilias.info (Steve Singer)
Date: Tue, 24 Aug 2010 15:35:16 -0400
Subject: [Slony1-general] Platforms slony is used on
Message-ID: <4C741EF4.5070601@ca.afilias.info>


We've been wondering what platforms slony is actually being used on by 
people.

We are aware of

Linux (all sorts)
AIX
FreeBSD
Win32

Are there others?

If your using slony on a platform other than what I've listed above can 
you drop me an email (emailing the list or me privately are both fine)

Thanks




-- 
Steve Singer
Afilias Canada
Data Services Developer
416-673-1142

From ncslists at googlemail.com  Wed Aug 25 06:02:03 2010
From: ncslists at googlemail.com (Csaba Nagy)
Date: Wed, 25 Aug 2010 15:02:03 +0200
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <87vd76l19p.fsf@cbbrowne.afilias-int.info>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>
	<4C6D761B.40505@Yahoo.com>
	<AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>
	<8762z6mnur.fsf@cbbrowne.afilias-int.info>
	<4C6D85AF.1080003@ca.afilias.info>
	<87zkwil2ai.fsf@cbbrowne.afilias-int.info>
	<AANLkTikK+BTUWb_ZmfU8xMfRkvGvi7Nhnp86VS-E5yS6@mail.gmail.com>
	<87vd76l19p.fsf@cbbrowne.afilias-int.info>
Message-ID: <1282741323.3899.9.camel@pcd12478>

On Thu, 2010-08-19 at 17:51 -0400, Christopher Browne wrote:
> Selena Deckelmann <selenamarie at gmail.com> writes:
> > It would be lovely if there was a way to get a list of potential locks
> > required by a script run, without actually taking the locks.
> 
[snip]
> Fortunately, you may an excellent approximation (which should be good
> enough for any but rather perverse situations) by doing a QA run (not in
> production!) as follows:
[snip]
> If there are crucial differences between the data QA and production,
> then the list *could* be wrong, due to the DDL behaving differently.
> That's an argument for realistic test environments, not for not doing
> this.

What about running the locking test on an actual replica (and perhaps
inside a transaction which is rolled back at the end) ? For any sane DDL
which should replicate correctly that should take the same locks as on
the master, and if you stop the slon daemon for that replica (or execute
the test _via_ the slon daemon) it will also be sure not to deadlock.

Cheers,
Csaba.



From cbbrowne at ca.afilias.info  Wed Aug 25 09:13:24 2010
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed, 25 Aug 2010 12:13:24 -0400
Subject: [Slony1-general] Fwd: Slony & Locking
In-Reply-To: <1282741323.3899.9.camel@pcd12478> (Csaba Nagy's message of "Wed, 
	25 Aug 2010 15:02:03 +0200")
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTikMURGVhzWf1iXUafREHS65tW_1bwA1z6KQXF4u@mail.gmail.com>
	<4C6D761B.40505@Yahoo.com>
	<AANLkTik-6wNhT-yfdXSdbTmXnjGwPECjjmhjmNT=5n_J@mail.gmail.com>
	<8762z6mnur.fsf@cbbrowne.afilias-int.info>
	<4C6D85AF.1080003@ca.afilias.info>
	<87zkwil2ai.fsf@cbbrowne.afilias-int.info>
	<AANLkTikK+BTUWb_ZmfU8xMfRkvGvi7Nhnp86VS-E5yS6@mail.gmail.com>
	<87vd76l19p.fsf@cbbrowne.afilias-int.info>
	<1282741323.3899.9.camel@pcd12478>
Message-ID: <87y6buk6vv.fsf@cbbrowne.afilias-int.info>

Csaba Nagy <ncslists at googlemail.com> writes:
> On Thu, 2010-08-19 at 17:51 -0400, Christopher Browne wrote:
>> Selena Deckelmann <selenamarie at gmail.com> writes:
>> > It would be lovely if there was a way to get a list of potential locks
>> > required by a script run, without actually taking the locks.
>> 
> [snip]
>> Fortunately, you may an excellent approximation (which should be good
>> enough for any but rather perverse situations) by doing a QA run (not in
>> production!) as follows:
> [snip]
>> If there are crucial differences between the data QA and production,
>> then the list *could* be wrong, due to the DDL behaving differently.
>> That's an argument for realistic test environments, not for not doing
>> this.
>
> What about running the locking test on an actual replica (and perhaps
> inside a transaction which is rolled back at the end) ? For any sane DDL
> which should replicate correctly that should take the same locks as on
> the master, and if you stop the slon daemon for that replica (or execute
> the test _via_ the slon daemon) it will also be sure not to deadlock.

Sure, that would do the trick, and will be "sufficiently realistic" for
any but the most weirdly pathological sorts of DDL changes.  (Stuff that
would pretty much look like self-modifying code, and if you head down
that road, you can expect big trouble!) 

The other scenario where this is troublesome is the case where the
script includes a massive amount of DML work.  In that case, two
somewhat bad things happen:

  - It will take a long time to apply the DDL change.

  - When the DDL change gets rolled back, it leaves an enormous amount
    of trash to be vacuumed up afterwards.

That's not an argument against either the DDL+DML combination, just that
if you choose to do that sort of thing, you have to accept that it won't
be cheap.
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
Christopher Browne
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"

From stuart at stuartbishop.net  Wed Aug 25 20:26:58 2010
From: stuart at stuartbishop.net (Stuart Bishop)
Date: Thu, 26 Aug 2010 10:26:58 +0700
Subject: [Slony1-general] Slony & Locking
In-Reply-To: <4C727DBB.3080607@ca.afilias.info>
References: <AANLkTikkP=-hHX_rNoRcq23+euT2Ex2NNGEzekxKPfkX@mail.gmail.com>
	<AANLkTik9S0crKHdD-kXHeqsdh-N2BVMpDaFHLcvWA3X7@mail.gmail.com>
	<AANLkTik_ebW=bMNiiR_-4EBuWdky1AvqEjB=oJ1EH3tN@mail.gmail.com>
	<BLU0-SMTP3474A1A93EADFC648FEA54AC9E0@phx.gbl>
	<AANLkTik_VpFm4ctdTxvnai=W0pMQa7r5NFRvY0YK+zxf@mail.gmail.com>
	<AANLkTimkk3iN=gJUfPfvErbHL5_=wqU-dYmySys1b3f2@mail.gmail.com>
	<4C727DBB.3080607@ca.afilias.info>
Message-ID: <AANLkTinQO0+FxTE34m7WQY49=w_e3a=P4BXbo-Jq8don@mail.gmail.com>

On Mon, Aug 23, 2010 at 8:55 PM, Steve Singer <ssinger at ca.afilias.info> wrote:

> It is more of an issue with needing a lock that has already been granted to
> another connection. ?Say t1 (your application) needs locks on tables a and
> b, and t2 (your DDL script) needs locks on tables b and a.
>
> t1: locks a
> t2: locks b
> t1: tries to lock b, it has to wait for t2
> t2: tries to lock a but it has to wait for t1.
>
> Sometimes postgres can detect these deadlocks but it can't always, in theory
> the lock dependency cycles can be rather complex.
>
> The discussion elsewhere in the thread on solving this with query timeouts
> for application transactions sounds like it would work when combined with
> the 'lock file' option to execute script discussed.

I see. So even if PG grew more aggressive locking options, the
applications using the database would still have to cooperate. I'm
fine with that. For our rollouts, I'm expecting:

 - Background jobs stop running themselves before the rollout time.
 - Interactive systems promise short running transactions, and block
for slony lock requests at the start of a transaction.
 - A process is run after kicking off the slonik script to kill all
non-slony connections that we don't know are cooperating (a white list
of database user names in my case).

The suggestion to automatically kill processes with locks slony is
after would make that last stop unnecessary and would be friendlier.


> The DDL echoing sounds do-able open a bug in the slony bugzilla for it.
>
> I would also find SQL inline to the slonik script useful. ?Open a bug for
> that as well but I'm not sure (without looking into it) how easy it will be
> to get the slonik parser to properly accept inline SQL.

Bug 151, Bug 152 and you get Bug 153 as a freebie.


-- 
Stuart Bishop <stuart at stuartbishop.net>
http://www.stuartbishop.net/

From guy.helmer at palisadesystems.com  Thu Aug 26 06:11:28 2010
From: guy.helmer at palisadesystems.com (Guy Helmer)
Date: Thu, 26 Aug 2010 08:11:28 -0500
Subject: [Slony1-general] Rapid-fire updates to table missed by slony
In-Reply-To: <4C72CF3D.2000007@ca.afilias.info>
References: <6B66C950-980F-4608-844D-1A02A95C92CB@palisadesystems.com>
	<4C72CF3D.2000007@ca.afilias.info>
Message-ID: <C80821A7-A3D3-4D97-AAD5-2117393E7752@palisadesystems.com>

On Aug 23, 2010, at 2:42 PM, Steve Singer wrote:

> Guy Helmer wrote:
>> I'm seeing something odd occasionally on a fairly new slony1 (1.2.20) replication set involving one slave.  At times, the application inserts a record to a particular table, updates the record several times, and then deletes the record, sometimes in a fairly quick succession (but not always).
>> When I run the test-slony-state script, sometimes I find that the replication is failing, and when I look deeper, I find that Slony is having trouble replicating the changes to this table because of rows in the slave table that shouldn't be there.  After I manually remove the conflicting rows, Slony is then able to finish the backlogged replication.
>> Is there anything in particular I should look for in the log file prior to this problem?
> 
> 
> Shortly after the problem happens your going to want to look at sl_log_1  sl_log_2 and sl_event to figure out what was going on.
> 
> You want to find the what sync the delete should have been part of, and what sync the failing insert was part of and try to figure out why the delete wasn't applied to the slave by the time it tried the insert.
> 
> You would also want to look at the logs slon generates to see if that sync did get applied and look in sl_confirm to verify that.
> 
> 
> Honestly I am somewhat suspect that something else isn't going on I find your description somewhat hard reconcile with how things work.
> 

Thanks for the advice.  It has happened again.  Due to the timing of the issue corresponding somewhat closely with a software update where we took the database & slony down for the maintenance, I am wondering if we might be taking things down in incorrect order...

I didn't notice the problem until test-slony-state saw the problem during last night's check, so the data is about 21 hours old.  sl_log_1 contains this for the stuck table:

mydb=# SELECT * FROM _replication.sl_log_1 WHERE log_tableid = 28 ORDER BY log_xid;
 log_origin | log_xid | log_tableid | log_actionseq | log_cmdtype |              log_cmddata               
------------+---------+-------------+---------------+-------------+----------------------------------------
          1 | 2062810 |          28 |          6854 | I           | ("user_id","status") values ('1','2')
          1 | 2063155 |          28 |          6881 | I           | ("user_id","status") values ('3','2')
          1 | 2063342 |          28 |          6908 | I           | ("user_id","status") values ('3','2')
          1 | 2072564 |          28 |          6980 | I           | ("user_id","status") values ('34','2')
          1 | 2072564 |          28 |          6984 | D           | "user_id"='34'
          1 | 2072564 |          28 |          6986 | I           | ("user_id","status") values ('34','2')
          1 | 2072564 |          28 |          6990 | D           | "user_id"='34'
          1 | 2072564 |          28 |          6992 | I           | ("user_id","status") values ('34','2')
          1 | 2072580 |          28 |          7002 | I           | ("user_id","status") values ('34','2')
          1 | 2072586 |          28 |          7021 | D           | "user_id"='34'
          1 | 2072586 |          28 |          7023 | I           | ("user_id","status") values ('34','2')
          1 | 2072586 |          28 |          7027 | D           | "user_id"='34'
          1 | 2072586 |          28 |          7029 | I           | ("user_id","status") values ('34','2')
          1 | 2072586 |          28 |          7033 | D           | "user_id"='34'
          1 | 2072586 |          28 |          7035 | I           | ("user_id","status") values ('34','2')
(19 rows)

There are two consecutive inserts for user_id 34 (user_id is the primary key) -- is that a possible problem?

sl_log_2 is empty on both node1 and node2.  

Table 28 on node2 currently is empty.

Table 28 on node2 contains:
mydb=# SELECT * FROM config_change ORDER BY user_id ;
 user_id | status 
---------+--------
       1 |      2
      34 |      1
      36 |      3
      37 |      3
(4 rows)


--------
This message has been scanned by ComplianceSafe, powered by Palisade's PacketSure.

From JanWieck at Yahoo.com  Wed Aug 25 11:17:32 2010
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Wed, 25 Aug 2010 14:17:32 -0400
Subject: [Slony1-general] Rapid-fire updates to table missed by slony
In-Reply-To: <C80821A7-A3D3-4D97-AAD5-2117393E7752@palisadesystems.com>
References: <6B66C950-980F-4608-844D-1A02A95C92CB@palisadesystems.com>	<4C72CF3D.2000007@ca.afilias.info>
	<C80821A7-A3D3-4D97-AAD5-2117393E7752@palisadesystems.com>
Message-ID: <4C755E3C.2050108@Yahoo.com>

On 8/26/2010 9:11 AM, Guy Helmer wrote:
> On Aug 23, 2010, at 2:42 PM, Steve Singer wrote:
> 
>> Guy Helmer wrote:
>>> I'm seeing something odd occasionally on a fairly new slony1 (1.2.20) replication set involving one slave.  At times, the application inserts a record to a particular table, updates the record several times, and then deletes the record, sometimes in a fairly quick succession (but not always).
>>> When I run the test-slony-state script, sometimes I find that the replication is failing, and when I look deeper, I find that Slony is having trouble replicating the changes to this table because of rows in the slave table that shouldn't be there.  After I manually remove the conflicting rows, Slony is then able to finish the backlogged replication.
>>> Is there anything in particular I should look for in the log file prior to this problem?
>> 
>> 
>> Shortly after the problem happens your going to want to look at sl_log_1  sl_log_2 and sl_event to figure out what was going on.
>> 
>> You want to find the what sync the delete should have been part of, and what sync the failing insert was part of and try to figure out why the delete wasn't applied to the slave by the time it tried the insert.
>> 
>> You would also want to look at the logs slon generates to see if that sync did get applied and look in sl_confirm to verify that.
>> 
>> 
>> Honestly I am somewhat suspect that something else isn't going on I find your description somewhat hard reconcile with how things work.
>> 
> 
> Thanks for the advice.  It has happened again.  Due to the timing of the issue corresponding somewhat closely with a software update where we took the database & slony down for the maintenance, I am wondering if we might be taking things down in incorrect order...
> 
> I didn't notice the problem until test-slony-state saw the problem during last night's check, so the data is about 21 hours old.  sl_log_1 contains this for the stuck table:
> 
> mydb=# SELECT * FROM _replication.sl_log_1 WHERE log_tableid = 28 ORDER BY log_xid;
>  log_origin | log_xid | log_tableid | log_actionseq | log_cmdtype |              log_cmddata               
> ------------+---------+-------------+---------------+-------------+----------------------------------------
>           1 | 2062810 |          28 |          6854 | I           | ("user_id","status") values ('1','2')
>           1 | 2063155 |          28 |          6881 | I           | ("user_id","status") values ('3','2')
>           1 | 2063342 |          28 |          6908 | I           | ("user_id","status") values ('3','2')
>           1 | 2072564 |          28 |          6980 | I           | ("user_id","status") values ('34','2')
>           1 | 2072564 |          28 |          6984 | D           | "user_id"='34'
>           1 | 2072564 |          28 |          6986 | I           | ("user_id","status") values ('34','2')
>           1 | 2072564 |          28 |          6990 | D           | "user_id"='34'
>           1 | 2072564 |          28 |          6992 | I           | ("user_id","status") values ('34','2')
>           1 | 2072580 |          28 |          7002 | I           | ("user_id","status") values ('34','2')
>           1 | 2072586 |          28 |          7021 | D           | "user_id"='34'
>           1 | 2072586 |          28 |          7023 | I           | ("user_id","status") values ('34','2')
>           1 | 2072586 |          28 |          7027 | D           | "user_id"='34'
>           1 | 2072586 |          28 |          7029 | I           | ("user_id","status") values ('34','2')
>           1 | 2072586 |          28 |          7033 | D           | "user_id"='34'
>           1 | 2072586 |          28 |          7035 | I           | ("user_id","status") values ('34','2')
> (19 rows)
> 
> There are two consecutive inserts for user_id 34 (user_id is the primary key) -- is that a possible problem?

It looks like there is one delete for user_id=34 missing. This could be 
caused by a corrupted index on sl_log_1. Can you do a

     REINDEX _replication.sl_log_1;

and then repeat that SELECT?


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From guy.helmer at palisadesystems.com  Thu Aug 26 08:03:50 2010
From: guy.helmer at palisadesystems.com (Guy Helmer)
Date: Thu, 26 Aug 2010 10:03:50 -0500
Subject: [Slony1-general] Rapid-fire updates to table missed by slony
In-Reply-To: <4C755E3C.2050108@Yahoo.com>
References: <6B66C950-980F-4608-844D-1A02A95C92CB@palisadesystems.com>	<4C72CF3D.2000007@ca.afilias.info>
	<C80821A7-A3D3-4D97-AAD5-2117393E7752@palisadesystems.com>
	<4C755E3C.2050108@Yahoo.com>
Message-ID: <F28333AE-2DB0-43A8-AB5A-F2E0F02121E2@palisadesystems.com>

On Aug 25, 2010, at 1:17 PM, Jan Wieck wrote:

> On 8/26/2010 9:11 AM, Guy Helmer wrote:
>> On Aug 23, 2010, at 2:42 PM, Steve Singer wrote:
>>> Guy Helmer wrote:
>>>> I'm seeing something odd occasionally on a fairly new slony1 (1.2.20) replication set involving one slave.  At times, the application inserts a record to a particular table, updates the record several times, and then deletes the record, sometimes in a fairly quick succession (but not always).
>>>> When I run the test-slony-state script, sometimes I find that the replication is failing, and when I look deeper, I find that Slony is having trouble replicating the changes to this table because of rows in the slave table that shouldn't be there.  After I manually remove the conflicting rows, Slony is then able to finish the backlogged replication.
>>>> Is there anything in particular I should look for in the log file prior to this problem?
>>> Shortly after the problem happens your going to want to look at sl_log_1  sl_log_2 and sl_event to figure out what was going on.
>>> You want to find the what sync the delete should have been part of, and what sync the failing insert was part of and try to figure out why the delete wasn't applied to the slave by the time it tried the insert.
>>> You would also want to look at the logs slon generates to see if that sync did get applied and look in sl_confirm to verify that.
>>> Honestly I am somewhat suspect that something else isn't going on I find your description somewhat hard reconcile with how things work.
>> Thanks for the advice.  It has happened again.  Due to the timing of the issue corresponding somewhat closely with a software update where we took the database & slony down for the maintenance, I am wondering if we might be taking things down in incorrect order...
>> I didn't notice the problem until test-slony-state saw the problem during last night's check, so the data is about 21 hours old.  sl_log_1 contains this for the stuck table:
>> mydb=# SELECT * FROM _replication.sl_log_1 WHERE log_tableid = 28 ORDER BY log_xid;
>> log_origin | log_xid | log_tableid | log_actionseq | log_cmdtype |              log_cmddata               ------------+---------+-------------+---------------+-------------+----------------------------------------
>>          1 | 2062810 |          28 |          6854 | I           | ("user_id","status") values ('1','2')
>>          1 | 2063155 |          28 |          6881 | I           | ("user_id","status") values ('3','2')
>>          1 | 2063342 |          28 |          6908 | I           | ("user_id","status") values ('3','2')
>>          1 | 2072564 |          28 |          6980 | I           | ("user_id","status") values ('34','2')
>>          1 | 2072564 |          28 |          6984 | D           | "user_id"='34'
>>          1 | 2072564 |          28 |          6986 | I           | ("user_id","status") values ('34','2')
>>          1 | 2072564 |          28 |          6990 | D           | "user_id"='34'
>>          1 | 2072564 |          28 |          6992 | I           | ("user_id","status") values ('34','2')
>>          1 | 2072580 |          28 |          7002 | I           | ("user_id","status") values ('34','2')
>>          1 | 2072586 |          28 |          7021 | D           | "user_id"='34'
>>          1 | 2072586 |          28 |          7023 | I           | ("user_id","status") values ('34','2')
>>          1 | 2072586 |          28 |          7027 | D           | "user_id"='34'
>>          1 | 2072586 |          28 |          7029 | I           | ("user_id","status") values ('34','2')
>>          1 | 2072586 |          28 |          7033 | D           | "user_id"='34'
>>          1 | 2072586 |          28 |          7035 | I           | ("user_id","status") values ('34','2')
>> (19 rows)
>> There are two consecutive inserts for user_id 34 (user_id is the primary key) -- is that a possible problem?
> 
> It looks like there is one delete for user_id=34 missing. This could be caused by a corrupted index on sl_log_1. Can you do a
> 
>    REINDEX _replication.sl_log_1;
> 
> and then repeat that SELECT?
> 

I had already manually intervened in the slave's table to get the replication working again, so the sl_log_1 table was empty.  I have run the REINDEX TABLE _replication.sl_log_1 command, and the table is still empty...

Thanks,
Guy--------
This message has been scanned by ComplianceSafe, powered by Palisade's PacketSure.

From dba at richyen.com  Tue Aug 31 17:47:45 2010
From: dba at richyen.com (dba at richyen.com)
Date: Tue, 31 Aug 2010 19:47:45 -0500
Subject: [Slony1-general] =?utf-8?q?what_is_happening_on_the_subscriber_si?=
	=?utf-8?b?ZGU/?=
Message-ID: <c617607b5c1e1fb51824c8cb01ab790f@richyen.com>

Hi everyone,

Just wanted to look for an explanation regarding what happens on the
subscriber's end of a replication set.  I currently have 4 nodes (1 thru
4), and node 4 also has the "-a <dir>" flag turned on for log shipping (but
I think this is irrelevant)

Occasionally, I will see in test_slony_state_dbi.pl, that one of the
subscribers has really old events or that the provider is lagging behind
the provider, so I decided to harvest some data.  Wrote up a cronjob that
will fetch the average slony lag on node 4 (I could've picked any of them,
but just chose this one because load was lowest).

Basically, I ran this command from the shell every hour:  `psql -tc
"select avg(st_lag_time) from _slony_schema.sl_status" mydb postgres`

Now, I logged it into a file (http://pgsql.privatepaste.com/e4ce8f8f67)
and it shows that the other nodes average > 70 days'  worth of lag at
times.  (see period from May 10 to Jul 09)

There are 3 other replication clusters I tracked, and one of them even
went up to 153 days before dropping right back down to zero.

Could someone explain why this happens, or perhaps more importantly--what
causes the lag to drop from high 70s of days down to 0.  Is it sl_log_{1,2}
rotation?

Sorry, I might be able to find the answer by scouring the logs, but I'm
hoping to find a quick answer here.

Using Slony 2.0.3, postgres 8.4.2 on CentOS 2.6.18 on all nodes.

Much appreciated!
--Richard

