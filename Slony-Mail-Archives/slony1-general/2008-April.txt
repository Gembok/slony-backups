From scetbon at echo.fr  Tue Apr  1 02:26:10 2008
From: scetbon at echo.fr (Cyril SCETBON)
Date: Tue Apr  1 02:26:37 2008
Subject: [Slony1-general] Feature request for next slony version: initial
	replication of large DBs
In-Reply-To: <64706.196.23.181.69.1207031605.squirrel@zenmail.co.za>
References: <64706.196.23.181.69.1207031605.squirrel@zenmail.co.za>
Message-ID: <47F1FFB2.40602@echo.fr>

As said Christopher Brown new commands are coming : CLONE PREPARE and 
CLONE FINISH to bypass this mecanism

see http://lists.slony.info/pipermail/slony1-commit/2008-January/002145.html

Henry wrote:
> Good morning all,
>
> I seem to recall (I think it was touched on by someone else) that this
> aspect *might* be addressed in a near-future version of slony:
>
> Given that some users of slony have large (your definition of large will
> vary, but let's say DBs in excess of 100GB) databases, and that the
> initial replication of a DB can take weeks, would it not be a great idea
> to have a more efficient initial 'copy' mode?  ie, either allow a user to
> dump/restore to all slaves, then start replication from that point
> (without truncating/copying/etc), or, build this functionality into slony
> so it does the dump/restore, but does not then truncate all tables and
> start from scratch?
>
> For smaller DBs this doesn't present a problem, but for larger DDs coupled
> with LARGE clusters, this is a major problem.
>
> Regards
> Henry
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>   

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - OPF/PORTAILS/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From andreas at kostyrka.org  Tue Apr  1 03:02:14 2008
From: andreas at kostyrka.org (Andreas Kostyrka)
Date: Tue Apr  1 03:02:27 2008
Subject: [Slony1-general] Feature request for next slony version:
	initial replication of large DBs
In-Reply-To: <47F1FFB2.40602@echo.fr>
References: <64706.196.23.181.69.1207031605.squirrel@zenmail.co.za>
	<47F1FFB2.40602@echo.fr>
Message-ID: <1207044134.8299.64.camel@localhost>

One thing that should be also pointed out, that while a
pg_dump/pg_restore might be faster than slony initial copy, both use
basically the same mechanisms (COPY FROM/TO STDIN/STDOUT), so I'd guess
that you wouldn't shave to much of the initial replication time via
pg_dump. (Well, slony does need to get some locks to get going when I
remember right, which means that pg_dump/pg_restore has the potential to
be faster anyway.) OTOH, a filesystem level dump, can be, especially
when using LVM snapshots be produced rather quickly :)

Andreas


Am Dienstag, den 01.04.2008, 11:26 +0200 schrieb Cyril SCETBON:
> As said Christopher Brown new commands are coming : CLONE PREPARE and 
> CLONE FINISH to bypass this mecanism
> 
> see http://lists.slony.info/pipermail/slony1-commit/2008-January/002145.html
> 
> Henry wrote:
> > Good morning all,
> >
> > I seem to recall (I think it was touched on by someone else) that this
> > aspect *might* be addressed in a near-future version of slony:
> >
> > Given that some users of slony have large (your definition of large will
> > vary, but let's say DBs in excess of 100GB) databases, and that the
> > initial replication of a DB can take weeks, would it not be a great idea
> > to have a more efficient initial 'copy' mode?  ie, either allow a user to
> > dump/restore to all slaves, then start replication from that point
> > (without truncating/copying/etc), or, build this functionality into slony
> > so it does the dump/restore, but does not then truncate all tables and
> > start from scratch?
> >
> > For smaller DBs this doesn't present a problem, but for larger DDs coupled
> > with LARGE clusters, this is a major problem.
> >
> > Regards
> > Henry
> >
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general@lists.slony.info
> > http://lists.slony.info/mailman/listinfo/slony1-general
> >   
> 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: Dies ist ein digital signierter Nachrichtenteil
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20080401/65680202/attachment.pgp
From henry at zen.co.za  Tue Apr  1 03:27:09 2008
From: henry at zen.co.za (Henry)
Date: Tue Apr  1 03:27:43 2008
Subject: [Slony1-general] Feature request for next slony version: 
	initial replication of large DBs
In-Reply-To: <47F1FFB2.40602@echo.fr>
References: <64706.196.23.181.69.1207031605.squirrel@zenmail.co.za>
	<47F1FFB2.40602@echo.fr>
Message-ID: <61176.196.23.181.69.1207045629.squirrel@zenmail.co.za>



On Tue, April 1, 2008 11:26 am, Cyril SCETBON wrote:
> As said Christopher Brown new commands are coming : CLONE PREPARE and
> CLONE FINISH to bypass this mecanism
>
> see
> http://lists.slony.info/pipermail/slony1-commit/2008-January/002145.html

Excellent.  This will save so much time, you have no idea.

Regards
Henry



From henry at zen.co.za  Tue Apr  1 03:28:30 2008
From: henry at zen.co.za (Henry)
Date: Tue Apr  1 03:29:00 2008
Subject: [Slony1-general] Feature request for next slony version: 
	initial replication of large DBs
In-Reply-To: <1207044134.8299.64.camel@localhost>
References: <64706.196.23.181.69.1207031605.squirrel@zenmail.co.za>
	<47F1FFB2.40602@echo.fr> <1207044134.8299.64.camel@localhost>
Message-ID: <61180.196.23.181.69.1207045710.squirrel@zenmail.co.za>



On Tue, April 1, 2008 12:02 pm, Andreas Kostyrka wrote:
> One thing that should be also pointed out, that while a
> pg_dump/pg_restore might be faster than slony initial copy, both use
> basically the same mechanisms (COPY FROM/TO STDIN/STDOUT), so I'd guess
> that you wouldn't shave to much of the initial replication time via
> pg_dump. (Well, slony does need to get some locks to get going when I
> remember right, which means that pg_dump/pg_restore has the potential to
> be faster anyway.) OTOH, a filesystem level dump, can be, especially
> when using LVM snapshots be produced rather quickly :)

Exactly - dumping/restoring is but one option.  For example, on our
cluster slaves, we don't wast time manually installing the OS on each node
- we install once, them dump that image onto slaves...

From jc at oxado.com  Wed Apr  2 08:30:30 2008
From: jc at oxado.com (Jacques Caron)
Date: Wed Apr  2 08:32:48 2008
Subject: [Slony1-general] sl_log indexes
In-Reply-To: <60od8u52hu.fsf@dba2.int.libertyrms.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
Message-ID: <20080402153238.30326120F008@zeus.directinfos.com>

Hi Christopher,

At 17:37 31/03/2008, Christopher Browne wrote:
>The introduction of these partial indices dates back to the following
>discussion thread on pgsql-hackers:
>http://archives.postgresql.org/pgsql-hackers/2006-06/msg01516.php
>
>At one point, we had this as a second index:
>  create index sl_log_1_idx2 on @NAMESPACE@.sl_log_1
>         (log_xid @NAMESPACE@.xxid_ops);
>
>Unfortunately, it was apparently leading to problems in that data
>sourced from different origins might have xxid values of varying sign.
>
>So, in lieu of that, I introduced code that would generate a
>per-origin partial index, which would necessarily not suffer from the
>rollover problem that sl_log_1_idx2 would run into.
>
>It is quite likely that the partial indices will be preferred, as the
>first column in sl_log_1_idx1 doesn't discriminate much.

OK, so now I understand why there are partial indexes, but these 
partial indexes are redundant with quite a bit of the full index. The 
next logical step would be to remove the full index, however it seems 
there are some cases where it's still needed (i.e. queries with a 
where log_origin = node for which there is no partial index), at 
least some DELETEs (which my wild guess is that they actually always 
return 0 rows?).

So, possible options:
- add partial indexes for all possible origins (i.e. all nodes?) 
rather than just the ones that are actually origins? Those would most 
probably be completely empty most of the time.
- don't do any queries against nodes that are not really origins (but 
I guess this can become a bit complex in switchover/failover scenarios?)

The whole idea being of course to save a bit of I/O by avoiding the 
need to maintain duplicate indexes (always a good thing for 
heavily-updated tables when there's a bit of backlog).

Comments?

Jacques.

From craig_james at emolecules.com  Wed Apr  2 18:52:19 2008
From: craig_james at emolecules.com (Craig James)
Date: Wed Apr  2 18:52:42 2008
Subject: [Slony1-general] Version mismatch?  It's a new system...
In-Reply-To: <20080402153238.30326120F008@zeus.directinfos.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
Message-ID: <47F43853.9020003@emolecules.com>

I get the following error when I try to create a new Slony node:

  ERROR: Slonik version: 1.2.13 != Slony-I version in PG build 1.2.9

This is on a brand new server.  Postgres is 8.3.0, Slony was built from slony1-1.2.13.tar.bz2.  There has never been any other version of Slony installed on this system.  I am running everything from this system, including the slon daemons ('tho I haven't gotten that far yet).

The other system (the one that will become the master database) has had Slony 1.2.9 installed, but I did an "uninstall node" on it a long time ago.

I can only assume that the 1.2.9 is coming from the old system, but where?  How do I get rid of it?

Thanks!
Craig
From craig_james at emolecules.com  Wed Apr  2 19:30:38 2008
From: craig_james at emolecules.com (Craig James)
Date: Wed Apr  2 19:31:01 2008
Subject: [Slony1-general] Version mismatch?  It's a new system...
In-Reply-To: <47F43853.9020003@emolecules.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>	<60od8u52hu.fsf@dba2.int.libertyrms.com>	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com>
Message-ID: <47F4414E.8060602@emolecules.com>

Earlier I wrote:
> I get the following error when I try to create a new Slony node:
> 
>  ERROR: Slonik version: 1.2.13 != Slony-I version in PG build 1.2.9
> 
> This is on a brand new server.  Postgres is 8.3.0, Slony was built from 
> slony1-1.2.13.tar.bz2.  There has never been any other version of Slony 
> installed on this system.  I am running everything from this system, 
> including the slon daemons ('tho I haven't gotten that far yet).

I have since double checked everything.  There is no Slony schema on either database:

  select * from pg_tables where tableowner = 'postgres'

shows now sl_* tables at all.  So there is no old version of Slony.  This seems to be coming from the Slony 1.2.13 installation itself.

Can anyone shed any light on this?  In case anyone is still awake, I was hoping to get the thing started tonight.

Thanks.
Craig
From jeff at frostconsultingllc.com  Wed Apr  2 19:33:28 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Wed Apr  2 19:33:49 2008
Subject: [Slony1-general] Version mismatch?  It's a new system...
In-Reply-To: <47F4414E.8060602@emolecules.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
Message-ID: <Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>

On Wed, 2 Apr 2008, Craig James wrote:

> I have since double checked everything.  There is no Slony schema on either 
> database:
>
> select * from pg_tables where tableowner = 'postgres'
>
> shows now sl_* tables at all.  So there is no old version of Slony.  This 
> seems to be coming from the Slony 1.2.13 installation itself.
>
> Can anyone shed any light on this?  In case anyone is still awake, I was 
> hoping to get the thing started tonight.

Craig,

Look in your postgresql libdir for xxid.so.  That could be in /usr/lib/pgsql 
or /usr/lib64/pgsql or /usr/local/pgsql/lib, etc depending on how it was 
installed.  BTW, if this is a brand new server, why not start with postgresql 
8.3.1 instead of 8.3.0?

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From craig_james at emolecules.com  Wed Apr  2 19:48:01 2008
From: craig_james at emolecules.com (Craig James)
Date: Wed Apr  2 19:48:23 2008
Subject: [Slony1-general] Version mismatch?  It's a new system...
In-Reply-To: <Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
Message-ID: <47F44561.3050608@emolecules.com>

Jeff Frost wrote:
> On Wed, 2 Apr 2008, Craig James wrote:
> 
>> I have since double checked everything.  There is no Slony schema on 
>> either database:
>>
>> select * from pg_tables where tableowner = 'postgres'
>>
>> shows now sl_* tables at all.  So there is no old version of Slony.  
>> This seems to be coming from the Slony 1.2.13 installation itself.
>>
>> Can anyone shed any light on this?  In case anyone is still awake, I 
>> was hoping to get the thing started tonight.
> 
> Craig,
> 
> Look in your postgresql libdir for xxid.so.  That could be in 
> /usr/lib/pgsql or /usr/lib64/pgsql or /usr/local/pgsql/lib, etc 
> depending on how it was installed.

But what am I looking for?  There are no other slony libraries -- this system has never had any other version of Slony on it.

If I remove xxid.so, and everything else slony-related in /usr/local/pgsql/*, INCLUDING all of the sql files in /usr/local/pgsql/share, and then

  cd slony-1.2.13
  make install

then all the files are restored, including xxid.so.  But the problem persists -- same error.

<stdin>:5: loading of file /usr/local/pgsql/share/slony1_funcs.sql: PGRES_FATAL_ERROR ERROR:  Slonik version: 1.2.13 != Slony-I version in PG build 1.2.9
ERROR:  Slonik version: 1.2.13 != Slony-I version in PG build 1.2.9
<stdin>:5: ERROR: no admin conninfo for node 0


> BTW, if this is a brand new server, 
> why not start with postgresql 8.3.1 instead of 8.3.0?

I'll upgrade soon ... we must have got the system just before the 8.3.1 release last month.  In the mean time ...

Thanks,
Craig

From jeff at frostconsultingllc.com  Wed Apr  2 19:53:16 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Wed Apr  2 19:53:38 2008
Subject: [Slony1-general] Version mismatch?  It's a new system...
In-Reply-To: <47F44561.3050608@emolecules.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
Message-ID: <Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>

On Wed, 2 Apr 2008, Craig James wrote:

>> Look in your postgresql libdir for xxid.so.  That could be in 
>> /usr/lib/pgsql or /usr/lib64/pgsql or /usr/local/pgsql/lib, etc depending 
>> on how it was installed.
>
> But what am I looking for?  There are no other slony libraries -- this system 
> has never had any other version of Slony on it.
>
> If I remove xxid.so, and everything else slony-related in /usr/local/pgsql/*, 
> INCLUDING all of the sql files in /usr/local/pgsql/share, and then
>
> cd slony-1.2.13
> make install
>
> then all the files are restored, including xxid.so.  But the problem persists 
> -- same error.

Yah, but somewhere there is a 1.2.9 version of xxid.so.  Does your system have 
a locate db on it?

try: locate xxid.so ?

When I've had trouble finding this in the past, it has been installed in 
/usr/lib64/pgsql and I was looking in /usr/lib/pgsql or vice versa.  It's 
there somewhere.  If all else fails use find:

find / -name xxid.so -print

I believe there is also slony1_funcs.so to look for.

>
> <stdin>:5: loading of file /usr/local/pgsql/share/slony1_funcs.sql: 
> PGRES_FATAL_ERROR ERROR:  Slonik version: 1.2.13 != Slony-I version in PG 
> build 1.2.9
> ERROR:  Slonik version: 1.2.13 != Slony-I version in PG build 1.2.9
> <stdin>:5: ERROR: no admin conninfo for node 0



-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From craig_james at emolecules.com  Wed Apr  2 19:59:53 2008
From: craig_james at emolecules.com (Craig James)
Date: Wed Apr  2 20:00:16 2008
Subject: [Slony1-general] Version mismatch?  It's a new system...
In-Reply-To: <Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
Message-ID: <47F44829.6070007@emolecules.com>

Jeff Frost wrote:
> On Wed, 2 Apr 2008, Craig James wrote:
> 
>>> Look in your postgresql libdir for xxid.so.  That could be in 
>>> /usr/lib/pgsql or /usr/lib64/pgsql or /usr/local/pgsql/lib, etc 
>>> depending on how it was installed.
>>
>> But what am I looking for?  There are no other slony libraries -- this 
>> system has never had any other version of Slony on it.
>>
>> If I remove xxid.so, and everything else slony-related in 
>> /usr/local/pgsql/*, INCLUDING all of the sql files in 
>> /usr/local/pgsql/share, and then
>>
>> cd slony-1.2.13
>> make install
>>
>> then all the files are restored, including xxid.so.  But the problem 
>> persists -- same error.
> 
> Yah, but somewhere there is a 1.2.9 version of xxid.so.  Does your 
> system have a locate db on it?
> 
> try: locate xxid.so ?
> 
> When I've had trouble finding this in the past, it has been installed in 
> /usr/lib64/pgsql and I was looking in /usr/lib/pgsql or vice versa.  
> It's there somewhere.  If all else fails use find:
> 
> find / -name xxid.so -print
> 
> I believe there is also slony1_funcs.so to look for.

Right, good idea, but I tried that and the only two copies on the system are the Slony 1.2.13 source, and the installed version in /usr/local/pgsql.

$ find / -name xxid.so 2>/dev/null
/usr/local/pgsql/lib/xxid.so
/emi/src/external/slony1-1.2.13/src/xxid/xxid.so

$ find / -name slony1_funcs.so 2>/dev/null
/usr/local/pgsql/lib/slony1_funcs.so
/emi/src/external/slony1-1.2.13/src/backend/slony1_funcs.so

I guess I have to keep going back to what I started with: Version 1.2.9 is NOT, and has never been, on this system.  The error is in the 1.2.13 source distribution, as far as I can tell.  It's compiled fresh, there is no other Slony, and when I remove everything and start over, the same error happens.

Where could this be in the source?  Is there some configuration file?

Thanks,
Craig
From jeff at frostconsultingllc.com  Wed Apr  2 20:16:39 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Wed Apr  2 20:17:01 2008
Subject: [Slony1-general] Version mismatch?  It's a new system...
In-Reply-To: <47F44829.6070007@emolecules.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
	<47F44829.6070007@emolecules.com>
Message-ID: <Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>

On Wed, 2 Apr 2008, Craig James wrote:

> Jeff Frost wrote:
>> On Wed, 2 Apr 2008, Craig James wrote:
>> 
>>>> Look in your postgresql libdir for xxid.so.  That could be in 
>>>> /usr/lib/pgsql or /usr/lib64/pgsql or /usr/local/pgsql/lib, etc depending 
>>>> on how it was installed.
>>> 
>>> But what am I looking for?  There are no other slony libraries -- this 
>>> system has never had any other version of Slony on it.
>>> 
>>> If I remove xxid.so, and everything else slony-related in 
>>> /usr/local/pgsql/*, INCLUDING all of the sql files in 
>>> /usr/local/pgsql/share, and then
>>> 
>>> cd slony-1.2.13
>>> make install
>>> 
>>> then all the files are restored, including xxid.so.  But the problem 
>>> persists -- same error.
>> 
>> Yah, but somewhere there is a 1.2.9 version of xxid.so.  Does your system 
>> have a locate db on it?
>> 
>> try: locate xxid.so ?
>> 
>> When I've had trouble finding this in the past, it has been installed in 
>> /usr/lib64/pgsql and I was looking in /usr/lib/pgsql or vice versa.  It's 
>> there somewhere.  If all else fails use find:
>> 
>> find / -name xxid.so -print
>> 
>> I believe there is also slony1_funcs.so to look for.
>
> Right, good idea, but I tried that and the only two copies on the system are 
> the Slony 1.2.13 source, and the installed version in /usr/local/pgsql.
>
> $ find / -name xxid.so 2>/dev/null
> /usr/local/pgsql/lib/xxid.so
> /emi/src/external/slony1-1.2.13/src/xxid/xxid.so
>
> $ find / -name slony1_funcs.so 2>/dev/null
> /usr/local/pgsql/lib/slony1_funcs.so
> /emi/src/external/slony1-1.2.13/src/backend/slony1_funcs.so
>
> I guess I have to keep going back to what I started with: Version 1.2.9 is 
> NOT, and has never been, on this system.  The error is in the 1.2.13 source 
> distribution, as far as I can tell.  It's compiled fresh, there is no other 
> Slony, and when I remove everything and start over, the same error happens.
>
> Where could this be in the source?  Is there some configuration file?

What about the slave(s)?  You'll receive this error when you're subscribing 
the slave if the slave's .so files aren't the same.  Maybe you're looking on 
the wrong server.

You're correct in assuming you should be able to remove the files, then make 
install and be good.  Of course that has to happen on every one of the servers 
that will be part of the cluster and the slony versions have to be the same on 
all those servers.

BTW, are you using installing slony 1.2.13 in the default locations?


-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From craig_james at emolecules.com  Wed Apr  2 20:29:28 2008
From: craig_james at emolecules.com (Craig James)
Date: Wed Apr  2 20:29:52 2008
Subject: [Slony1-general] Version mismatch?  It's a new system...
In-Reply-To: <Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
	<47F44829.6070007@emolecules.com>
	<Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>
Message-ID: <47F44F18.4020908@emolecules.com>

Jeff Frost wrote:

> You're correct in assuming you should be able to remove the files, then 
> make install and be good.  Of course that has to happen on every one of 
> the servers that will be part of the cluster and the slony versions have 
> to be the same on all those servers.

But what if Slony isn't installed on the other database at all?  I thought that Slony only had to be installed where the slonik and slon daemons were going to run.

Either way, I'll reinstall Slony on the older system.

> BTW, are you using installing slony 1.2.13 in the default locations?

No, it's in the same directory as Postgres itself, which I put in /usr/local/pgsql

Thanks,
Craig


From jeff at frostconsultingllc.com  Wed Apr  2 20:32:13 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Wed Apr  2 20:32:37 2008
Subject: [Slony1-general] Version mismatch?  It's a new system...
In-Reply-To: <47F44F18.4020908@emolecules.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
	<47F44829.6070007@emolecules.com>
	<Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>
	<47F44F18.4020908@emolecules.com>
Message-ID: <Pine.LNX.4.64.0804022030020.5876@discord.home.frostconsultingllc.com>

On Wed, 2 Apr 2008, Craig James wrote:

> Jeff Frost wrote:
>
>> You're correct in assuming you should be able to remove the files, then 
>> make install and be good.  Of course that has to happen on every one of the 
>> servers that will be part of the cluster and the slony versions have to be 
>> the same on all those servers.
>
> But what if Slony isn't installed on the other database at all?  I thought 
> that Slony only had to be installed where the slonik and slon daemons were 
> going to run.
>
> Either way, I'll reinstall Slony on the older system.

I think you need to find the old versions that are installed on the other 
system.   You'll need the xxid.so and slony1_funcs.so in the libdir of all the 
postgresql servers that will be in the cluster, otherwise the slony functions 
won't install.  The problem you seem to be having is that there's an old 
version on one of these servers and when slonik tries to do the store node, it 
discovers a different version of xxid.so than 1.2.13, reports the error and 
bails out.

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From craig_james at emolecules.com  Wed Apr  2 20:45:22 2008
From: craig_james at emolecules.com (Craig James)
Date: Wed Apr  2 20:45:47 2008
Subject: [Slony1-general] Version mismatch?  It's a new system...
In-Reply-To: <Pine.LNX.4.64.0804022030020.5876@discord.home.frostconsultingllc.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
	<47F44829.6070007@emolecules.com>
	<Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>
	<47F44F18.4020908@emolecules.com>
	<Pine.LNX.4.64.0804022030020.5876@discord.home.frostconsultingllc.com>
Message-ID: <47F452D2.4000704@emolecules.com>

Jeff Frost wrote:
> On Wed, 2 Apr 2008, Craig James wrote:
> 
>> Jeff Frost wrote:
>>
>>> You're correct in assuming you should be able to remove the files, 
>>> then make install and be good.  Of course that has to happen on every 
>>> one of the servers that will be part of the cluster and the slony 
>>> versions have to be the same on all those servers.
>>
>> But what if Slony isn't installed on the other database at all?  I 
>> thought that Slony only had to be installed where the slonik and slon 
>> daemons were going to run.
>>
>> Either way, I'll reinstall Slony on the older system.
> 
> I think you need to find the old versions that are installed on the 
> other system.   You'll need the xxid.so and slony1_funcs.so in the 
> libdir of all the postgresql servers that will be in the cluster, 
> otherwise the slony functions won't install.  The problem you seem to be 
> having is that there's an old version on one of these servers and when 
> slonik tries to do the store node, it discovers a different version of 
> xxid.so than 1.2.13, reports the error and bails out.

Ok, it looks like we're in business again.  It was the older libraries on the other system causing the problem.

Thanks a lot for your help!

Craig
From craig_james at emolecules.com  Wed Apr  2 21:55:34 2008
From: craig_james at emolecules.com (Craig James)
Date: Wed Apr  2 21:55:59 2008
Subject: [Slony1-general] slon can't distinguish nodes?
In-Reply-To: <47F452D2.4000704@emolecules.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>	<60od8u52hu.fsf@dba2.int.libertyrms.com>	<20080402153238.30326120F008@zeus.directinfos.com>	<47F43853.9020003@emolecules.com>
	<47F4414E.8060602@emolecules.com>	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>	<47F44561.3050608@emolecules.com>	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>	<47F44829.6070007@emolecules.com>	<Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>	<47F44F18.4020908@emolecules.com>	<Pine.LNX.4.64.0804022030020.5876@discord.home.frostconsultingllc.com>
	<47F452D2.4000704@emolecules.com>
Message-ID: <47F46346.6030207@emolecules.com>

I keep getting this error:

   remoteListenThread_1: db_getLocalNodeId() returned 2 - wrong database?

I suspect the slon daemon can't handle port numbers correctly.  In this case, both the master and slave databases have the same name, AND the same host.  The only difference is the port number.

When I start slon, it seems to try to figure out the node number from the combination of dbname+host, but it seems to ignore the port number, so it arbitrarily will get node 1 or node 2.

(In case you're wondering, the second database is actually on a different machine, accessed via an encrypted ssh(1) tunnel that maps port 5433 on the local machine to port 5432 on the remote machine.  So the two databases are accessed by the same name and same host, with only the port to distinguish them.)

Is my analysis correct?  How does the slon daemon figure out which node number it is working on?  There doesn't seem to be any way to tell it.

Thanks,
Craig
From jeff at frostconsultingllc.com  Wed Apr  2 22:16:51 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Wed Apr  2 22:17:16 2008
Subject: [Slony1-general] slon can't distinguish nodes?
In-Reply-To: <47F46346.6030207@emolecules.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
	<47F44829.6070007@emolecules.com>
	<Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>
	<47F44F18.4020908@emolecules.com>
	<Pine.LNX.4.64.0804022030020.5876@discord.home.frostconsultingllc.com>
	<47F452D2.4000704@emolecules.com> <47F46346.6030207@emolecules.com>
Message-ID: <Pine.LNX.4.64.0804022213001.5451@discord.home.frostconsultingllc.com>

On Wed, 2 Apr 2008, Craig James wrote:

> I keep getting this error:
>
>  remoteListenThread_1: db_getLocalNodeId() returned 2 - wrong database?
>
> I suspect the slon daemon can't handle port numbers correctly.  In this case, 
> both the master and slave databases have the same name, AND the same host. 
> The only difference is the port number.
>
> When I start slon, it seems to try to figure out the node number from the 
> combination of dbname+host, but it seems to ignore the port number, so it 
> arbitrarily will get node 1 or node 2.
>
> (In case you're wondering, the second database is actually on a different 
> machine, accessed via an encrypted ssh(1) tunnel that maps port 5433 on the 
> local machine to port 5432 on the remote machine.  So the two databases are 
> accessed by the same name and same host, with only the port to distinguish 
> them.)
>
> Is my analysis correct?  How does the slon daemon figure out which node 
> number it is working on?  There doesn't seem to be any way to tell it.

It calls the getlocalnodeid(name) function on the DB specified in the conninfo 
when it's started.

How are you providing the conninfo to the slon daemons?

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From craig_james at emolecules.com  Wed Apr  2 22:29:41 2008
From: craig_james at emolecules.com (Craig James)
Date: Wed Apr  2 22:30:07 2008
Subject: [Slony1-general] slon can't distinguish nodes?
In-Reply-To: <Pine.LNX.4.64.0804022213001.5451@discord.home.frostconsultingllc.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
	<47F44829.6070007@emolecules.com>
	<Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>
	<47F44F18.4020908@emolecules.com>
	<Pine.LNX.4.64.0804022030020.5876@discord.home.frostconsultingllc.com>
	<47F452D2.4000704@emolecules.com> <47F46346.6030207@emolecules.com>
	<Pine.LNX.4.64.0804022213001.5451@discord.home.frostconsultingllc.com>
Message-ID: <47F46B45.9090101@emolecules.com>

Jeff Frost wrote:
> On Wed, 2 Apr 2008, Craig James wrote:
> 
>> I keep getting this error:
>>
>>  remoteListenThread_1: db_getLocalNodeId() returned 2 - wrong database?
>>
>> I suspect the slon daemon can't handle port numbers correctly.  In 
>> this case, both the master and slave databases have the same name, AND 
>> the same host. The only difference is the port number.
>>
>> When I start slon, it seems to try to figure out the node number from 
>> the combination of dbname+host, but it seems to ignore the port 
>> number, so it arbitrarily will get node 1 or node 2.
>>
>> (In case you're wondering, the second database is actually on a 
>> different machine, accessed via an encrypted ssh(1) tunnel that maps 
>> port 5433 on the local machine to port 5432 on the remote machine.  So 
>> the two databases are accessed by the same name and same host, with 
>> only the port to distinguish them.)
>>
>> Is my analysis correct?  How does the slon daemon figure out which 
>> node number it is working on?  There doesn't seem to be any way to 
>> tell it.
> 
> It calls the getlocalnodeid(name) function on the DB specified in the 
> conninfo when it's started.
> 
> How are you providing the conninfo to the slon daemons?

The same string I used to create the nodes, for example, here are the master and slave, respectively:

  Node 1 (master): slon -d 1 my_db_cluster 'dbname=my_db host=au user=postgres port=5433'
  Node 2 (slave):  slon -d 1 my_db_cluster 'dbname=my_db host=au user=postgres'

I also tried to make up a dummy hostname "au2", just to make them look different.  After deleting both nodes and rebuilding them with the different server names:

  Node 1 (master): slon -d 1 my_db_cluster 'dbname=my_db host=au2 user=postgres port=5433'
  Node 2 (slave):  slon -d 1 my_db_cluster 'dbname=my_db host=au user=postgres'

but I still get the error.  This is a bit baffling.  I can't really see what's different than the other Slony configurations I've set up, other than that I've never used port numbers before.

Thanks,
Craig

From jeff at frostconsultingllc.com  Wed Apr  2 22:47:29 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Wed Apr  2 22:47:54 2008
Subject: [Slony1-general] slon can't distinguish nodes?
In-Reply-To: <47F46B45.9090101@emolecules.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
	<47F44829.6070007@emolecules.com>
	<Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>
	<47F44F18.4020908@emolecules.com>
	<Pine.LNX.4.64.0804022030020.5876@discord.home.frostconsultingllc.com>
	<47F452D2.4000704@emolecules.com> <47F46346.6030207@emolecules.com>
	<Pine.LNX.4.64.0804022213001.5451@discord.home.frostconsultingllc.com>
	<47F46B45.9090101@emolecules.com>
Message-ID: <Pine.LNX.4.64.0804022236500.5451@discord.home.frostconsultingllc.com>

On Wed, 2 Apr 2008, Craig James wrote:

> Jeff Frost wrote:
>> On Wed, 2 Apr 2008, Craig James wrote:
>> 
>>> I keep getting this error:
>>>
>>>  remoteListenThread_1: db_getLocalNodeId() returned 2 - wrong database?
>>> 
>>> I suspect the slon daemon can't handle port numbers correctly.  In this 
>>> case, both the master and slave databases have the same name, AND the same 
>>> host. The only difference is the port number.
>>> 
>>> When I start slon, it seems to try to figure out the node number from the 
>>> combination of dbname+host, but it seems to ignore the port number, so it 
>>> arbitrarily will get node 1 or node 2.
>>> 
>>> (In case you're wondering, the second database is actually on a different 
>>> machine, accessed via an encrypted ssh(1) tunnel that maps port 5433 on 
>>> the local machine to port 5432 on the remote machine.  So the two 
>>> databases are accessed by the same name and same host, with only the port 
>>> to distinguish them.)
>>> 
>>> Is my analysis correct?  How does the slon daemon figure out which node 
>>> number it is working on?  There doesn't seem to be any way to tell it.
>> 
>> It calls the getlocalnodeid(name) function on the DB specified in the 
>> conninfo when it's started.
>> 
>> How are you providing the conninfo to the slon daemons?
>
> The same string I used to create the nodes, for example, here are the master 
> and slave, respectively:
>
> Node 1 (master): slon -d 1 my_db_cluster 'dbname=my_db host=au user=postgres 
> port=5433'
> Node 2 (slave):  slon -d 1 my_db_cluster 'dbname=my_db host=au 
> user=postgres'
>
> I also tried to make up a dummy hostname "au2", just to make them look 
> different.  After deleting both nodes and rebuilding them with the different 
> server names:
>
> Node 1 (master): slon -d 1 my_db_cluster 'dbname=my_db host=au2 
> user=postgres port=5433'
> Node 2 (slave):  slon -d 1 my_db_cluster 'dbname=my_db host=au 
> user=postgres'
>
> but I still get the error.  This is a bit baffling.  I can't really see 
> what's different than the other Slony configurations I've set up, other than 
> that I've never used port numbers before.

I've replicated to a different PostgreSQL instance on the same host in the 
past, so I would expect your setup to work fine.

Don't you have to connect to localhost port 5433 for the ssh port forward to 
work or does host 'au' resolve to 127.0.0.1?

What does the output of this look like:

netstat -an | grep 543[23]

and better yet, can you connect to both of them on the machine where the slons 
will run like this:

psql -h au -p 5433 -U postgres my_db
psql -h au -p 5432 -U postgres my_db

and if so, what's the output of:

select _my_db_cluster.getlocalnodeid('_my_db_cluster');

on both those?

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From craig_james at emolecules.com  Wed Apr  2 23:00:34 2008
From: craig_james at emolecules.com (Craig James)
Date: Wed Apr  2 23:01:01 2008
Subject: [Slony1-general] slon can't distinguish nodes?
In-Reply-To: <Pine.LNX.4.64.0804022236500.5451@discord.home.frostconsultingllc.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
	<47F44829.6070007@emolecules.com>
	<Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>
	<47F44F18.4020908@emolecules.com>
	<Pine.LNX.4.64.0804022030020.5876@discord.home.frostconsultingllc.com>
	<47F452D2.4000704@emolecules.com> <47F46346.6030207@emolecules.com>
	<Pine.LNX.4.64.0804022213001.5451@discord.home.frostconsultingllc.com>
	<47F46B45.9090101@emolecules.com>
	<Pine.LNX.4.64.0804022236500.5451@discord.home.frostconsultingllc.com>
Message-ID: <47F47282.3020302@emolecules.com>

Jeff Frost wrote:
> On Wed, 2 Apr 2008, Craig James wrote:
> 
>> Jeff Frost wrote:
>>> On Wed, 2 Apr 2008, Craig James wrote:
>>>
>>>> I keep getting this error:
>>>>
>>>>  remoteListenThread_1: db_getLocalNodeId() returned 2 - wrong database?
>>>>
>>>> I suspect the slon daemon can't handle port numbers correctly.  In 
>>>> this case, both the master and slave databases have the same name, 
>>>> AND the same host. The only difference is the port number.
>>>>
>>>> When I start slon, it seems to try to figure out the node number 
>>>> from the combination of dbname+host, but it seems to ignore the port 
>>>> number, so it arbitrarily will get node 1 or node 2.
>>>>
>>>> (In case you're wondering, the second database is actually on a 
>>>> different machine, accessed via an encrypted ssh(1) tunnel that maps 
>>>> port 5433 on the local machine to port 5432 on the remote machine.  
>>>> So the two databases are accessed by the same name and same host, 
>>>> with only the port to distinguish them.)
>>>>
>>>> Is my analysis correct?  How does the slon daemon figure out which 
>>>> node number it is working on?  There doesn't seem to be any way to 
>>>> tell it.
>>>
>>> It calls the getlocalnodeid(name) function on the DB specified in the 
>>> conninfo when it's started.
>>>
>>> How are you providing the conninfo to the slon daemons?
>>
>> The same string I used to create the nodes, for example, here are the 
>> master and slave, respectively:
>>
>> Node 1 (master): slon -d 1 my_db_cluster 'dbname=my_db host=au 
>> user=postgres port=5433'
>> Node 2 (slave):  slon -d 1 my_db_cluster 'dbname=my_db host=au 
>> user=postgres'
>>
>> I also tried to make up a dummy hostname "au2", just to make them look 
>> different.  After deleting both nodes and rebuilding them with the 
>> different server names:
>>
>> Node 1 (master): slon -d 1 my_db_cluster 'dbname=my_db host=au2 
>> user=postgres port=5433'
>> Node 2 (slave):  slon -d 1 my_db_cluster 'dbname=my_db host=au 
>> user=postgres'
>>
>> but I still get the error.  This is a bit baffling.  I can't really 
>> see what's different than the other Slony configurations I've set up, 
>> other than that I've never used port numbers before.
> 
> I've replicated to a different PostgreSQL instance on the same host in 
> the past, so I would expect your setup to work fine.
> 
> Don't you have to connect to localhost port 5433 for the ssh port 
> forward to work or does host 'au' resolve to 127.0.0.1?

Yes, that's right, it resolves to 127.0.0.1, for the reason you mention.


> What does the output of this look like:
> 
> netstat -an | grep 543[23]

A whole bunch of ports in use (there are a lot of persistent mod_perl connections from Apache).

> and better yet, can you connect to both of them on the machine where the 
> slons will run like this:
> 
> psql -h au -p 5433 -U postgres my_db
> psql -h au -p 5432 -U postgres my_db
> 
> and if so, what's the output of:
> 
> select _my_db_cluster.getlocalnodeid('_my_db_cluster');
> 
> on both those?

The first one (the master) reports 1, and the second one (the slave) reports 2, as expected.

So I guess the question is, why does slon think it is on the wrong node?  If it connects and does the getlocalnodeid() as you say, then what makes it think that's the wrong node?  What tells it that node 2 is the wrong one?

Thanks,
Craig


From jeff at frostconsultingllc.com  Wed Apr  2 23:04:00 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Wed Apr  2 23:04:25 2008
Subject: [Slony1-general] slon can't distinguish nodes?
In-Reply-To: <47F47282.3020302@emolecules.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
	<47F44829.6070007@emolecules.com>
	<Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>
	<47F44F18.4020908@emolecules.com>
	<Pine.LNX.4.64.0804022030020.5876@discord.home.frostconsultingllc.com>
	<47F452D2.4000704@emolecules.com> <47F46346.6030207@emolecules.com>
	<Pine.LNX.4.64.0804022213001.5451@discord.home.frostconsultingllc.com>
	<47F46B45.9090101@emolecules.com>
	<Pine.LNX.4.64.0804022236500.5451@discord.home.frostconsultingllc.com>
	<47F47282.3020302@emolecules.com>
Message-ID: <010701c89550$82fcff80$120a0a0a@jefflap>

 
> > and better yet, can you connect to both of them on the machine where the
> > slons will run like this:
> >
> > psql -h au -p 5433 -U postgres my_db
> > psql -h au -p 5432 -U postgres my_db
> >
> > and if so, what's the output of:
> >
> > select _my_db_cluster.getlocalnodeid('_my_db_cluster');
> >
> > on both those?
> 
> The first one (the master) reports 1, and the second one (the slave)
> reports 2, as expected.
> 
> So I guess the question is, why does slon think it is on the wrong node?
> If it connects and does the getlocalnodeid() as you say, then what makes
> it think that's the wrong node?  What tells it that node 2 is the wrong
> one?

In that case, I bet one of the store paths is wrong.  I.e. it thinks it's
connecting to node 1, but is really connecting to node 2.

Does the conninfo in _my_db_cluster.sl_path match the conninfo you expect to
see?


 

__________ Information from ESET NOD32 Antivirus, version of virus signature
database 2996 (20080403) __________

The message was checked by ESET NOD32 Antivirus.

http://www.eset.com
 

From craig_james at emolecules.com  Wed Apr  2 23:22:34 2008
From: craig_james at emolecules.com (Craig James)
Date: Wed Apr  2 23:23:02 2008
Subject: [Slony1-general] slon can't distinguish nodes?
In-Reply-To: <010701c89550$82fcff80$120a0a0a@jefflap>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
	<47F44829.6070007@emolecules.com>
	<Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>
	<47F44F18.4020908@emolecules.com>
	<Pine.LNX.4.64.0804022030020.5876@discord.home.frostconsultingllc.com>
	<47F452D2.4000704@emolecules.com> <47F46346.6030207@emolecules.com>
	<Pine.LNX.4.64.0804022213001.5451@discord.home.frostconsultingllc.com>
	<47F46B45.9090101@emolecules.com>
	<Pine.LNX.4.64.0804022236500.5451@discord.home.frostconsultingllc.com>
	<47F47282.3020302@emolecules.com>
	<010701c89550$82fcff80$120a0a0a@jefflap>
Message-ID: <47F477AA.8080509@emolecules.com>

Jeff Frost wrote:
>  
>>> and better yet, can you connect to both of them on the machine where the
>>> slons will run like this:
>>>
>>> psql -h au -p 5433 -U postgres my_db
>>> psql -h au -p 5432 -U postgres my_db
>>>
>>> and if so, what's the output of:
>>>
>>> select _my_db_cluster.getlocalnodeid('_my_db_cluster');
>>>
>>> on both those?
>> The first one (the master) reports 1, and the second one (the slave)
>> reports 2, as expected.
>>
>> So I guess the question is, why does slon think it is on the wrong node?
>> If it connects and does the getlocalnodeid() as you say, then what makes
>> it think that's the wrong node?  What tells it that node 2 is the wrong
>> one?
> 
> In that case, I bet one of the store paths is wrong.  I.e. it thinks it's
> connecting to node 1, but is really connecting to node 2.
> 
> Does the conninfo in _my_db_cluster.sl_path match the conninfo you expect to
> see?

On the master, something is odd:

my_db=# select * from _my_db_cluster.sl_path;
 pa_server | pa_client |            pa_conninfo               | pa_connretry 
-----------+-----------+--------------------------------------+--------------
         2 |         1 | dbname=my_db  host=au  user=postgres |           10
         1 |         2 | <event pending>                      |           10

Does that make any sense?

Craig
From cbbrowne at ca.afilias.info  Thu Apr  3 07:26:40 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Apr  3 07:26:49 2008
Subject: [Slony1-general] Feature request for next slony version: initial
	replication of large DBs
In-Reply-To: <47F1FFB2.40602@echo.fr> (Cyril SCETBON's message of "Tue,
	01 Apr 2008 11:26:10 +0200")
References: <64706.196.23.181.69.1207031605.squirrel@zenmail.co.za>
	<47F1FFB2.40602@echo.fr>
Message-ID: <60myob2evz.fsf@dba2.int.libertyrms.com>

Cyril SCETBON <scetbon@echo.fr> writes:
> As said Christopher Brown new commands are coming : CLONE PREPARE and
> CLONE FINISH to bypass this mecanism
>
> see http://lists.slony.info/pipermail/slony1-commit/2008-January/002145.html

They do, to a degree, but not completely.  The CLONE commands operate
on subscribers, so you need to have at least one subscriber in order
to start cloning.

It would be in principle possible to do a "clone" against a master; we
prepared a gedanken experiment as to how this would be done...  It
would require a slight outage to establish a synchronization point,
which makes it somewhat problematic, and which is why we haven't
pursued the more extensive cloning.
-- 
(format nil "~S@~S" "cbbrowne" "cbbrowne.com")
http://www3.sympatico.ca/cbbrowne/multiplexor.html
"Programming is an unnatural act." -- Alan J. Perlis
From jeff at frostconsultingllc.com  Thu Apr  3 07:43:44 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Thu Apr  3 07:43:50 2008
Subject: [Slony1-general] slon can't distinguish nodes?
In-Reply-To: <47F477AA.8080509@emolecules.com>
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
	<47F44829.6070007@emolecules.com>
	<Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>
	<47F44F18.4020908@emolecules.com>
	<Pine.LNX.4.64.0804022030020.5876@discord.home.frostconsultingllc.com>
	<47F452D2.4000704@emolecules.com> <47F46346.6030207@emolecules.com>
	<Pine.LNX.4.64.0804022213001.5451@discord.home.frostconsultingllc.com>
	<47F46B45.9090101@emolecules.com>
	<Pine.LNX.4.64.0804022236500.5451@discord.home.frostconsultingllc.com>
	<47F47282.3020302@emolecules.com>
	<010701c89550$82fcff80$120a0a0a@jefflap>
	<47F477AA.8080509@emolecules.com>
Message-ID: <015101c89599$1df72450$120a0a0a@jefflap>

> 
> On the master, something is odd:
> 
> my_db=# select * from _my_db_cluster.sl_path;
>  pa_server | pa_client |            pa_conninfo               |
> pa_connretry
> -----------+-----------+--------------------------------------+-----------
> ---
>          2 |         1 | dbname=my_db  host=au  user=postgres |
> 10
>          1 |         2 | <event pending>                      |
> 10
> 
> Does that make any sense?

Yah, check out the source for the storepath function here:
http://slony.info/documentation/function.storepath-int-integer-integer-text-
integer.html

I think you need to regenerate your paths and then you'll probably be in
business.  Give the store path slonik command a try and see if that lets you
fix it.
 

__________ Information from ESET NOD32 Antivirus, version of virus signature
database 2998 (20080403) __________

The message was checked by ESET NOD32 Antivirus.

http://www.eset.com
 

From cbbrowne at ca.afilias.info  Thu Apr  3 07:45:49 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Apr  3 07:45:55 2008
Subject: [Slony1-general] sl_log indexes
In-Reply-To: <20080402153238.30326120F008@zeus.directinfos.com> (Jacques
	Caron's message of "Wed, 02 Apr 2008 17:30:30 +0200")
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
Message-ID: <60iqyz2e02.fsf@dba2.int.libertyrms.com>

Jacques Caron <jc@oxado.com> writes:
> Hi Christopher,
>
> At 17:37 31/03/2008, Christopher Browne wrote:
>>The introduction of these partial indices dates back to the following
>>discussion thread on pgsql-hackers:
>>http://archives.postgresql.org/pgsql-hackers/2006-06/msg01516.php
>>
>>At one point, we had this as a second index:
>>  create index sl_log_1_idx2 on @NAMESPACE@.sl_log_1
>>         (log_xid @NAMESPACE@.xxid_ops);
>>
>>Unfortunately, it was apparently leading to problems in that data
>>sourced from different origins might have xxid values of varying sign.
>>
>>So, in lieu of that, I introduced code that would generate a
>>per-origin partial index, which would necessarily not suffer from the
>>rollover problem that sl_log_1_idx2 would run into.
>>
>>It is quite likely that the partial indices will be preferred, as the
>>first column in sl_log_1_idx1 doesn't discriminate much.
>
> OK, so now I understand why there are partial indexes, but these
> partial indexes are redundant with quite a bit of the full index. The
> next logical step would be to remove the full index, however it seems
> there are some cases where it's still needed (i.e. queries with a
> where log_origin = node for which there is no partial index), at least
> some DELETEs (which my wild guess is that they actually always return
> 0 rows?).

The other reason to need the "full index" is that immediately after
creating a new origin, there probably won't yet be a partial index to
consult, because the partial indices are added in as lazily as
possible, at the instant that the unused sl_log_n table is being
truncated.

There may be some time delay between establishing an origin node and
there being an index specifically for it.

> So, possible options:
> - add partial indexes for all possible origins (i.e. all nodes?) 
> rather than just the ones that are actually origins? Those would most
> probably be completely empty most of the time.

Seems overkill.

> - don't do any queries against nodes that are not really origins (but
> I guess this can become a bit complex in switchover/failover
> scenarios?)

Well, the origin node ID is always stored in sl_log_n, so that you
don't do any queries where "log_origin" isn't an origin.

It's not an option to restrict queries to origin nodes - that prevents
having cascaded cases, which are one of the major reasons for Slony-I
to exist in the first place.

> The whole idea being of course to save a bit of I/O by avoiding the
> need to maintain duplicate indexes (always a good thing for
> heavily-updated tables when there's a bit of backlog).
>
> Comments?

If anyone can suggest better index coverage, I'd be happy to hear of
it.  I don't think we can "improve things" without worsening them in
some sense.  :-(

The quote below was randomly chosen, but fairly serendipitous.  

The addition of the partial indexes was done with the following
reasoning:

   - We had started with a single index on (log_origin, log_xid,
     log_actionseq)

     In cases where log_origin was fixed, this wound up being
     unnecessarily inefficient.

  - We then added a secondary index on (log_xid).  Unfortunately, this
    got us in trouble, because there could be a mixture of nodes on
    different sides of the 32 bit transaction rollover, which would make
    the ordering seem a tad nondeterministic :-(.  This was the point at
    which Tom Lane pointed out a risk of corruption of this sort of 
    index.  *CLEARLY* bad mojo, if Tom warns of such!

  - I then concluded that the alternative of creating per-origin 
    partial indexes would provide something quite a bit better than the
    index that got ruled out.

I don't think we can afford to drop out either of the two sorts of
indices that we are using now, and whether it "costs too much" isn't
the problem, because the *other* evaluation is of whether or not we
can afford to lose what each of them provides.  If they're "too
expensive," then I have to point out that running a Seq Scan because a
needful index is GONE is likely to be More Expensive Still.

We don't want to commit any more computing sins than necessary,
particularly if we can't be certain they will actually achieve
efficiency!
-- 
(reverse (concatenate 'string "gro.mca" "@" "enworbbc"))
http://www3.sympatico.ca/cbbrowne/rdbms.html
"More computing sins are committed  in the name of efficiency (without
necessarily achieving it) than for any other single reason - including
blind stupidity."  -- W.A. Wulf
From cbbrowne at ca.afilias.info  Thu Apr  3 07:48:24 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Apr  3 07:48:31 2008
Subject: [Slony1-general] slon can't distinguish nodes?
In-Reply-To: <47F477AA.8080509@emolecules.com> (Craig James's message of "Wed,
	02 Apr 2008 23:22:34 -0700")
References: <20080331141043.5626D11B4FEA@zeus.directinfos.com>
	<60od8u52hu.fsf@dba2.int.libertyrms.com>
	<20080402153238.30326120F008@zeus.directinfos.com>
	<47F43853.9020003@emolecules.com> <47F4414E.8060602@emolecules.com>
	<Pine.LNX.4.64.0804021932170.5876@discord.home.frostconsultingllc.com>
	<47F44561.3050608@emolecules.com>
	<Pine.LNX.4.64.0804021949410.5876@discord.home.frostconsultingllc.com>
	<47F44829.6070007@emolecules.com>
	<Pine.LNX.4.64.0804022008110.5876@discord.home.frostconsultingllc.com>
	<47F44F18.4020908@emolecules.com>
	<Pine.LNX.4.64.0804022030020.5876@discord.home.frostconsultingllc.com>
	<47F452D2.4000704@emolecules.com> <47F46346.6030207@emolecules.com>
	<Pine.LNX.4.64.0804022213001.5451@discord.home.frostconsultingllc.com>
	<47F46B45.9090101@emolecules.com>
	<Pine.LNX.4.64.0804022236500.5451@discord.home.frostconsultingllc.com>
	<47F47282.3020302@emolecules.com>
	<010701c89550$82fcff80$120a0a0a@jefflap>
	<47F477AA.8080509@emolecules.com>
Message-ID: <60ej9n2dvr.fsf@dba2.int.libertyrms.com>

Craig James <craig_james@emolecules.com> writes:
> On the master, something is odd:
>
> my_db=# select * from _my_db_cluster.sl_path;
> pa_server | pa_client |            pa_conninfo               |
> pa_connretry
> -----------+-----------+--------------------------------------+--------------
>         2 |         1 | dbname=my_db  host=au  user=postgres |           10
>         1 |         2 | <event pending>                      |           10
>
> Does that make any sense?

Normal.  Things don't get completely cleared up until you start
running the slons, they start processing events, and, notably, handle
the pending STORE PATH requests that are queued up...
-- 
let name="cbbrowne" and tld="cbbrowne.com" in String.concat "@" [name;tld];;
http://cbbrowne.com/info/emacs.html
Rules of  the Evil Overlord  #228.  "If the  hero claims he  wishes to
confess  in public  or to  me  personally, I  will remind  him that  a
notarized deposition will serve just as well."
<http://www.eviloverlord.com/>
From jamiel at istreamimaging.com  Thu Apr  3 11:14:23 2008
From: jamiel at istreamimaging.com (Jeff Amiel)
Date: Thu Apr  3 11:15:09 2008
Subject: [Slony1-general] I screwed myself (single table issue)
Message-ID: <47F51E7F.3030606@istreamimaging.com>

I added a new replication set recently with a few new tables and sequences.

Today I started getting error  "duplicate key violates unique 
constraint" when slony was trying to insert into my two subscriber nodes.
I looked and sure enough..there was already an entry in table with the 
same primary key as the one it was trying to insert...

I thought maybe I had not replicated the sequence or something 
silly...but that wasn't the case.
I chalked it up to a really bad and confusing week and decided that I 
would just drop the table from replication and then re-add it
(table has mostly transient data that is deleted nearly as quickly as it 
is inserted but there are SOME long term records ...and in this case 
just one so resyncing that table would be no great hardship)

I did  a set drop table and set drop sequence (separately for some 
reason) on the table and it's correlated sequence....and yet I still was 
getting the duplicate key error.

At that point I decided to drop the data from the table in the 
subscriber nodes....(delete from yadda yadda) but got the 'permission 
denied to do bad things on subscriber node' error.

Hmmm, I thought.....
well...so I circumvented by dropping and re-adding the table in both 
subscriber nodes.

Ick..things got worse.

Now slony just keeps 'restarting' on both subscriber nodes with error 
like this:

ERROR  remoteWorkerThread_1: "begin transaction; set transaction 
isolation level serializable; lock table 
"_istream_replication_cluster".sl_config_lock; select 
"_istream_replication_cluster".setDropTable_int(103);notify 
"_istream_replication_cluster_Event"; notify 
"_istream_replication_cluster_Confirm"; insert into 
"_istream_replication_cluster".sl_event     (ev_origin, ev_seqno, 
ev_timestamp,      ev_minxid, ev_maxxid, ev_xip, ev_type , ev_data1    ) 
values ('1', '3115555', '2008-04-03 12:22:15.552003', '629198517', 
'629198538', '''629198517'',''629198534''', 'SET_DROP_TABLE', '103'); 
insert into "_istream_replication_cluster".sl_confirm  (con_origin, 
con_received, con_seqno, con_timestamp)    values (1, 4, '3115555', 
now()); commit transaction;" PGRES_FATAL_ERROR ERROR:  Slony-I: 
alterTableRestore(): Table with id 103 not found
CONTEXT:  SQL statement "SELECT  
"_istream_replication_cluster".alterTableRestore( $1 )"
PL/pgSQL function "setdroptable_int" line 52 at perform


oops...of course I have no table 103....at least not any more.

Now what....?
How do I either fool the system into thinking the table is their so it 
can remove it...or clean up these stale sync items for a table that does 
not exist so I can re-add this rougue table and sequence again from scratch?

What SHOULD I have done instead of the fiasco that I created?


Any help would be appreciated.






From henry at zen.co.za  Fri Apr  4 05:32:00 2008
From: henry at zen.co.za (Henry)
Date: Fri Apr  4 05:32:07 2008
Subject: [Slony1-general] Initial replication repeatedly restarts/copies
	same tables
Message-ID: <63150.196.23.181.69.1207312320.squirrel@zenmail.co.za>

Hello,

We're busy with an initial replication of a large DB to multiple slaves. 
The first slave has completed (after more than a week), but the others are
having what I imagine is a hiccup.

They're repeatedly restarting and copying the same tables - and never
completing.

The relevant section (during a funny restart) from the slony log (on a
slave):

>>> here's the first sign of something amiss (?):
...
01:53:16 FATAL localListenThread: cannot start transaction -
...
01:53:16 DEBUG2 slon_retry() from pid=7750
01:53:17 DEBUG1 slon: retry requested
01:53:17 DEBUG2 slon: notify worker process to shutdown
01:53:17 INFO remoteListenThread_4: disconnecting from 'dbname=xxx
host=zzz3 user=hhh password=000 port=5431'
01:53:17 INFO remoteListenThread_2: disconnecting from 'dbname=xxx
host=zzz1 user=hhh password=000 port=5431'
01:53:17 DEBUG1 syncThread: thread done
01:53:17 INFO remoteListenThread_1: disconnecting from 'dbname=xxx
host=zzz0 user=hhh password=000'
01:53:17 INFO remoteListenThread_3: disconnecting from 'dbname=xxx
host=zzz2 user=hhh password=000 port=5431'
01:53:18 DEBUG1 main: scheduler mainloop returned
01:53:18 DEBUG2 main: wait for remote threads
01:53:18 DEBUG2 sched_wakeup_node(): no_id=1 (0 threads + worker signaled)
01:53:20 DEBUG1 remoteListenThread_3: thread done
01:53:21 DEBUG1 remoteListenThread_1: thread done
01:53:21 DEBUG1 remoteListenThread_2: thread done
01:53:21 DEBUG1 remoteListenThread_4: thread done
01:53:37 DEBUG1 slon: child termination timeout - kill child
01:53:37 DEBUG2 slon: child terminated status: 9; pid: 7750, current
worker pid: 7750
01:53:37 DEBUG1 slon: restart of worker in 10 seconds
...
>>> slony starts again, and proceeds to copy the same tables...
...
01:53:47 CONFIG  main: slon version 1.2.12 starting up
01:53:47 DEBUG2 slon: watchdog process started
01:53:47 DEBUG2 slon: watchdog ready - pid = 7749
01:53:47 DEBUG2 slon: worker process created - pid = 19510
01:53:49 CONFIG  main: local node id = 5
01:53:49 DEBUG2 main: main process started
...

I've also checked the PG logs for any obvious errors.

Any idea where else to look and what to look for?

Any comments welcome.

Thanks
Henry

From glynastill at yahoo.co.uk  Fri Apr  4 07:05:18 2008
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Fri Apr  4 07:05:24 2008
Subject: [Slony1-general] ERROR:  XX000: cache lookup failed for relation
Message-ID: <498765.17802.qm@web25813.mail.ukl.yahoo.com>

Hi chaps,

I've got a problem trying to drop a table, I get the error "cache lookup failed for relation"

SEE=# drop table replicated_users;
ERROR:  XX000: cache lookup failed for relation 30554884
LOCATION:  getRelationDescription, dependency.c:2021
Now this table is on a slony-I slave and was in replication when I tried to drop it - I presume this is a big mistake and I should never try to drop a table without first droping it from replication?

In addition I'd set up a trigger on the table "replicate_users".

If I do:

 select relname,oid from pg_class where relname = 'replicated_users';

-[ RECORD 1 ]-------------
relname | replicated_users
oid     | 30554879

Thats not the same oid as the one it's complaining about.

Does anyone have any idea why this has happened or how I can fix it?

Cheers
Glyn






      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  

http://uk.promotions.yahoo.com/forgood/

From cjames at emolecules.com  Fri Apr  4 07:06:55 2008
From: cjames at emolecules.com (Craig A. James)
Date: Fri Apr  4 07:07:03 2008
Subject: [Slony1-general] Initial copy fails, le
Message-ID: <47F635FF.1030302@emolecules.com>

During the initial copy, the master database had a problem and died.  Fair enough, usually Slony will try again.  But this time, it has gotten itself into an invalid state -- see the attached log dump.

I have already copied a LOT of data, and the connection between master and slave isn't reliable, so I don't want to start over.  I REALLY need to get this system replicated SOON.  How can I repair this problem and get Slony to continue?  For the moment, I've killed the slon(1) daemons, but if I restart them, the "sequence ID 51 has already been assigned" message just keeps getting repeated.

Thanks,
Craig


NOTICE:  truncate of "emol_warehouse_1"."sample" succeeded
2008-04-04 00:29:30 PDT DEBUG1 cleanupThread:    0.002 seconds for cleanupEvent()
2008-04-04 01:05:33 PDT ERROR  remoteWorkerThread_1: "select SL.seql_seqid, SL.seql_last_value,     "_emol_warehouse_1_cluster".slon_quote_brute(PGN.nspname) || '.' ||     "\
_emol_warehouse_1_cluster".slon_quote_brute(PGC.relname) as tab_fqname     from "_emol_warehouse_1_cluster".sl_sequence SQ, "_emol_warehouse_1_cluster".sl_seqlog SL,        \
      "pg_catalog".pg_class PGC,              "pg_catalog".pg_namespace PGN   where SQ.seq_set = 5            and SL.seql_seqid = SQ.seq_id           and SL.seql_ev_seqno = \
'43'             and PGC.oid = SQ.seq_reloid             and PGN.oid = PGC.relnamespace; " server closed the connection unexpectedly
        This probably means the server terminated abnormally
        before or while processing the request.
2008-04-04 01:05:33 PDT WARN   remoteWorkerThread_1: data copy for set 5 failed - sleep 15 seconds
2008-04-04 01:05:34 PDT DEBUG1 cleanupThread: 2163.722 seconds for delete logs
2008-04-04 01:05:49 PDT DEBUG1 copy_set 5
2008-04-04 01:05:49 PDT DEBUG1 remoteWorkerThread_1: connected to provider DB
NOTICE:  truncate of "emol_warehouse_1"."sample" succeeded
2008-04-04 01:16:52 PDT DEBUG1 cleanupThread:    0.016 seconds for cleanupEvent()
2008-04-04 01:16:52 PDT DEBUG1 cleanupThread:    0.032 seconds for delete logs
2008-04-04 01:28:43 PDT DEBUG1 cleanupThread:    0.001 seconds for cleanupEvent()
2008-04-04 01:28:43 PDT DEBUG1 cleanupThread:    0.002 seconds for delete logs
2008-04-04 01:40:45 PDT DEBUG1 cleanupThread:    0.002 seconds for cleanupEvent()
2008-04-04 01:40:45 PDT DEBUG1 cleanupThread:    0.014 seconds for delete logs
WARNING:  terminating connection because of crash of another server process
DETAIL:  The postmaster has commanded this server process to roll back the current transaction and exit, because another server process exited abnormally and possibly corrup\
HINT:  In a moment you should be able to reconnect to the database and repeat your command.
2008-04-04 01:43:59 PDT ERROR  remoteListenThread_1: "select ev_origin, ev_seqno, ev_timestamp,        ev_minxid, ev_maxxid, ev_xip,        ev_type,        ev_data1, ev_data2,     \
   ev_data3, ev_data4,        ev_data5, ev_data6,        ev_data7, ev_data8 from "_emol_warehouse_1_cluster".sl_event e where (e.ev_origin = '1' and e.ev_seqno > '1012') order by e\
.ev_origin, e.ev_seqno" - server closed the connection unexpectedly
        This probably means the server terminated abnormally
        before or while processing the request.
2008-04-04 01:44:09 PDT DEBUG1 remoteListenThread_1: connected to 'dbname=emol_warehouse_1 host=aurum user=postgres port=5435'
NOTICE:  Slony-I: cleanup stale sl_nodelock entry for pid=20890
CONTEXT:  SQL statement "SELECT  "_emol_warehouse_1_cluster".cleanupNodelock()"
PL/pgSQL function "cleanupevent" line 77 at PERFORM
2008-04-04 01:51:32 PDT DEBUG1 cleanupThread:    0.001 seconds for cleanupEvent()
2008-04-04 01:51:32 PDT DEBUG1 cleanupThread:    0.002 seconds for delete logs
WARNING:  terminating connection because of crash of another server process
DETAIL:  The postmaster has commanded this server process to roll back the current transaction and exit, because another server process exited abnormally and possibly corrupted sha\
red memory.
HINT:  In a moment you should be able to reconnect to the database and repeat your command.
2008-04-04 01:52:35 PDT ERROR  remoteWorkerThread_1: "select SL.seql_seqid, SL.seql_last_value,     "_emol_warehouse_1_cluster".slon_quote_brute(PGN.nspname) || '.' ||     "_emol_w\
arehouse_1_cluster".slon_quote_brute(PGC.relname) as tab_fqname     from "_emol_warehouse_1_cluster".sl_sequence SQ, "_emol_warehouse_1_cluster".sl_seqlog SL,              "pg_cata\
log".pg_class PGC,              "pg_catalog".pg_namespace PGN   where SQ.seq_set = 5            and SL.seql_seqid = SQ.seq_id           and SL.seql_ev_seqno = '43'             and \
PGC.oid = SQ.seq_reloid             and PGN.oid = PGC.relnamespace; " server closed the connection unexpectedly
        This probably means the server terminated abnormally
        before or while processing the request.
2008-04-04 01:52:35 PDT WARN   remoteWorkerThread_1: data copy for set 5 failed - sleep 30 seconds
NOTICE:  there is no transaction in progress
2008-04-04 01:53:05 PDT DEBUG1 copy_set 5
2008-04-04 01:53:05 PDT DEBUG1 remoteWorkerThread_1: connected to provider DB
2008-04-04 01:53:06 PDT ERROR  remoteWorkerThread_1: "select "_emol_warehouse_1_cluster".setAddSequence_int(5, 51, '"emol_warehouse_1"."sample_id_seq"', 'emol_warehouse_1.sample_id\
_seq')" PGRES_FATAL_ERROR ERROR:  Slony-I: setAddSequence_int(): sequence ID 51 has already been assigned
2008-04-04 01:53:06 PDT WARN   remoteWorkerThread_1: data copy for set 5 failed - sleep 60 seconds
NOTICE:  there is no transaction in progress
2008-04-04 01:54:06 PDT DEBUG1 copy_set 5
2008-04-04 01:54:06 PDT DEBUG1 remoteWorkerThread_1: connected to provider DB
2008-04-04 01:54:07 PDT ERROR  remoteWorkerThread_1: "select "_emol_warehouse_1_cluster".setAddSequence_int(5, 51, '"emol_warehouse_1"."sample_id_seq"', 'emol_warehouse_1.sample_id\
_seq')" PGRES_FATAL_ERROR ERROR:  Slony-I: setAddSequence_int(): sequence ID 51 has already been assigned
2008-04-04 01:54:07 PDT WARN   remoteWorkerThread_1: data copy for set 5 failed - sleep 60 seconds
NOTICE:  there is no transaction in progress
2008-04-04 01:55:07 PDT DEBUG1 copy_set 5
2008-04-04 01:55:07 PDT DEBUG1 remoteWorkerThread_1: connected to provider DB
2008-04-04 01:55:07 PDT ERROR  remoteWorkerThread_1: "select "_emol_warehouse_1_cluster".setAddSequence_int(5, 51, '"emol_warehouse_1"."sample_id_seq"', 'emol_warehouse_1.sample_id\
_seq')" PGRES_FATAL_ERROR ERROR:  Slony-I: setAddSequence_int(): sequence ID 51 has already been assigned
2008-04-04 01:55:07 PDT WARN   remoteWorkerThread_1: data copy for set 5 failed - sleep 60 seconds
NOTICE:  there is no transaction in progress
From craig_james at emolecules.com  Fri Apr  4 07:34:25 2008
From: craig_james at emolecules.com (Craig James)
Date: Fri Apr  4 07:34:33 2008
Subject: [Slony1-general] Initial copy fails, le
In-Reply-To: <47F635FF.1030302@emolecules.com>
References: <47F635FF.1030302@emolecules.com>
Message-ID: <47F63C71.3010709@emolecules.com>

Craig A. James wrote:
> During the initial copy, the master database had a problem and died.  
> Fair enough, usually Slony will try again.  But this time, it has gotten 
> itself into an invalid state -- see the attached log dump.
> 
> I have already copied a LOT of data, and the connection between master 
> and slave isn't reliable, so I don't want to start over.  I REALLY need 
> to get this system replicated SOON.  How can I repair this problem and 
> get Slony to continue?  For the moment, I've killed the slon(1) daemons, 
> but if I restart them, the "sequence ID 51 has already been assigned" 
> message just keeps getting repeated.

Ok, forget this question ... I did the obvious, drop-set followed by create-set, which recreated the original set using the exact same commands as the first time.

Now I get another error that makes no sense:

  remoteWorkerThread_1: node -1 not found in runtime configuration

So for some reason, it can't connect any more, but the only change was the drop-set/create-set.

I tried re-executing the store-path commands, but that makes no difference.  I also verified that the databases are both running, and that both are accessible.

What's going on here?

Thanks,
Craig
From craig_james at emolecules.com  Fri Apr  4 07:54:24 2008
From: craig_james at emolecules.com (Craig James)
Date: Fri Apr  4 07:54:32 2008
Subject: [Slony1-general] drop-set/create-set, causes  "node -1 not found"
In-Reply-To: <47F635FF.1030302@emolecules.com>
References: <47F635FF.1030302@emolecules.com>
Message-ID: <47F64120.1080708@emolecules.com>

A replication set failed to do the initial copy (the network connection is unreliable), and got into a state where it couldn't finish.  So I did a drop-set / create-set to recreate the set, using the exact same slonik commands that I used initially.

Now I get an error that makes no sense:

 remoteWorkerThread_1: node -1 not found in runtime configuration

So for some reason, it can't connect any more, but the only change was the drop-set/create-set.

I tried re-executing the store-path commands, but that makes no difference.  I also verified that the databases are both running, and that both are accessible.

What's going on here?  Any help would be appreciated, I REALLY need to get this database copied soon!

Thanks,
Craig

From craig_james at emolecules.com  Fri Apr  4 09:12:05 2008
From: craig_james at emolecules.com (Craig James)
Date: Fri Apr  4 09:12:16 2008
Subject: [Slony1-general] drop-set/create-set, causes  "node -1 not found"
In-Reply-To: <47F64120.1080708@emolecules.com>
References: <47F635FF.1030302@emolecules.com> <47F64120.1080708@emolecules.com>
Message-ID: <47F65355.7010205@emolecules.com>

Craig James wrote:
> A replication set failed to do the initial copy (the network connection 
> is unreliable), and got into a state where it couldn't finish.  So I did 
> a drop-set / create-set to recreate the set, using the exact same slonik 
> commands that I used initially.
> 
> Now I get an error that makes no sense:
> 
> remoteWorkerThread_1: node -1 not found in runtime configuration
> 
> So for some reason, it can't connect any more, but the only change was 
> the drop-set/create-set.
> 
> I tried re-executing the store-path commands, but that makes no 
> difference.  I also verified that the databases are both running, and 
> that both are accessible.
> 
> What's going on here?  Any help would be appreciated, I REALLY need to 
> get this database copied soon!

Just to keep things going while I wait for an answer, I did "drop set" on set 5, so that sets 6 & 7 could copy.  Now things are even stranger:  It is STILL trying to copy set 5!  But there is no set 5.

So that leads me to believe there is an event in the queue that can never finish because, after the copy-set failed, and the set was deleted, but event was NOT deleted.

I'm stuck in a loop of errors.  Please, answers anyone???

Thanks,
Craig
From glynastill at yahoo.co.uk  Fri Apr  4 09:24:57 2008
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Fri Apr  4 09:25:09 2008
Subject: [Slony1-general] drop-set/create-set, causes  "node -1 not found"
Message-ID: <438265.93604.qm@web25811.mail.ukl.yahoo.com>

Hi Craig,

I had a similar scenario a few months ago and never managed to figure out what happened. Nobody could tell me what the node -1 was all about, I did hear that it was possibly something pgAdmin was using to manage things, or slony switching the node to -1 to prevent further operations when trying to subscribe an ID already present on the slave.

I'd love to know if you  get to the bottom of it.

I could only guess that it was for one of the following 2 reasons:

- I tried to add a table to a set by creating a new set, subscribing then merging it.

However at the time I was managing slony using pgadmin, and I presume because I didn't wait for confirmations from both nodes regarding the subscribe before preceding with the merge it shagged it. I now avoid using pgadmin for anything replication wise other than viewing and make sure I have the following in my slonik scripts between subscribe and merge.

WAIT FOR EVENT (ORIGIN=2, CONFIRMED = 1, TIMEOUT = 0);
SYNC(ID = 1);
WAIT FOR EVENT (ORIGIN = 1, CONFIRMED = 2, TIMEOUT = 0);

Imho pgAdmin should block anyone trying to merge a set before getting the relevent confirmations from the last subscribe.

- I somehow managed to assign an id already used, again using pgAdmin and it managed to shag something.

Since I've been using slonik exclusively and making sure I sync and wait for event I've not had any problems.

Glyn


----- Original Message ----
> From: Craig James <craig_james@emolecules.com>
> To: slony1-general@lists.slony.info
> Sent: Friday, 4 April, 2008 3:54:24 PM
> Subject: [Slony1-general] drop-set/create-set, causes  "node -1 not found"
> 
> A replication set failed to do the initial copy (the network connection is 
> unreliable), and got into a state where it couldn't finish.  So I did a drop-set 
> / create-set to recreate the set, using the exact same slonik commands that I 
> used initially.
> 
> Now I get an error that makes no sense:
> 
>  remoteWorkerThread_1: node -1 not found in runtime configuration
> 
> So for some reason, it can't connect any more, but the only change was the 
> drop-set/create-set.
> 
> I tried re-executing the store-path commands, but that makes no difference.  I 
> also verified that the databases are both running, and that both are accessible.
> 
> What's going on here?  Any help would be appreciated, I REALLY need to get this 
> database copied soon!
> 
> Thanks,
> Craig
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
> 




      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  

http://uk.promotions.yahoo.com/forgood/

From craig_james at emolecules.com  Fri Apr  4 11:09:24 2008
From: craig_james at emolecules.com (Craig James)
Date: Fri Apr  4 11:09:37 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
 causes  "node -1 not found")
In-Reply-To: <438265.93604.qm@web25811.mail.ukl.yahoo.com>
References: <438265.93604.qm@web25811.mail.ukl.yahoo.com>
Message-ID: <47F66ED4.6060404@emolecules.com>

Glyn Astill wrote:

> I had a similar scenario a few months ago and never managed to figure
> out what happened. Nobody could tell me what the node -1 was all about...
> 
> I'd love to know if you  get to the bottom of it.

Yes, I just now got to the bottom of it.  I realized that Slony is not high enough quality to use in a production environment, and I'm abandoning it until some time in the future when it has matured a bit more.

This is just the last straw.  I really hate to be critical of any open-source project, because I genuinely appreciate everyone's hard work.  But in the end, Slony has proved to be more trouble that it is worth.  It simply doesn't get the job done reliably.

It's clear to me that Slony's developers are focused on features, and have not paid enough attention to the user experience.  It's a classic case where the developers, who are experts in their own technology, don't realize just how difficult their product is for the mainstream user.

* Slony's configuration is like programming in FORTRAN or assembly language in 1966.  There is no reason why Slony should need anything more than a set's name and the table's names that belong to the set.  Computers are good at numbering things, why should I have to?  It takes DAYS to learn how to create a Slony configuration, and it is only achieved through lots of trial and error.

* It is trivially easy to DESTROY an entire database with Slony.  All you have to do is a simply typo, reversing node 1 and node 2, and Slony will, with no further warning, truncate every table in your master database.  There is no way to say, "This is the MASTER, no matter what else I say, never mess with it."  This should be a fundamental concept in Slony, but is not.  This is particularly serious, given that Slony expects to connect as the super-user, so you can't (for example) use a guest account that has no write priviliges, which would be the sensible approach.  Slony really needs two users: The super user (during configuration only), and the operational user (during normal operation), and these should be set separately for the master and slaves.

* Slony's configuration files can contain errors that are only detected after many hours, even days, of operation have elapsed. This happened to me yesterday: 14 hours after an initial copy-set operation started, it reported that one of the slave tables was missing its primary key, something it could have reported when the cluster was created.  And often when the error is discovered, the only recourse seems to be to uninstall the Slony schema, and restart from ground zero.

* Slony can encounter errors from which there is no recovery, except to blow off the system and start over.  Such as the one I'm facing right now.

* Almost every serious error I've encountered has resulted in a meaningless error message.  The only recourse is to post a question on this forum, and wait for an answer.  Developers have been very friendly and helpful, but the point is, I shouldn't have to come here for EVERY problem.  Take this particular problem, "node -1 not found in runtime configuration."  In the exact spot of code that generated that message, the developer who wrote that code KNEW what was going on.  What operation was being tried?  What set is being copied?  What generated this event?  This information is available somewhere, but IS NOT REPORTED TO THE USER.  This seems to be the rule, not the exception, in my experience with Slony, and it demonstrates a lack of attention to the quality of the user experience.  There is never an excuse for not telling the user 100% of the information that is known when an exception occurs.

Or take this example, that I reported on 4/2/2008:

    ERROR: Slonik version: 1.2.13 != Slony-I version in PG build 1.2.9

What's the critical missing information here? WHICH NODE NUMBER IS REPORTING THIS???  The developer who wrote this code KNEW which node generated the problem, but didn't put that information into the error message, which cost me, and Jeff Frost (who helped my diagnose the problem), about 4 hours of wasted time.  This seems to be the rule, rather than the exception, in the way Slony is coded.

Slony is like a really fast race car.  The drivers are justifiably proud that it is a very fine machine, that their machine is REALLY fast.  But if you want to get to the grocery store, you're better off to take the family car, or even a horse and buggy, because if you take the race car to the grocery store, you may be hungry several times each week.  And if you have a critical situation, like someone is sick, the race car might get them to the hospital very quickly indeed.  But there's an equally good chance the sick patient would die by the side of the road waiting for the the race car's team to repair the engine.

So, best wishes to the Slony team, and keep up the good work.  If my comments seem harsh, it's because I care: I wouldn't even bother if Slony was junk.  It's a great idea, and most of Slony is well conceived and well executed.  I hope that my comments will be take as constructive criticism.  I hope to be back in a few years when you've made more progress.

Regards,
Craig




From msmith at crsinc.com  Fri Apr  4 14:23:31 2008
From: msmith at crsinc.com (stuntmusic)
Date: Fri Apr  4 14:23:45 2008
Subject: [Slony1-general] Data from slaves pushed back to master - Can it be
	done?
Message-ID: <16467554.post@talk.nabble.com>


I have an office that works on the master database of our application and I
want to set up a way for these users to work on a slave DB to keep them off
the production 'wire'

It appears that Slony-I can replicate the data DOWN to the slave easily
enough, but can it also handle replication UP, back to the production db?

For example, a user here needs to modify a record. They make the mod on the
slave DB. When or how does Slony-I get that mod back to the Master? Is there
a setting that allows me to set the refresh up to the master, or is it a
built in interval?

Thanks in advance.

- Marc
-- 
View this message in context: http://www.nabble.com/Data-from-slaves-pushed-back-to-master---Can-it-be-done--tp16467554p16467554.html
Sent from the Slony-I -- General mailing list archive at Nabble.com.

From glynastill at yahoo.co.uk  Fri Apr  4 14:25:05 2008
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Fri Apr  4 14:25:19 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
	causes  "node -1 not found")
Message-ID: <889775.88069.qm@web25803.mail.ukl.yahoo.com>

See below

----- Original Message ----
> From: Craig James <craig_james@emolecules.com>
> To: slony1-general@lists.slony.info
> Sent: Friday, 4 April, 2008 7:09:24 PM
> Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set, causes  "node -1 not found")
> 
> Glyn Astill wrote:
> 
> > I had a similar scenario a few months ago and never managed to figure
> > out what happened. Nobody could tell me what the node -1 was all about...
> > 
> > I'd love to know if you  get to the bottom of it.
> 
> Yes, I just now got to the bottom of it.  I realized that Slony is not high 
> enough quality to use in a production environment, and I'm abandoning it until 
> some time in the future when it has matured a bit more.
> 
> This is just the last straw.  I really hate to be critical of any open-source 
> project, because I genuinely appreciate everyone's hard work.  But in the end, 
> Slony has proved to be more trouble that it is worth.  It simply doesn't get the 
> job done reliably.
> 
> It's clear to me that Slony's developers are focused on features, and have not 
> paid enough attention to the user experience.  It's a classic case where the 
> developers, who are experts in their own technology, don't realize just how 
> difficult their product is for the mainstream user.
> 
> * Slony's configuration is like programming in FORTRAN or assembly language in 
> 1966.  There is no reason why Slony should need anything more than a set's name 
> and the table's names that belong to the set.  Computers are good at numbering 
> things, why should I have to?  It takes DAYS to learn how to create a Slony 
> configuration, and it is only achieved through lots of trial and error.

Really? I found the slony docs quite good to be honest, and the slonik language is there to make it flexible.
How you manage to compare slonik scripts to fortran is beyond me, and from that comment I can only guess you've never touched any form of assembly.

> 
> * It is trivially easy to DESTROY an entire database with Slony.  All you have 
> to do is a simply typo, reversing node 1 and node 2, and Slony will, with no 
> further warning, truncate every table in your master database.  There is no way 
> to say, "This is the MASTER, no matter what else I say, never mess with it."  
> This should be a fundamental concept in Slony, but is not.  This is particularly 
> serious, given that Slony expects to connect as the super-user, so you can't 
> (for example) use a guest account that has no write priviliges, which would be 
> the sensible approach.  Slony really needs two users: The super user (during 
> configuration only), and the operational user (during normal operation), and 
> these should be set separately for the master and slaves..
> 

Hmm, slonik has proved to be very forgiving with any typos like that for me. If something is wrong then it generally doesn't run the script. However you can get yourself into a mess if you're not careful to wait for certain things to complete, in my opinion it could do with a little brushing up here. I also recently made a bit of a mess by adding a trigger onto a slave database, then trying to drop the table without bringing it out of the cluster - I still need to sort this.


> * Slony's configuration files can contain errors that are only detected after 
> many hours, even days, of operation have elapsed. This happened to me yesterday: 
> 14 hours after an initial copy-set operation started, it reported that one of 
> the slave tables was missing its primary key, something it could have reported 
> when the cluster was created.  And often when the error is discovered, the only 
> recourse seems to be to uninstall the Slony schema, and restart from ground 
> zero.
>

Afaik if theres no primary key on the table slony will create what it needs?
 
> * Slony can encounter errors from which there is no recovery, except to blow off 
> the system and start over.  Such as the one I'm facing right now.
>

In the aforementioned shagged scenario, I can agree that I had to recreate the slony cluster here to get our of a similar problem - and I can see how it could be a big problem. But honestly - since I read the docs better and ran the scripts ONLY as described in the docs, I've yet to have another big problem.

> 
> * Almost every serious error I've encountered has resulted in a meaningless 
> error message.  The only recourse is to post a question on this forum, and wait 
> for an answer.  Developers have been very friendly and helpful, but the point 
> is, I shouldn't have to come here for EVERY problem.  Take this particular 
> problem, "node -1 not found in runtime configuration."  In the exact spot of 
> code that generated that message, the developer who wrote that code KNEW what 
> was going on.  What operation was being tried?  What set is being copied?  What 
> generated this event?  This information is available somewhere, but IS NOT 
> REPORTED TO THE USER.  This seems to be the rule, not the exception, in my 
> experience with Slony, and it demonstrates a lack of attention to the quality of 
> the user experience.  There is never an excuse for not telling the user 100% of 
> the information that is known when an exception occurs.

I've seen worse in commercial products. But must agree I thought the same about the -1 thing - Surely someone at affilias has to know how we end up with that?

> 
> Or take this example, that I reported on 4/2/2008:
> 
>     ERROR: Slonik version: 1.2.13 != Slony-I version in PG build 1.2.9
> 
> What's the critical missing information here? WHICH NODE NUMBER IS REPORTING 
> THIS???  The developer who wrote this code KNEW which node generated the 
> problem, but didn't put that information into the error message, which cost me, 
> and Jeff Frost (who helped my diagnose the problem), about 4 hours of wasted 
> time.  This seems to be the rule, rather than the exception, in the way Slony is 
> coded.
>

Bloomin heck! How many nodes have you got!
 
> Slony is like a really fast race car.  The drivers are justifiably proud that it 
> is a very fine machine, that their machine is REALLY fast.  But if you want to 
> get to the grocery store, you're better off to take the family car, or even a 
> horse and buggy, because if you take the race car to the grocery store, you may 
> be hungry several times each week.  And if you have a critical situation, like 
> someone is sick, the race car might get them to the hospital very quickly 
> indeed.  But there's an equally good chance the sick patient would die by the 
> side of the road waiting for the the race car's team to repair the engine.
> 
> So, best wishes to the Slony team, and keep up the good work.  If my comments 
> seem harsh, it's because I care: I wouldn't even bother if Slony was junk.  It's 
> a great idea, and most of Slony is well conceived and well executed.  I hope 
> that my comments will be take as constructive criticism.  I hope to be back in a 
> few years when you've made more progress.
> 
> Regards,
> Craig
> 
> 
> 
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
> 




      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  

http://uk.promotions.yahoo.com/forgood/

From ahodgson at simkin.ca  Fri Apr  4 14:43:49 2008
From: ahodgson at simkin.ca (Alan Hodgson)
Date: Fri Apr  4 14:42:15 2008
Subject: [Slony1-general] Data from slaves pushed back to master - Can it
	be done?
In-Reply-To: <16467554.post@talk.nabble.com>
References: <16467554.post@talk.nabble.com>
Message-ID: <200804041443.49745@hal.medialogik.com>

On Friday 04 April 2008, stuntmusic <msmith@crsinc.com> wrote:
> For example, a user here needs to modify a record. They make the mod on
> the slave DB. When or how does Slony-I get that mod back to the Master?
> Is there a setting that allows me to set the refresh up to the master, or
> is it a built in interval?

Slaves are read-only. An agent like PgPool can dispatch write operations to 
a master while directing reads to slaves, though.

-- 
Alan
From craig_james at emolecules.com  Fri Apr  4 15:06:28 2008
From: craig_james at emolecules.com (Craig James)
Date: Fri Apr  4 15:06:44 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
	causes  "node -1 not found")
In-Reply-To: <889775.88069.qm@web25803.mail.ukl.yahoo.com>
References: <889775.88069.qm@web25803.mail.ukl.yahoo.com>
Message-ID: <47F6A664.3070404@emolecules.com>

Glyn Astill wrote:

> How you manage to compare slonik scripts to fortran is beyond me,
> and from that comment I can only guess you've never touched any form of assembly.

Ha, boy you guessed wrong on that one.  I started programming IBM360 assembly on 80-column punch cards in 1969, when there were only two IBM computers in the entire County of Santa Cruz, CA.  I wrote my own assembler (most of you have probably never even run an assembler, you only know about compilers!) in Algol on a Burroughs B6700 at UC Davis in 1975, because the assembler Intel gave us was too slow and crashed.  It compiled 8080 assembly into object that was download from the B6700 to an Intel CPU through a 110 BAUD paper-tape punch teletype.  I wrote tens of thousands of lines of Motorola 6800 and Motorola 68000 assembly code in the early 1980's for high-performance chemistry instruments.

I programmed in FORTRAN II (have you even heard of FORTRAN II?), FORTRAN IV, FORTRAN 77, and various other flavors, not to mention a half-dozen languages that went obsolete before many of you guys were even born, literally.

Thankfully, those days are over.  The trick in life is to keep educating yourself!

These days, I program in high-level languages like Java and Perl.  Why should programmers waste their time doing stuff that the computer can do?  Like creating Slony's configuration files?

Craig
From JanWieck at Yahoo.com  Fri Apr  4 17:18:10 2008
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Fri Apr  4 17:18:37 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
	causes  "node -1 not found")
In-Reply-To: <889775.88069.qm@web25803.mail.ukl.yahoo.com>
References: <889775.88069.qm@web25803.mail.ukl.yahoo.com>
Message-ID: <47F6C542.5050206@Yahoo.com>

On 4/4/2008 5:25 PM, Glyn Astill wrote:
> See below

It appeared to me that Craig needed to get something off his chest after 
getting very frustrated. And getting frustrated with Slony is something 
that we all know is possible. The only thing that really worried me in 
the whole rant was that he obviously ran into all these problems while 
attempting to use Slony in a large scale production environment without 
bothering to test and learn in a lab setup prior to risking all that 
precious data.

Slony was not developed with that sort of irresponsible user in mind.

I am sorry that Slony does not meet Craig's ease of use expectations. As 
has been said many times, there can not be a one size fits all approach 
to replication. Hopefully he will find that some other project, like 
Mammoth (which is being open sourced right now) can deliver the 
functionality, performance as well as simplicity that he expects.


Good luck
Jan


> 
> ----- Original Message ----
>> From: Craig James <craig_james@emolecules.com>
>> To: slony1-general@lists.slony.info
>> Sent: Friday, 4 April, 2008 7:09:24 PM
>> Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set, causes  "node -1 not found")
>> 
>> Glyn Astill wrote:
>> 
>> > I had a similar scenario a few months ago and never managed to figure
>> > out what happened. Nobody could tell me what the node -1 was all about...
>> > 
>> > I'd love to know if you  get to the bottom of it.
>> 
>> Yes, I just now got to the bottom of it.  I realized that Slony is not high 
>> enough quality to use in a production environment, and I'm abandoning it until 
>> some time in the future when it has matured a bit more.
>> 
>> This is just the last straw.  I really hate to be critical of any open-source 
>> project, because I genuinely appreciate everyone's hard work.  But in the end, 
>> Slony has proved to be more trouble that it is worth.  It simply doesn't get the 
>> job done reliably.
>> 
>> It's clear to me that Slony's developers are focused on features, and have not 
>> paid enough attention to the user experience.  It's a classic case where the 
>> developers, who are experts in their own technology, don't realize just how 
>> difficult their product is for the mainstream user.
>> 
>> * Slony's configuration is like programming in FORTRAN or assembly language in 
>> 1966.  There is no reason why Slony should need anything more than a set's name 
>> and the table's names that belong to the set.  Computers are good at numbering 
>> things, why should I have to?  It takes DAYS to learn how to create a Slony 
>> configuration, and it is only achieved through lots of trial and error.
> 
> Really? I found the slony docs quite good to be honest, and the slonik language is there to make it flexible.
> How you manage to compare slonik scripts to fortran is beyond me, and from that comment I can only guess you've never touched any form of assembly.
> 
>> 
>> * It is trivially easy to DESTROY an entire database with Slony.  All you have 
>> to do is a simply typo, reversing node 1 and node 2, and Slony will, with no 
>> further warning, truncate every table in your master database.  There is no way 
>> to say, "This is the MASTER, no matter what else I say, never mess with it."  
>> This should be a fundamental concept in Slony, but is not.  This is particularly 
>> serious, given that Slony expects to connect as the super-user, so you can't 
>> (for example) use a guest account that has no write priviliges, which would be 
>> the sensible approach.  Slony really needs two users: The super user (during 
>> configuration only), and the operational user (during normal operation), and 
>> these should be set separately for the master and slaves..
>> 
> 
> Hmm, slonik has proved to be very forgiving with any typos like that for me. If something is wrong then it generally doesn't run the script. However you can get yourself into a mess if you're not careful to wait for certain things to complete, in my opinion it could do with a little brushing up here. I also recently made a bit of a mess by adding a trigger onto a slave database, then trying to drop the table without bringing it out of the cluster - I still need to sort this.
> 
> 
>> * Slony's configuration files can contain errors that are only detected after 
>> many hours, even days, of operation have elapsed. This happened to me yesterday: 
>> 14 hours after an initial copy-set operation started, it reported that one of 
>> the slave tables was missing its primary key, something it could have reported 
>> when the cluster was created.  And often when the error is discovered, the only 
>> recourse seems to be to uninstall the Slony schema, and restart from ground 
>> zero.
>>
> 
> Afaik if theres no primary key on the table slony will create what it needs?
>  
>> * Slony can encounter errors from which there is no recovery, except to blow off 
>> the system and start over.  Such as the one I'm facing right now.
>>
> 
> In the aforementioned shagged scenario, I can agree that I had to recreate the slony cluster here to get our of a similar problem - and I can see how it could be a big problem. But honestly - since I read the docs better and ran the scripts ONLY as described in the docs, I've yet to have another big problem.
> 
>> 
>> * Almost every serious error I've encountered has resulted in a meaningless 
>> error message.  The only recourse is to post a question on this forum, and wait 
>> for an answer.  Developers have been very friendly and helpful, but the point 
>> is, I shouldn't have to come here for EVERY problem.  Take this particular 
>> problem, "node -1 not found in runtime configuration."  In the exact spot of 
>> code that generated that message, the developer who wrote that code KNEW what 
>> was going on.  What operation was being tried?  What set is being copied?  What 
>> generated this event?  This information is available somewhere, but IS NOT 
>> REPORTED TO THE USER.  This seems to be the rule, not the exception, in my 
>> experience with Slony, and it demonstrates a lack of attention to the quality of 
>> the user experience.  There is never an excuse for not telling the user 100% of 
>> the information that is known when an exception occurs.
> 
> I've seen worse in commercial products. But must agree I thought the same about the -1 thing - Surely someone at affilias has to know how we end up with that?
> 
>> 
>> Or take this example, that I reported on 4/2/2008:
>> 
>>     ERROR: Slonik version: 1.2.13 != Slony-I version in PG build 1.2.9
>> 
>> What's the critical missing information here? WHICH NODE NUMBER IS REPORTING 
>> THIS???  The developer who wrote this code KNEW which node generated the 
>> problem, but didn't put that information into the error message, which cost me, 
>> and Jeff Frost (who helped my diagnose the problem), about 4 hours of wasted 
>> time.  This seems to be the rule, rather than the exception, in the way Slony is 
>> coded.
>>
> 
> Bloomin heck! How many nodes have you got!
>  
>> Slony is like a really fast race car.  The drivers are justifiably proud that it 
>> is a very fine machine, that their machine is REALLY fast.  But if you want to 
>> get to the grocery store, you're better off to take the family car, or even a 
>> horse and buggy, because if you take the race car to the grocery store, you may 
>> be hungry several times each week.  And if you have a critical situation, like 
>> someone is sick, the race car might get them to the hospital very quickly 
>> indeed.  But there's an equally good chance the sick patient would die by the 
>> side of the road waiting for the the race car's team to repair the engine.
>> 
>> So, best wishes to the Slony team, and keep up the good work.  If my comments 
>> seem harsh, it's because I care: I wouldn't even bother if Slony was junk.  It's 
>> a great idea, and most of Slony is well conceived and well executed.  I hope 
>> that my comments will be take as constructive criticism.  I hope to be back in a 
>> few years when you've made more progress.
>> 
>> Regards,
>> Craig
>> 
>> 
>> 
>> 
>> _______________________________________________
>> Slony1-general mailing list
>> Slony1-general@lists.slony.info
>> http://lists.slony.info/mailman/listinfo/slony1-general
>> 
> 
> 
> 
> 
>       ___________________________________________________________ 
> Yahoo! For Good helps you make a difference  
> 
> http://uk.promotions.yahoo.com/forgood/
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From JanWieck at Yahoo.com  Fri Apr  4 17:24:53 2008
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Fri Apr  4 17:25:14 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
	causes  "node -1 not found")
In-Reply-To: <47F6A664.3070404@emolecules.com>
References: <889775.88069.qm@web25803.mail.ukl.yahoo.com>
	<47F6A664.3070404@emolecules.com>
Message-ID: <47F6C6D5.4070304@Yahoo.com>

On 4/4/2008 6:06 PM, Craig James wrote:
> Why should programmers waste their time doing stuff that the computer can do?  Like creating Slony's configuration files?

Very simple, because in a Slony replication cluster, it is possible to 
have different nodes being origin and/or subscriber of different sets as 
well as have quite different access patterns per node which results in 
different schema requirements (like extra indexes, views, custom 
triggers etc.). Sure, for some users it would be nice to have tools like 
the altperl stuff, that can easily generate those "me master, you slave" 
configuration files. However, if there is so broad need for them, why 
does nobody bother maintaining them?


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From WCoole at aperiogroup.com  Fri Apr  4 17:56:59 2008
From: WCoole at aperiogroup.com (Walter Coole)
Date: Fri Apr  4 17:57:23 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
	causes  "node -1 not found")
In-Reply-To: <47F6C542.5050206@Yahoo.com>
References: <889775.88069.qm@web25803.mail.ukl.yahoo.com>
	<47F6C542.5050206@Yahoo.com>
Message-ID: <4292CEA5F4927248979C701CA83500BB83DD59@SERVER.aperiogroup.local>

Having attempted to use Slony and given up (for now), I share some of Craig's frustration.  It appears that the Slony community has focused on making a very powerful and highly configurable toolset.  What has been lost is ease of use.

Having worked with other databases, where replication is very easy to set up, I was surprised and frustrated by the extent that Slony was not a replication appliance, so much as a collection of tools with which a replication solution can be crafted.  It is, apparently, a very good set of tools, but I imagine that the vast majority of database users (as opposed to Slony users) really only need a simple setup: replicate all tables onto 1 or a few slaves.

My difficulties (and perhaps Craig's) were not with the technology, but with packaging.  I would find enormous value in a canned, complete, pre-configured, one-size-fits-all distribution with a simple user interface.  Perhaps I'm just displaying my stupidity, but having spent weeks compiling, configuring, debugging, recompiling, restoring a mangled database, lather, rinse repeat, I have to concur with Craig's characterization of the documentation and error messaging as inadequate.  I've done the equivalent task with MySQL in less than an hour (including the replication time), without any loss of data, despite having (at the time) considerably more ignorance.

Some have indicated that they "found the slony docs quite good", which may be true at the detail level, but from the I-haven't-a-clue-how-do-I-get-started level, I never found a single, complete, correct, applicable set of instructions, but instead found many little snippets that explained part of the job, then pointed to other instructions that made conflicting assumptions about how things were set up.

Perhaps Mammoth will provide the simple solution that we (Craig and I) need, but I don't see value in splitting the efforts of the community across 2 solutions.  I would have thought it better to write a simple setup script for Slony, or at least a Slony Setup for Dummies document.

FWIW, I learned to program in machine code, it's merely that my boss expects me to be more productive than that.

Walter
-----Original Message-----
From: slony1-general-bounces@lists.slony.info [mailto:slony1-general-bounces@lists.slony.info] On Behalf Of Jan Wieck
Sent: Friday, April 04, 2008 5:18 PM
To: Glyn Astill
Cc: slony1-general@lists.slony.info
Subject: Re: [Slony1-general] Abandoning Slony (was: drop-set/create-set,causes "node -1 not found")

On 4/4/2008 5:25 PM, Glyn Astill wrote:
> See below

It appeared to me that Craig needed to get something off his chest after 
getting very frustrated. And getting frustrated with Slony is something 
that we all know is possible. The only thing that really worried me in 
the whole rant was that he obviously ran into all these problems while 
attempting to use Slony in a large scale production environment without 
bothering to test and learn in a lab setup prior to risking all that 
precious data.

Slony was not developed with that sort of irresponsible user in mind.

I am sorry that Slony does not meet Craig's ease of use expectations. As 
has been said many times, there can not be a one size fits all approach 
to replication. Hopefully he will find that some other project, like 
Mammoth (which is being open sourced right now) can deliver the 
functionality, performance as well as simplicity that he expects.


Good luck
Jan


> 
> ----- Original Message ----
>> From: Craig James <craig_james@emolecules.com>
>> To: slony1-general@lists.slony.info
>> Sent: Friday, 4 April, 2008 7:09:24 PM
>> Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set, causes  "node -1 not found")
>> 
>> Glyn Astill wrote:
>> 
>> > I had a similar scenario a few months ago and never managed to figure
>> > out what happened. Nobody could tell me what the node -1 was all about...
>> > 
>> > I'd love to know if you  get to the bottom of it.
>> 
>> Yes, I just now got to the bottom of it.  I realized that Slony is not high 
>> enough quality to use in a production environment, and I'm abandoning it until 
>> some time in the future when it has matured a bit more.
>> 
>> This is just the last straw.  I really hate to be critical of any open-source 
>> project, because I genuinely appreciate everyone's hard work.  But in the end, 
>> Slony has proved to be more trouble that it is worth.  It simply doesn't get the 
>> job done reliably.
>> 
>> It's clear to me that Slony's developers are focused on features, and have not 
>> paid enough attention to the user experience.  It's a classic case where the 
>> developers, who are experts in their own technology, don't realize just how 
>> difficult their product is for the mainstream user.
>> 
>> * Slony's configuration is like programming in FORTRAN or assembly language in 
>> 1966.  There is no reason why Slony should need anything more than a set's name 
>> and the table's names that belong to the set.  Computers are good at numbering 
>> things, why should I have to?  It takes DAYS to learn how to create a Slony 
>> configuration, and it is only achieved through lots of trial and error.
> 
> Really? I found the slony docs quite good to be honest, and the slonik language is there to make it flexible.
> How you manage to compare slonik scripts to fortran is beyond me, and from that comment I can only guess you've never touched any form of assembly.
> 
>> 
>> * It is trivially easy to DESTROY an entire database with Slony.  All you have 
>> to do is a simply typo, reversing node 1 and node 2, and Slony will, with no 
>> further warning, truncate every table in your master database.  There is no way 
>> to say, "This is the MASTER, no matter what else I say, never mess with it."  
>> This should be a fundamental concept in Slony, but is not.  This is particularly 
>> serious, given that Slony expects to connect as the super-user, so you can't 
>> (for example) use a guest account that has no write priviliges, which would be 
>> the sensible approach.  Slony really needs two users: The super user (during 
>> configuration only), and the operational user (during normal operation), and 
>> these should be set separately for the master and slaves..
>> 
> 
> Hmm, slonik has proved to be very forgiving with any typos like that for me. If something is wrong then it generally doesn't run the script. However you can get yourself into a mess if you're not careful to wait for certain things to complete, in my opinion it could do with a little brushing up here. I also recently made a bit of a mess by adding a trigger onto a slave database, then trying to drop the table without bringing it out of the cluster - I still need to sort this.
> 
> 
>> * Slony's configuration files can contain errors that are only detected after 
>> many hours, even days, of operation have elapsed. This happened to me yesterday: 
>> 14 hours after an initial copy-set operation started, it reported that one of 
>> the slave tables was missing its primary key, something it could have reported 
>> when the cluster was created.  And often when the error is discovered, the only 
>> recourse seems to be to uninstall the Slony schema, and restart from ground 
>> zero.
>>
> 
> Afaik if theres no primary key on the table slony will create what it needs?
>  
>> * Slony can encounter errors from which there is no recovery, except to blow off 
>> the system and start over.  Such as the one I'm facing right now.
>>
> 
> In the aforementioned shagged scenario, I can agree that I had to recreate the slony cluster here to get our of a similar problem - and I can see how it could be a big problem. But honestly - since I read the docs better and ran the scripts ONLY as described in the docs, I've yet to have another big problem.
> 
>> 
>> * Almost every serious error I've encountered has resulted in a meaningless 
>> error message.  The only recourse is to post a question on this forum, and wait 
>> for an answer.  Developers have been very friendly and helpful, but the point 
>> is, I shouldn't have to come here for EVERY problem.  Take this particular 
>> problem, "node -1 not found in runtime configuration."  In the exact spot of 
>> code that generated that message, the developer who wrote that code KNEW what 
>> was going on.  What operation was being tried?  What set is being copied?  What 
>> generated this event?  This information is available somewhere, but IS NOT 
>> REPORTED TO THE USER.  This seems to be the rule, not the exception, in my 
>> experience with Slony, and it demonstrates a lack of attention to the quality of 
>> the user experience.  There is never an excuse for not telling the user 100% of 
>> the information that is known when an exception occurs.
> 
> I've seen worse in commercial products. But must agree I thought the same about the -1 thing - Surely someone at affilias has to know how we end up with that?
> 
>> 
>> Or take this example, that I reported on 4/2/2008:
>> 
>>     ERROR: Slonik version: 1.2.13 != Slony-I version in PG build 1.2.9
>> 
>> What's the critical missing information here? WHICH NODE NUMBER IS REPORTING 
>> THIS???  The developer who wrote this code KNEW which node generated the 
>> problem, but didn't put that information into the error message, which cost me, 
>> and Jeff Frost (who helped my diagnose the problem), about 4 hours of wasted 
>> time.  This seems to be the rule, rather than the exception, in the way Slony is 
>> coded.
>>
> 
> Bloomin heck! How many nodes have you got!
>  
>> Slony is like a really fast race car.  The drivers are justifiably proud that it 
>> is a very fine machine, that their machine is REALLY fast.  But if you want to 
>> get to the grocery store, you're better off to take the family car, or even a 
>> horse and buggy, because if you take the race car to the grocery store, you may 
>> be hungry several times each week.  And if you have a critical situation, like 
>> someone is sick, the race car might get them to the hospital very quickly 
>> indeed.  But there's an equally good chance the sick patient would die by the 
>> side of the road waiting for the the race car's team to repair the engine.
>> 
>> So, best wishes to the Slony team, and keep up the good work.  If my comments 
>> seem harsh, it's because I care: I wouldn't even bother if Slony was junk.  It's 
>> a great idea, and most of Slony is well conceived and well executed.  I hope 
>> that my comments will be take as constructive criticism.  I hope to be back in a 
>> few years when you've made more progress.
>> 
>> Regards,
>> Craig
>> 
>> 
>> 
>> 
>> _______________________________________________
>> Slony1-general mailing list
>> Slony1-general@lists.slony.info
>> http://lists.slony.info/mailman/listinfo/slony1-general
>> 
> 
> 
> 
> 
>       ___________________________________________________________ 
> Yahoo! For Good helps you make a difference  
> 
> http://uk.promotions.yahoo.com/forgood/
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

_______________________________________________
Slony1-general mailing list
Slony1-general@lists.slony.info
http://lists.slony.info/mailman/listinfo/slony1-general
From craig_james at emolecules.com  Fri Apr  4 20:35:01 2008
From: craig_james at emolecules.com (Craig James)
Date: Fri Apr  4 20:35:22 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
	causes  "node -1 not found")
In-Reply-To: <47F6C542.5050206@Yahoo.com>
References: <889775.88069.qm@web25803.mail.ukl.yahoo.com>
	<47F6C542.5050206@Yahoo.com>
Message-ID: <47F6F365.3080009@emolecules.com>

Jan Wieck wrote:
> It appeared to me that Craig needed to get something off his chest after 
> getting very frustrated. And getting frustrated with Slony is something 
> that we all know is possible. The only thing that really worried me in 
> the whole rant was that he obviously ran into all these problems while 
> attempting to use Slony in a large scale production environment without 
> bothering to test and learn in a lab setup prior to risking all that 
> precious data.
> 
> Slony was not developed with that sort of irresponsible user in mind.

Your attitude illustrates the very problem I wrote about -- a lack of concern for the real-life problems of your users, and outright disrepect for criticism.  I rarely engage in these tit-for-tat insult exchanges, as they're not productive.  But in this case, I will at least correct the factual errors in your reply.

I have been using Slony for quite some time.  I started with small databases, "learned the ropes" exactly as you suggest, read the documentation carefully, asked a number of questions on this forum, then replicated a medium-sized database, and finally worked up to a full-sized database.  We have been using Slony successfully for about 6 months, on this very same large production database that caused me all the trouble this week.

So, you are simply flat-out wrong in your assumption.  EVEN AFTER doing exactly what you suggest is the correct way to use Slony, and EVEN AFTER using it successfully for over a year, I have decided to abandon it, based on my extensive experience with Slony itself, and on my expertise as a computer scientist.

I have absolutely no need to get something "off my chest."  I've been around too long to care about such things.  My critique was my way of contributing to the Slony project.  Open source is about collaboration, and sometimes that collaboration comes in the form of feedback, not code.  And you may not like the feedback ... does that mean I shouldn't tell you the truth?  If I make use of your project, and I decide I can't use it, the least I can do is tell you why.

As for my expertise, I've operated Oracle, MySQL and Postgres databases for almost 15 years.   I started programming in high school 1968, received a bachelor's degree in computer science in 1978 from UC Davis, and my Master's degree in 1985 from Stanford University, which was paid for by an honors fellowship from Hewlett Packard Laboratories, where I was a reasearcher in molecular modeling.  I am considered one of the world's leading experts in my field (chemical database systems), and was a director of computer architecture at a major scientific software company.

Do you thing you're dealing with kids?

Calling my carefully-worded critique a "rant" is hardly the way a computer scientist should treat a fellow computer scientists who is offering his time and experience to give your project his expert advice.

> I am sorry that Slony does not meet Craig's ease of use expectations. As 
> has been said many times, there can not be a one size fits all approach 
> to replication. Hopefully he will find that some other project, like 
> Mammoth (which is being open sourced right now) can deliver the 
> functionality, performance as well as simplicity that he expects.

My "rant" was about quality, not ease of use.  If you've never read "Zen and the Art of Motorcycle Maintenance," you may not know the difference.  It's a book every real programmer should read ... twice.  It's not an easy book to read, but if you get it, it will change your life.  Ease of use is a natural side effect of a Quality attitude, but quality comes from an appreciation for the beauty in a well-crafted system, not from school.

Sincerely,
Craig
From henry at zen.co.za  Fri Apr  4 23:36:13 2008
From: henry at zen.co.za (Henry)
Date: Fri Apr  4 23:36:47 2008
Subject: [Slony1-general] Data from slaves pushed back to master - Can 
	it be done?
In-Reply-To: <16467554.post@talk.nabble.com>
References: <16467554.post@talk.nabble.com>
Message-ID: <63836.196.23.181.69.1207377373.squirrel@zenmail.co.za>

On Fri, April 4, 2008 11:23 pm, stuntmusic wrote:
> I have an office that works on the master database of our application and
> I
> want to set up a way for these users to work on a slave DB to keep them
> off
> the production 'wire'

Try using slony with PgPool - pgpool can intercept mods
(update/insert/delete) and send them to the master, while selects stay on
the slave.  Slony then takes care of replicating those changes back to the
slave/s.

We used this setup for months for exactly the same reason - reducing load
on the master (big selects), while reducing bandwidth use over a WAN line.

Let me know if you decide to go this way and I'll send you a typical
pgpool config.

Regards
Henry

From drees76 at gmail.com  Sat Apr  5 01:09:14 2008
From: drees76 at gmail.com (David Rees)
Date: Sat Apr  5 01:09:40 2008
Subject: [Slony1-general] Abandoning Slony
Message-ID: <72dbd3150804050109l67352280k7f3c598beeedb8cf@mail.gmail.com>

On Fri, Apr 4, 2008 at 11:09 AM, Craig James <craig_james@emolecules.com> wrote:
>  Yes, I just now got to the bottom of it.  I realized that Slony is not high
> enough quality to use in a production environment, and I'm abandoning it
> until some time in the future when it has matured a bit more.

That should be clarified - Slony is not enough high quality to use in
a production environment _for you_. It works very well for me. It took
a few days of reading docs and testing to get familiar enough with how
Slony works to become comfortable using it in production, and I find
it works great.

In fact, compared to the commercial replication product it replaced,
Slony is the following:

Cheaper (I was paying $25k for a basic replication license per server)
Faster (Replication lag is minimal and so is overhead)
Reliable (Have never had a problem that wasn't caused by me doing
something the docs said not to - and even then I was able to correct
the problem)

>  This is just the last straw.  I really hate to be critical of any
> open-source project, because I genuinely appreciate everyone's hard work.
> But in the end, Slony has proved to be more trouble that it is worth.

It sounds to me that what you really need is a Slony expert - Perhaps
calling up Command Prompt and getting them to help would be a
solution.

>  It's clear to me that Slony's developers are focused on features, and have
> not paid enough attention to the user experience.  It's a classic case where
> the developers, who are experts in their own technology, don't realize just
> how difficult their product is for the mainstream user.

Yes, a spiffy whiz-bang interface to simply things for the mainstream
user would be nice. But that's not going to happen until one of two
things happen:

1. A developer gets an itch and decides to build it.
2. A customer decides to pay a developer to build it.

>  * It is trivially easy to DESTROY an entire database with Slony.  All you
> have to do is a simply typo, reversing node 1 and node 2, and Slony will,
> with no further warning, truncate every table in your master database.

That's really the job of the to be designed whiz-bang interface, not Slony.

>  * Slony's configuration files can contain errors that are only detected
> after many hours, even days, of operation have elapsed. This happened to me
> yesterday: 14 hours after an initial copy-set operation started, it reported
> that one of the slave tables was missing its primary key, something it could
> have reported when the cluster was created.  And often when the error is
> discovered, the only recourse seems to be to uninstall the Slony schema, and
> restart from ground zero.

Checking tables for primary keys before starting copying sounds like a
good idea. Have you filed a bug report?

>  * Slony can encounter errors from which there is no recovery, except to
> blow off the system and start over.  Such as the one I'm facing right now.

I've never seen a problem that absolutely requires one to blow off the
system and start over - but often it is easier to do so rather than
debug the issue.

>  So, best wishes to the Slony team, and keep up the good work.  If my
> comments seem harsh, it's because I care:

Unfortunately, your situation is prevalent with many open source
projects like Slony.

It goes like this:

1. Developers release open source software.
2. Users find open source software rough around the edges or encounters bugs.
3. Users expect instant support to their questions on mailing lists
(hurry, it's production and critical!)
4. Users give up, get mad and leave when the answers do not come while
secretly praying that someone else makes things better while they are
gone.

What can be done?

1. Don't expect fast, free support.
2. If you need fast support from people who know the product inside
and out, pay for it.
3. Paying for support also helps to pay for the development of tools
that can make things easier in the future.

I'm not a Slony developer, just a user, but I do write software for a
living so I know how much time, effort and resources it takes to
create a polished product. So when I do find something that is an
issue I try to make note of it and make it as easy as possible for the
developers to fix it.

-Dave
From henry at zen.co.za  Sat Apr  5 02:30:48 2008
From: henry at zen.co.za (Henry)
Date: Sat Apr  5 02:31:17 2008
Subject: [Slony1-general] Initial replication repeatedly 
	restarts/copies same tables
In-Reply-To: <63150.196.23.181.69.1207312320.squirrel@zenmail.co.za>
References: <63150.196.23.181.69.1207312320.squirrel@zenmail.co.za>
Message-ID: <64421.196.23.181.69.1207387848.squirrel@zenmail.co.za>

On Fri, April 4, 2008 2:32 pm, Henry wrote:
> They're repeatedly restarting and copying the same tables - and never
> completing.

To clarify, "never completing" is probably not accurate; it's just been
repeating the truncate/copy process repeatedly several times since the
initial replication started (and the first slave finished) nine days ago.

Question:  does updates of some of the tables on the origin during the
initial replication have a bearing on this?  One of the parent tables on
the master is regularly updated, but the other tables are not.

test_slony_state.pl reports that "pg_listener relpages high -
6460"..."Perhaps a long running transaction is preventing pg_listener from
being vacuumed out?"   Presumably this is just a side-effect of the
initial replication?  Anyway, I did a vacuum full analyze on pg_listener
on all the nodes since it couldn't hurt.  After that vacuum, the report
says "pg_listener reltuples high - 346307"... :-)))

Sorry guys, please forgive my ignorance.  I'm feeling my way through this.
 The last time I felt so ignorant was (I think) over a decade ago digging
in a filesystem with debugfs.  Fortunately this is a prototyping
cluster... my ignorance-o-meter needs to come down a bit before I use it
live (think software RAID, LVM, clustering, etc).  Anyway, this
replication cluster worked fine for months, then one of the nodes lagged
behind in a big way and my impatience cajoled me into taking the tactical
nuke option of restarting from scratch (now, the db is bigger, so
everything is slower).

I can provide more config detail if required (plus output from
test_slony_state.pl).

Thanks
Henry



From henry at zen.co.za  Sat Apr  5 02:58:49 2008
From: henry at zen.co.za (Henry)
Date: Sat Apr  5 02:59:20 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
	causes  "node -1 not found")
In-Reply-To: <47F6C542.5050206@Yahoo.com>
References: <889775.88069.qm@web25803.mail.ukl.yahoo.com>
	<47F6C542.5050206@Yahoo.com>
Message-ID: <64647.196.23.181.69.1207389529.squirrel@zenmail.co.za>

On Sat, April 5, 2008 2:18 am, Jan Wieck wrote:

> ... Mammoth (which is being open sourced right now) ...

Curios:  I've checked out CommandPrompt's website but can find no
reference to the imminent open-sourcing of Mammoth.

Can you provide a link?

Regards
Henry


From glynastill at yahoo.co.uk  Sat Apr  5 04:47:08 2008
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Sat Apr  5 04:47:41 2008
Subject: [Slony1-general] ERROR:  XX000: cache lookup failed for relation
Message-ID: <860349.6752.qm@web25803.mail.ukl.yahoo.com>

Hi chaps,

I know there's been a bit of "activity" on this listrecently - but does anyone know where I should start looking to resolvethe below?

----- Original Message ----
> From: Glyn Astill <glynastill@yahoo.co.uk>
> To: slony1-general@lists.slony.info
> Cc: pgsql-general@postgresql.org
> Sent: Friday, 4 April, 2008 3:05:18 PM
> Subject: [Slony1-general] ERROR:  XX000: cache lookup failed for relation
> 
> Hi chaps,
> 
> I've got a problem trying to drop a table, I get the error "cache lookup failed 
> for relation"
> 
> SEE=# drop table replicated_users;
> ERROR:  XX000: cache lookup failed for relation 30554884
> LOCATION:  getRelationDescription, dependency.c:2021
> Now this table is on a slony-I slave and was in replication when I tried to drop 
> it - I presume this is a big mistake and I should never try to drop a table 
> without first droping it from replication?
> 
> In addition I'd set up a trigger on the table "replicate_users".
> 
> If I do:
> 
>  select relname,oid from pg_class where relname = 'replicated_users';
> 
> -[ RECORD 1 ]-------------
> relname | replicated_users
> oid     | 30554879
> 
> Thats not the same oid as the one it's complaining about.
> 
> Does anyone have any idea why this has happened or how I can fix it?
> 
> Cheers
> Glyn
> 
> 
> 
> 
> 
> 
>       ___________________________________________________________ 
> Yahoo! For Good helps you make a difference  
> 
> http://uk.promotions.yahoo.com/forgood/
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
> 




      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  

http://uk.promotions.yahoo.com/forgood/

From hannu at krosing.net  Sat Apr  5 05:00:03 2008
From: hannu at krosing.net (Hannu Krosing)
Date: Sat Apr  5 05:24:17 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
	causes  "node -1 not found")
In-Reply-To: <47F6F365.3080009@emolecules.com>
References: <889775.88069.qm@web25803.mail.ukl.yahoo.com>
	<47F6C542.5050206@Yahoo.com>  <47F6F365.3080009@emolecules.com>
Message-ID: <1207396803.7782.41.camel@huvostro>


On Fri, 2008-04-04 at 20:35 -0700, Craig James wrote:
> Jan Wieck wrote:
> > It appeared to me that Craig needed to get something off his chest after 
> > getting very frustrated. And getting frustrated with Slony is something 
> > that we all know is possible. The only thing that really worried me in 
> > the whole rant was that he obviously ran into all these problems while 
> > attempting to use Slony in a large scale production environment without 
> > bothering to test and learn in a lab setup prior to risking all that 
> > precious data.
> > 
> > Slony was not developed with that sort of irresponsible user in mind.
> 
> Your attitude illustrates the very problem I wrote about -- a lack of 
> concern for the real-life problems of your users, and outright disrepect 
> for criticism.  I rarely engage in these tit-for-tat insult exchanges, 
> as they're not productive.  But in this case, I will at least correct 
> the factual errors in your reply.
> 
> I have been using Slony for quite some time.  I started with small 
> databases, "learned the ropes" exactly as you suggest, read the 
> documentation carefully, asked a number of questions on this forum, 
> then replicated a medium-sized database, and finally worked up to a 
> full-sized database.  We have been using Slony successfully for about 
> 6 months, on this very same large production database that caused me 
> all the trouble this week.

This is very much like what my experience of using slony at times when I
was the only DBA at skype. 
Initially it was a heaven sent and worked marvelously for small/simple
setups but then deteriorated as it was used for more complicated tasks.

When databases, replication complexity and loads grew, it started to
cause more and more trouble and frustration, up to the point we needed
to abandon it.

Especially bad were schema changes at high loads which caused several
really bad experiences, both for db users and especially for the DBA.

Fortunately, by the time we finally had to abandon it, we had hired more
people with good postgresql knowledge and were able to do the
"abandoning" in stages.

First we took what is good in slony (snapshot based replication, logging
triggers), and extracted and rewrote it into simpler building blocks,
essentially separating out a generic queueing system pgQ. 

Marko Kreen, who did all the actual coding, will talk about it on pgCon
2008 ( http://www.pgcon.org/2008/schedule/events/79.en.html )

Then we built a replication system (actually two of them ;) ) on top of
it.

Like you, we had a lots of problems with slonys sets, so our replication
system was designed without sets, trading lack of sets for more work at
setup time. This enabled us to add/remove tables to replication sets
without disturbing already running replications.

> So, you are simply flat-out wrong in your assumption.  EVEN AFTER doing 
> exactly what you suggest is the correct way to use Slony, and EVEN AFTER
>  using it successfully for over a year, I have decided to abandon it, 
> based on my extensive experience with Slony itself, and on my expertise 
> as a computer scientist.

You might want to try out SkyTools, which includes pgQ and replication
tools https://developer.skype.com/SkypeGarage/DbProjects/SkyTools

It may have even less docs, but its failure modes are less dramatic and
it usually is much easier to debug if things go wrong.

It also has less protection (slave tables are not write-protected by
special triggers), so you have to take that into account when doing the
replication.

> ...

> Calling my carefully-worded critique a "rant" is hardly the way a computer 
> scientist should treat a fellow computer scientists who is offering his time
>  and experience to give your project his expert advice.
> 
> > I am sorry that Slony does not meet Craig's ease of use expectations. As 
> > has been said many times, there can not be a one size fits all approach 
> > to replication. Hopefully he will find that some other project, like 
> > Mammoth (which is being open sourced right now) can deliver the 
> > functionality, performance as well as simplicity that he expects.
> 
> My "rant" was about quality, not ease of use. 

The devilish thing about slony is that from initial tests and ones
postgresql experience you get the false sense of robustness similar to
what postgresql itself offers and only later you find out that it is not
so at all.

It gives you a false sense of a nice and simple to use product and then
fails in mysterious and convoluted ways when you least expect and can
afford it.

> If you've never read "Zen and 
> the Art of Motorcycle Maintenance," you may not know the difference.  It's a 
> book every real programmer should read ... twice.  It's not an easy book to 
> read, but if you get it, it will change your life.  Ease of use is a natural
> side effect of a Quality attitude, but quality comes from an appreciation
> for the beauty in a well-crafted system, not from school.

The sad thing about slony is that I still can't put my finger on one
thing that is wrong with slony and say "if you fix this then it is ok".

--------------------
Hannu Krosing



From hannu at krosing.net  Sat Apr  5 05:44:53 2008
From: hannu at krosing.net (Hannu Krosing)
Date: Sat Apr  5 05:45:03 2008
Subject: [Slony1-general] drop-set/create-set, causes  "node -1 not found"
In-Reply-To: <47F65355.7010205@emolecules.com>
References: <47F635FF.1030302@emolecules.com>
	<47F64120.1080708@emolecules.com>  <47F65355.7010205@emolecules.com>
Message-ID: <1207399493.7782.44.camel@huvostro>


On Fri, 2008-04-04 at 09:12 -0700, Craig James wrote:
> Craig James wrote:
> > A replication set failed to do the initial copy (the network connection 
> > is unreliable), and got into a state where it couldn't finish.  So I did 
> > a drop-set / create-set to recreate the set, using the exact same slonik 
> > commands that I used initially.
> > 
> > Now I get an error that makes no sense:
> > 
> > remoteWorkerThread_1: node -1 not found in runtime configuration
> > 
> > So for some reason, it can't connect any more, but the only change was 
> > the drop-set/create-set.
> > 
> > I tried re-executing the store-path commands, but that makes no 
> > difference.  I also verified that the databases are both running, and 
> > that both are accessible.
> > 
> > What's going on here?  Any help would be appreciated, I REALLY need to 
> > get this database copied soon!
> 
> Just to keep things going while I wait for an answer, I did "drop set" on set 5, so that sets 6 & 7 could copy.  Now things are even stranger:  It is STILL trying to copy set 5!  But there is no set 5.
> 
> So that leads me to believe there is an event in the queue that can never finish because, after the copy-set failed, and the set was deleted, but event was NOT deleted.
> 
> I'm stuck in a loop of errors.  Please, answers anyone???

You have to clean up all the sl_* tables on all nodes from rows
referring to set 5 between dropping and recreating the set.

> Thanks,
> Craig
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general

From JanWieck at Yahoo.com  Sat Apr  5 06:37:15 2008
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sat Apr  5 06:37:25 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
	causes  "node -1 not found")
In-Reply-To: <64647.196.23.181.69.1207389529.squirrel@zenmail.co.za>
References: <889775.88069.qm@web25803.mail.ukl.yahoo.com>	<47F6C542.5050206@Yahoo.com>
	<64647.196.23.181.69.1207389529.squirrel@zenmail.co.za>
Message-ID: <47F7808B.3070300@Yahoo.com>

On 4/5/2008 5:58 AM, Henry wrote:
> On Sat, April 5, 2008 2:18 am, Jan Wieck wrote:
> 
>> ... Mammoth (which is being open sourced right now) ...
> 
> Curios:  I've checked out CommandPrompt's website but can find no
> reference to the imminent open-sourcing of Mammoth.
> 
> Can you provide a link?

Joshua announced that step on PG East, I don't know what his exact time 
frame is and how it will be made available.


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From JanWieck at Yahoo.com  Sat Apr  5 07:00:04 2008
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sat Apr  5 07:00:30 2008
Subject: [Slony1-general] ERROR:  XX000: cache lookup failed for relation
In-Reply-To: <860349.6752.qm@web25803.mail.ukl.yahoo.com>
References: <860349.6752.qm@web25803.mail.ukl.yahoo.com>
Message-ID: <47F785E4.4070606@Yahoo.com>

On 4/5/2008 7:47 AM, Glyn Astill wrote:
> Hi chaps,
> 
> I know there's been a bit of "activity" on this listrecently - but does anyone know where I should start looking to resolvethe below?

Yes, a "SET DROP TABLE" is mandatory prior to dropping the table itself. 
This is because up to version 1.2.x, Slony is deliberately corrupting 
the system catalog on subscriber nodes in order to suppress triggers and 
rules to fire (this can only be controlled by other means since Postgres 
8.3 and will be done so in Slony 2.0).


Jan

> 
> ----- Original Message ----
>> From: Glyn Astill <glynastill@yahoo.co.uk>
>> To: slony1-general@lists.slony.info
>> Cc: pgsql-general@postgresql.org
>> Sent: Friday, 4 April, 2008 3:05:18 PM
>> Subject: [Slony1-general] ERROR:  XX000: cache lookup failed for relation
>> 
>> Hi chaps,
>> 
>> I've got a problem trying to drop a table, I get the error "cache lookup failed 
>> for relation"
>> 
>> SEE=# drop table replicated_users;
>> ERROR:  XX000: cache lookup failed for relation 30554884
>> LOCATION:  getRelationDescription, dependency.c:2021
>> Now this table is on a slony-I slave and was in replication when I tried to drop 
>> it - I presume this is a big mistake and I should never try to drop a table 
>> without first droping it from replication?
>> 
>> In addition I'd set up a trigger on the table "replicate_users".
>> 
>> If I do:
>> 
>>  select relname,oid from pg_class where relname = 'replicated_users';
>> 
>> -[ RECORD 1 ]-------------
>> relname | replicated_users
>> oid     | 30554879
>> 
>> Thats not the same oid as the one it's complaining about.
>> 
>> Does anyone have any idea why this has happened or how I can fix it?
>> 
>> Cheers
>> Glyn
>> 
>> 
>> 
>> 
>> 
>> 
>>       ___________________________________________________________ 
>> Yahoo! For Good helps you make a difference  
>> 
>> http://uk.promotions.yahoo.com/forgood/
>> 
>> _______________________________________________
>> Slony1-general mailing list
>> Slony1-general@lists.slony.info
>> http://lists.slony.info/mailman/listinfo/slony1-general
>> 
> 
> 
> 
> 
>       ___________________________________________________________ 
> Yahoo! For Good helps you make a difference  
> 
> http://uk.promotions.yahoo.com/forgood/
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From glynastill at yahoo.co.uk  Sat Apr  5 08:02:24 2008
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Sat Apr  5 08:02:31 2008
Subject: [Slony1-general] Re: ERROR: XX000: cache lookup failed for relation
Message-ID: <826739.58967.qm@web25808.mail.ukl.yahoo.com>

Hi Jan,

Is that still true for 1.2.12? As that's the version I'm using.. Also any ideas on where I start to sort it out? I just want to drop the old table now I've removed it from replication, but the error mentioned previously is stopping me.

Thanks


----- Original Message ----
> From: Jan Wieck <JanWieck@Yahoo.com>
> To: Glyn Astill <glynastill@yahoo.co.uk>
> Cc: slony1-general@lists.slony.info; pgsql-general@postgresql.org
> Sent: Saturday, 5 April, 2008 3:00:04 PM
> Subject: Re: [Slony1-general] ERROR:  XX000: cache lookup failed for relation
> 
> On 4/5/2008 7:47 AM, Glyn Astill wrote:
> > Hi chaps,
> > 
> > I know there's been a bit of "activity" on this listrecently - but does anyone 
> know where I should start looking to resolvethe below?
> 
> Yes, a "SET DROP TABLE" is mandatory prior to dropping the table itself. 
> This is because up to version 1.2.x, Slony is deliberately corrupting 
> the system catalog on subscriber nodes in order to suppress triggers and 
> rules to fire (this can only be controlled by other means since Postgres 
> 8.3 and will be done so in Slony 2.0).
> 
> 
> Jan
> 
> > 
> > ----- Original Message ----
> >> From: Glyn Astill 
> >> To: slony1-general@lists.slony.info
> >> Cc: pgsql-general@postgresql.org
> >> Sent: Friday, 4 April, 2008 3:05:18 PM
> >> Subject: [Slony1-general] ERROR:  XX000: cache lookup failed for relation
> >> 
> >> Hi chaps,
> >> 
> >> I've got a problem trying to drop a table, I get the error "cache lookup 
> failed 
> >> for relation"
> >> 
> >> SEE=# drop table replicated_users;
> >> ERROR:  XX000: cache lookup failed for relation 30554884
> >> LOCATION:  getRelationDescription, dependency.c:2021
> >> Now this table is on a slony-I slave and was in replication when I tried to 
> drop 
> >> it - I presume this is a big mistake and I should never try to drop a table 
> >> without first droping it from replication?
> >> 
> >> In addition I'd set up a trigger on the table "replicate_users".
> >> 
> >> If I do:
> >> 
> >>  select relname,oid from pg_class where relname = 'replicated_users';
> >> 
> >> -[ RECORD 1 ]-------------
> >> relname | replicated_users
> >> oid     | 30554879
> >> 
> >> Thats not the same oid as the one it's complaining about.
> >> 
> >> Does anyone have any idea why this has happened or how I can fix it?
> >> 
> >> Cheers
> >> Glyn
> >> 
> >> 
> >> 
> >> 
> >> 
> >> 
> >>       ___________________________________________________________ 
> >> Yahoo! For Good helps you make a difference  
> >> 
> >> http://uk.promotions.yahoo.com/forgood/
> >> 
> >> _______________________________________________
> >> Slony1-general mailing list
> >> Slony1-general@lists.slony.info
> >> http://lists.slony.info/mailman/listinfo/slony1-general
> >> 
> > 
> > 
> > 
> > 
> >       ___________________________________________________________ 
> > Yahoo! For Good helps you make a difference  
> > 
> > http://uk.promotions.yahoo.com/forgood/
> > 
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general@lists.slony.info
> > http://lists.slony.info/mailman/listinfo/slony1-general
> 
> 
> -- 
> Anyone who trades liberty for security deserves neither
> liberty nor security. -- Benjamin Franklin
> 
> 




      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  

http://uk.promotions.yahoo.com/forgood/

From ssinger_pg at sympatico.ca  Sat Apr  5 09:05:08 2008
From: ssinger_pg at sympatico.ca (Steve Singer)
Date: Sat Apr  5 09:05:19 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
	causes  "node -1 not found")
In-Reply-To: <1207396803.7782.41.camel@huvostro>
References: <889775.88069.qm@web25803.mail.ukl.yahoo.com>
	<47F6C542.5050206@Yahoo.com>
	<47F6F365.3080009@emolecules.com> <1207396803.7782.41.camel@huvostro>
Message-ID: <BAYC1-PASMTP15CDCDF740FDAF6A77ED14ACF10@CEZ.ICE>

On Sat, 5 Apr 2008, Hannu Krosing wrote:

>
> The sad thing about slony is that I still can't put my finger on one
> thing that is wrong with slony and say "if you fix this then it is ok".

Maybe the question you/we should be asking is "What are the the list of 
things that are wrong with slony and how can we make them better."

In this thread some of the following areas for improvement have already been 
brought up:

1. Error messages that don't provide enough details on the problem. 
2. The slonik configuration scripts can get a bit complicated for simple
    tasks. 
3. The easy out of the box setup for simple configurations isn't regarded as
    core functionality and is left to the altperl tools that tend to not work
    very well.

1 Can be helped by giving the error messages more details.

2 and 3 are somewhat related and could be approached in multiple was. This 
also tie into a recent discussion on pgsql-advocacy (I think) related to 
integration with pgadmin and slony.

I'm sure this list can be expanded on.


Steve




>
> --------------------
> Hannu Krosing
>
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>

From JanWieck at Yahoo.com  Sat Apr  5 15:10:58 2008
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sat Apr  5 15:11:20 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
	causes  "node -1 not found")
In-Reply-To: <47F6F365.3080009@emolecules.com>
References: <889775.88069.qm@web25803.mail.ukl.yahoo.com>	<47F6C542.5050206@Yahoo.com>
	<47F6F365.3080009@emolecules.com>
Message-ID: <47F7F8F2.3040505@Yahoo.com>

On 4/4/2008 11:35 PM, Craig James wrote:
> Calling my carefully-worded critique a "rant" is hardly the way a computer scientist should treat a fellow computer scientists who is offering his time and experience to give your project his expert advice.

>> It simply doesn't get the job done reliably.

>> It's clear to me that Slony's developers are focused on features, and have not 
>> paid enough attention to the user experience.

>> * Slony's configuration is like programming in FORTRAN or assembly language in 
>> 1966.

>> Slony is like a really fast race car.  The drivers are justifiably proud that it 
>> is a very fine machine, that their machine is REALLY fast.  But if you want to 
>> get to the grocery store, you're better off to take the family car, or even a 
>> horse and buggy, because if you take the race car to the grocery store, you may 
>> be hungry several times each week.

If that is what you call "carefully worded critique", then I wonder what 
you would actually call a rant.


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From JanWieck at Yahoo.com  Sat Apr  5 15:22:06 2008
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sat Apr  5 15:22:29 2008
Subject: [Slony1-general] Re: ERROR: XX000: cache lookup failed for relation
In-Reply-To: <826739.58967.qm@web25808.mail.ukl.yahoo.com>
References: <826739.58967.qm@web25808.mail.ukl.yahoo.com>
Message-ID: <47F7FB8E.7060901@Yahoo.com>

On 4/5/2008 11:02 AM, Glyn Astill wrote:
> Hi Jan,
> 
> Is that still true for 1.2.12? As that's the version I'm using.. Also any ideas on where I start to sort it out? I just want to drop the old table now I've removed it from replication, but the error mentioned previously is stopping me.

Yes, this is and will be true for ALL 1.2 versions. And this is also the 
reason why Slony 2.0 will NOT be supporting any Postgres version prior 
to 8.3.

If you removed the table from the replication set, then this error 
should not appear any more. All I can think of is that the table might 
have foreign key relationships with other tables, which are still 
involved in replication. If that is the case, try dropping it by using 
the EXECUTE SCRIPT feature of the slonik command language to perform the 
DROP TABLE (which I think is highly recommended for any sort of DDL 
throughout the Slony documentation anyway).


Jan

> 
> Thanks
> 
> 
> ----- Original Message ----
>> From: Jan Wieck <JanWieck@Yahoo.com>
>> To: Glyn Astill <glynastill@yahoo.co.uk>
>> Cc: slony1-general@lists.slony.info; pgsql-general@postgresql.org
>> Sent: Saturday, 5 April, 2008 3:00:04 PM
>> Subject: Re: [Slony1-general] ERROR:  XX000: cache lookup failed for relation
>> 
>> On 4/5/2008 7:47 AM, Glyn Astill wrote:
>> > Hi chaps,
>> > 
>> > I know there's been a bit of "activity" on this listrecently - but does anyone 
>> know where I should start looking to resolvethe below?
>> 
>> Yes, a "SET DROP TABLE" is mandatory prior to dropping the table itself. 
>> This is because up to version 1.2.x, Slony is deliberately corrupting 
>> the system catalog on subscriber nodes in order to suppress triggers and 
>> rules to fire (this can only be controlled by other means since Postgres 
>> 8.3 and will be done so in Slony 2.0).
>> 
>> 
>> Jan
>> 
>> > 
>> > ----- Original Message ----
>> >> From: Glyn Astill 
>> >> To: slony1-general@lists.slony.info
>> >> Cc: pgsql-general@postgresql.org
>> >> Sent: Friday, 4 April, 2008 3:05:18 PM
>> >> Subject: [Slony1-general] ERROR:  XX000: cache lookup failed for relation
>> >> 
>> >> Hi chaps,
>> >> 
>> >> I've got a problem trying to drop a table, I get the error "cache lookup 
>> failed 
>> >> for relation"
>> >> 
>> >> SEE=# drop table replicated_users;
>> >> ERROR:  XX000: cache lookup failed for relation 30554884
>> >> LOCATION:  getRelationDescription, dependency.c:2021
>> >> Now this table is on a slony-I slave and was in replication when I tried to 
>> drop 
>> >> it - I presume this is a big mistake and I should never try to drop a table 
>> >> without first droping it from replication?
>> >> 
>> >> In addition I'd set up a trigger on the table "replicate_users".
>> >> 
>> >> If I do:
>> >> 
>> >>  select relname,oid from pg_class where relname = 'replicated_users';
>> >> 
>> >> -[ RECORD 1 ]-------------
>> >> relname | replicated_users
>> >> oid     | 30554879
>> >> 
>> >> Thats not the same oid as the one it's complaining about.
>> >> 
>> >> Does anyone have any idea why this has happened or how I can fix it?
>> >> 
>> >> Cheers
>> >> Glyn
>> >> 
>> >> 
>> >> 
>> >> 
>> >> 
>> >> 
>> >>       ___________________________________________________________ 
>> >> Yahoo! For Good helps you make a difference  
>> >> 
>> >> http://uk.promotions.yahoo.com/forgood/
>> >> 
>> >> _______________________________________________
>> >> Slony1-general mailing list
>> >> Slony1-general@lists.slony.info
>> >> http://lists.slony.info/mailman/listinfo/slony1-general
>> >> 
>> > 
>> > 
>> > 
>> > 
>> >       ___________________________________________________________ 
>> > Yahoo! For Good helps you make a difference  
>> > 
>> > http://uk.promotions.yahoo.com/forgood/
>> > 
>> > _______________________________________________
>> > Slony1-general mailing list
>> > Slony1-general@lists.slony.info
>> > http://lists.slony.info/mailman/listinfo/slony1-general
>> 
>> 
>> -- 
>> Anyone who trades liberty for security deserves neither
>> liberty nor security. -- Benjamin Franklin
>> 
>> 
> 
> 
> 
> 
>       ___________________________________________________________ 
> Yahoo! For Good helps you make a difference  
> 
> http://uk.promotions.yahoo.com/forgood/
> 


-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From drees76 at gmail.com  Sun Apr  6 00:18:09 2008
From: drees76 at gmail.com (David Rees)
Date: Sun Apr  6 00:18:32 2008
Subject: [Slony1-general] Initial replication repeatedly restarts/copies
	same tables
In-Reply-To: <64421.196.23.181.69.1207387848.squirrel@zenmail.co.za>
References: <63150.196.23.181.69.1207312320.squirrel@zenmail.co.za>
	<64421.196.23.181.69.1207387848.squirrel@zenmail.co.za>
Message-ID: <72dbd3150804060018s4f9845av506ae1e29eecfdb5@mail.gmail.com>

On Sat, Apr 5, 2008 at 2:30 AM, Henry <henry@zen.co.za> wrote:
> On Fri, April 4, 2008 2:32 pm, Henry wrote:
>  > They're repeatedly restarting and copying the same tables - and never
>  > completing.
>
>  To clarify, "never completing" is probably not accurate; it's just been
>  repeating the truncate/copy process repeatedly several times since the
>  initial replication started (and the first slave finished) nine days ago.

Which indicates that an error is occurring during the subscription process.

Either the slon logs or pg logs on the affected slave will indicate the problem.

>  Question:  does updates of some of the tables on the origin during the
>  initial replication have a bearing on this?  One of the parent tables on
>  the master is regularly updated, but the other tables are not.

No, you can update away on the master while subscribing slaves.

>  test_slony_state.pl reports that "pg_listener relpages high -
>  6460"..."Perhaps a long running transaction is preventing pg_listener from
>  being vacuumed out?"   Presumably this is just a side-effect of the
>  initial replication?  Anyway, I did a vacuum full analyze on pg_listener
>  on all the nodes since it couldn't hurt.  After that vacuum, the report
>  says "pg_listener reltuples high - 346307"... :-)))

This is probably because it has been trying to replicate and faiing -
in the mean time it is queuing up all the changes in the master
database.

>  I can provide more config detail if required (plus output from
>  test_slony_state.pl).

Please provide as much detail as possible. You haven't even told us
what version of PostgreSQL you are running and only accidently told us
what version of Slony because it was in a log snippet.

-Dave
From jameshtucker at gmail.com  Sun Apr  6 16:44:22 2008
From: jameshtucker at gmail.com (James Tucker)
Date: Sun Apr  6 16:44:42 2008
Subject: [Slony1-general] ERROR: Slony-I: old key column TTT.FFF IS NULL on
	{UPDATE, DELETE}
Message-ID: <b10d372b0804061644x5b0a5e2fxba07b1486f503338@mail.gmail.com>

Hi All,

We have recently experienced an incident whereby certain tables were
directly updated and new columns and constraints added without using the
execute script function.  We are now receiving errors (ERROR: Slony-I: old
key column TTT.FFF IS NULL on {UPDATE,DELETE}) on certain transactions, and
these transactions are being rolled back.  The DDL changes were also done on
the slave node, so schemas are are both correct.  I believe the issue is to
do with the triggers not being updated after .

What is the best way to update/rebuild the existing triggers on tables which
have been modified ?

Thanks

James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080407/=
1b34775e/attachment.htm
From andreas at kostyrka.org  Sun Apr  6 23:27:10 2008
From: andreas at kostyrka.org (Andreas Kostyrka)
Date: Sun Apr  6 23:27:23 2008
Subject: [Slony1-general] ERROR: Slony-I: old key column TTT.FFF IS
	NULL on {UPDATE, DELETE}
In-Reply-To: <b10d372b0804061644x5b0a5e2fxba07b1486f503338@mail.gmail.com>
References: <b10d372b0804061644x5b0a5e2fxba07b1486f503338@mail.gmail.com>
Message-ID: <1207549630.20984.7.camel@localhost>

Run an EXECUTE SCRIPT on the cluster?
The good part here is that you can run it node by node to help locking
contention.

Andreas

Am Montag, den 07.04.2008, 09:44 +1000 schrieb James Tucker:
> Hi All,
> 
> We have recently experienced an incident whereby certain tables were
> directly updated and new columns and constraints added without using
> the execute script function.  We are now receiving errors (ERROR:
> Slony-I: old key column TTT.FFF IS NULL on {UPDATE,DELETE}) on certain
> transactions, and these transactions are being rolled back.  The DDL
> changes were also done on the slave node, so schemas are are both
> correct.  I believe the issue is to do with the triggers not being
> updated after .
> 
> What is the best way to update/rebuild the existing triggers on tables
> which have been modified ? 
> 
> Thanks
> 
> James
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: Dies ist ein digital signierter Nachrichtenteil
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20080407/8ece17d7/attachment.pgp
From jameshtucker at gmail.com  Sun Apr  6 23:44:18 2008
From: jameshtucker at gmail.com (James Tucker)
Date: Sun Apr  6 23:44:41 2008
Subject: [Slony1-general] ERROR: Slony-I: old key column TTT.FFF IS NULL
	on {UPDATE, DELETE}
In-Reply-To: <1207549630.20984.7.camel@localhost>
References: <b10d372b0804061644x5b0a5e2fxba07b1486f503338@mail.gmail.com>
	<1207549630.20984.7.camel@localhost>
Message-ID: <b10d372b0804062344v2a8478aseb5ffd7f2d4ad050@mail.gmail.com>

Thanks Andreas,

Yes eventually figured out I could just run a blank sql using execute script
and that appears to have fixed the problem.  I thought perhaps it only
rebuilt triggers for tables modified in the SQL or something tricky.

Thanks very much for the response, I'm interested in what you mean when you
say run it node by node.  How can one run it node by node ? I'm just passing
slonik a script such as

cluster name =3D cluster;
node 2 conninfo=3D"xxx"
node 3 conninfo=3D"xxx"
  execute script (
    set id =3D 1,
    filename =3D '/tmp/file.sql',
    event node =3D 3
  );


On Mon, Apr 7, 2008 at 4:27 PM, Andreas Kostyrka <andreas@kostyrka.org>
wrote:

> Run an EXECUTE SCRIPT on the cluster?
> The good part here is that you can run it node by node to help locking
> contention.
>
> Andreas
>
> Am Montag, den 07.04.2008, 09:44 +1000 schrieb James Tucker:
> > Hi All,
> >
> > We have recently experienced an incident whereby certain tables were
> > directly updated and new columns and constraints added without using
> > the execute script function.  We are now receiving errors (ERROR:
> > Slony-I: old key column TTT.FFF IS NULL on {UPDATE,DELETE}) on certain
> > transactions, and these transactions are being rolled back.  The DDL
> > changes were also done on the slave node, so schemas are are both
> > correct.  I believe the issue is to do with the triggers not being
> > updated after .
> >
> > What is the best way to update/rebuild the existing triggers on tables
> > which have been modified ?
> >
> > Thanks
> >
> > James
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general@lists.slony.info
> > http://lists.slony.info/mailman/listinfo/slony1-general
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080407/=
cd51fc06/attachment.htm
From andreas at kostyrka.org  Mon Apr  7 00:33:43 2008
From: andreas at kostyrka.org (Andreas Kostyrka)
Date: Mon Apr  7 00:33:49 2008
Subject: [Slony1-general] ERROR: Slony-I: old key column TTT.FFF IS
	NULL on {UPDATE, DELETE}
In-Reply-To: <b10d372b0804062344v2a8478aseb5ffd7f2d4ad050@mail.gmail.com>
References: <b10d372b0804061644x5b0a5e2fxba07b1486f503338@mail.gmail.com>
	<1207549630.20984.7.camel@localhost>
	<b10d372b0804062344v2a8478aseb5ffd7f2d4ad050@mail.gmail.com>
Message-ID: <1207553623.20984.9.camel@localhost>

Node by node => I meant execute only on node, you need to look up the
exact syntax (I haven't been admining slony for some months now :-P)

Andreas

Am Montag, den 07.04.2008, 16:44 +1000 schrieb James Tucker:
> 
> Yes eventually figured out I could just run a blank sql using execute
> script and that appears to have fixed the problem.  I thought perhaps
> it only rebuilt triggers for tables modified in the SQL or something
> tricky.
> 
> Thanks very much for the response, I'm interested in what you mean
> when you say run it node by node.  How can one run it node by node ?
> I'm just passing slonik a script such as
> 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: Dies ist ein digital signierter Nachrichtenteil
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20080407/a0761bad/attachment.pgp
From mark at summersault.com  Mon Apr  7 11:03:37 2008
From: mark at summersault.com (Mark Stosberg)
Date: Mon Apr  7 11:03:48 2008
Subject: [Slony1-general] FreeBSD altperl rc.d script for peer review
Message-ID: <47FA61F9.3080303@summersault.com>


I wrote the following alternative to the provided FreeBSD rc.d script
for the following reasons:

- I didn't want to duplicate the set-up of profiles and options to slon
that altperl was already managing for me.
- I didn't want to install svscan for service monitoring when altperl
was already handling setup and teardown of watchdogs, and I didn't have
any other reason to run svscan.

With this solution I can still the Altperl tools I was already using to
manage slony, but I still get to have standard FreeBSD-style management
with "slon start", "slon stop" and enabling/disabling the service
through /etc/rc.conf.

The only thing I don't like about this is that I which slons to start
hardcoded in this script, which would vary from project project. I
suppose it would be possible to use Perl, load slon_tools.conf and
figure out an automatic default for these.

Comments ?

      Mark

#########

#!/bin/sh
#
# By Mark Stosberg for use with altperl

# PROVIDE: slon
# REQUIRE: postgresql
# KEYWORD: shutdown

. "/etc/rc.subr"

name="slon"
rcvar=`set_rcvar`

load_rc_config "$name"

# From global rc.conf(5); if unset, set them here
[ -z "$slon_enable" ]       && slon_enable="NO"

case $1 in
start)
# NOTE: These lines are customized for the number and quantity of nodes
in a given cluster
          /usr/local/sbin/slon_start 3
          /usr/local/sbin/slon_start 2
          /usr/local/sbin/slon_start 1
          echo -n 'slon started'
      ;;

stop)
          /usr/local/sbin/slon_kill
      ;;

*)
      echo "usage: `basename $0` {start|stop}" >&2
      exit 64
      ;;
esac



-- 
  . . . . . . . . . . . . . . . . . . . . . . . . . . .
    Mark Stosberg            Principal Developer
    mark@summersault.com     Summersault, LLC
    765-939-9301 ext 202     database driven websites
  . . . . . http://www.summersault.com/ . . . . . . . .
From jeff at frostconsultingllc.com  Mon Apr  7 11:06:56 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Mon Apr  7 11:07:16 2008
Subject: [Slony1-general] autovacuum doc change
Message-ID: <Pine.LNX.4.64.0804071104400.7373@discord.home.frostconsultingllc.com>

It looks like with 8.3, this example insert on the maintenance.html page:

  insert into pg_catalog.pg_autovacuum (vacrelid, enabled) select oid, 'f' from 
pg_catalog.pg_class where relnamespace = (select oid from pg_namespace where 
nspname = '_' || 'MyCluster') and relhasindex;

doesn't work because all the columns in pg_autovacuum are now marked as NOT 
NULL.

Here's one that does work:

INSERT INTO pg_catalog.pg_autovacuum (vacrelid, enabled, vac_base_thresh, vac_scale_factor, anl_base_thresh, anl_scale_factor, vac_cost_delay, vac_cost_limit, freeze_min_age, freeze_max_age) SELECT oid, 'f', -1, -1, -1, -1, -1, -1, -1, -1  FROM pg_catalog.pg_class WHERE relnamespace = (SELECT OID FROM pg_namespace WHERE nspname = '_' || 'MyCluster') AND relhasindex;

I'm not sure how to submit a patch, but if you let me know I can do that. :-)

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From cbbrowne at ca.afilias.info  Mon Apr  7 12:25:14 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Apr  7 12:25:25 2008
Subject: [Slony1-general] autovacuum doc change
In-Reply-To: <Pine.LNX.4.64.0804071104400.7373@discord.home.frostconsultingllc.com>
	(Jeff Frost's message of "Mon, 7 Apr 2008 11:06:56 -0700 (PDT)")
References: <Pine.LNX.4.64.0804071104400.7373@discord.home.frostconsultingllc.com>
Message-ID: <60iqyt1n8l.fsf@dba2.int.libertyrms.com>

Jeff Frost <jeff@frostconsultingllc.com> writes:
> It looks like with 8.3, this example insert on the maintenance.html page:
>
>  insert into pg_catalog.pg_autovacuum (vacrelid, enabled) select oid,
> 'f' from pg_catalog.pg_class where relnamespace = (select oid from
> pg_namespace where nspname = '_' || 'MyCluster') and relhasindex;
>
> doesn't work because all the columns in pg_autovacuum are now marked
> as NOT NULL.
>
> Here's one that does work:
>
> INSERT INTO pg_catalog.pg_autovacuum (vacrelid, enabled, vac_base_thresh, vac_scale_factor, anl_base_thresh, anl_scale_factor, vac_cost_delay, vac_cost_limit, freeze_min_age, freeze_max_age) SELECT oid, 'f', -1, -1, -1, -1, -1, -1, -1, -1  FROM pg_catalog.pg_class WHERE relnamespace = (SELECT OID FROM pg_namespace WHERE nspname = '_' || 'MyCluster') AND relhasindex;
>
> I'm not sure how to submit a patch, but if you let me know I can do that. :-)

Committed to CVS HEAD...

http://lists.slony.info/pipermail/slony1-commit/2008-April/002223.html
-- 
output = ("cbbrowne" "@" "ca.afilias.info")
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)
From shoaibmir at gmail.com  Mon Apr  7 17:32:59 2008
From: shoaibmir at gmail.com (Shoaib Mir)
Date: Mon Apr  7 17:33:17 2008
Subject: [Slony1-general] Failover versus Store Node
Message-ID: <bf54be870804071732i52866d68p9b3cbda58981942f@mail.gmail.com>

While trying out different scenarios in Slony (ver 1.2.9) I came across the
following:

When I did a failover on a node and made it back online again without doing
an uninstall or delete on it, I was still able to see it in the sl_node
table with active status and this is why when I did a subscribe again for
the failed node (without a delete) I didnt get any error through slonik and
I could see the entry in sl_subscribe for the failed node but the
replication was not working for this node.

Now in the other scenario when I did a store node and store node (without
subscribe) for a fresh node to a cluster I could see in the sl_node table
having exactly the same kind of entry as the failed node in sl_node table.

I will like to know how can I differentiate between a failed node and a
recently added node (without subscriptions) from the slony catalog tables?

Thank you,

Shoaib Mir
Fujitsu Australia Software Technology
shoaibm@fast.fujistu.com.au
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080408/=
2a598662/attachment.htm
From satya461 at gmail.com  Tue Apr  8 03:25:34 2008
From: satya461 at gmail.com (Satya)
Date: Tue Apr  8 03:26:02 2008
Subject: [Slony1-general] Slony localization support?
Message-ID: <6ccff2720804080325ndf5da3dye069a09bb1061eab@mail.gmail.com>

Hi,

  Can we localize the slon process messages and also any other process
messages? Can we select the locale for slon process ? I think slony doesn't
have localization support. Can someone please confirm it?

Thanks,
Satya.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080408/=
ca5dde79/attachment.htm
From wmoran at collaborativefusion.com  Tue Apr  8 07:34:14 2008
From: wmoran at collaborativefusion.com (Bill Moran)
Date: Tue Apr  8 07:34:28 2008
Subject: [Slony1-general] Monitorning script
Message-ID: <20080408103414.ae292275.wmoran@collaborativefusion.com>


I used check_slony_cluster.sh as a starting point to make something a
little more sophisticated.  I hope folks find this useful:

http://people.collaborativefusion.com/~wmoran/PostgreSQL/check_slony_lag.html

-- 
Bill Moran
Collaborative Fusion Inc.
http://people.collaborativefusion.com/~wmoran/

wmoran@collaborativefusion.com
Phone: 412-422-3463x4023

****************************************************************
IMPORTANT: This message contains confidential information and is
intended only for the individual named. If the reader of this
message is not an intended recipient (or the individual
responsible for the delivery of this message to an intended
recipient), please be advised that any re-use, dissemination,
distribution or copying of this message is prohibited. Please
notify the sender immediately by e-mail if you have received
this e-mail by mistake and delete this e-mail from your system.
E-mail transmission cannot be guaranteed to be secure or
error-free as information could be intercepted, corrupted, lost,
destroyed, arrive late or incomplete, or contain viruses. The
sender therefore does not accept liability for any errors or
omissions in the contents of this message, which arise as a
result of e-mail transmission.
****************************************************************
From plk.zuber at gmail.com  Tue Apr  8 08:07:31 2008
From: plk.zuber at gmail.com (=?UTF-8?Q?Filip_Rembia=C5=82kowski?=)
Date: Tue Apr  8 08:07:36 2008
Subject: [Slony1-general] FreeBSD altperl rc.d script for peer review
In-Reply-To: <47FA61F9.3080303@summersault.com>
References: <47FA61F9.3080303@summersault.com>
Message-ID: <92869e660804080807n400cd855q47cc19e57fc7bba5@mail.gmail.com>

2008/4/7, Mark Stosberg <mark@summersault.com>:
>
>  case $1 in
>  start)
>  # NOTE: These lines are customized for the number and quantity of nodes
>  in a given cluster
>          /usr/local/sbin/slon_start 3
>          /usr/local/sbin/slon_start 2
>          /usr/local/sbin/slon_start 1
>          echo -n 'slon started'
>      ;;

you could determine number of nodes from existing config file or using
slony_show_configuration.




-- 
Filip Rembia?kowski
From irichardson at opushealthcare.com  Tue Apr  8 09:02:25 2008
From: irichardson at opushealthcare.com (Ian Richardson)
Date: Tue Apr  8 09:02:31 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
Message-ID: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>

Has anyone successfully compiled slony 1.2.x on HP-UX 11.23 /w IA-64?
Any insight is appreciated!

 

Thanks,

 

Ian

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080408/b44c352c/attachment.htm
From ajs at crankycanuck.ca  Tue Apr  8 09:35:16 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Tue Apr  8 09:35:51 2008
Subject: [Slony1-general] Abandoning Slony (was: drop-set/create-set,
	causes  "node -1 not found")
In-Reply-To: <47F6F365.3080009@emolecules.com>
References: <889775.88069.qm@web25803.mail.ukl.yahoo.com>
	<47F6C542.5050206@Yahoo.com> <47F6F365.3080009@emolecules.com>
Message-ID: <20080408163516.GB10909@crankycanuck.ca>

Craig:

I have read your complaint, and I actually share some of your frustration
(and I was, I'll note, responsible for getting the Slony project off the
ground at all at Afilias).  But I do take issue with a couple remarks:

On Fri, Apr 04, 2008 at 08:35:01PM -0700, Craig James wrote:

> Calling my carefully-worded critique a "rant" is hardly the way a computer 
> scientist should treat a fellow computer scientists who is offering his 
> time and experience to give your project his expert advice.

I'm sorry, but I think it was a rant.  It contains a number of true remarks:
operating Slony by slonik commands or even config files is frustrating and
clumsy; error messages are not always illuminating; some of the generality
of Slony's functionality is sufficiently complicated that it makes
apparently simple things mind-bogglingly hard.  But your exasperation
certainly led you to exaggerate some of your claims, which means you made
real criticisms that were nevertheless embedded in a rant.  (I don't think
that means that others here should dismiss your criticisms as meaningless.)

> My "rant" was about quality, not ease of use.  If you've never read "Zen 
> and the Art of Motorcycle Maintenance," you may not know the difference.  
> It's a book every real programmer should read ... twice.  

In my opinion, it's a book that nobody should ever read even once.  Every
remark in it about the history of philosophy is so deeply wrong as to make
anyone with the merest acquaintance with (for instance) Kant blush.  But in
any case, you can learn the virtues of a well-crafted system as it relates
to software much more easily from authors less pompous.  Joel Spolsky's
site, before it became mostly about self-promotion, used to have excellent
remarks about this.

I remember one time, Spolsky remarked about installing Debian that it was
very close to impossible.  Now, that's obviously an exaggeration; but
there's something important in it.  It used to be that I found systems like
SGI's IRIX comical, because I knew that Debian's conflict-and-dependency
resolution was so better.  Debian has rested on that, though, and you now
need to know a whole lot about the system to get things installed.  Finding
packages that do what you want requires a bizarre invocation of a utility
called apt-file, which isn't even installed itself by default.  There's no
excuse for this any more, right?

And the same may hold for Slony: there are all kinds of nasty, sharp corners
on it, and you need to know a great deal about it (and revel in its twiddly
complicated bits) in order to make it play nicely rather than, say, slicing
off your data.  It works really really well for a long time until it does
something surprising and nasty (except that it turns out it was always doing
that surprising and nasty thing, and you just didn't know it.  Pity, that).

Part of the problem is that nobody is spending the time to build on the bits
that are working, and solve these cases.  As Jan pointed out, the altperl
tools are a good idea, except mostly unmaintained (and, IMO, dangerously so
-- they ought to be ripped out, I think, because they're not reliable).  I
think the pgadmin project is trying to make things easier, but there's no
real convenient interface to Slony for them; and in any case I think that a
fairly comprehensive task analysis for administering Slony is probably a
necessary condition for making a good interface.  (In my experience, the
free software world is abysmal at this sort of thing, which is why KDE and
Gnome both feel like poor knock-offs of better-designed environments.)  This
requires serious time (==money, probably) be poured into the problem, I
think.

Note that Debian did get a good installer.  It's called "Ubuntu".  Their
goal was entirely different from the Debian project: they wanted a system
that was more usable.  So that's what they prioritised.  They created a
wholly separate project.

In order to make this better, someone needs to spend serious time not just
providing a list of what sucks in the current Slony system.  Someone needs
to spend that time working out what would be _good and usable_, and make
proposals that are consistent with that, taking into account all the use
cases that Slony is supposed to be covering.  That's a lot of work, I know,
but until it happens, the frustration you and I share will probably
continue.  I'm frustrated that Slony doesn't work naturally -- that it
requires a great deal of understanding of the system just to make it work
reliably.  But I haven't the time to fix that, and unless someone comes
along to ensure my time is available to fix it, the problem will go unfixed.

Best,

A

From cbbrowne at ca.afilias.info  Tue Apr  8 10:57:42 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Apr  8 10:57:53 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	(Ian Richardson's message of "Tue, 8 Apr 2008 11:02:25 -0500")
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
Message-ID: <6063us1b6x.fsf@dba2.int.libertyrms.com>

"Ian Richardson" <irichardson@opushealthcare.com> writes:
> Has anyone successfully compiled slony 1.2.x on HP-UX 11.23 /w
> IA-64? Any insight is appreciated!:p>

HP/UX has not been a platform we have received many compile reports
on, so there is a pretty fair chance that you're the first to discover
any issues that you discover.
-- 
let name="cbbrowne" and tld="linuxdatabases.info" in String.concat "@" [name;tld];;
http://linuxfinances.info/info/lisp.html
Dijkstra probably hates me
(Linus Torvalds, in kernel/sched.c)
From salmanb at quietcaresystems.com  Tue Apr  8 12:14:34 2008
From: salmanb at quietcaresystems.com (salman)
Date: Tue Apr  8 12:14:43 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
Message-ID: <47FBC41A.3060307@quietcaresystems.com>

Hello,

I looked through the docs already but I have a couple of questions about 
the process and wanted clarification.

I would like to use the slony recommended method to upgrade our 8.2.x pg 
install to 8.3.1. If I understand the documentation correctly, I need to 
install 8.3.1 on the server, make a slave node to the master and let 
slony sync the data between the two. Then, once the data is fairly 
in-sync, stop write applications, and issue a move set command to start 
using the new, updated master.

The questions I have are as follows:

1) Since node IDs x,y are already in use by the primary master (x) and 
slave (y), the new 8.3.1 node will receive an ID of 'z' (1,2,3 in 
numbers). Is it possible to rename the new node (z) to x?  I was unable 
to find any docs about this.

2) Am I correct to assume that any subscriber nodes will also receive 
the move set notification and start receiving notifications from the new 
master? Or would this require any reconfig on the slave node? I was 
unable to find any docs related to this, also.

-salman
From cbbrowne at ca.afilias.info  Tue Apr  8 12:32:23 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Apr  8 12:32:33 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <47FBC41A.3060307@quietcaresystems.com> (salman's message of "Tue,
	08 Apr 2008 15:14:34 -0400")
References: <47FBC41A.3060307@quietcaresystems.com>
Message-ID: <601w5g16t4.fsf@dba2.int.libertyrms.com>

salman <salmanb@quietcaresystems.com> writes:
> I looked through the docs already but I have a couple of questions
> about the process and wanted clarification.
>
> I would like to use the slony recommended method to upgrade our 8.2.x
> pg install to 8.3.1. If I understand the documentation correctly, I
> need to install 8.3.1 on the server, make a slave node to the master
> and let slony sync the data between the two. Then, once the data is
> fairly in-sync, stop write applications, and issue a move set command
> to start using the new, updated master.
>
> The questions I have are as follows:
>
> 1) Since node IDs x,y are already in use by the primary master (x) and
> slave (y), the new 8.3.1 node will receive an ID of 'z' (1,2,3 in
> numbers). Is it possible to rename the new node (z) to x?  I was
> unable to find any docs about this.

There isn't a "rename name" function, sorry.

At one point, I looked into giving nodes a "name" as well, and found
it was going to be a lot more trouble than it was worth.

> 2) Am I correct to assume that any subscriber nodes will also
> receive the move set notification and start receiving notifications
> from the new master? Or would this require any reconfig on the slave
> node? I was unable to find any docs related to this, also.

Yes, the subscribers will become aware of the new master.  It is quite
likely that the change will not require any reconfiguration of slave
nodes.
-- 
(format nil "~S@~S" "cbbrowne" "ca.afilias.info")
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)
From wmoran at collaborativefusion.com  Tue Apr  8 12:37:10 2008
From: wmoran at collaborativefusion.com (Bill Moran)
Date: Tue Apr  8 12:37:28 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <47FBC41A.3060307@quietcaresystems.com>
References: <47FBC41A.3060307@quietcaresystems.com>
Message-ID: <20080408153710.b128758f.wmoran@collaborativefusion.com>

In response to salman <salmanb@quietcaresystems.com>:
> 
> I looked through the docs already but I have a couple of questions about 
> the process and wanted clarification.
> 
> I would like to use the slony recommended method to upgrade our 8.2.x pg 
> install to 8.3.1. If I understand the documentation correctly, I need to 
> install 8.3.1 on the server, make a slave node to the master and let 
> slony sync the data between the two. Then, once the data is fairly 
> in-sync, stop write applications, and issue a move set command to start 
> using the new, updated master.
> 
> The questions I have are as follows:
> 
> 1) Since node IDs x,y are already in use by the primary master (x) and 
> slave (y), the new 8.3.1 node will receive an ID of 'z' (1,2,3 in 
> numbers). Is it possible to rename the new node (z) to x?  I was unable 
> to find any docs about this.

I don't know the answer to this one.

> 2) Am I correct to assume that any subscriber nodes will also receive 
> the move set notification and start receiving notifications from the new 
> master? Or would this require any reconfig on the slave node? I was 
> unable to find any docs related to this, also.

Here you are correct.  Slony will reshape the cluster when you do the
move set, and all nodes will adjust their subscriptions as needed, although
it's not always in the way you suspect.

Keep in mind that you can see what was done by looking at the
$cluster_name$.sl_subscribe table, and if anything isn't how you want
it, you can re-issue subscribe set() commands to reshape it manually
after the move set() has been done.

-- 
Bill Moran
Collaborative Fusion Inc.
http://people.collaborativefusion.com/~wmoran/

wmoran@collaborativefusion.com
Phone: 412-422-3463x4023

****************************************************************
IMPORTANT: This message contains confidential information and is
intended only for the individual named. If the reader of this
message is not an intended recipient (or the individual
responsible for the delivery of this message to an intended
recipient), please be advised that any re-use, dissemination,
distribution or copying of this message is prohibited. Please
notify the sender immediately by e-mail if you have received
this e-mail by mistake and delete this e-mail from your system.
E-mail transmission cannot be guaranteed to be secure or
error-free as information could be intercepted, corrupted, lost,
destroyed, arrive late or incomplete, or contain viruses. The
sender therefore does not accept liability for any errors or
omissions in the contents of this message, which arise as a
result of e-mail transmission.
****************************************************************
From wmoran at collaborativefusion.com  Tue Apr  8 12:38:57 2008
From: wmoran at collaborativefusion.com (Bill Moran)
Date: Tue Apr  8 12:39:14 2008
Subject: [Slony1-general] Small tool to make Slony management easier
Message-ID: <20080408153857.5c7660d7.wmoran@collaborativefusion.com>


I've been putting this together over the last couple weeks for
the reasons listed on the HTML page:
http://people.collaborativefusion.com/~wmoran/PostgreSQL/slony_switchover.html

I'm interested to hear how useful this is to others, and of course
suggestions for improvement are welcome.

-- 
Bill Moran
Collaborative Fusion Inc.
http://people.collaborativefusion.com/~wmoran/

wmoran@collaborativefusion.com
Phone: 412-422-3463x4023

****************************************************************
IMPORTANT: This message contains confidential information and is
intended only for the individual named. If the reader of this
message is not an intended recipient (or the individual
responsible for the delivery of this message to an intended
recipient), please be advised that any re-use, dissemination,
distribution or copying of this message is prohibited. Please
notify the sender immediately by e-mail if you have received
this e-mail by mistake and delete this e-mail from your system.
E-mail transmission cannot be guaranteed to be secure or
error-free as information could be intercepted, corrupted, lost,
destroyed, arrive late or incomplete, or contain viruses. The
sender therefore does not accept liability for any errors or
omissions in the contents of this message, which arise as a
result of e-mail transmission.
****************************************************************
From jeff at frostconsultingllc.com  Tue Apr  8 12:42:40 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Tue Apr  8 12:42:53 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <20080408153710.b128758f.wmoran@collaborativefusion.com>
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
Message-ID: <Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>

On Tue, 8 Apr 2008, Bill Moran wrote:

> In response to salman <salmanb@quietcaresystems.com>:
>>
>> I looked through the docs already but I have a couple of questions about
>> the process and wanted clarification.
>>
>> I would like to use the slony recommended method to upgrade our 8.2.x pg
>> install to 8.3.1. If I understand the documentation correctly, I need to
>> install 8.3.1 on the server, make a slave node to the master and let
>> slony sync the data between the two. Then, once the data is fairly
>> in-sync, stop write applications, and issue a move set command to start
>> using the new, updated master.
>>
>> The questions I have are as follows:
>>
>> 1) Since node IDs x,y are already in use by the primary master (x) and
>> slave (y), the new 8.3.1 node will receive an ID of 'z' (1,2,3 in
>> numbers). Is it possible to rename the new node (z) to x?  I was unable
>> to find any docs about this.
>
> I don't know the answer to this one.

The answer is unfortunately, still no.  So, your upgraded server will become 
node 3 and if that's going to be the new master and you want it to be node 1, 
the only way to do this is tear down replication and reinstall the cluster 
with different node IDs.

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From salmanb at quietcaresystems.com  Tue Apr  8 13:04:44 2008
From: salmanb at quietcaresystems.com (salman)
Date: Tue Apr  8 13:04:56 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
Message-ID: <47FBCFDC.9020101@quietcaresystems.com>

Jeff Frost wrote:
> On Tue, 8 Apr 2008, Bill Moran wrote:
> 
>> In response to salman <salmanb@quietcaresystems.com>:
>>>
>>> I looked through the docs already but I have a couple of questions about
>>> the process and wanted clarification.
>>>
>>> I would like to use the slony recommended method to upgrade our 8.2.x pg
>>> install to 8.3.1. If I understand the documentation correctly, I need to
>>> install 8.3.1 on the server, make a slave node to the master and let
>>> slony sync the data between the two. Then, once the data is fairly
>>> in-sync, stop write applications, and issue a move set command to start
>>> using the new, updated master.
>>>
>>> The questions I have are as follows:
>>>
>>> 1) Since node IDs x,y are already in use by the primary master (x) and
>>> slave (y), the new 8.3.1 node will receive an ID of 'z' (1,2,3 in
>>> numbers). Is it possible to rename the new node (z) to x?  I was unable
>>> to find any docs about this.
>>
>> I don't know the answer to this one.
> 
> The answer is unfortunately, still no.  So, your upgraded server will 
> become node 3 and if that's going to be the new master and you want it 
> to be node 1, the only way to do this is tear down replication and 
> reinstall the cluster with different node IDs.
> 

Ugh. So any existing scripts and/or cron jobs would have to be modified 
and tested, again, to make sure they work. I was hoping such a base 
feature would be in there and I just missed it while going through the 
docs page, but I guess not.

-salman
From jeff at frostconsultingllc.com  Tue Apr  8 13:29:00 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Tue Apr  8 13:29:12 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <47FBCFDC.9020101@quietcaresystems.com>
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
Message-ID: <Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>

On Tue, 8 Apr 2008, salman wrote:

>> The answer is unfortunately, still no.  So, your upgraded server will 
>> become node 3 and if that's going to be the new master and you want it to 
>> be node 1, the only way to do this is tear down replication and reinstall 
>> the cluster with different node IDs.
>> 
>
> Ugh. So any existing scripts and/or cron jobs would have to be modified and 
> tested, again, to make sure they work. I was hoping such a base feature would 
> be in there and I just missed it while going through the docs page, but I 
> guess not.

I know, it's definitely a drag.  One thing you can do is use the define 
command to give meaningful names to everything:

http://slony.info/documentation/stmtdefine.html

You can put that stuff in your included preamble (you are using an included 
preamble, right?) and then refer to the nodes my name instaed of node id.

I think if the default event node wasn't always 1, but in fact the current 
master, then things would be less painful when you end up with a master that 
isn't node id 1.

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From salmanb at quietcaresystems.com  Tue Apr  8 13:45:00 2008
From: salmanb at quietcaresystems.com (salman)
Date: Tue Apr  8 13:45:11 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
	<Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>
Message-ID: <47FBD94C.7010804@quietcaresystems.com>

> 
> I know, it's definitely a drag.  One thing you can do is use the define 
> command to give meaningful names to everything:
> 
> http://slony.info/documentation/stmtdefine.html
> 
> You can put that stuff in your included preamble (you are using an 
> included preamble, right?) and then refer to the nodes my name instaed 
> of node id.
> 
> I think if the default event node wasn't always 1, but in fact the 
> current master, then things would be less painful when you end up with a 
> master that isn't node id 1.
> 

Ah. Thank you very much, this will work great.

-salman
From cbbrowne at ca.afilias.info  Tue Apr  8 14:47:47 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Apr  8 14:47:59 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <47FBCFDC.9020101@quietcaresystems.com> (salman's message of "Tue,
	08 Apr 2008 16:04:44 -0400")
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
Message-ID: <60skxwyq64.fsf@dba2.int.libertyrms.com>

salman <salmanb@quietcaresystems.com> writes:
>>>> 1) Since node IDs x,y are already in use by the primary master (x) and
>>>> slave (y), the new 8.3.1 node will receive an ID of 'z' (1,2,3 in
>>>> numbers). Is it possible to rename the new node (z) to x?  I was unable
>>>> to find any docs about this.
>>>
>>> I don't know the answer to this one.
>> The answer is unfortunately, still no.  So, your upgraded server
>> will become node 3 and if that's going to be the new master and you
>> want it to be node 1, the only way to do this is tear down
>> replication and reinstall the cluster with different node IDs.
>>
>
> Ugh. So any existing scripts and/or cron jobs would have to be
> modified and tested, again, to make sure they work. I was hoping such
> a base feature would be in there and I just missed it while going
> through the docs page, but I guess not.

I have to object somewhat; the idea of being able to change the
identity of a node in this fashion is NOT any sort of "base feature"
or "basic feature."

The node ID is deeply used throughout the functionality of Slony-I,
and the notion of changing it would require some rather deep changes
that are very much NOT "basic."

The essential problem is that node identity is not merely stored in
one spot (e.g. - the sequence sl_local_node_id); it is stored widely,
with varying levels of indirection, in *most* of the tables in the
Slony-I internal schema.

To change a node identity would require updating widely the contents
of virtually all the tables in the cluster, thus requiring locking
practically the entire state of each node.  But that's the first,
naive view of it.

Going on to the fact that Slony-I is a distributed system takes us a
step further; in order to consistently perform this update would not
only require that we lock down *a* node to substantially rewrite its
configuration; it would require rewriting the configuration of the
WHOLE cluster in a consistent fashion.  We really don't have a way to
do this.

There does now exist a way of renumbering a node, in the form of the
CLONE PREPARE/CLONE FINISH functionality that is coming in v2.0.  But
even in that case, we depend on setting up the new node by copying
data from the state of the new node under its former identity to
establish its new identity.  There is actually not much need to revise
the new node's configuration (see cloneNodeFinish(int4, int4) for
details on how little the change is).

I don't want to go into any sort of "big rant" to parallel the recent
comments on the list, but I do need to point out that the notion of
renumbering nodes _is not basic functionality_.  It represents
something that would be really rather difficult to accomplish.
-- 
(reverse (concatenate 'string "ofni.sesabatadxunil" "@" "enworbbc"))
http://cbbrowne.com/info/sgml.html
The purpose of an undergraduate education at MIT is to give you a case
of post-traumatic stress syndrome that won't wear off for forty years.
From cbbrowne at ca.afilias.info  Tue Apr  8 15:13:43 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Apr  8 15:13:57 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <47FBCFDC.9020101@quietcaresystems.com> (salman's message of "Tue,
	08 Apr 2008 16:04:44 -0400")
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
Message-ID: <60od8kyoyw.fsf@dba2.int.libertyrms.com>

salman <salmanb@quietcaresystems.com> writes:
> Ugh. So any existing scripts and/or cron jobs would have to be
> modified and tested, again, to make sure they work. I was hoping such
> a base feature would be in there and I just missed it while going
> through the docs page, but I guess not.

It was not made clear that renumbering nodes is not practical; I have
patched the docs to indicate this...

http://lists.slony.info/pipermail/slony1-commit/2008-April/002226.html
-- 
output = reverse("ofni.secnanifxunil" "@" "enworbbc")
http://linuxdatabases.info/info/nonrdbms.html
Multics Emacs: a lifetime of convenience, a moment of regret.
From jeff at frostconsultingllc.com  Tue Apr  8 15:19:06 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Tue Apr  8 15:19:22 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <60od8kyoyw.fsf@dba2.int.libertyrms.com>
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
	<60od8kyoyw.fsf@dba2.int.libertyrms.com>
Message-ID: <Pine.LNX.4.64.0804081515380.7373@discord.home.frostconsultingllc.com>

On Tue, 8 Apr 2008, Christopher Browne wrote:

> salman <salmanb@quietcaresystems.com> writes:
>> Ugh. So any existing scripts and/or cron jobs would have to be
>> modified and tested, again, to make sure they work. I was hoping such
>> a base feature would be in there and I just missed it while going
>> through the docs page, but I guess not.
>
> It was not made clear that renumbering nodes is not practical; I have
> patched the docs to indicate this...
>
> http://lists.slony.info/pipermail/slony1-commit/2008-April/002226.html

Christopher,

Any chance of changing the slonik functions to have a default EVENT NODE of 
<ORIGIN NODE> instead of 1?  I think this plus the ability to DEFINE aliases 
would take care of all these issues.  Perhaps we should make the DEFINE more 
prominent in the docs.  I suppose also making EVENT NODE required instead of 
optional could help with that as well.

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From drees76 at gmail.com  Tue Apr  8 17:08:16 2008
From: drees76 at gmail.com (David Rees)
Date: Tue Apr  8 17:08:30 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <Pine.LNX.4.64.0804081515380.7373@discord.home.frostconsultingllc.com>
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
	<60od8kyoyw.fsf@dba2.int.libertyrms.com>
	<Pine.LNX.4.64.0804081515380.7373@discord.home.frostconsultingllc.com>
Message-ID: <72dbd3150804081708q39cda377pfa3f408e733688cd@mail.gmail.com>

On Tue, Apr 8, 2008 at 3:19 PM, Jeff Frost <jeff@frostconsultingllc.com> wrote:
> Perhaps we should make the DEFINE more
> prominent in the docs.  I suppose also making EVENT NODE required instead of
> optional could help with that as well.

This is a good idea - while I primarily use the alt-perl scripts to
maintain my clusters I occasionally need to write slonik scripts by
hand - and I didn't know about the DEFINE syntax - it would certainly
come in handy when it comes to testing scripts on dev systems and then
applying those scripts to production systems.

-Dave
From shoaibmir at gmail.com  Tue Apr  8 17:24:26 2008
From: shoaibmir at gmail.com (Shoaib Mir)
Date: Tue Apr  8 17:24:42 2008
Subject: [Slony1-general] Re: Failover versus Store Node
In-Reply-To: <bf54be870804071732i52866d68p9b3cbda58981942f@mail.gmail.com>
References: <bf54be870804071732i52866d68p9b3cbda58981942f@mail.gmail.com>
Message-ID: <bf54be870804081724v20d36aekd5ff9ee2481908b1@mail.gmail.com>

Does anyone has any idea about it? I am looking for any Slony catalog table
differences that I couldnt find myself in this specific scenario.

-Shoaib

On Tue, Apr 8, 2008 at 10:32 AM, Shoaib Mir <shoaibmir@gmail.com> wrote:

> While trying out different scenarios in Slony (ver 1.2.9) I came across
> the following:
>
> When I did a failover on a node and made it back online again without
> doing an uninstall or delete on it, I was still able to see it in the
> sl_node table with active status and this is why when I did a subscribe
> again for the failed node (without a delete) I didnt get any error through
> slonik and I could see the entry in sl_subscribe for the failed node but =
the
> replication was not working for this node.
>
> Now in the other scenario when I did a store node and store node (without
> subscribe) for a fresh node to a cluster I could see in the sl_node table
> having exactly the same kind of entry as the failed node in sl_node table.
>
> I will like to know how can I differentiate between a failed node and a
> recently added node (without subscriptions) from the slony catalog tables?
>
> Thank you,
>
> Shoaib Mir
> Fujitsu Australia Software Technology
> shoaibm@fast.fujistu.com.au
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080409/=
f84effe9/attachment.htm
From JanWieck at Yahoo.com  Tue Apr  8 17:31:04 2008
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Tue Apr  8 17:31:30 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <Pine.LNX.4.64.0804081515380.7373@discord.home.frostconsultingllc.com>
References: <47FBC41A.3060307@quietcaresystems.com>	<20080408153710.b128758f.wmoran@collaborativefusion.com>	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>	<47FBCFDC.9020101@quietcaresystems.com>	<60od8kyoyw.fsf@dba2.int.libertyrms.com>
	<Pine.LNX.4.64.0804081515380.7373@discord.home.frostconsultingllc.com>
Message-ID: <47FC0E48.3030903@Yahoo.com>

On 4/8/2008 6:19 PM, Jeff Frost wrote:
> I suppose also making EVENT NODE required instead of 
> optional could help with that as well.

Yes. Having a default of 1 for commands that actually need to be coming 
from the origin of a set was definitely a mistake in the implementation.

Commands that are not logically bound to a node already given in other 
parameters (like STORE PATH, which must always be initiated on the 
client side of the connection) should require the specification of the 
origin or event node.


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From cbbrowne at ca.afilias.info  Tue Apr  8 19:23:17 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Apr  8 19:23:35 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <Pine.LNX.4.64.0804081515380.7373@discord.home.frostconsultingllc.com>
	(Jeff Frost's message of "Tue, 8 Apr 2008 15:19:06 -0700 (PDT)")
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
	<60od8kyoyw.fsf@dba2.int.libertyrms.com>
	<Pine.LNX.4.64.0804081515380.7373@discord.home.frostconsultingllc.com>
Message-ID: <60iqyrzrze.fsf@dba2.int.libertyrms.com>

Jeff Frost <jeff@frostconsultingllc.com> writes:
> On Tue, 8 Apr 2008, Christopher Browne wrote:
>
>> salman <salmanb@quietcaresystems.com> writes:
>>> Ugh. So any existing scripts and/or cron jobs would have to be
>>> modified and tested, again, to make sure they work. I was hoping such
>>> a base feature would be in there and I just missed it while going
>>> through the docs page, but I guess not.
>>
>> It was not made clear that renumbering nodes is not practical; I have
>> patched the docs to indicate this...
>>
>> http://lists.slony.info/pipermail/slony1-commit/2008-April/002226.html
>
> Christopher,
>
> Any chance of changing the slonik functions to have a default EVENT
> NODE of <ORIGIN NODE> instead of 1?  I think this plus the ability to
> DEFINE aliases would take care of all these issues.  Perhaps we should
> make the DEFINE more prominent in the docs.  I suppose also making
> EVENT NODE required instead of optional could help with that as well.

<ORIGIN NODE> has two demerits:

  a) If there is more than one origin node, then it may be ambiguous
     (if the command also specifies a set that it operates on, then
     that ambiguity would go away).

  b) Calculating the origin node may require an extra DB query,
     which isn't particularly prohibitive from a performance
     standpoint, but it definitely would add to the complexity
     of the Slonik commands, which is somewhat of a pain :-(

I think I'd rather go with making EVENT NODE a mandatory parameter.

Actually, this is a *very* good time to debate this, as v2.0 would be
a reasonable place for such changes to take place.  It would not be
overly intrusive, right now, to change EVENT NODE to be mandatory.
After v2.0 gets released, such changes become rather more painful to
make.

Jan, what do you think of making EVENT NODE mandatory, and eliminating
the "default of 1"?  I kind of like that...
-- 
(reverse (concatenate 'string "ofni.secnanifxunil" "@" "enworbbc"))
http://www3.sympatico.ca/cbbrowne/advocacy.html
Rules of the  Evil Overlord #187. "I will not  hold lavish banquets in
the middle of  a famine. The good PR among the  guests doesn't make up
for the bad PR among the masses."  <http://www.eviloverlord.com/>
From cbbrowne at ca.afilias.info  Tue Apr  8 19:43:35 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Apr  8 19:43:53 2008
Subject: [Slony1-general] Re: Failover versus Store Node
In-Reply-To: <bf54be870804081724v20d36aekd5ff9ee2481908b1@mail.gmail.com>
	(Shoaib Mir's message of "Wed, 9 Apr 2008 10:24:26 +1000")
References: <bf54be870804071732i52866d68p9b3cbda58981942f@mail.gmail.com>
	<bf54be870804081724v20d36aekd5ff9ee2481908b1@mail.gmail.com>
Message-ID: <60ej9fzr1k.fsf@dba2.int.libertyrms.com>

"Shoaib Mir" <shoaibmir@gmail.com> writes:
> Does anyone has any idea about it? I am looking for any Slony
> catalog table differences that I couldnt find myself in this
> specific scenario.

It depends heavily on why the node failed.

- If it failed because the DBMS got corrupted, then there could be
  pretty well any sort of trash in the DB on the failed node.

- If you chose to fail over because [say] there was a temporary
  communications problem, then that database essentially gets "shunned."

  It will appear, internally, to be in perfectly good shape, but, as
  you noticed, the cluster wasn't quite happy with it ;-(.

You really need to drop the node and recreate it.

It's not worth trying to reconstruct that node into the cluster; head
back to the problem statement, namely:

  "We had such a serious problem that it warranted doing a FAIL OVER."

If you had so serious a problem, then it warrants rebuilding that
database from scratch, period.
-- 
"cbbrowne","@","acm.org"
http://www3.sympatico.ca/cbbrowne/
Entia non sunt multiplicanda sine necessitate.
From shoaibmir at gmail.com  Tue Apr  8 19:53:49 2008
From: shoaibmir at gmail.com (Shoaib Mir)
Date: Tue Apr  8 19:54:09 2008
Subject: [Slony1-general] Re: Failover versus Store Node
In-Reply-To: <60ej9fzr1k.fsf@dba2.int.libertyrms.com>
References: <bf54be870804071732i52866d68p9b3cbda58981942f@mail.gmail.com>
	<bf54be870804081724v20d36aekd5ff9ee2481908b1@mail.gmail.com>
	<60ej9fzr1k.fsf@dba2.int.libertyrms.com>
Message-ID: <bf54be870804081953u60da1664h85706d829f2c9f67@mail.gmail.com>

On Wed, Apr 9, 2008 at 12:43 PM, Christopher Browne <
cbbrowne@ca.afilias.info> wrote:

> "Shoaib Mir" <shoaibmir@gmail.com> writes:
> > Does anyone has any idea about it? I am looking for any Slony
> > catalog table differences that I couldnt find myself in this
> > specific scenario.
>
> It depends heavily on why the node failed.
>
> - If it failed because the DBMS got corrupted, then there could be
>  pretty well any sort of trash in the DB on the failed node.
>
> - If you chose to fail over because [say] there was a temporary
>  communications problem, then that database essentially gets "shunned."
>
>  It will appear, internally, to be in perfectly good shape, but, as
>  you noticed, the cluster wasn't quite happy with it ;-(.
>
> You really need to drop the node and recreate it.
>
> It's not worth trying to reconstruct that node into the cluster; head
> back to the problem statement, namely:
>
>  "We had such a serious problem that it warranted doing a FAIL OVER."
>
> If you had so serious a problem, then it warrants rebuilding that
> database from scratch, period.
>

Thanks a lot for a detailed reply on this, this was helpful. I was also
finally able to find the differences in sl_subscribe tables for failed node
and active nodes which will help me to identify the failed nodes that have
not yet been deleted from cluster.

Regards,
Shoaib
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080409/=
d8373d74/attachment-0001.htm
From shoaibmir at gmail.com  Wed Apr  9 01:44:01 2008
From: shoaibmir at gmail.com (Shoaib Mir)
Date: Wed Apr  9 01:44:27 2008
Subject: [Slony1-general] Slony on Opensolaris
Message-ID: <bf54be870804090144m8906a03h3bbb061f03d2a3c6@mail.gmail.com>

While installing latest 1.2.13 source on Opensolaris I am getting the
following error:

"src/slonik/parser.y", line 16: cannot find include file: "slonik.h"
"src/slonik/parser.y", line 110: syntax error before or at: SlonikAdmInfo
"y.tab.c", line 390: syntax error before or at: typedef
"y.tab.c", line 398: syntax error before or at: typedef
"y.tab.c", line 404: syntax error before or at: typedef

I have tried all kinds of version and I can across this one.

Can anyone help me out with this?

Regards,
Shoaib
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080409/=
90d3167c/attachment.htm
From shoaibmir at gmail.com  Wed Apr  9 04:58:05 2008
From: shoaibmir at gmail.com (Shoaib Mir)
Date: Wed Apr  9 04:58:41 2008
Subject: [Slony1-general] Re: Slony on Opensolaris
In-Reply-To: <bf54be870804090144m8906a03h3bbb061f03d2a3c6@mail.gmail.com>
References: <bf54be870804090144m8906a03h3bbb061f03d2a3c6@mail.gmail.com>
Message-ID: <bf54be870804090458w6f73433ft3ca6ecb8049946f1@mail.gmail.com>

ahh just got around using gcc instead of cc :)

-Shoaib

On Wed, Apr 9, 2008 at 6:44 PM, Shoaib Mir <shoaibmir@gmail.com> wrote:

> While installing latest 1.2.13 source on Opensolaris I am getting the
> following error:
>
> "src/slonik/parser.y", line 16: cannot find include file: "slonik.h"
> "src/slonik/parser.y", line 110: syntax error before or at: SlonikAdmInfo
> "y.tab.c", line 390: syntax error before or at: typedef
> "y.tab.c", line 398: syntax error before or at: typedef
> "y.tab.c", line 404: syntax error before or at: typedef
>
> I have tried all kinds of version and I can across this one.
>
> Can anyone help me out with this?
>
> Regards,
> Shoaib
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080409/=
5bf15cc6/attachment.htm
From ajs at crankycanuck.ca  Wed Apr  9 06:09:18 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Wed Apr  9 06:09:47 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <47FBCFDC.9020101@quietcaresystems.com>
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
Message-ID: <20080409130918.GB12469@crankycanuck.ca>

On Tue, Apr 08, 2008 at 04:04:44PM -0400, salman wrote:
> Ugh. So any existing scripts and/or cron jobs would have to be modified 
> and tested, again, to make sure they work. I was hoping such a base 
> feature would be in there and I just missed it while going through the 
> docs page, but I guess not.

If you're going to modify such scripts, it would seem wise to parameterise
the naming.  The reason this isn't a "base feature" is that the node numbers
are not _supposed_ to have any special meaning: there's nothing special
about node 1 (although in practice, it turns out there have been bugs making
node 1 special).

A

From ajs at crankycanuck.ca  Wed Apr  9 11:08:14 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Wed Apr  9 11:08:48 2008
Subject: [Slony1-general] ERROR: Slony-I: old key column TTT.FFF IS NULL
	on {UPDATE, DELETE}
In-Reply-To: <b10d372b0804061644x5b0a5e2fxba07b1486f503338@mail.gmail.com>
References: <b10d372b0804061644x5b0a5e2fxba07b1486f503338@mail.gmail.com>
Message-ID: <20080409180814.GA21319@crankycanuck.ca>

On Mon, Apr 07, 2008 at 09:44:22AM +1000, James Tucker wrote:
> We have recently experienced an incident whereby certain tables were
> directly updated and new columns and constraints added without using the
> execute script function.  We are now receiving errors (ERROR: Slony-I: old
> key column TTT.FFF IS NULL on {UPDATE,DELETE}) on certain transactions, and
> these transactions are being rolled back.  The DDL changes were also done on
> the slave node, so schemas are are both correct.  I believe the issue is to
> do with the triggers not being updated after .

Among other things, yes.  The short answer is Don't Do That.  The other
poster suggested what you can do.

The other approach is to use the "bare metal" functions.  These are
documented in the Slony manual.

A

From vivek at khera.org  Wed Apr  9 11:14:43 2008
From: vivek at khera.org (Vivek Khera)
Date: Wed Apr  9 11:14:52 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
	<Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>
Message-ID: <3B3D73DC-D579-4532-803E-7E0F604F4B22@khera.org>


On Apr 8, 2008, at 4:29 PM, Jeff Frost wrote:
> I think if the default event node wasn't always 1, but in fact the  
> current master, then things would be less painful when you end up  
> with a master that isn't node id 1.

I think it would be even better if there was NO default event node. I  
intentionally avoid node number 1 just for this reason -- I can debug  
my scripts much more easily.

From cbbrowne at ca.afilias.info  Wed Apr  9 11:44:58 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Apr  9 11:45:09 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <3B3D73DC-D579-4532-803E-7E0F604F4B22@khera.org> (Vivek Khera's
	message of "Wed, 9 Apr 2008 14:14:43 -0400")
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
	<Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>
	<3B3D73DC-D579-4532-803E-7E0F604F4B22@khera.org>
Message-ID: <6063uqzx3p.fsf@dba2.int.libertyrms.com>

Vivek Khera <vivek@khera.org> writes:
> On Apr 8, 2008, at 4:29 PM, Jeff Frost wrote:
>> I think if the default event node wasn't always 1, but in fact the
>> current master, then things would be less painful when you end up
>> with a master that isn't node id 1.
>
> I think it would be even better if there was NO default event node. I
> intentionally avoid node number 1 just for this reason -- I can debug
> my scripts much more easily.

Reviewing the parser, there only seem to be the following slonik
commands that use a default of 1:

  INIT CLUSTER has default ID = 1
  STORE NODE has default EVENT NODE = 1
  DROP NODE has default EVENT NODE = 1
  FAILOVER has default BACKUP NODE = 1
  EXECUTE SCRIPT has default EVENT NODE = 1
  UPDATE FUNCTIONS has default ID = 1
  REPAIR CONFIG has default EVENT NODE = 1
  WAIT FOR EVENT has default WAIT ON = 1

It doesn't take a very big patch to implement the requirement that these:
a) Default to -1, and
b) Error out if left as -1

Index: parser.y
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/parser.y,v
retrieving revision 1.31
diff -c -u -r1.31 parser.y
--- parser.y	14 Feb 2008 22:21:42 -0000	1.31
+++ parser.y	9 Apr 2008 18:41:05 -0000
@@ -149,6 +149,7 @@
 %type <statement>	stmt_set_move_sequence
 %type <statement>	stmt_subscribe_set
 %type <statement>	stmt_unsubscribe_set
 %type <statement>	stmt_lock_set
 %type <statement>	stmt_unlock_set
 %type <statement>	stmt_move_set
@@ -174,6 +175,7 @@
 %token	K_ADMIN
 %token	K_ALL
 %token	K_BACKUP
 %token	K_CLIENT
 %token	K_CLONE
 %token	K_CLUSTER
@@ -229,6 +231,7 @@
 %token	K_SET
 %token	K_STORE
 %token	K_SUBSCRIBE
 %token	K_SUCCESS
 %token	K_SWITCH
 %token	K_TABLE
@@ -565,8 +568,8 @@
 					{
 						SlonikStmt_init_cluster *new;
 						statement_option opt[] = {
-							STMT_OPTION_INT( O_ID, 1 ),
-							STMT_OPTION_STR( O_COMMENT, "Primary Node 1" ),
+							STMT_OPTION_INT( O_ID, -1 ),
+							STMT_OPTION_STR( O_COMMENT, "Initial Node" ),
 							STMT_OPTION_END
 						};
 
@@ -595,7 +598,7 @@
 						statement_option opt[] = {
 							STMT_OPTION_INT( O_ID, -1 ),
 							STMT_OPTION_STR( O_COMMENT, NULL ),
-							STMT_OPTION_INT( O_EVENT_NODE, 1 ),
+							STMT_OPTION_INT( O_EVENT_NODE, -1 ),
 							STMT_OPTION_END
 						};
 
@@ -624,7 +627,7 @@
 						SlonikStmt_drop_node *new;
 						statement_option opt[] = {
 							STMT_OPTION_INT( O_ID, -1 ),
-							STMT_OPTION_INT( O_EVENT_NODE, 1 ),
+							STMT_OPTION_INT( O_EVENT_NODE, -1 ),
 							STMT_OPTION_END
 						};
 
@@ -652,7 +655,7 @@
 						SlonikStmt_failed_node *new;
 						statement_option opt[] = {
 							STMT_OPTION_INT( O_ID, -1 ),
-							STMT_OPTION_INT( O_BACKUP_NODE, 1 ),
+							STMT_OPTION_INT( O_BACKUP_NODE, -1 ),
 							STMT_OPTION_END
 						};
 					{
@@ -1304,7 +1331,7 @@
 						statement_option opt[] = {
 							STMT_OPTION_INT( O_SET_ID, -1 ),
 							STMT_OPTION_STR( O_FILENAME, NULL ),
-							STMT_OPTION_INT( O_EVENT_NODE, 1 ),
+							STMT_OPTION_INT( O_EVENT_NODE, -1 ),
 							STMT_OPTION_INT( O_EXECUTE_ONLY_ON, -1 ),
 							STMT_OPTION_END
 						};
@@ -1335,7 +1362,7 @@
 					{
 						SlonikStmt_update_functions *new;
 						statement_option opt[] = {
-							STMT_OPTION_INT( O_ID, 1 ),
+							STMT_OPTION_INT( O_ID, -1 ),
 							STMT_OPTION_END
 						};
 
@@ -1361,7 +1388,7 @@
 						SlonikStmt_repair_config *new;
 						statement_option opt[] = {
 							STMT_OPTION_INT( O_SET_ID, -1 ),
-							STMT_OPTION_INT( O_EVENT_NODE, 1 ),
+							STMT_OPTION_INT( O_EVENT_NODE, -1 ),
 							STMT_OPTION_INT( O_EXECUTE_ONLY_ON, -1 ),
 							STMT_OPTION_END
 						};
@@ -1393,7 +1420,7 @@
 						statement_option opt[] = {
 							STMT_OPTION_INT( O_ORIGIN, -1 ),
 							STMT_OPTION_INT( O_WAIT_CONFIRMED, -1 ),
-							STMT_OPTION_INT( O_WAIT_ON, 1 ),
+							STMT_OPTION_INT( O_WAIT_ON, -1 ),
 							STMT_OPTION_INT( O_TIMEOUT, 600 ),
 							STMT_OPTION_END
 						};
Index: slonik.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slonik/slonik.c,v
retrieving revision 1.87
diff -c -u -r1.87 slonik.c
--- slonik.c	14 Feb 2008 22:21:42 -0000	1.87
+++ slonik.c	9 Apr 2008 18:41:05 -0000
@@ -29,6 +29,7 @@
 
 #include "postgres.h"
 #include "libpq-fe.h"
+#include "port.h"
 
 #include "slonik.h"
 #include "config.h"
@@ -315,7 +316,9 @@
 
 					if (stmt->ev_origin < 0)
 					{
-						stmt->ev_origin = 1;
+						printf("%s:%d: Error: require EVENT NODE\n", 
+						       hdr->stmt_filename, hdr->stmt_lno);
+						errors++;
 					}
 					if (stmt->no_id == stmt->ev_origin)
 					{
@@ -335,6 +338,12 @@
 					SlonikStmt_drop_node *stmt =
 					(SlonikStmt_drop_node *) hdr;
 
+					if (stmt->ev_origin < 0)
+					{
+						printf("%s:%d: Error: require EVENT NODE\n", 
+						       hdr->stmt_filename, hdr->stmt_lno);
+						errors++;
+					}
 					if (stmt->ev_origin == stmt->no_id)
 					{
 						printf("%s:%d: Error: "
@@ -352,6 +361,12 @@
 					SlonikStmt_failed_node *stmt =
 					(SlonikStmt_failed_node *) hdr;
 
+					if (stmt->backup_node < 0)
+					{
+						printf("%s:%d: Error: require BACKUP NODE\n", 
+						       hdr->stmt_filename, hdr->stmt_lno);
+						errors++;
+					}
 					if (stmt->backup_node == stmt->no_id)
 					{
 						printf("%s:%d: Error: "
@@ -828,6 +843,21 @@
 						errors++;
 				}
 				break;
+                        case STMT_CANCEL_SUBSCRIPTION:
+			        {
+					SlonikStmt_cancel_subscription *stmt =
+						(SlonikStmt_cancel_subscription *) hdr;
+					if (stmt->sub_setid < 0)
+					{
+						printf("%s:%d: Error: "
+							   "set id must be specified\n",
+							   hdr->stmt_filename, hdr->stmt_lno);
+						errors++;
+					}
+					if (script_check_adminfo(hdr, stmt->sub_node) < 0)
+						errors++;
+				}
+				break;
 
 			case STMT_LOCK_SET:
 				{
@@ -925,7 +955,9 @@
 
 					if (stmt->ev_origin < 0)
 					{
-						stmt->ev_origin = 1;
+						printf("%s:%d: Error: require EVENT NODE\n", 
+						       hdr->stmt_filename, hdr->stmt_lno);
+						errors++;
 					}
 					if (stmt->ddl_setid < 0)
 					{
-- 
output = ("cbbrowne" "@" "acm.org")
http://www3.sympatico.ca/cbbrowne/linuxdistributions.html
Why is  it that  when you  transport something by  car, it's  called a
shipment, but when you transport something by ship, it's called cargo?
From vivek at khera.org  Wed Apr  9 11:51:10 2008
From: vivek at khera.org (Vivek Khera)
Date: Wed Apr  9 11:51:19 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <6063uqzx3p.fsf@dba2.int.libertyrms.com>
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
	<Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>
	<3B3D73DC-D579-4532-803E-7E0F604F4B22@khera.org>
	<6063uqzx3p.fsf@dba2.int.libertyrms.com>
Message-ID: <D307CE9A-89C1-44A7-BE95-7E6E33BA7380@khera.org>


On Apr 9, 2008, at 2:44 PM, Christopher Browne wrote:
> It doesn't take a very big patch to implement the requirement that  
> these:
> a) Default to -1, and
> b) Error out if left as -1

+1


From jeff at frostconsultingllc.com  Wed Apr  9 11:51:29 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Wed Apr  9 11:51:44 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <6063uqzx3p.fsf@dba2.int.libertyrms.com>
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
	<Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>
	<3B3D73DC-D579-4532-803E-7E0F604F4B22@khera.org>
	<6063uqzx3p.fsf@dba2.int.libertyrms.com>
Message-ID: <Pine.LNX.4.64.0804091150150.3675@discord.home.frostconsultingllc.com>

On Wed, 9 Apr 2008, Christopher Browne wrote:

> Vivek Khera <vivek@khera.org> writes:
>> On Apr 8, 2008, at 4:29 PM, Jeff Frost wrote:
>>> I think if the default event node wasn't always 1, but in fact the
>>> current master, then things would be less painful when you end up
>>> with a master that isn't node id 1.
>>
>> I think it would be even better if there was NO default event node. I
>> intentionally avoid node number 1 just for this reason -- I can debug
>> my scripts much more easily.
>
> Reviewing the parser, there only seem to be the following slonik
> commands that use a default of 1:
>
>  INIT CLUSTER has default ID = 1
>  STORE NODE has default EVENT NODE = 1
>  DROP NODE has default EVENT NODE = 1
>  FAILOVER has default BACKUP NODE = 1
>  EXECUTE SCRIPT has default EVENT NODE = 1
>  UPDATE FUNCTIONS has default ID = 1
>  REPAIR CONFIG has default EVENT NODE = 1
>  WAIT FOR EVENT has default WAIT ON = 1
>
> It doesn't take a very big patch to implement the requirement that these:
> a) Default to -1, and
> b) Error out if left as -1

I think that's pretty reasonable.  It'll break all my scripts that depend on a 
default event node, but they're easily fixed.

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From cbbrowne at ca.afilias.info  Wed Apr  9 13:44:23 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Apr  9 13:44:36 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <Pine.LNX.4.64.0804091150150.3675@discord.home.frostconsultingllc.com>
	(Jeff Frost's message of "Wed, 9 Apr 2008 11:51:29 -0700 (PDT)")
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
	<Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>
	<3B3D73DC-D579-4532-803E-7E0F604F4B22@khera.org>
	<6063uqzx3p.fsf@dba2.int.libertyrms.com>
	<Pine.LNX.4.64.0804091150150.3675@discord.home.frostconsultingllc.com>
Message-ID: <60wsn6yd08.fsf@dba2.int.libertyrms.com>

Jeff Frost <jeff@frostconsultingllc.com> writes:
> On Wed, 9 Apr 2008, Christopher Browne wrote:
>
>> Vivek Khera <vivek@khera.org> writes:
>>> On Apr 8, 2008, at 4:29 PM, Jeff Frost wrote:
>>>> I think if the default event node wasn't always 1, but in fact the
>>>> current master, then things would be less painful when you end up
>>>> with a master that isn't node id 1.
>>>
>>> I think it would be even better if there was NO default event node. I
>>> intentionally avoid node number 1 just for this reason -- I can debug
>>> my scripts much more easily.
>>
>> Reviewing the parser, there only seem to be the following slonik
>> commands that use a default of 1:
>>
>>  INIT CLUSTER has default ID = 1
>>  STORE NODE has default EVENT NODE = 1
>>  DROP NODE has default EVENT NODE = 1
>>  FAILOVER has default BACKUP NODE = 1
>>  EXECUTE SCRIPT has default EVENT NODE = 1
>>  UPDATE FUNCTIONS has default ID = 1
>>  REPAIR CONFIG has default EVENT NODE = 1
>>  WAIT FOR EVENT has default WAIT ON = 1
>>
>> It doesn't take a very big patch to implement the requirement that these:
>> a) Default to -1, and
>> b) Error out if left as -1
>
> I think that's pretty reasonable.  It'll break all my scripts that
> depend on a default event node, but they're easily fixed.

Yes, this will break some scripts.  It'll probably break some of the
test scripts ;-).

That seems like a not too unreasonable cost, and when I apply the
change, I will definitely update the documentation to indicate that it
is mandatory to set these values, as well as updating the test
scripts.

Hopefully we can attract hands to help update the "altperl" scripts
:-).

I'm seeing some agreement on the merits of this; I'll hold off on the
change until I see one or two more "+1"'s :-).
-- 
"cbbrowne","@","linuxfinances.info"
http://www3.sympatico.ca/cbbrowne/linuxxian.html
Rules of  the Evil Overlord  #225. "I will  explain to my  guards that
most people have their eyes in the front of their heads and thus while
searching  for someone  it makes  little sense  to draw  a  weapon and
slowly back down the hallway." <http://www.eviloverlord.com/>
From kevin at kevinkempterllc.com  Wed Apr  9 14:03:32 2008
From: kevin at kevinkempterllc.com (kevin kempter)
Date: Wed Apr  9 14:03:45 2008
Subject: [Slony1-general] SLONY and post GIS (Spatial data)
Message-ID: <C701A346-F016-4EFE-8DCA-966E5116826B@kevinkempterllc.com>

Hi List;

I may have already asked this, but I couldn't find it in the archives  
ad zi want to be sure.

Can SLONY replicate postGIS / spatial data ?



Thanks in advance
From satya461 at gmail.com  Thu Apr 10 03:05:58 2008
From: satya461 at gmail.com (Satya)
Date: Thu Apr 10 03:06:26 2008
Subject: [Slony1-general] Re: Slony on Opensolaris
In-Reply-To: <bf54be870804090458w6f73433ft3ca6ecb8049946f1@mail.gmail.com>
References: <bf54be870804090144m8906a03h3bbb061f03d2a3c6@mail.gmail.com>
	<bf54be870804090458w6f73433ft3ca6ecb8049946f1@mail.gmail.com>
Message-ID: <6ccff2720804100305s4c724b1cgbe3a2d78ec6fdc9b@mail.gmail.com>

you can also try exporting CFLAGS=3D"-I ./" then do configure,gmake,gmake
install..

I have seen this when using Sun Studio Compliers. Dont know why it is
happening.

-Satya

On Wed, Apr 9, 2008 at 5:28 PM, Shoaib Mir <shoaibmir@gmail.com> wrote:

> ahh just got around using gcc instead of cc :)
>
> -Shoaib
>
> On Wed, Apr 9, 2008 at 6:44 PM, Shoaib Mir <shoaibmir@gmail.com> wrote:
>
> > While installing latest 1.2.13 source on Opensolaris I am getting the
> > following error:
> >
> > "src/slonik/parser.y", line 16: cannot find include file: "slonik.h"
> > "src/slonik/parser.y", line 110: syntax error before or at:
> > SlonikAdmInfo
> > "y.tab.c", line 390: syntax error before or at: typedef
> > "y.tab.c", line 398: syntax error before or at: typedef
> > "y.tab.c", line 404: syntax error before or at: typedef
> >
> > I have tried all kinds of version and I can across this one.
> >
> > Can anyone help me out with this?
> >
> > Regards,
> > Shoaib
> >
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080410/=
f942f696/attachment.htm
From ajs at crankycanuck.ca  Thu Apr 10 08:43:39 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Thu Apr 10 08:44:20 2008
Subject: [Slony1-general] SLONY and post GIS (Spatial data)
In-Reply-To: <C701A346-F016-4EFE-8DCA-966E5116826B@kevinkempterllc.com>
References: <C701A346-F016-4EFE-8DCA-966E5116826B@kevinkempterllc.com>
Message-ID: <20080410154339.GA23408@crankycanuck.ca>

On Wed, Apr 09, 2008 at 03:03:32PM -0600, kevin kempter wrote:
> Hi List;
> 
> I may have already asked this, but I couldn't find it in the archives  
> ad zi want to be sure.
> 
> Can SLONY replicate postGIS / spatial data ?

Slony can replicate anything that can cause a trigger to fire.  It can even
replicate custom datatypes.  So yes.  (The reason it can't do large objects
with the lo interface is that you can't fire triggers on the relevant system
table.)

A

From ajs at crankycanuck.ca  Thu Apr 10 08:44:20 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Thu Apr 10 08:44:47 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <60wsn6yd08.fsf@dba2.int.libertyrms.com>
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
	<Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>
	<3B3D73DC-D579-4532-803E-7E0F604F4B22@khera.org>
	<6063uqzx3p.fsf@dba2.int.libertyrms.com>
	<Pine.LNX.4.64.0804091150150.3675@discord.home.frostconsultingllc.com>
	<60wsn6yd08.fsf@dba2.int.libertyrms.com>
Message-ID: <20080410154420.GB23408@crankycanuck.ca>

On Wed, Apr 09, 2008 at 04:44:23PM -0400, Christopher Browne wrote:
> :-).
> 
> I'm seeing some agreement on the merits of this; I'll hold off on the
> change until I see one or two more "+1"'s :-).

I think it's a good idea.

A
From cbbrowne at ca.afilias.info  Thu Apr 10 09:25:14 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Apr 10 09:25:22 2008
Subject: [Slony1-general] SLONY and post GIS (Spatial data)
In-Reply-To: <C701A346-F016-4EFE-8DCA-966E5116826B@kevinkempterllc.com> (kevin
	kempter's message of "Wed, 9 Apr 2008 15:03:32 -0600")
References: <C701A346-F016-4EFE-8DCA-966E5116826B@kevinkempterllc.com>
Message-ID: <60skxty8wl.fsf@dba2.int.libertyrms.com>

kevin kempter <kevin@kevinkempterllc.com> writes:
> I may have already asked this, but I couldn't find it in the archives
> ad zi want to be sure.
>
> Can SLONY replicate postGIS / spatial data ?

It should, as long as they use data types that can be manipulated via
INSERT/UPDATE/DELETE/COPY, and don't *require* further function usage
to access their data.

One of the base regression tests has, as examples, a whole series of
the data types supported by PostgreSQL:

create table table4 (
  id serial primary key,
  numcol numeric(12,4), -- 1.23
  realcol real,     -- (1.23)
  ptcol point,      -- (1,2)
  pathcol path,     -- ((1,1),(2,2),(3,3),(4,4))
  polycol polygon,  -- ((1,1),(2,2),(3,3),(4,4))
  circcol circle,   -- <(1,2>,3>
  ipcol inet,       -- "192.168.1.1"
  maccol macaddr,   -- "04:05:06:07:08:09"
  bitcol bit varying(20)  -- X'123' 
);

Those all work fine :-).

I'd definitely suggest running some tests on it before depending on
it, but I'd certainly expect it to work.

There is of course the extra "system management challenge" of needing
to manage deployment of code both for PostGIS and Slony-I, and to make
sure PostgreSQL is built suitably for both.

The requirements for both are fairly similar; they both need for all
PostgreSQL installations to include server header files ("make
install-all-headers").

Slony-I requires on some platforms (notably AIX, Solaris) that libpq
be compiled to be threadsafe (e.g. - PostgreSQL is configured with the
option --enable-thread-safety), which PostGIS doesn't seem to be
concerned about.  That might force you to rebuild PostgreSQL.

So there are some "small challenges" to be careful about; none of them
seem particularly insurmountable.  Good luck!  :-)
-- 
(format nil "~S@~S" "cbbrowne" "acm.org")
http://www3.sympatico.ca/cbbrowne/linuxxian.html
Rules of the Evil Overlord #79. "If my doomsday device happens to come
with  a reverse switch, as  soon as  it has  been employed  it will be
melted    down and  made  into   limited-edition commemorative coins."
<http://www.eviloverlord.com/>
From mark at summersault.com  Thu Apr 10 14:09:54 2008
From: mark at summersault.com (Mark Stosberg)
Date: Thu Apr 10 14:10:07 2008
Subject: [Slony1-general] recovering from "could not find trigger"
Message-ID: <47FE8222.4020904@summersault.com>

Today I see a lot of this in my slony logs:

insert into "_production".sl_confirm        (con_origin, con_received,
con_seqno, con_timestamp)    values (1, 2, '1179655', now()); commit
transaction;" PGRES_FATAL_ERROR ERROR:  could not find trigger 142380

###

I'm not sure what caused it, but I'm interested to recover from it. :)
We upgraded the OS last night, but I don't  think that was related.
It's possible some developer dropped, created or altered something
outside of slonik_execute_script.

When I searched for this error, it looks like it's something that was an
issue in the past, but was fixed by 1.2.12, which I'm using.

Thanks!

     Mark

From lists at serioustechnology.com  Thu Apr 10 18:14:26 2008
From: lists at serioustechnology.com (Geoffrey)
Date: Thu Apr 10 18:14:49 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <60wsn6yd08.fsf@dba2.int.libertyrms.com>
References: <47FBC41A.3060307@quietcaresystems.com>	<20080408153710.b128758f.wmoran@collaborativefusion.com>	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>	<47FBCFDC.9020101@quietcaresystems.com>	<Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>	<3B3D73DC-D579-4532-803E-7E0F604F4B22@khera.org>	<6063uqzx3p.fsf@dba2.int.libertyrms.com>	<Pine.LNX.4.64.0804091150150.3675@discord.home.frostconsultingllc.com>
	<60wsn6yd08.fsf@dba2.int.libertyrms.com>
Message-ID: <47FEBB72.8050409@serioustechnology.com>

Christopher Browne wrote:

> I'm seeing some agreement on the merits of this; I'll hold off on the
> change until I see one or two more "+1"'s :-).

+1


-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From glynastill at yahoo.co.uk  Fri Apr 11 01:29:09 2008
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Fri Apr 11 01:29:35 2008
Subject: [Slony1-general] Triggers on slave tables
Message-ID: <762435.78334.qm@web25814.mail.ukl.yahoo.com>

Hi chaps,

When a table on a slave is put into slony replication, what happens to the driggers on the table?

E.g I have a table "replicated_users" on each server and the table has a trigger "replicate_users". Once in replication I can no longer asee the "replicate_users" trigger on the slave, I presume it is just dropped? At the moment I'm just recreating the trigger after putting the table into replication, however I wondered if this could cause any problems?

I guess it would be better to create a slonik script to create the tables with execute_script, then subscribe them, and then add int he triggers with execute_script?



      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  

http://uk.promotions.yahoo.com/forgood/

From cbbrowne at ca.afilias.info  Fri Apr 11 07:37:41 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri Apr 11 07:37:47 2008
Subject: [Slony1-general] Triggers on slave tables
In-Reply-To: <762435.78334.qm@web25814.mail.ukl.yahoo.com> (Glyn Astill's
	message of "Fri, 11 Apr 2008 08:29:09 +0000 (GMT)")
References: <762435.78334.qm@web25814.mail.ukl.yahoo.com>
Message-ID: <60bq4gxxsa.fsf@dba2.int.libertyrms.com>

Glyn Astill <glynastill@yahoo.co.uk> writes:
> When a table on a slave is put into slony replication, what happens
> to the driggers on the table?
>
> E.g I have a table "replicated_users" on each server and the table
> has a trigger "replicate_users". Once in replication I can no longer
> asee the "replicate_users" trigger on the slave, I presume it is
> just dropped? At the moment I'm just recreating the trigger after
> putting the table into replication, however I wondered if this could
> cause any problems?
>
> I guess it would be better to create a slonik script to create the
> tables with execute_script, then subscribe them, and then add int he
> triggers with execute_script?

Actually, you presume wrong :-).

The triggers are not dropped; they are altered (via a direct update to
pg_trigger) to point them to the primary key's index rather than the
table.

That way, they can be restored when/if:

a) You run a DDL script, and
b) You decide to drop replication from the node.

If you add back a trigger "by hand," then you will eventually (when
running DDL/dropping replication) run into the problem that there will
be multiple instances of that trigger.  Could cause problems :-).

There is a slonik command, "STORE TRIGGER" that can be used to
indicate that certain triggers *are* supposed to run on one/all nodes.

Note that in PostgreSQL 8.3, there is new functionality that triggers
can have "replication control" put on them via having an extra trigger
attribute and a GUC variable.  This eliminates the need to do the
pg_trigger trickery.

The support for the 8.3 functionality is nearly done in CVS HEAD which
will become Slony-I v2.0 Real Soon Now.
-- 
output = ("cbbrowne" "@" "linuxfinances.info")
http://www3.sympatico.ca/cbbrowne/x.html
"IBM may have originated Not Invented Here, but Microsoft has managed
to squander their mountain of technical talent by not harvesting prior
art until the rain of flaming hardware makes it difficult for the
executives to drive to the Redmond campus.)" -- david parsons
From jeff at frostconsultingllc.com  Fri Apr 11 07:52:24 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Fri Apr 11 07:52:29 2008
Subject: [Slony1-general] 1.2.14rc -=> 1.2.14?
Message-ID: <Pine.LNX.4.64.0804110751060.3084@discord.home.frostconsultingllc.com>

Is 1.2.14rc going to get promoted to 1.2.14 anytime soon or is there another 
rc forthcoming?  I've been using it in a few 8.3.1 environments with no 
problems.

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From cbbrowne at ca.afilias.info  Fri Apr 11 08:50:02 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri Apr 11 08:50:13 2008
Subject: [Slony1-general] add_empty_table_to_replication()
In-Reply-To: <200803311437.46611@hal.medialogik.com> (Alan Hodgson's message
	of "Mon, 31 Mar 2008 14:37:46 -0700")
References: <200803311437.46611@hal.medialogik.com>
Message-ID: <607if4xufp.fsf@dba2.int.libertyrms.com>

Alan Hodgson <ahodgson@simkin.ca> writes:
> I would like to start making use of this function to add new tables, but I'm 
> having trouble making sense of it.

Did I make any comment on this?

> How would one actually use this function? Run it through a DDL script? The 
> docs seem to imply that.

Yes, that's right.

> Why does the function call alterTableRestore at the end? That seems wrong; 
> calling the function seems to add the table to a set on the local node but 
> it leaves it in a non-replicated state.

Actually, while a bit nonintuitive, that *is* correct.

If you're running this function within an "EXECUTE SCRIPT" request,
the cleanup portion of "EXECUTE SCRIPT" goes back and alters tables to
put them into replicated state.

Thus, add_empty_table_to_replication() doesn't need to put the table
into replicated state - we can depend on EXECUTE SCRIPT to handle
that.

> Also, what happens if that script executes on a node that is neither
> an origin or a subscriber to the table? It would appear that it
> doesn't actually check if the table should be touched on the local
> node.

That could be; I'll have to think about that...
-- 
let name="cbbrowne" and tld="linuxfinances.info" in name ^ "@" ^ tld;;
http://linuxdatabases.info/info/emacs.html
"Though the Chinese should adore APL, it's FORTRAN they put their
money on." -- Alan J. Perlis
From cbbrowne at ca.afilias.info  Fri Apr 11 08:59:11 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri Apr 11 08:59:18 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <47FEBB72.8050409@serioustechnology.com> (Geoffrey's message of
	"Thu, 10 Apr 2008 21:14:26 -0400")
References: <47FBC41A.3060307@quietcaresystems.com>
	<20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
	<Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>
	<3B3D73DC-D579-4532-803E-7E0F604F4B22@khera.org>
	<6063uqzx3p.fsf@dba2.int.libertyrms.com>
	<Pine.LNX.4.64.0804091150150.3675@discord.home.frostconsultingllc.com>
	<60wsn6yd08.fsf@dba2.int.libertyrms.com>
	<47FEBB72.8050409@serioustechnology.com>
Message-ID: <603apsxu0g.fsf@dba2.int.libertyrms.com>

Geoffrey <lists@serioustechnology.com> writes:
> Christopher Browne wrote:
>
>> I'm seeing some agreement on the merits of this; I'll hold off on the
>> change until I see one or two more "+1"'s :-).
>
> +1

I have gotten enough of a population of "+1"s, including Jan
indicating that he thought it was a mistake to have default values of
1's in the first place.

I have committed the change to CVS HEAD.  Alas, it got split across
about 4 commit messages, so I can't just point to one :-(.

----------------------------------------------------------------------
Various instances where slonik would use a default node ID of 1 have been changed to remove this.

Slonik scripts may need to be changed to indicate an EVENT NODE (or
similar) after migration to v2.0 as a result.

The slonik commands involved:

- STORE NODE - EVENT NODE
- DROP NODE - EVENT NODE
- WAIT FOR EVENT - WAIT ON
- FAILOVER - BACKUP NODE
- EXECUTE SCRIPT - EVENT NODE
----------------------------------------------------------------------

Things updated include:
 a) slonik sources
 b) admin guide
 c) tests under tests/
 d) I'm about to commit a fix to tools/configure-replication.sh
 e) I'm taking a walk thru the ducttape tests; found a bunch of changes to make :-(
-- 
let name="cbbrowne" and tld="ca.afilias.info" in name ^ "@" ^ tld;;
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)
From glynastill at yahoo.co.uk  Fri Apr 11 09:46:10 2008
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Fri Apr 11 09:49:01 2008
Subject: Fw: [Slony1-general] Triggers on slave tables
Message-ID: <939450.5363.qm@web25801.mail.ukl.yahoo.com>


> ----- Original Message ----
> > From: Christopher Browne 
> > To: Glyn Astill 
> > Cc: slony1-general@lists.slony.info
> > Sent: Friday, 11 April, 2008 3:37:41 PM
> > Subject: Re: [Slony1-general] Triggers on slave tables
> >
> > >Once in replication I can no longer
> > > see the "replicate_users" trigger on the slave, I presume it is
> > > just dropped? 
> > Actually, you presume wrong :-).
> >
> 
 \o/ Excellent
> 
> > The triggers are not dropped; they are altered (via a direct update to
> > pg_trigger) to point them to the primary key's index rather than the
> > table.
> > 
> > That way, they can be restored when/if:
> > 
> > a) You run a DDL script, and
> > b) You decide to drop replication from the node.
> > 
> > If you add back a trigger "by hand," then you will eventually (when
> > running DDL/dropping replication) run into the problem that there will
> > be multiple instances of that trigger.  Could cause problems :-).
> >
 
 I'm thinking this did cause my last problem
 
> > There is a slonik command, "STORE TRIGGER" that can be used to
> > indicate that certain triggers *are* supposed to run on one/all nodes.
> > 
 
 I've had a peek in the docs, but do I run store trigger before or after I 
 subscribe the table? And I presume the trigger needs to be uniform across all 
 nodes too.
 
> > Note that in PostgreSQL 8..3, there is new functionality that triggers
> > can have "replication control" put on them via having an extra trigger
> > attribute and a GUC variable.  This eliminates the need to do the
> > pg_trigger trickery.
> > 
> > The support for the 8.3 functionality is nearly done in CVS HEAD which
> > will become Slony-I v2.0 Real Soon Now.
> 
 
 Very interesting, is there any estimated time frome for 2.0?
 
 





      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  

http://uk.promotions.yahoo.com/forgood/

From ajs at crankycanuck.ca  Fri Apr 11 10:07:27 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Fri Apr 11 10:08:01 2008
Subject: [Slony1-general] Postgresql upgrades and Slony
In-Reply-To: <603apsxu0g.fsf@dba2.int.libertyrms.com>
References: <20080408153710.b128758f.wmoran@collaborativefusion.com>
	<Pine.LNX.4.64.0804081241150.7373@discord.home.frostconsultingllc.com>
	<47FBCFDC.9020101@quietcaresystems.com>
	<Pine.LNX.4.64.0804081326210.7373@discord.home.frostconsultingllc.com>
	<3B3D73DC-D579-4532-803E-7E0F604F4B22@khera.org>
	<6063uqzx3p.fsf@dba2.int.libertyrms.com>
	<Pine.LNX.4.64.0804091150150.3675@discord.home.frostconsultingllc.com>
	<60wsn6yd08.fsf@dba2.int.libertyrms.com>
	<47FEBB72.8050409@serioustechnology.com>
	<603apsxu0g.fsf@dba2.int.libertyrms.com>
Message-ID: <20080411170727.GE28760@crankycanuck.ca>

On Fri, Apr 11, 2008 at 11:59:11AM -0400, Christopher Browne wrote:

>  e) I'm taking a walk thru the ducttape tests; found a bunch of changes to
>  make :-(

I don't think that merits a frowny; I rather think instead it highlights how
pervasive the effects of this mistake were.

A

From dane at greatschools.net  Fri Apr 11 15:28:38 2008
From: dane at greatschools.net (Dane Miller)
Date: Fri Apr 11 15:28:55 2008
Subject: [Slony1-general] Re: Small tool to make Slony management easier
Message-ID: <1207952918.16726.33.camel@danespc.home>

Bill Moran wrote:
> I've been putting this together over the last couple weeks for
> the reasons listed on the HTML page:
> http://people.collaborativefusion.com/~wmoran/PostgreSQL/slony_switchover.html
> 
> I'm interested to hear how useful this is to others, and of course
> suggestions for improvement are welcome.

This looks good Bill.  I like how you build the preamble from the
database instead of relying on slonik config files.  We currently rely
on slonik_move_set to do an origin "switchover", which requires that we
maintain an accurate preamble file on all our database nodes.  Keeping
the preamble and other slon* configs up to date is cumbersome (although
we use puppet for this, which helps).

Some questions for you:

You put a 'wait for event' command after 'lock set' *and* 'move set'.
slonik_move_set only waits after 'lock set'.  Is this extra wait
necessary?  If so, should it be fixed in slonik_move_set?  I'm using
this version:
   slonik_move_set.pl,v 1.1.4.1 2006-10-27 17:54:21


you state here
http://people.collaborativefusion.com/~wmoran/PostgreSQL/slony_switchover.html that...
> Our network topology causes connection paths to vary depending on
> where you're running the slonik script from, thus each node would need
> its own slonik script that was different than other nodes

So there's more than one way to connect to a given node?  Can you
explain this further?  What kind of network topology do you have that
necessitates having connection paths that vary?  (I obviously need to
read more slony documentation)


Thanks for the script (-:

Dane
-- 
Dane Miller
Systems Administrator
Greatschools.net http://www.greatschools.net


From ssinger_pg at sympatico.ca  Fri Apr 11 20:49:59 2008
From: ssinger_pg at sympatico.ca (Steve Singer)
Date: Fri Apr 11 20:50:20 2008
Subject: [Slony1-general] Re: Slony on Opensolaris
In-Reply-To: <bf54be870804090458w6f73433ft3ca6ecb8049946f1@mail.gmail.com>
References: <bf54be870804090144m8906a03h3bbb061f03d2a3c6@mail.gmail.com>
	<bf54be870804090458w6f73433ft3ca6ecb8049946f1@mail.gmail.com>
Message-ID: <BAYC1-PASMTP11C100864BF9708D9209CDACEE0@CEZ.ICE>

On Wed, 9 Apr 2008, Shoaib Mir wrote:

Shoaib,

Getting slony 1.2.13 to build with cc on OpenSolaris just requires a small 
change to the src/slonik/Makefile.

A patch is attached. (Just add -I. to the slonik CFLAGS).

HEAD seems to build fine with sun studio as is.

Steve


> ahh just got around using gcc instead of cc :)
>
> -Shoaib
>
> On Wed, Apr 9, 2008 at 6:44 PM, Shoaib Mir <shoaibmir@gmail.com> wrote:
>
>> While installing latest 1.2.13 source on Opensolaris I am getting the
>> following error:
>>
>> "src/slonik/parser.y", line 16: cannot find include file: "slonik.h"
>> "src/slonik/parser.y", line 110: syntax error before or at: SlonikAdmInfo
>> "y.tab.c", line 390: syntax error before or at: typedef
>> "y.tab.c", line 398: syntax error before or at: typedef
>> "y.tab.c", line 404: syntax error before or at: typedef
>>
>> I have tried all kinds of version and I can across this one.
>>
>> Can anyone help me out with this?
>>
>> Regards,
>> Shoaib
>>
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: slony_sunstudio.diff
Type: text/x-diff
Size: 773 bytes
Desc: 
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20080411/21e21d8f/slony_sunstudio.bin
From shoaibmir at gmail.com  Sat Apr 12 00:22:31 2008
From: shoaibmir at gmail.com (Shoaib Mir)
Date: Sat Apr 12 00:23:38 2008
Subject: [Slony1-general] Re: Slony on Opensolaris
In-Reply-To: <BAYC1-PASMTP11C100864BF9708D9209CDACEE0@CEZ.ICE>
References: <bf54be870804090144m8906a03h3bbb061f03d2a3c6@mail.gmail.com>
	<bf54be870804090458w6f73433ft3ca6ecb8049946f1@mail.gmail.com>
	<BAYC1-PASMTP11C100864BF9708D9209CDACEE0@CEZ.ICE>
Message-ID: <bf54be870804120022q3d6102ay993b7c159470949d@mail.gmail.com>

On Sat, Apr 12, 2008 at 1:49 PM, Steve Singer <ssinger_pg@sympatico.ca>
wrote:

> On Wed, 9 Apr 2008, Shoaib Mir wrote:
>
> Shoaib,
>
> Getting slony 1.2.13 to build with cc on OpenSolaris just requires a small
> change to the src/slonik/Makefile.
>
> A patch is attached. (Just add -I. to the slonik CFLAGS).
>
> HEAD seems to build fine with sun studio as is.
>
> Steve
>


 Thanks Steve, that is true as it requires this change otherwise using gcc
its goes as it is without a problem.

--
Shoaib Mir
Fujistu Australia Software Technology
shoaibm@fast.fujitsu.com.au


>
>
>
> ahh just got around using gcc instead of cc :)
> >
> > -Shoaib
> >
> > On Wed, Apr 9, 2008 at 6:44 PM, Shoaib Mir <shoaibmir@gmail.com> wrote:
> >
> > While installing latest 1.2.13 source on Opensolaris I am getting the
> > > following error:
> > >
> > > "src/slonik/parser.y", line 16: cannot find include file: "slonik.h"
> > > "src/slonik/parser.y", line 110: syntax error before or at:
> > > SlonikAdmInfo
> > > "y.tab.c", line 390: syntax error before or at: typedef
> > > "y.tab.c", line 398: syntax error before or at: typedef
> > > "y.tab.c", line 404: syntax error before or at: typedef
> > >
> > > I have tried all kinds of version and I can across this one.
> > >
> > > Can anyone help me out with this?
> > >
> > > Regards,
> > > Shoaib
> > >
> > >
> >
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080412/=
fb7de4e9/attachment.htm
From wmoran at collaborativefusion.com  Sat Apr 12 05:55:43 2008
From: wmoran at collaborativefusion.com (Bill Moran)
Date: Sat Apr 12 05:55:49 2008
Subject: [Slony1-general] Re: Small tool to make Slony management easier
In-Reply-To: <1207952918.16726.33.camel@danespc.home>
References: <1207952918.16726.33.camel@danespc.home>
Message-ID: <20080412085543.a9ce1734.wmoran@collaborativefusion.com>

Dane Miller <dane@greatschools.net> wrote:
>
> Bill Moran wrote:
> > I've been putting this together over the last couple weeks for
> > the reasons listed on the HTML page:
> > http://people.collaborativefusion.com/~wmoran/PostgreSQL/slony_switchover.html
> > 
> > I'm interested to hear how useful this is to others, and of course
> > suggestions for improvement are welcome.

[snip]

> You put a 'wait for event' command after 'lock set' *and* 'move set'.
> slonik_move_set only waits after 'lock set'.  Is this extra wait
> necessary?  If so, should it be fixed in slonik_move_set?  I'm using
> this version:
>    slonik_move_set.pl,v 1.1.4.1 2006-10-27 17:54:21

The rationale behind that is that the shell script doesn't exit until
the move set() is complete.  I _believe_ the slonik move set() command
can return once the event is submitted, even though the operation is
not complete.  I don't want this -- I want the operation to feel confident
that the operation is complete when the command returns.

If I'm wrong about move set()'s behaviour, then this last wait is unneeded.
I'll try to make time to test this next week.

> you state here
> http://people.collaborativefusion.com/~wmoran/PostgreSQL/slony_switchover.html that...
> > Our network topology causes connection paths to vary depending on
> > where you're running the slonik script from, thus each node would need
> > its own slonik script that was different than other nodes
> 
> So there's more than one way to connect to a given node?  Can you
> explain this further?  What kind of network topology do you have that
> necessitates having connection paths that vary?  (I obviously need to
> read more slony documentation)

Each of our DB servers has multiple IP addresses and firewall policies
dictate who can talk to who.  For example, two DB servers in the same
data center will talk directly to each other on their DB IPs, whereas
a DB server in another facility will have to go through two firewalls
and connect to another DB's management IP.  In somewhat less abstract
terms, if I have 3 servers:
db0 - datacenter 1
db1 - datacenter 1
db2 - datacenter 2

If I execute slonik commands from db1, it will use the hostname
db0-db to connect to db0, but db2 will use the hostname db0-mgmnt.

Are you running Linux by any chance?  This script was developed and
is deployed for us on FreeBSD, and I've verified that it works as
advertised on that platform.  I've _attempted_ to make sure that it
will work on Linux as well, but I've not had the opportunity to test
it.  Testing and feedback is encouraged.

-- 
Bill Moran
Collaborative Fusion Inc.

wmoran@collaborativefusion.com
Phone: 412-422-3463x4023

****************************************************************
IMPORTANT: This message contains confidential information
and is intended only for the individual named. If the reader of
this message is not an intended recipient (or the individual
responsible for the delivery of this message to an intended
recipient), please be advised that any re-use, dissemination,
distribution or copying of this message is prohibited. Please
notify the sender immediately by e-mail if you have received
this e-mail by mistake and delete this e-mail from your system.
E-mail transmission cannot be guaranteed to be secure or
error-free as information could be intercepted, corrupted, lost,
destroyed, arrive late or incomplete, or contain viruses. The
sender therefore does not accept liability for any errors or
omissions in the contents of this message, which arise as a
result of e-mail transmission.
****************************************************************
From dane at greatschools.net  Sat Apr 12 10:04:04 2008
From: dane at greatschools.net (Dane Miller)
Date: Sat Apr 12 10:05:10 2008
Subject: [Slony1-general] Re: Small tool to make Slony management easier
In-Reply-To: <20080412085543.a9ce1734.wmoran@collaborativefusion.com>
References: <1207952918.16726.33.camel@danespc.home>
	<20080412085543.a9ce1734.wmoran@collaborativefusion.com>
Message-ID: <1208019844.8331.18.camel@danespc.home>

Bill Moran wrote:
> Each of our DB servers has multiple IP addresses and firewall policies
> dictate who can talk to who.  For example, two DB servers in the same
> data center will talk directly to each other on their DB IPs, whereas
> a DB server in another facility will have to go through two firewalls
> and connect to another DB's management IP.  In somewhat less abstract
> terms, if I have 3 servers:
> db0 - datacenter 1
> db1 - datacenter 1
> db2 - datacenter 2
> 
> If I execute slonik commands from db1, it will use the hostname
> db0-db to connect to db0, but db2 will use the hostname db0-mgmnt.

Clever.  Thanks for the info, this helped my understanding a lot.  Out
of curiosity, couldn't you also tunnel the inter-datacenter db traffic
and add some routes down the tunnel to simplify slony config paths?

> Are you running Linux by any chance?  

Only on my personal workstations.  Our postgresql servers are FreeBSD.
If I get motivated this weekend, I'll setup some linux virtual machines
to test on.

Dane

From wmoran at collaborativefusion.com  Mon Apr 14 06:36:51 2008
From: wmoran at collaborativefusion.com (Bill Moran)
Date: Mon Apr 14 06:37:32 2008
Subject: [Slony1-general] Re: Small tool to make Slony management easier
In-Reply-To: <1208019844.8331.18.camel@danespc.home>
References: <1207952918.16726.33.camel@danespc.home>
	<20080412085543.a9ce1734.wmoran@collaborativefusion.com>
	<1208019844.8331.18.camel@danespc.home>
Message-ID: <20080414093651.5238748c.wmoran@collaborativefusion.com>

In response to Dane Miller <dane@greatschools.net>:

> Bill Moran wrote:
> > Each of our DB servers has multiple IP addresses and firewall policies
> > dictate who can talk to who.  For example, two DB servers in the same
> > data center will talk directly to each other on their DB IPs, whereas
> > a DB server in another facility will have to go through two firewalls
> > and connect to another DB's management IP.  In somewhat less abstract
> > terms, if I have 3 servers:
> > db0 - datacenter 1
> > db1 - datacenter 1
> > db2 - datacenter 2
> > 
> > If I execute slonik commands from db1, it will use the hostname
> > db0-db to connect to db0, but db2 will use the hostname db0-mgmnt.
> 
> Clever.  Thanks for the info, this helped my understanding a lot.  Out
> of curiosity, couldn't you also tunnel the inter-datacenter db traffic
> and add some routes down the tunnel to simplify slony config paths?

Sure, but that would make our firewall rules more complex.  It's a
tradeoff.

-- 
Bill Moran
Collaborative Fusion Inc.
http://people.collaborativefusion.com/~wmoran/

wmoran@collaborativefusion.com
Phone: 412-422-3463x4023
From seby.francis at gmail.com  Mon Apr 14 11:43:26 2008
From: seby.francis at gmail.com (Seby)
Date: Mon Apr 14 11:43:39 2008
Subject: [Slony1-general] Slony shutdowns throwing "Tuple" error
Message-ID: <4aad10a00804141143x2015f303j38aafd31108aeaaa@mail.gmail.com>

Could anyone help me to figure out the problem. It looks like the slony
shutdowns throwing the below error:

2008-04-12 18:15:07 GMT CONFIG main: configuration complete - starting
threads
2008-04-12 18:15:07 GMT DEBUG1 localListenThread: thread starts
2008-04-12 18:15:07 GMT FATAL  localListenThread: "select
"_sf_cluster".cleanupListener(); listen "_sf_cluster_
Event"; listen "_sf_cluster_Restart"; " - *ERROR:  tuple already updated by
self*
2008-04-1218:15:07 GMT DEBUG1 slon: shutdown requested

Thanks,
Seby.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080414/=
1e71905a/attachment.htm
From pgsql at bluepolka.net  Tue Apr 15 11:30:49 2008
From: pgsql at bluepolka.net (pgsql)
Date: Tue Apr 15 11:30:37 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <6063us1b6x.fsf@dba2.int.libertyrms.com>
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	<6063us1b6x.fsf@dba2.int.libertyrms.com>
Message-ID: <200804151230.49563.pgsql@bluepolka.net>

On Tuesday 04/08/08 @ 11:57 am MDT, I received this from Christopher Browne=
 <cbbrowne@ca.afilias.info>:
> "Ian Richardson" <irichardson@opushealthcare.com> writes:
> > Has anyone successfully compiled slony 1.2.x on HP-UX 11.23
> > /w IA-64? Any insight is appreciated!:p>
>
> HP/UX has not been a platform we have received many compile
> reports on, so there is a pretty fair chance that you're the
> first to discover any issues that you discover.

Well, here goes.  I'm hitting the attached build error on this platform:

gmake[2]: Entering directory `/users/dists/pgsql/builds/slony1-1.2.14rc/src=
/slony_logshipper'
/opt/ansic/bin/cc +DD64 -I../.. -DPGSHARE=3D"\"/opt/pgsql/installs/postgres=
ql-8.1.2/share/\""  -I/opt/pgsql/installs/postgresql-8.1.2/incl
ude/ -I/opt/pgsql/installs/postgresql-8.1.2/include/server/   -c -o slony_l=
ogshipper.o slony_logshipper.c
/opt/ansic/bin/cc +DD64 -I../.. -DPGSHARE=3D"\"/opt/pgsql/installs/postgres=
ql-8.1.2/share/\""  -I/opt/pgsql/installs/postgresql-8.1.2/incl
ude/ -I/opt/pgsql/installs/postgresql-8.1.2/include/server/   -c -o dbutil.=
o dbutil.c
/opt/ansic/bin/cc +DD64 -I../.. -DPGSHARE=3D"\"/opt/pgsql/installs/postgres=
ql-8.1.2/share/\""  -I/opt/pgsql/installs/postgresql-8.1.2/incl
ude/ -I/opt/pgsql/installs/postgresql-8.1.2/include/server/   -c -o ipcutil=
.o ipcutil.c
bison -y -d  parser.y
gmake[2]: Leaving directory `/users/dists/pgsql/builds/slony1-1.2.14rc/src/=
slony_logshipper'
gmake[1]: Leaving directory `/users/dists/pgsql/builds/slony1-1.2.14rc/src'
*** Error exit code 2

I've attached the full configure/build output.  Any suggestions?

Thanks,
Ed
-------------- next part --------------
A non-text attachment was scrubbed...
Name: build.log
Type: text/x-log
Size: 12282 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20080415=
/787adae4/build.bin
From ajs at crankycanuck.ca  Tue Apr 15 13:19:37 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Tue Apr 15 13:19:57 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <200804151230.49563.pgsql@bluepolka.net>
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	<6063us1b6x.fsf@dba2.int.libertyrms.com>
	<200804151230.49563.pgsql@bluepolka.net>
Message-ID: <20080415201937.GE25083@crankycanuck.ca>

On Tue, Apr 15, 2008 at 12:30:49PM -0600, pgsql wrote: 

> I've attached the full configure/build output.  Any suggestions?

My first question is about this:

> $ /opt/ansic/bin/cc -V
> cc: HP aC++/ANSI C B3910B A.06.05 [Jul 25 2005]

[. . .]

> checking for gcc... /opt/ansic/bin/cc

It usually gives me heartburn when gcc tests find some non-gcc compiler and
think it's gcc.  Is this because aC++ (if that's what it's called) has some
gcc-like mode that it's using?  If so, any way to turn that off?

A
From dba at richyen.com  Tue Apr 15 14:33:19 2008
From: dba at richyen.com (Richard Yen)
Date: Tue Apr 15 14:33:32 2008
Subject: [Slony1-general] dual-purpose subscriptions?
Message-ID: <ACABF865-8FE4-4005-846D-297FD0F73910@richyen.com>

Hi,

Wondering if anyone has ever attempted this...

Is it possible for node B to subscribe table X from node A on set 2  
(new set), then turn around and have node B provide table X to nodes C  
and D on set 1 (existing set)?

I suppose it's easier for nodes C and D to subscribe to node A on set  
1, but if we could do it the above method, I'd believe there would be  
less network traffic

Thanks for any comments/suggestions!
--Richard
From cbbrowne at ca.afilias.info  Tue Apr 15 14:53:11 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Apr 15 14:53:24 2008
Subject: [Slony1-general] dual-purpose subscriptions?
In-Reply-To: <ACABF865-8FE4-4005-846D-297FD0F73910@richyen.com> (Richard Yen's
	message of "Tue, 15 Apr 2008 14:33:19 -0700")
References: <ACABF865-8FE4-4005-846D-297FD0F73910@richyen.com>
Message-ID: <60fxtmvl88.fsf@dba2.int.libertyrms.com>

Richard Yen <dba@richyen.com> writes:
> Wondering if anyone has ever attempted this...
>
> Is it possible for node B to subscribe table X from node A on set 2
> (new set), then turn around and have node B provide table X to nodes C
> and D on set 1 (existing set)?
>
> I suppose it's easier for nodes C and D to subscribe to node A on set
> 1, but if we could do it the above method, I'd believe there would be
> less network traffic
>
> Thanks for any comments/suggestions!

In principle, something like this would be at least conceivable, as
what is stored in the log tables is not the set ID, but rather the
origin node, so if we somehow tied this table + origin to a different
set on the different nodes, what you describe would be at least sort
of possible.

However, the association of tables to sets is done on a cluster-wide
basis, and it would be a rather big design change to decouple that.

I'm curious as to why you expect there to be less network traffic.  It
seems to me that the main traffic would come from query application,
and I don't see any reason for the change you are suggesting to cut
down on that.

The *possible* change would be for there to be less network traffic as
a result of fewer events propagating, but I don't see that changing
network traffic particularly materially.
-- 
let name="cbbrowne" and tld="cbbrowne.com" in name ^ "@" ^ tld;;
http://cbbrowne.com/info/nonrdbms.html
Rules of  the Evil Overlord  #210. "All guest-quarters will  be bugged
and monitored so that I can keep track of what the visitors I have for
some reason allowed to roam  about my fortress are actually plotting."
<http://www.eviloverlord.com/>
From dba at richyen.com  Tue Apr 15 15:06:27 2008
From: dba at richyen.com (Richard Yen)
Date: Tue Apr 15 15:06:41 2008
Subject: [Slony1-general] dual-purpose subscriptions?
In-Reply-To: <60fxtmvl88.fsf@dba2.int.libertyrms.com>
References: <ACABF865-8FE4-4005-846D-297FD0F73910@richyen.com>
	<60fxtmvl88.fsf@dba2.int.libertyrms.com>
Message-ID: <F7E0F53E-D78D-4872-A457-1A58BFFB36AF@richyen.com>

>
> I'm curious as to why you expect there to be less network traffic.  It
> seems to me that the main traffic would come from query application,
> and I don't see any reason for the change you are suggesting to cut
> down on that.
>
Well, the way we've got this set up is table X has copies of itself on  
three clusters.  So among the three clusters, there's already network  
connections open to each of their respective nodes.  The new thing we  
want to do is to create a "master copy" of table X, so that we can  
just update once, and the changes would propagate to the three other  
clusters.  If each node in each cluster were to create a new network  
connection to this "master copy" node, that would increase network  
traffic; if we just left it to the providers on each cluster to  
propagate to its subscribers, we'd use existing network connections,  
and it would possibly be cleaner.  Hence, the desire for the table to  
subscribe via one setID, and provide via another setID.

> The *possible* change would be for there to be less network traffic as
> a result of fewer events propagating, but I don't see that changing
> network traffic particularly materially.
True.  In terms of net bytes transferred, there's no difference.  I  
suppose it's just the thought of more network connections that  
initially raises flags.

--Richard
From pgsql at bluepolka.net  Tue Apr 15 19:27:14 2008
From: pgsql at bluepolka.net (Ed L.)
Date: Tue Apr 15 19:27:08 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <200804151230.49563.pgsql@bluepolka.net>
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	<6063us1b6x.fsf@dba2.int.libertyrms.com>
	<200804151230.49563.pgsql@bluepolka.net>
Message-ID: <200804152027.14938.pgsql@bluepolka.net>

On Tue Apr 15 13:19:37 PDT 2008, Andrew Sullivan wrote: 
>> $ /opt/ansic/bin/cc -V
>> cc: HP aC++/ANSI C B3910B A.06.05 [Jul 25 2005]
>[. . .]
>> checking for gcc... /opt/ansic/bin/cc
>
>It usually gives me heartburn when gcc tests find some non-gcc 
>compiler and think it's gcc.  Is this because aC++ (if that's 
>what it's called) has some gcc-like mode that it's using?  If 
>so, any way to turn that off?   

I have no idea, not sure how to find out.  There are flags to turn 
*on* gcc compatibility, but I'm not using them and that line 
comes from within configure.  Where else would I look?

Other ideas?

Ed
From pgsql at bluepolka.net  Tue Apr 15 19:37:49 2008
From: pgsql at bluepolka.net (Ed L.)
Date: Tue Apr 15 19:37:45 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <200804152027.14938.pgsql@bluepolka.net>
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	<200804151230.49563.pgsql@bluepolka.net>
	<200804152027.14938.pgsql@bluepolka.net>
Message-ID: <200804152037.49446.pgsql@bluepolka.net>


On Tuesday 04/15/08 @ 8:27 pm MDT, I received this from "Ed L." 
<pgsql@bluepolka.net>:
> On Tue Apr 15 13:19:37 PDT 2008, Andrew Sullivan wrote:
> >> $ /opt/ansic/bin/cc -V
> >> cc: HP aC++/ANSI C B3910B A.06.05 [Jul 25 2005]
> >
> >[. . .]
> >
> >> checking for gcc... /opt/ansic/bin/cc
> >
> >It usually gives me heartburn when gcc tests find some
> > non-gcc compiler and think it's gcc.  Is this because aC++
> > (if that's what it's called) has some gcc-like mode that
> > it's using?  If so, any way to turn that off?
>
> I have no idea, not sure how to find out.  There are flags to
> turn *on* gcc compatibility, but I'm not using them and that
> line comes from within configure.  Where else would I look?

Your question makes me wonder if the gcc check is necessary since 
my old Pg 8.1.2 configure.log shows that, using the same 
compiler+flags, there's no obvious check for gcc like the one 
above (and it builds correctly):

checking build system type... ia64-hp-hpux11.23
checking host system type... ia64-hp-hpux11.23
checking which template to use... hpux
checking whether to build with 64-bit integer date/time 
support... no
checking whether NLS is wanted... no
checking for default port number... 5432
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables... 
checking for suffix of object files... o
checking whether we are using the GNU C compiler... no
checking whether cc accepts -g... yes
checking for cc option to accept ANSI C... none needed
configure: using CFLAGS=+DD64
checking whether the C compiler still works... yes
checking how to run the C preprocessor... cc -Ae -E

From james at africonnect.co.zm  Wed Apr 16 04:10:56 2008
From: james at africonnect.co.zm (James T Mugauri)
Date: Wed Apr 16 04:11:43 2008
Subject: [Slony1-general] replication for distributed authentication
Message-ID: <4805DEC0.4090901@africonnect.co.zm>

Hi, all

Hope this is the right forum for this. I have recently installed Slony 
1.2.13 on Postgres 8.3.1 for CentOS5. I work for an ISP with Wi-Max 
presence in several areas in an African country. We are trying to 
implement centralised customer billing and relationship management while 
enabling each geographic area to have independence in terms of 
Authorization and Authentication of customer devices... These latter 
functions are carried out by a Motorola-developed application running on 
a Postgres database.

This interfaces with the CRM and billing application on one hand for 
authentication et al, and Wi-Max base stations for Accounting on the 
other hand.. Obviously, with 3 (and soon more) areas in operation, these 
have to all syncronise the accounting data with the head office database 
(one of the 3) while sourcing Authentication and Authorisation details 
from the same head office 'mothership'.

This suggests to me that while i can have all 3 in the same replication 
set for the purposes of authentication/authorisation, I have to set up 
separate replication sets for accounting data as follows:

1. Each satellite is the master node of a replication set with the head 
office where, crucially
2. The head office also allows local updates to itself

Would this work without undue fuss, or do i have to find a more 
intricate solution (e.g. creating a 4th database which will be slave to 
all and master of the master, so to speak?)

Hope for some pointers from y'all.. I'm sure someone's done this before

Regards,

James T Mugauri

-- 
Systems Development Engineer
AfriConnect (Zambia) Limited
+260 (977) 77 1447
+260 (211) 23 2005
+260 (977) 69 6889

In every work of genius we recognize our own rejected thoughts; they come back to us with a certain alienated majesty.
  - Ralph Waldo Emerson

From ajs at crankycanuck.ca  Wed Apr 16 05:36:41 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Wed Apr 16 05:36:49 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <200804152037.49446.pgsql@bluepolka.net>
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	<200804151230.49563.pgsql@bluepolka.net>
	<200804152027.14938.pgsql@bluepolka.net>
	<200804152037.49446.pgsql@bluepolka.net>
Message-ID: <20080416123641.GB30171@crankycanuck.ca>

On Tue, Apr 15, 2008 at 08:37:49PM -0600, Ed L. wrote:
> Your question makes me wonder if the gcc check is necessary since 
> my old Pg 8.1.2 configure.log shows that, using the same 
> compiler+flags, there's no obvious check for gcc like the one 
> above (and it builds correctly):

But Tom Lane has an HP-UX system in his house (he used to write device
drivers for HP-UX), so we have a reason to believe that builds are actually
tested on HP-UX.  I am unaware of any Slony developer who tests on HP-UX (I
could be wrong, but it'd be nice to hear otherwise right about now).

Part of the reason I'm bothered is because of the opacity of the error you
get.  You seem to be getting an error with no reason.  It's gonna be pretty
hard to troubleshoot it without access to an HP-UX system.

A

From cbbrowne at ca.afilias.info  Wed Apr 16 08:22:57 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Apr 16 08:23:04 2008
Subject: [Slony1-general] dual-purpose subscriptions?
In-Reply-To: <F7E0F53E-D78D-4872-A457-1A58BFFB36AF@richyen.com> (Richard Yen's
	message of "Tue, 15 Apr 2008 15:06:27 -0700")
References: <ACABF865-8FE4-4005-846D-297FD0F73910@richyen.com>
	<60fxtmvl88.fsf@dba2.int.libertyrms.com>
	<F7E0F53E-D78D-4872-A457-1A58BFFB36AF@richyen.com>
Message-ID: <603aplvn72.fsf@dba2.int.libertyrms.com>

Richard Yen <dba@richyen.com> writes:
>> I'm curious as to why you expect there to be less network traffic.  It
>> seems to me that the main traffic would come from query application,
>> and I don't see any reason for the change you are suggesting to cut
>> down on that.
>>
> Well, the way we've got this set up is table X has copies of itself on
> three clusters.  So among the three clusters, there's already network
> connections open to each of their respective nodes.  The new thing we
> want to do is to create a "master copy" of table X, so that we can
> just update once, and the changes would propagate to the three other
> clusters.  If each node in each cluster were to create a new network
> connection to this "master copy" node, that would increase network
> traffic; if we just left it to the providers on each cluster to
> propagate to its subscribers, we'd use existing network connections,
> and it would possibly be cleaner.  Hence, the desire for the table to
> subscribe via one setID, and provide via another setID.
>
>> The *possible* change would be for there to be less network traffic as
>> a result of fewer events propagating, but I don't see that changing
>> network traffic particularly materially.
> True.  In terms of net bytes transferred, there's no difference.  I
> suppose it's just the thought of more network connections that
> initially raises flags.

Idle thinking...  If you separate that table into its own set, you
ought to be able to set up whatever cascading you want, and that
should allow minimizing the amount of traffic...

I notice you indicate three clusters.  By that, do you mean that you
have 3 Slony-I clusters?  That is, 3 separate cluster names, each with
its own set of nodes and such?  That's not going to "share" terribly
well, because the design of things is for those clusters to be
essentially unable to perceive one another.

If you do indeed mean 3 clusters, then the way I'd expect to need to
do this is to create a 4th cluster for propagation of this table.
That unfortunately means extra slons, extra connections, and such.
-- 
let name="cbbrowne" and tld="linuxfinances.info" in name ^ "@" ^ tld;;
http://cbbrowne.com/info/sgml.html
Rules of the Evil Overlord #56.  "My Legions of Terror will be trained
in basic marksmanship. Any who  cannot learn to hit a man-sized target
at 10 meters will be used for target practice."
<http://www.eviloverlord.com/>
From pgsql at bluepolka.net  Wed Apr 16 08:25:06 2008
From: pgsql at bluepolka.net (Ed L.)
Date: Wed Apr 16 08:24:48 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <20080416123641.GB30171@crankycanuck.ca>
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	<200804152037.49446.pgsql@bluepolka.net>
	<20080416123641.GB30171@crankycanuck.ca>
Message-ID: <200804160925.06809.pgsql@bluepolka.net>

On Wednesday 04/16/08 @ 6:36 am MDT, I received this from Andrew 
Sullivan <ajs@crankycanuck.ca>:
> On Tue, Apr 15, 2008 at 08:37:49PM -0600, Ed L. wrote:
> > Your question makes me wonder if the gcc check is necessary
> > since my old Pg 8.1.2 configure.log shows that, using the
> > same compiler+flags, there's no obvious check for gcc like
> > the one above (and it builds correctly):
>
> Part of the reason I'm bothered is because of the opacity of
> the error you get.  You seem to be getting an error with no
> reason.  It's gonna be pretty hard to troubleshoot it without
> access to an HP-UX system.

Unfortunately I can't help you with access.  But I can try 
suggestions.  Is there a way to turn up the debug volume on make 
ala 'sh -v script.sh'?

Building with gcc (and CFLAGS="-mlp64" LDFLAGS="-mlp64) results 
in the exact same error output.  If I built pg with ANSI C 
compiler using "+DD64", is there any dependency requiring me to 
build slony with the same compiler since it links with pg's 
libs?  Or should their end results be compatible due to same 
architecture?

Other ideas to try?

Ed
From cbbrowne at ca.afilias.info  Wed Apr 16 08:49:18 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Apr 16 08:49:26 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <200804160925.06809.pgsql@bluepolka.net> (Ed L.'s message of "Wed,
	16 Apr 2008 09:25:06 -0600")
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	<200804152037.49446.pgsql@bluepolka.net>
	<20080416123641.GB30171@crankycanuck.ca>
	<200804160925.06809.pgsql@bluepolka.net>
Message-ID: <60tzi1u7ep.fsf@dba2.int.libertyrms.com>

"Ed L." <pgsql@bluepolka.net> writes:
> Building with gcc (and CFLAGS="-mlp64" LDFLAGS="-mlp64) results 
> in the exact same error output.  If I built pg with ANSI C 
> compiler using "+DD64", is there any dependency requiring me to 
> build slony with the same compiler since it links with pg's 
> libs?  Or should their end results be compatible due to same 
> architecture?

Vendors (and GCC porters) try pretty hard, often with reasonable
success, to have binary interoperability between C compilers.  

We can often use AIX libraries built using IBM's VisualAge C with
programs compiled using GCC.

The same is usually *not* true for C++; there's usually enough gross
name mangling behind the scenes that tends to vary based on compiler
strategy that linking programs compiled with one C++ compiler against
libs compiled with another often doesn't work.  (Indeed, it often
doesn't work if the two compilers are varying versions of G++...)

All that being said, I'd really want to use the same compiler to build
Slony-I that I used to build PostgreSQL, particularly if the
difference looked like it might be causing problems.
-- 
(format nil "~S@~S" "cbbrowne" "cbbrowne.com")
http://linuxfinances.info/info/linuxxian.html
They have finally found the most ultimately useless thing on the web...
Found at the Victoria's Secret website:
   "The online shop: Text Only Listing"
From ajs at crankycanuck.ca  Wed Apr 16 09:06:59 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Wed Apr 16 09:07:11 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <200804160925.06809.pgsql@bluepolka.net>
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	<200804152037.49446.pgsql@bluepolka.net>
	<20080416123641.GB30171@crankycanuck.ca>
	<200804160925.06809.pgsql@bluepolka.net>
Message-ID: <20080416160659.GD30171@crankycanuck.ca>

On Wed, Apr 16, 2008 at 09:25:06AM -0600, Ed L. wrote:
> Building with gcc (and CFLAGS="-mlp64" LDFLAGS="-mlp64) results 
> in the exact same error output.  If I built pg with ANSI C 
> compiler using "+DD64", is there any dependency requiring me to 
> build slony with the same compiler since it links with pg's 
> libs?  Or should their end results be compatible due to same 
> architecture?

If you remove +DD64, does it help?  (Without an ERROR that at least tells us
what it's trying to do, this is going to be a very frustrating experience.)

There's a -d flag to make.  I don't know whether it will help in this case,
but it's worth a try.  (IIRC, you're definitely using gmake, and not
something pretending to be GNU make, right?  That's important.)

A

From dane at greatschools.net  Wed Apr 16 10:15:28 2008
From: dane at greatschools.net (Dane Miller)
Date: Wed Apr 16 10:15:47 2008
Subject: [Slony1-general] replication for distributed authentication
In-Reply-To: <4805DEC0.4090901@africonnect.co.zm>
References: <4805DEC0.4090901@africonnect.co.zm>
Message-ID: <1208366128.23805.39.camel@danespc.home>

Hi James,
  I'm definitely not the Slony expert of this list, but I'm pretty
confused by your description.  Could you try simplifying it and making
it more generic?  It's hard to parse, but I tried.  See below.

James T Mugauri wrote:
> We are trying to implement centralised customer billing and
> relationship management while enabling each geographic area to have
> independence in terms of Authorization and Authentication of customer
> devices... These latter functions are carried out by a
> Motorola-developed application running on a Postgres database.

To clarify, "these latter functions" refer to auth?  So you want
separate geographic locations to have their own auth data.  Each
location has a Motorola application that uses this auth data.  Is that
right?

> This interfaces with the CRM and billing application on one hand for 
> authentication et al, and Wi-Max base stations for Accounting on the 
> other hand.. 

So is "This" the Postgresql database?  It sounds like each geographic
location has several applications that connect to a database.  The CRM
app and the Billing app use Postgresql for auth data (usernames,
passwords, etc).  The Wi-Max base stations (aka Motorola app?) use
Postgresql to store accounting data.  Is this right?

> Obviously, with 3 (and soon more) areas in operation, these have to
> all syncronise the accounting data with the head office database (one
> of the 3) while sourcing Authentication and Authorisation details from
> the same head office 'mothership'.

Warning bells sound when I see 'synchronize'.  It sounds like each of
your geographic locations must write auth data and accounting data to
the location's local postgresql database.  And you want some mechanism
to synchronize each location's local database with every other location?

> This suggests to me that while i can have all 3 in the same
> replication set for the purposes of authentication/authorisation, I
> have to set up separate replication sets for accounting data as
> follows:
> 
> 1. Each satellite is the master node of a replication set with the
> head office where, crucially
> 2. The head office also allows local updates to itself

I don't think I can answer these until I get clarification on my
questions above.  But it's important that you remember what kind of
replication Slony provides:  asynchronous master->slave replication.
Writes to any replicated table can happen only on the "master" aka
"origin" aka "provider" node.

Dane
---
Dane Miller
Systems Administrator
Greatschools.net
http://www.greatschools.net

From james at africonnect.co.zm  Wed Apr 16 11:55:11 2008
From: james at africonnect.co.zm (James T Mugauri)
Date: Wed Apr 16 11:55:32 2008
Subject: [Slony1-general] replication for distributed authentication
In-Reply-To: <1208366128.23805.39.camel@danespc.home>
References: <4805DEC0.4090901@africonnect.co.zm>
	<1208366128.23805.39.camel@danespc.home>
Message-ID: <48064B8F.8070403@africonnect.co.zm>


On 04/16/2008 07:15 PM, Dane Miller wrote:
> Hi James,
>   I'm definitely not the Slony expert of this list, but I'm pretty
> confused by your description.  Could you try simplifying it and making
> it more generic?  It's hard to parse, but I tried.  See below.
>   =

sorry, man.. something of mine got in the way of me..... :)
> James T Mugauri wrote:
>   =

>> We are trying to implement centralised customer billing and
>> relationship management while enabling each geographic area to have
>> independence in terms of Authorization acrmnd Authentication of customer
>> devices... These latter functions are carried out by a
>> Motorola-developed application running on a Postgres database.
>>     =

>
> To clarify, "these latter functions" refer to auth?  So you want
> separate geographic locations to have their own auth data.  Each
> location has a Motorola application that uses this auth data.  Is that
> right?
>   =

There are 2 main databases, both running postgres... billing and client =

relations, which needs no replication, then auth n acc which relies on =

the billing/crm and should be replicated (for better availability, =

robustness et al)..

Auth and acc information should also be 'aggregated' in real time since =

subscription is based on both speed and usage.
> It sounds like each of your geographic locations must write auth data and=
 accounting data to
> the location's local postgresql database.  =

yes, invariably
> And you want some mechanism
> to synchronize each location's local database with every other location?
>
>   =

yes... is this, frankly, better achieved with cronjobs?
> Dane
>   =

thanks for this response, Dane... Looking forward to your next...
> ---
> Dane Miller
> Systems Administrator
> Greatschools.net
> http://www.greatschools.net
>
>   =

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080416/=
c0b30066/attachment.htm
From cbbrowne at ca.afilias.info  Wed Apr 16 12:41:49 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Apr 16 12:42:01 2008
Subject: [Slony1-general] pgindent run planned on CVS HEAD
Message-ID: <601w55twn6.fsf@dba2.int.libertyrms.com>

We have had people editing the code with varying sets of editor
configuration for quite a while now, which has had the result that the
code has diverged away from the "PostgreSQL style" by quite a bit.
(I daresay I'm one of the offenders on this!)

It seems preferable to announce a forthcoming pgindent run so that if
anyone has outstanding work on -HEAD, there is either:

a) a chance to object, or
b) a chance to commit those changes, or
c) well, there isn't really a c) :-)

I'll plan to do this run next Wednesday, on April 23rd.

If you have big patches outstanding, be aware :-).
-- 
let name="cbbrowne" and tld="linuxfinances.info" in String.concat "@" [name;tld];;
http://cbbrowne.com/info/slony.html
"If you were plowing a field, which  would you rather use?  Two strong
oxen or 1024 chickens?"  -- Seymour Cray
From pgsql at bluepolka.net  Wed Apr 16 16:47:38 2008
From: pgsql at bluepolka.net (Ed L.)
Date: Wed Apr 16 16:47:30 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <200804161742.09972.pgsql@bluepolka.net>
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	<20080416160659.GD30171@crankycanuck.ca>
	<200804161742.09972.pgsql@bluepolka.net>
Message-ID: <200804161747.38656.pgsql@bluepolka.net>

T24gV2VkbmVzZGF5IDA0LzE2LzA4IEAgNTo0MiBwbSBNRFQsIEkgcmVjZWl2ZWQgdGhpcyBmcm9t
ICJFZCBMLiIgCjxwZ3NxbEBibHVlcG9sa2EubmV0PjoKPiBPbiBXZWRuZXNkYXkgMDQvMTYvMDgg
QCAxMDowNiBhbSBNRFQsIEkgcmVjZWl2ZWQgdGhpcyBmcm9tCj4gQW5kcmV3Cj4KPiBTdWxsaXZh
biA8YWpzQGNyYW5reWNhbnVjay5jYT46Cj4gPiBJZiB5b3UgcmVtb3ZlICtERDY0LCBkb2VzIGl0
IGhlbHA/ICAoV2l0aG91dCBhbiBFUlJPUiB0aGF0Cj4gPiBhdCBsZWFzdCB0ZWxscyB1cyB3aGF0
IGl0J3MgdHJ5aW5nIHRvIGRvLCB0aGlzIGlzIGdvaW5nIHRvCj4gPiBiZSBhIHZlcnkgZnJ1c3Ry
YXRpbmcgZXhwZXJpZW5jZS4pCj4gPgo+ID4gVGhlcmUncyBhIC1kIGZsYWcgdG8gbWFrZS4gIEkg
ZG9uJ3Qga25vdyB3aGV0aGVyIGl0IHdpbGwKPiA+IGhlbHAgaW4gdGhpcyBjYXNlLCBidXQgaXQn
cyB3b3J0aCBhIHRyeS4gIChJSVJDLCB5b3UncmUKPiA+IGRlZmluaXRlbHkgdXNpbmcgZ21ha2Us
IGFuZCBub3Qgc29tZXRoaW5nIHByZXRlbmRpbmcgdG8gYmUKPiA+IEdOVSBtYWtlLCByaWdodD8g
IFRoYXQncyBpbXBvcnRhbnQuKQo+Cj4gUmVtb3ZpbmcgREQ2NCAoYW5kIGxpbmtpbmcgYWdhaW5z
dCAzMi1iaXQgUGdzcWwpIG1ha2VzIG5vCj4gZGlmZmVyZW5jZSwgc3RpbGwgdGhlIHNhbWUgZXJy
b3IuICBCdXQgdGhlIG1ha2UgLWQgb3V0cHV0IG1heQo+IHBlcmhhcHMgbW9yZSBpbmZvcm1hdGl2
ZS4gIEkndmUgYXR0YWNoZWQgaXQuCgpQcmV2aW91cyBhdHRhY2htZW50IHdhcyB0b28gYmlnLiAg
SGVyZSdzIGEgdHJpbW1lZCB2ZXJzaW9uIGZvciAKdGhlIGxpc3QuCgpFZAoKCi0tLS0tLS0tLS0t
LS0tIG5leHQgcGFydCAtLS0tLS0tLS0tLS0tLQpBIG5vbi10ZXh0IGF0dGFjaG1lbnQgd2FzIHNj
cnViYmVkLi4uCk5hbWU6IGJ1aWxkLmxvZwpUeXBlOiB0ZXh0L3gtbG9nClNpemU6IDE5MjgyIGJ5
dGVzCkRlc2M6IG5vdCBhdmFpbGFibGUKVXJsIDogaHR0cDovL2xpc3RzLnNsb255LmluZm8vcGlw
ZXJtYWlsL3Nsb255MS1nZW5lcmFsL2F0dGFjaG1lbnRzLzIwMDgwNDE2LzNkZjAwODJlL2J1aWxk
LmJpbgo=
From pgsql at bluepolka.net  Wed Apr 16 16:55:00 2008
From: pgsql at bluepolka.net (Ed L.)
Date: Wed Apr 16 16:54:53 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <20080416160659.GD30171@crankycanuck.ca>
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	<200804160925.06809.pgsql@bluepolka.net>
	<20080416160659.GD30171@crankycanuck.ca>
Message-ID: <200804161755.00855.pgsql@bluepolka.net>

On Wednesday 04/16/08 @ 10:06 am MDT, I received this from Andrew 
Sullivan <ajs@crankycanuck.ca>:
> (IIRC, you're definitely
> using gmake, and not something pretending to be GNU make,
> right? ?That's important.)

$ /bin/gmake -v
GNU Make 3.80
Copyright (C) 2002  Free Software Foundation, Inc.
This is free software; see the source for copying conditions.
There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR 
A PARTICULAR PURPOSE.
From pgsql at bluepolka.net  Wed Apr 16 16:56:18 2008
From: pgsql at bluepolka.net (Ed L.)
Date: Wed Apr 16 16:56:08 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <200804161755.00855.pgsql@bluepolka.net>
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	<20080416160659.GD30171@crankycanuck.ca>
	<200804161755.00855.pgsql@bluepolka.net>
Message-ID: <200804161756.18321.pgsql@bluepolka.net>

On Wednesday 04/16/08 @ 5:55 pm MDT, I received this from "Ed L." 
<pgsql@bluepolka.net>:
> On Wednesday 04/16/08 @ 10:06 am MDT, I received this from
> Andrew
>
> Sullivan <ajs@crankycanuck.ca>:
> > (IIRC, you're definitely
> > using gmake, and not something pretending to be GNU make,
> > right? ?That's important.)
>
> $ /bin/gmake -v
> GNU Make 3.80
> Copyright (C) 2002  Free Software Foundation, Inc.
> This is free software; see the source for copying conditions.
> There is NO warranty; not even for MERCHANTABILITY or FITNESS
> FOR A PARTICULAR PURPOSE.

That's really /usr/local/bin/gmake... I snipped the first part of 
the path accidentally while pasting.
From ajs at crankycanuck.ca  Wed Apr 16 20:37:45 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Wed Apr 16 20:38:20 2008
Subject: [Slony1-general] Slony 1.2.x on HP-UX 11.23 IA-64
In-Reply-To: <200804161747.38656.pgsql@bluepolka.net>
References: <9A94DD30EF16234995D0A3DE9983C840015D2AD7@sleepy.opushealthcare.com>
	<20080416160659.GD30171@crankycanuck.ca>
	<200804161742.09972.pgsql@bluepolka.net>
	<200804161747.38656.pgsql@bluepolka.net>
Message-ID: <20080417033745.GC1226@crankycanuck.ca>

On Wed, Apr 16, 2008 at 05:47:38PM -0600, Ed L. wrote:
> 
> Previous attachment was too big.  Here's a trimmed version for 
> the list.

Hrm.  I can't remember whether there's some way not to make the logshipper
code.  A very cursory glance here suggests to me it might be part of the
problem.

Also, I don't suppose there's any possibility of problems in the bison or
flex toolchains -- more than one installation, &c?  

Note that I'm really pretty much feeling in the dark here.  I certainly have
no clue what the problem is.

A


From james at africonnect.co.zm  Thu Apr 17 08:02:21 2008
From: james at africonnect.co.zm (James T Mugauri)
Date: Thu Apr 17 08:02:38 2008
Subject: [Slony1-general] ERROR:  invalid input syntax for type timestamp
In-Reply-To: <20080416235610.97B64290179@main.slony.info>
References: <20080416235610.97B64290179@main.slony.info>
Message-ID: <4807667D.6060708@africonnect.co.zm>

Hi,

Any idea how to solve the following problem when initialising the cluster?

JamesTM

From salmanb at quietcaresystems.com  Thu Apr 17 08:54:48 2008
From: salmanb at quietcaresystems.com (salman)
Date: Thu Apr 17 08:54:57 2008
Subject: [Slony1-general] Deleting from log tables
Message-ID: <480772C8.2060801@quietcaresystems.com>

Hello,

At some point last night, a few of our scripts went haywire and 
generated an enormous amount of bogus data. Due to this, slony fell 
behind and now there are 13 million+ rows in the sl_log_2 table.

I would like to remove the bogus data that was inserted into the log 
table and have come up with a query which should do that. If I stop the 
slon daemons, run this query, and then restart the services, will slony 
care about the missing records due to the jump in seq numbers?

Is there any other table that I should update as well?
From cbbrowne at ca.afilias.info  Thu Apr 17 08:58:18 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Apr 17 08:58:35 2008
Subject: [Slony1-general] ERROR:  invalid input syntax for type timestamp
In-Reply-To: <4807667D.6060708@africonnect.co.zm> (James T. Mugauri's message
	of "Thu, 17 Apr 2008 17:02:21 +0200")
References: <20080416235610.97B64290179@main.slony.info>
	<4807667D.6060708@africonnect.co.zm>
Message-ID: <60hce0scbp.fsf@dba2.int.libertyrms.com>

James T Mugauri <james@africonnect.co.zm> writes:
> Any idea how to solve the following problem when initialising the cluster?
>
> JamesTM

How your name is spelled doesn't seem like a solvable problem ;-).
(If you've got a problem with it, I have no suggestions!)

But seriously, seems your problem is thus, that something is reporting:

    ERROR:  invalid input syntax for type timestamp

You have evidently set your timezone to something that PostgreSQL does
not recognize.

This issue is documented in the "Best Practices" portion of the admin
guide:

   http://linuxdatabases.info/info/bestpractices.html

"Principle: Use an unambiguous, stable time zone such as UTC or GMT.

Users have run into problems with slon(1) functioning properly when
their system uses a time zone that PostgreSQL was unable to recognize
such as CUT0 or WST. It is necessary that you use a timezone that
PostgreSQL can recognize correctly. It is furthermore preferable to
use a time zone where times do not shift around due to Daylight
Savings Time.

The "geographically unbiased" choice seems to be TZ=UTC or TZ=GMT, and
to make sure that systems are "in sync" by using NTP to synchronize
clocks throughout the environment.

See also Section 3.4.
[http://linuxfinances.info/info/requirements.html#TIMES]"

Hope that helps!
-- 
"cbbrowne","@","acm.org"
http://linuxdatabases.info/info/slony.html
No one ever says, "Hey, I can't read that ASCII attachment you sent
me."
From cbbrowne at ca.afilias.info  Thu Apr 17 10:08:27 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Apr 17 10:08:44 2008
Subject: [Slony1-general] Deleting from log tables
In-Reply-To: <480772C8.2060801@quietcaresystems.com> (salman's message of "Thu,
	17 Apr 2008 11:54:48 -0400")
References: <480772C8.2060801@quietcaresystems.com>
Message-ID: <608wzcs92s.fsf@dba2.int.libertyrms.com>

salman <salmanb@quietcaresystems.com> writes:
> At some point last night, a few of our scripts went haywire and
> generated an enormous amount of bogus data. Due to this, slony fell
> behind and now there are 13 million+ rows in the sl_log_2 table.
>
> I would like to remove the bogus data that was inserted into the log
> table and have come up with a query which should do that. If I stop
> the slon daemons, run this query, and then restart the services, will
> slony care about the missing records due to the jump in seq numbers?
>
> Is there any other table that I should update as well?

If you delete the "bogus" rows from sl_log_2, then, when the
corresponding SYNC goes looking for rows to apply, it simply won't
find them.

Deletion of data from the log tables definitely *is* "rocket surgery;"
you need to be quite careful to identify the updates that you don't
want replicated.  But if you're sure you have the right ones, there
isn't anything much to worry about in the other tables.

The thing I'd be worried about is that by having 13M updates committed
on the origin, I imagine there might be some rather huge difference
between the data in the source tables on the origin and the
equivalents on the other nodes.  You might be forcing there to be a
huge variation between origin and other nodes...

Or did the changes cancel each other out?
-- 
output = ("cbbrowne" "@" "acm.org")
http://www3.sympatico.ca/cbbrowne/spreadsheets.html
"Computers in the future may weigh no more than 1.5 tons".  -- POPULAR
MECHANICS magazine forecasting the "relentless march of science" 1955
From james at africonnect.co.zm  Thu Apr 17 14:34:34 2008
From: james at africonnect.co.zm (James T Mugauri)
Date: Thu Apr 17 14:34:58 2008
Subject: [Slony1-general] Re: ERROR: invalid input syntax for type timestamp
In-Reply-To: <60hce0scbp.fsf@dba2.int.libertyrms.com>
References: <20080416235610.97B64290179@main.slony.info>	<4807667D.6060708@africonnect.co.zm>
	<60hce0scbp.fsf@dba2.int.libertyrms.com>
Message-ID: <4807C26A.2020200@africonnect.co.zm>

On 04/17/2008 05:58 PM, Christopher Browne wrote:
> James T Mugauri <james@africonnect.co.zm> writes:
>   
>   
Thanks, Chris
> "Principle: Use an unambiguous, stable time zone such as UTC or GMT.
>
> It is furthermore preferable to
> use a time zone where times do not shift around due to Daylight
> Savings Time.
>
> The "geographically unbiased" choice seems to be TZ=UTC or TZ=GMT, and
> to make sure that systems are "in sync" by using NTP to synchronize
> clocks throughout the environment.
>   
I'n using Central Africa Time, which is clearly defined in 
/usr/share/pgsql/timezones (in Africa.txt) and there's no Daylight 
Savings Times here. I'm loathe to mess with the apps that rely on the db.

If I have to use GMT, where is the change effectively made (aside from 
timezone_abbreviations in postgres)?
> See also Section 3.4.
> [http://linuxfinances.info/info/requirements.html#TIMES]"
>
> Hope that helps!
>   
Thanks. It's a start
From drees76 at gmail.com  Fri Apr 18 01:29:43 2008
From: drees76 at gmail.com (David Rees)
Date: Fri Apr 18 01:30:12 2008
Subject: [Slony1-general] Re: ERROR: invalid input syntax for type
	timestamp
In-Reply-To: <4807C26A.2020200@africonnect.co.zm>
References: <20080416235610.97B64290179@main.slony.info>
	<4807667D.6060708@africonnect.co.zm>
	<60hce0scbp.fsf@dba2.int.libertyrms.com>
	<4807C26A.2020200@africonnect.co.zm>
Message-ID: <72dbd3150804180129u562edbcak4ddd0ff2f01d36fe@mail.gmail.com>

On Thu, Apr 17, 2008 at 2:34 PM, James T Mugauri
<james@africonnect.co.zm> wrote:
>  If I have to use GMT, where is the change effectively made (aside from
> timezone_abbreviations in postgres)?

Typically, you just set the TZ environment variable appropriately for
the postgres user.

-Dave
From salmanb at quietcaresystems.com  Fri Apr 18 08:07:58 2008
From: salmanb at quietcaresystems.com (salman)
Date: Fri Apr 18 08:08:06 2008
Subject: [Slony1-general] Deleting from log tables
In-Reply-To: <608wzcs92s.fsf@dba2.int.libertyrms.com>
References: <480772C8.2060801@quietcaresystems.com>
	<608wzcs92s.fsf@dba2.int.libertyrms.com>
Message-ID: <4808B94E.6090402@quietcaresystems.com>

Christopher Browne wrote:
> salman <salmanb@quietcaresystems.com> writes:
>> At some point last night, a few of our scripts went haywire and
>> generated an enormous amount of bogus data. Due to this, slony fell
>> behind and now there are 13 million+ rows in the sl_log_2 table.
>>
>> I would like to remove the bogus data that was inserted into the log
>> table and have come up with a query which should do that. If I stop
>> the slon daemons, run this query, and then restart the services, will
>> slony care about the missing records due to the jump in seq numbers?
>>
>> Is there any other table that I should update as well?
> 
> If you delete the "bogus" rows from sl_log_2, then, when the
> corresponding SYNC goes looking for rows to apply, it simply won't
> find them.
> 
> Deletion of data from the log tables definitely *is* "rocket surgery;"
> you need to be quite careful to identify the updates that you don't
> want replicated.  But if you're sure you have the right ones, there
> isn't anything much to worry about in the other tables.
> 
> The thing I'd be worried about is that by having 13M updates committed
> on the origin, I imagine there might be some rather huge difference
> between the data in the source tables on the origin and the
> equivalents on the other nodes.  You might be forcing there to be a
> huge variation between origin and other nodes...
> 
> Or did the changes cancel each other out?

Well, at the end of the day, instead of waiting for the 13M+ updates to 
sync, I opted for uninstalling slony and the reinstalling it to get the 
two machines in sync quicker; we insert a *lot* of data and catching up 
would have probably required a few days, at least. The bogus data is 
still there, but some of our other maintenance scripts will get rid of 
it all, eventually.

-salman
From dane at greatschools.net  Sat Apr 19 13:42:13 2008
From: dane at greatschools.net (Dane Miller)
Date: Sat Apr 19 13:42:48 2008
Subject: [Slony1-general] Re: Small tool to make Slony management easier
In-Reply-To: <20080412085543.a9ce1734.wmoran@collaborativefusion.com>
References: <1207952918.16726.33.camel@danespc.home>
	<20080412085543.a9ce1734.wmoran@collaborativefusion.com>
Message-ID: <1208637733.24575.31.camel@danespc.home>

On Sat, 2008-04-12 at 08:55 -0400, Bill Moran wrote:
> > > I've been putting this together over the last couple weeks for
> > > the reasons listed on the HTML page:
> > >
> http://people.collaborativefusion.com/~wmoran/PostgreSQL/slony_switchover.html
> > > 
> > > I'm interested to hear how useful this is to others, and of course
> > > suggestions for improvement are welcome.
> 
> Are you running Linux by any chance?  This script was developed and
> is deployed for us on FreeBSD, and I've verified that it works as
> advertised on that platform.  I've _attempted_ to make sure that it
> will work on Linux as well, but I've not had the opportunity to test
> it.  Testing and feedback is encouraged.

I was able to do some testing on Linux this week.  I setup three nodes
running Debian 4.0 (Etch), Postgresql 8.1, and Slony 1.2.1-1.  In the
end, I didn't succeed at moving the replication origin between nodes
using slony_switchover.sh (although slonik_move_set worked).  

I fixed the first issue I encountered (bug #3 below) by adding extra
functionality to the script. However, the problem that I got stuck on
was that sl_path didn't contain connection info between my two
subscriber nodes, node 30 and node 31.  

Here's what my sl_path table looks like:

community=# select pa_server,pa_client,pa_conninfo from sl_path ;
 pa_server | pa_client |  pa_conninfo (truncated)         
-----------+-----------+---------------------------------------
        30 |        29 | host=172.16.32.130 dbname=community 
        29 |        30 | host=172.16.32.129 dbname=community 
        29 |        31 | host=172.16.32.129 dbname=community 
        31 |        29 | host=172.16.32.131 dbname=community 
(4 rows)

Notice that there are no entries for (pa_server, pa_client) = (31, 30)
or (30, 31).  Not sure if sl_path is missing entries due to a mistake I
made in configuring replication, or perhaps a bug in the version of the
slonik_* scripts packaged for Debian 4.0.  In any case, on my FreeBSD
production machines sl_path is complete, so this isn't a blocker for my
using this in production.

Here are the bugs I found.  Only the first is Linux-specific.  Hope this
is helpful feedback.

1. absolute path to psql, line 89

psql is at /usr/bin/psql in debian

  R=`/usr/local/bin/psql -t -U $PUSER -d $DB -A -c "$1" | /usr/bin/tail
-1`

2. Comparison operator '-eq' should be '=' at line 102

JOT=`which jot`
if [ "x$JOT" -eq "x" ]  <--- 102
then
  JOT=`which seq`
fi

3. slony_switchover.sh fails when node ids don't follow the sequence 1,
2, 3, .... For example, my slons have node ids 29, 30, and 31.  As a
result, the following comparison always fails at line 109:

for I in `$JOT $NUMNODES`;
do
  if [ $ME -eq $I ]   <--- 109
  then


Dane

From dane at greatschools.net  Sat Apr 19 14:32:07 2008
From: dane at greatschools.net (Dane Miller)
Date: Sat Apr 19 14:32:29 2008
Subject: [Slony1-general] Re: database dump
Message-ID: <1208640727.24575.64.camel@danespc.home>

Christopher Browne wrote:
> Alex Haugg <haugg@...> writes:
> > i have a tiny problem,
> >
> > i need a db dump command without slony configurations (without:
> > slony_cluster, slony functions and without slony trigger).
> >
> > thanks for your answer,
> 
> If it is acceptable to do this in two parts, there are two tools that
> can be used:
> 
> 1.  tools/slony1_extract_schema.sh is a script that extracts the user
> schema for a Slony-I node in the original state with all the
> Slony-I-related "cruft" removed.
> 
> You could run that against the "master" node, and that will give you a
> suitable schema.
> 
> 2.  You could subsequently run "pg_dump --data-only" against a node
> (could be any node) and that will give you a dump of all the data.
> The dump will include Slony-I-internal "cruft", but since the schema
> doesn't have those tables, the data won't load :-)
> 
> Ideally, you would split apart the schema from #1 into two pieces:
>   - Firstly, all the CREATE TABLE DDL;
> 
>   - Then, you would load the data from #2...
> 
>   - Finally, you would run the remainder of the schema from #1, to
>     create indexes, triggers, and such like.


I've been working on putting this into use at my site.  I ran into a
problem loading the data-only dump because it contained an extra
_Slony-I_* column for my serial tables (tables without a primary key
where Slony adds its own sequence as an extra column).  The DDL
extracted using slony1_extract_schema.sh does not include this column,
so the data fails to load into these tables.

I wrote a script, deslon.pl (attached), to strip out this extra column
from serial tables.  With that in mind, here's the full procedure I'm
using to extract data from a subscriber node and load it into a new
database:

1. Extract the Schema 
Use tools/slony1_extract_schema.sh to extract the DDL from the origin
node.  Save these schema-only statements to file "schema.sql"

2. Data-Only Dump 
On the subscriber database, use pg_dump to get create a data-only file
"data.sql" that can be loaded into a skeleton database.

user@subscriber:~$ datname="mydatabase"; clustername="myclustername"
user@subscriber:~$ pg_dump -Uroot --data-only \
                      --exclude-schema="_$clustername" \
                      --disable-triggers \
                      $datname \
              > /tmp/$datname.data-only.sql

3. Clean the Dump 
Any serial tables in the database will still have slony cruft in the
dump file because Slony adds a unique sequence to non-indexed tables.
This Slony column must be removed from all serial tables in the dump
file.

The perl script deslon.pl will remove this column from all tables. 

user@anyhost:~$ ./deslon.pl "myclustername" < data-only.sql >
data-only.deslon.sql

4. Load the Schema 
Prerequisites:

      * postgresql installed
      * db created and empty
      * db roles created
      * tablespaces created

Load the table definitions and other DDL into an empty database by
applying the schema.sql file.

user@host:~$ psql -Uroot mydatname < schema.sql

5. Load the Data 

user@host:~$ psql -Uroot mydatname < data-only.deslon.sql



Hope this helps.  This would be a good wiki topic.  Is there a Slony
wiki for community documentation topics like this?

Dane
-------------- next part --------------
A non-text attachment was scrubbed...
Name: deslon.pl
Type: application/x-perl
Size: 701 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20080419/65a4ac7b/deslon.bin
From mgruetzn at HTWM.De  Sun Apr 20 02:48:37 2008
From: mgruetzn at HTWM.De (Michael Gruetzner)
Date: Sun Apr 20 02:49:06 2008
Subject: [Slony1-general] Slony Replication in wide-area applications?
Message-ID: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>

Hi,

I have to meet the challenge of creating a wide area database cluster.  
Since
I have made some good experiences with Slony-1 in the past, I'm  
wondering
if it would also work with wide-area networks. Of course, bandwidth  
and latency
are main issues but also network failures.
The Slony-1 documetation says that it might not be suitable if some  
nodes may
fail oftenly but it does not explain how slony deals with such  
failures (maybe someone
can explain this to me?).

So what I'm asking is: Does anyone have experience with Slony-1 and  
wide area
clusters?

Thank you very much in advance.

Best regards,
Michael
From wmoran at collaborativefusion.com  Sun Apr 20 09:31:56 2008
From: wmoran at collaborativefusion.com (Bill Moran)
Date: Sun Apr 20 09:32:06 2008
Subject: [Slony1-general] Slony Replication in wide-area applications?
In-Reply-To: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
References: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
Message-ID: <20080420123156.8c9bc048.wmoran@collaborativefusion.com>

Michael Gruetzner <mgruetzn@HTWM.De> wrote:
>
> Hi,
> 
> I have to meet the challenge of creating a wide area database cluster.  
> Since
> I have made some good experiences with Slony-1 in the past, I'm  
> wondering
> if it would also work with wide-area networks. Of course, bandwidth  
> and latency
> are main issues but also network failures.
> The Slony-1 documetation says that it might not be suitable if some  
> nodes may
> fail oftenly but it does not explain how slony deals with such  
> failures (maybe someone
> can explain this to me?).
> 
> So what I'm asking is: Does anyone have experience with Slony-1 and  
> wide area
> clusters?

Yes.  My opinion is that it works well for typical cases.

Network failures are a problem for a few reasons:
1) It can take Slony a bit to find it's feet again after a network failure.
   So if you have frequent failures, Slony can get into a situation where
   it can't get caught back up.
2) Slony tends to bomb the slaves with lots of bandwidth when they come
   back online after an outage.  This can (potentially) be a problem if
   your bandwidth is limited and it fills up the pipe, interfering with
   other types of traffic.
3) During an outage, Slony has to track all changes until the slave comes
   back online.  This can use up a lot of disk space pretty quickly, so
   an extended outage can be a real issue if you don't size your hardware
   to account for it.

It's a vague question with a vague answer, because whether or not it will
work for you is a combination of many factors: how much spare bandwidth
do you have?  How frequent are the outages?  How much updating is occurring?
How much update lag is acceptable in the slaves during an outage, and how
much lag to getting caught back up after an outage is acceptable?  Can you
size your disks to be large enough to backlog an outages worth of updates
while the network is down?

If you can get all those issues into a range that's acceptable for you,
then Slony will meet your needs, but there are too many questions and
too many details to be able to provide a pat answer like "yes" or "no".

-- 
Bill Moran
Collaborative Fusion Inc.

wmoran@collaborativefusion.com
Phone: 412-422-3463x4023
From mgruetzn at HTWM.De  Sun Apr 20 23:53:40 2008
From: mgruetzn at HTWM.De (Michael Gruetzner)
Date: Sun Apr 20 23:54:11 2008
Subject: [Slony1-general] Slony Replication in wide-area applications?
In-Reply-To: <20080420123156.8c9bc048.wmoran@collaborativefusion.com>
References: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
	<20080420123156.8c9bc048.wmoran@collaborativefusion.com>
Message-ID: <D003B3E8-080D-4AFD-9418-DBB4AC09E232@HTWM.De>

Hi Bill,

thank you for your detailed reply. There is yet another issue
that I need to be aware of: network partitions. Since I can't
ensure that all sites are connected directly, I belive that this
kind of failure is a possible scenario.
Do you have any idea, how Slony deals with that kind of issue?

Best regards,
Michael

On 20.04.2008, at 18:31, Bill Moran wrote:

> Michael Gruetzner <mgruetzn@HTWM.De> wrote:
>>
>> Hi,
>>
>> I have to meet the challenge of creating a wide area database  
>> cluster.
>> Since
>> I have made some good experiences with Slony-1 in the past, I'm
>> wondering
>> if it would also work with wide-area networks. Of course, bandwidth
>> and latency
>> are main issues but also network failures.
>> The Slony-1 documetation says that it might not be suitable if some
>> nodes may
>> fail oftenly but it does not explain how slony deals with such
>> failures (maybe someone
>> can explain this to me?).
>>
>> So what I'm asking is: Does anyone have experience with Slony-1 and
>> wide area
>> clusters?
>
> Yes.  My opinion is that it works well for typical cases.
>
> Network failures are a problem for a few reasons:
> 1) It can take Slony a bit to find it's feet again after a network  
> failure.
>   So if you have frequent failures, Slony can get into a situation  
> where
>   it can't get caught back up.
> 2) Slony tends to bomb the slaves with lots of bandwidth when they  
> come
>   back online after an outage.  This can (potentially) be a problem if
>   your bandwidth is limited and it fills up the pipe, interfering with
>   other types of traffic.
> 3) During an outage, Slony has to track all changes until the slave  
> comes
>   back online.  This can use up a lot of disk space pretty quickly, so
>   an extended outage can be a real issue if you don't size your  
> hardware
>   to account for it.
>
> It's a vague question with a vague answer, because whether or not it  
> will
> work for you is a combination of many factors: how much spare  
> bandwidth
> do you have?  How frequent are the outages?  How much updating is  
> occurring?
> How much update lag is acceptable in the slaves during an outage,  
> and how
> much lag to getting caught back up after an outage is acceptable?   
> Can you
> size your disks to be large enough to backlog an outages worth of  
> updates
> while the network is down?
>
> If you can get all those issues into a range that's acceptable for  
> you,
> then Slony will meet your needs, but there are too many questions and
> too many details to be able to provide a pat answer like "yes" or  
> "no".
>
> -- 
> Bill Moran
> Collaborative Fusion Inc.
>
> wmoran@collaborativefusion.com
> Phone: 412-422-3463x4023
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general

From wmoran at collaborativefusion.com  Mon Apr 21 06:05:46 2008
From: wmoran at collaborativefusion.com (Bill Moran)
Date: Mon Apr 21 06:05:46 2008
Subject: [Slony1-general] Slony Replication in wide-area applications?
In-Reply-To: <D003B3E8-080D-4AFD-9418-DBB4AC09E232@HTWM.De>
References: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
	<20080420123156.8c9bc048.wmoran@collaborativefusion.com>
	<D003B3E8-080D-4AFD-9418-DBB4AC09E232@HTWM.De>
Message-ID: <20080421090546.65a50421.wmoran@collaborativefusion.com>

In response to Michael Gruetzner <mgruetzn@HTWM.De>:

> Hi Bill,
> 
> thank you for your detailed reply. There is yet another issue
> that I need to be aware of: network partitions. Since I can't
> ensure that all sites are connected directly, I belive that this
> kind of failure is a possible scenario.
> Do you have any idea, how Slony deals with that kind of issue?

I don't understand the question.  What do you mean by "network
partition" and how does this represent a failure scenario?

> 
> Best regards,
> Michael
> 
> On 20.04.2008, at 18:31, Bill Moran wrote:
> 
> > Michael Gruetzner <mgruetzn@HTWM.De> wrote:
> >>
> >> Hi,
> >>
> >> I have to meet the challenge of creating a wide area database  
> >> cluster.
> >> Since
> >> I have made some good experiences with Slony-1 in the past, I'm
> >> wondering
> >> if it would also work with wide-area networks. Of course, bandwidth
> >> and latency
> >> are main issues but also network failures.
> >> The Slony-1 documetation says that it might not be suitable if some
> >> nodes may
> >> fail oftenly but it does not explain how slony deals with such
> >> failures (maybe someone
> >> can explain this to me?).
> >>
> >> So what I'm asking is: Does anyone have experience with Slony-1 and
> >> wide area
> >> clusters?
> >
> > Yes.  My opinion is that it works well for typical cases.
> >
> > Network failures are a problem for a few reasons:
> > 1) It can take Slony a bit to find its feet again after a network  
> > failure.
> >   So if you have frequent failures, Slony can get into a situation  
> > where
> >   it can't get caught back up.
> > 2) Slony tends to bomb the slaves with lots of bandwidth when they  
> > come
> >   back online after an outage.  This can (potentially) be a problem if
> >   your bandwidth is limited and it fills up the pipe, interfering with
> >   other types of traffic.
> > 3) During an outage, Slony has to track all changes until the slave  
> > comes
> >   back online.  This can use up a lot of disk space pretty quickly, so
> >   an extended outage can be a real issue if you don't size your  
> > hardware
> >   to account for it.
> >
> > It's a vague question with a vague answer, because whether or not it  
> > will
> > work for you is a combination of many factors: how much spare  
> > bandwidth
> > do you have?  How frequent are the outages?  How much updating is  
> > occurring?
> > How much update lag is acceptable in the slaves during an outage,  
> > and how
> > much lag to getting caught back up after an outage is acceptable?   
> > Can you
> > size your disks to be large enough to backlog an outages worth of  
> > updates
> > while the network is down?
> >
> > If you can get all those issues into a range that's acceptable for  
> > you,
> > then Slony will meet your needs, but there are too many questions and
> > too many details to be able to provide a pat answer like "yes" or  
> > "no".
> >
> > -- 
> > Bill Moran
> > Collaborative Fusion Inc.
> >
> > wmoran@collaborativefusion.com
> > Phone: 412-422-3463x4023
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general@lists.slony.info
> > http://lists.slony.info/mailman/listinfo/slony1-general
> 


-- 
Bill Moran
Collaborative Fusion Inc.
http://people.collaborativefusion.com/~wmoran/

wmoran@collaborativefusion.com
Phone: 412-422-3463x4023
From vivek at khera.org  Mon Apr 21 08:52:03 2008
From: vivek at khera.org (Vivek Khera)
Date: Mon Apr 21 08:52:10 2008
Subject: [Slony1-general] Slony Replication in wide-area applications?
In-Reply-To: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
References: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
Message-ID: <A8EC0A15-91F9-4D99-8E78-266671892707@khera.org>


On Apr 20, 2008, at 5:48 AM, Michael Gruetzner wrote:

> The Slony-1 documetation says that it might not be suitable if some  
> nodes may
> fail oftenly but it does not explain how slony deals with such  
> failures (maybe someone
> can explain this to me?).
>

Slony deals well with hosts which go offline for a bit.  The problem  
lies with the amount of change your DB has.  If you're doing millions  
of updates per day, then slony has to queue up all those changes to  
apply later.

If your WAN can handle that much data flying across, you're ok.  It  
must also be able to handle your normal volume plus any backlog  
updates that slony needs to apply.


> So what I'm asking is: Does anyone have experience with Slony-1 and  
> wide area
> clusters?

I do, but the one application that I do this for has perhaps a dozen  
insert/update/delete per day.  Having four or five day downtime is a  
total non-issue for this case.  I only do it with two nodes.
From vivek at khera.org  Mon Apr 21 08:55:13 2008
From: vivek at khera.org (Vivek Khera)
Date: Mon Apr 21 08:55:20 2008
Subject: [Slony1-general] Slony Replication in wide-area applications?
In-Reply-To: <20080421090546.65a50421.wmoran@collaborativefusion.com>
References: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
	<20080420123156.8c9bc048.wmoran@collaborativefusion.com>
	<D003B3E8-080D-4AFD-9418-DBB4AC09E232@HTWM.De>
	<20080421090546.65a50421.wmoran@collaborativefusion.com>
Message-ID: <E0807848-8FC0-49A8-9CB5-E7A637328B1E@khera.org>


On Apr 21, 2008, at 9:05 AM, Bill Moran wrote:

> I don't understand the question.  What do you mean by "network
> partition" and how does this represent a failure scenario?

Normally all hosts can see every other one. When your network is  
partitioned, you end up with at least two subsets which can still see  
every other host within that subset, bot none of the hosts in the  
other subset(s).


From wmoran at collaborativefusion.com  Mon Apr 21 09:02:33 2008
From: wmoran at collaborativefusion.com (Bill Moran)
Date: Mon Apr 21 09:02:36 2008
Subject: [Slony1-general] Slony Replication in wide-area applications?
In-Reply-To: <E0807848-8FC0-49A8-9CB5-E7A637328B1E@khera.org>
References: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
	<20080420123156.8c9bc048.wmoran@collaborativefusion.com>
	<D003B3E8-080D-4AFD-9418-DBB4AC09E232@HTWM.De>
	<20080421090546.65a50421.wmoran@collaborativefusion.com>
	<E0807848-8FC0-49A8-9CB5-E7A637328B1E@khera.org>
Message-ID: <20080421120233.4aa5b7e0.wmoran@collaborativefusion.com>

In response to Vivek Khera <vivek@khera.org>:

> 
> On Apr 21, 2008, at 9:05 AM, Bill Moran wrote:
> 
> > I don't understand the question.  What do you mean by "network
> > partition" and how does this represent a failure scenario?
> 
> Normally all hosts can see every other one. When your network is  
> partitioned, you end up with at least two subsets which can still see  
> every other host within that subset, bot none of the hosts in the  
> other subset(s).

So the answer is "yes, if your network is so thoughtlessly designed
that hosts can't reach each other, Slony won't work"

However, I suspect I'm still not understanding.  It's sounds like a
pre-meditated failure.

-- 
Bill Moran
Collaborative Fusion Inc.
http://people.collaborativefusion.com/~wmoran/

wmoran@collaborativefusion.com
Phone: 412-422-3463x4023
From cbbrowne at ca.afilias.info  Mon Apr 21 09:24:06 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Apr 21 09:24:13 2008
Subject: [Slony1-general] Slony Replication in wide-area applications?
In-Reply-To: <E0807848-8FC0-49A8-9CB5-E7A637328B1E@khera.org> (Vivek Khera's
	message of "Mon, 21 Apr 2008 11:55:13 -0400")
References: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
	<20080420123156.8c9bc048.wmoran@collaborativefusion.com>
	<D003B3E8-080D-4AFD-9418-DBB4AC09E232@HTWM.De>
	<20080421090546.65a50421.wmoran@collaborativefusion.com>
	<E0807848-8FC0-49A8-9CB5-E7A637328B1E@khera.org>
Message-ID: <60lk37npll.fsf@dba2.int.libertyrms.com>

Vivek Khera <vivek@khera.org> writes:
> On Apr 21, 2008, at 9:05 AM, Bill Moran wrote:
>
>> I don't understand the question.  What do you mean by "network
>> partition" and how does this represent a failure scenario?
>
> Normally all hosts can see every other one. When your network is
> partitioned, you end up with at least two subsets which can still see
> every other host within that subset, bot none of the hosts in the
> other subset(s).

Slony-I can work fine with network configurations where there are such
partitions where you have clusters[1] of nodes in LANs, where there is
limited communications across a WAN.

Consider:
- Nodes 1-3 are in a LAN at Data Centre A
- Nodes 4-6 are in a LAN at Data Centre B

There are constrictions...
- 1-3 can easily "talk amongst themselves."
- Likewise, 4-6 can easily "talk amongst themselves."
- However, we pick #3 and #4 as being the only nodes that are allowed
  to talk with one another across the WAN

There are configurations you cannot create, in such a case:
- You cannot have any configuration where nodes 5 or 6 subscribe directly to
  1-3; they *MUST* go thru node 4
- Likewise, you cannot have any configuration where nodes 1 or 2
  subscribe directly to 4-6; they *MUST* go thru node 3

I don't think network partitioning represents a particularly
compelling problem.

The essential WAN problems are three-fold:

- If the WAN is flakey, a frequently observed problem is that
  connections will have failed, but the database connection doesn't
  actually get dropped by the DB server until a TCP/IP timeout takes
  place, which often takes 2-3 hours.

  During that time, attempts for a slon to reconnect will be rebuffed
  because the old connection is still there, even though there is no
  way for it to be used.  This is somewhat of a moral equivalent to a
  zombie process; the old DB connection is unusable, but doesn't know
  it's dead.

  There's probably some way to automate cleaning the old connection
  out, though it's not something Slony-I could do itself, and I
  haven't tried constructing such a cleanup process.

- If the WAN is sufficiently flakey, it may be problematic to keep a
  transaction running across the WAN for long enough to get a
  subscription going.

- If the WAN is sufficiently flakey, then you may not have enough
  network bandwidth to keep a replica fed.

(Those represent three problems that are different from one another in
their essences...)

Footnotes: 
[1]  In this case, "cluster" isn't in the Slony-I sense, but rather
simply "a bunch of nodes."
-- 
(format nil "~S@~S" "cbbrowne" "cbbrowne.com")
http://linuxfinances.info/info/sgml.html
"I think you ought to know I'm feeling very depressed"
-- Marvin the Paranoid Android
From mgruetzn at HTWM.De  Mon Apr 21 09:31:23 2008
From: mgruetzn at HTWM.De (Michael Gruetzner)
Date: Mon Apr 21 09:31:34 2008
Subject: [Slony1-general] Slony Replication in wide-area applications?
In-Reply-To: <E0807848-8FC0-49A8-9CB5-E7A637328B1E@khera.org>
References: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
	<20080420123156.8c9bc048.wmoran@collaborativefusion.com>
	<D003B3E8-080D-4AFD-9418-DBB4AC09E232@HTWM.De>
	<20080421090546.65a50421.wmoran@collaborativefusion.com>
	<E0807848-8FC0-49A8-9CB5-E7A637328B1E@khera.org>
Message-ID: <C72649D0-C0E9-44AA-90EB-AB3C80ABF172@htwm.de>


On 21.04.2008, at 17:55, Vivek Khera wrote:

>
> On Apr 21, 2008, at 9:05 AM, Bill Moran wrote:
>
>> I don't understand the question.  What do you mean by "network
>> partition" and how does this represent a failure scenario?
>
> Normally all hosts can see every other one. When your network is  
> partitioned, you end up with at least two subsets which can still  
> see every other host within that subset, bot none of the hosts in  
> the other subset(s).
>
This is exactly what I was talking about. Most clustering solutions  
handle this issue by shutting down one of both
subsets. Usually there happens some kind of evaluation to determine  
which subset to shut down.

Unfortunately the Slony documentation says nothing about that kind of  
issue.

Best regards,
Michael

>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general

From vivek at khera.org  Mon Apr 21 09:36:26 2008
From: vivek at khera.org (Vivek Khera)
Date: Mon Apr 21 09:36:33 2008
Subject: [Slony1-general] Slony Replication in wide-area applications?
In-Reply-To: <C72649D0-C0E9-44AA-90EB-AB3C80ABF172@htwm.de>
References: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
	<20080420123156.8c9bc048.wmoran@collaborativefusion.com>
	<D003B3E8-080D-4AFD-9418-DBB4AC09E232@HTWM.De>
	<20080421090546.65a50421.wmoran@collaborativefusion.com>
	<E0807848-8FC0-49A8-9CB5-E7A637328B1E@khera.org>
	<C72649D0-C0E9-44AA-90EB-AB3C80ABF172@htwm.de>
Message-ID: <5BD5B648-67AA-4E5E-8CE6-BC797D6FD50D@khera.org>


On Apr 21, 2008, at 12:31 PM, Michael Gruetzner wrote:

> Unfortunately the Slony documentation says nothing about that kind  
> of issue.

This is because slony doesn't offer any solution to make such a  
determination.  It leaves the problem of detecting failed nodes and  
reacting to them to the user.  Everyone has different business needs  
and network architecture, so it is very much a custom solution.

From ajs at crankycanuck.ca  Mon Apr 21 09:51:50 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Mon Apr 21 09:52:07 2008
Subject: [Slony1-general] Re: database dump
In-Reply-To: <1208640727.24575.64.camel@danespc.home>
References: <1208640727.24575.64.camel@danespc.home>
Message-ID: <20080421165150.GA26298@crankycanuck.ca>

On Sat, Apr 19, 2008 at 02:32:07PM -0700, Dane Miller wrote:
> 
> I've been working on putting this into use at my site.  I ran into a
> problem loading the data-only dump because it contained an extra
> _Slony-I_* column for my serial tables (tables without a primary key
> where Slony adds its own sequence as an extra column).  

You need to modify your schema for real.  That feature of Slony is going
away.  It caused too much grief.

A
From dane at greatschools.net  Mon Apr 21 12:39:19 2008
From: dane at greatschools.net (Dane Miller)
Date: Mon Apr 21 12:39:40 2008
Subject: [Slony1-general] Re: database dump
In-Reply-To: <20080421165150.GA26298@crankycanuck.ca>
References: <1208640727.24575.64.camel@danespc.home>
	<20080421165150.GA26298@crankycanuck.ca>
Message-ID: <1208806759.25299.10.camel@danespc.home>

Andrew Sullivan wrote:
> You need to modify your schema for real.  That feature of Slony is
> going away.  It caused too much grief.

Thanks for the warning Andrew.  Can you point me to more info on this
issue?

Dane

From dane at greatschools.net  Mon Apr 21 13:07:04 2008
From: dane at greatschools.net (Dane Miller)
Date: Mon Apr 21 13:07:17 2008
Subject: [Slony1-general] Network Partitioning (was: Slony Replication in
	wide-area applications?)
In-Reply-To: <60lk37npll.fsf@dba2.int.libertyrms.com>
References: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
	<20080420123156.8c9bc048.wmoran@collaborativefusion.com>
	<D003B3E8-080D-4AFD-9418-DBB4AC09E232@HTWM.De>
	<20080421090546.65a50421.wmoran@collaborativefusion.com>
	<E0807848-8FC0-49A8-9CB5-E7A637328B1E@khera.org>
	<60lk37npll.fsf@dba2.int.libertyrms.com>
Message-ID: <1208808424.25299.30.camel@danespc.home>

Christopher Browne wrote:
> Consider:
> - Nodes 1-3 are in a LAN at Data Centre A
> - Nodes 4-6 are in a LAN at Data Centre B
> 
> There are constrictions...
> - 1-3 can easily "talk amongst themselves."
> - Likewise, 4-6 can easily "talk amongst themselves."
> - However, we pick #3 and #4 as being the only nodes that are allowed
>   to talk with one another across the WAN
> 
> There are configurations you cannot create, in such a case:
> - You cannot have any configuration where nodes 5 or 6 subscribe
> directly to
>   1-3; they *MUST* go thru node 4
> - Likewise, you cannot have any configuration where nodes 1 or 2
>   subscribe directly to 4-6; they *MUST* go thru node 3 

This is similar to a setup I was managing at my site until recently.  We
gave up because, to follow this example, events from nodes 5 and 6 were
making their way to nodes 1-3.  It was easy to configure the proper
parent for each node, which determined the data path data.  But I wasn't
sure how to setup Slony replication such that there were no listen paths
between nodes 5, 6 and 1-3.

Our requirement was that nodes 1-3 were not allowed to know about or be
influenced by any events on nodes 5 and 6.  5 and 6 should communicate
only with node 4, which in turn would communicate with nodes 1-3.  Is
this possible?  Doesn't 'store path()' create listen paths between all
cluster nodes?

Dane

From ajs at crankycanuck.ca  Mon Apr 21 13:30:31 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Mon Apr 21 13:30:56 2008
Subject: [Slony1-general] Re: database dump
In-Reply-To: <1208806759.25299.10.camel@danespc.home>
References: <1208640727.24575.64.camel@danespc.home>
	<20080421165150.GA26298@crankycanuck.ca>
	<1208806759.25299.10.camel@danespc.home>
Message-ID: <20080421203031.GE27155@crankycanuck.ca>

On Mon, Apr 21, 2008 at 12:39:19PM -0700, Dane Miller wrote:
> Andrew Sullivan wrote:
> > You need to modify your schema for real.  That feature of Slony is
> > going away.  It caused too much grief.
> 
> Thanks for the warning Andrew.  Can you point me to more info on this
> issue?

If you look in the CAUTION box of
http://slony.info/documentation/stmttableaddkey.html, you'll see that it
warns you that this sort of thing is a sign that your schema needs fixing
anyway, and that there's no support for this in log shipping (and no support
is contemplated).  I thought I remembered a plan actually to rip this
functionality out, but so far I don't see that it actually has been. 
Nevertheless, it's definitely deprecated.  Having some database component
modify your schema is a good way to be surprised later.

A
From cbbrowne at ca.afilias.info  Mon Apr 21 13:46:59 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Apr 21 13:47:12 2008
Subject: [Slony1-general] Re: database dump
In-Reply-To: <20080421203031.GE27155@crankycanuck.ca> (Andrew Sullivan's
	message of "Mon, 21 Apr 2008 16:30:31 -0400")
References: <1208640727.24575.64.camel@danespc.home>
	<20080421165150.GA26298@crankycanuck.ca>
	<1208806759.25299.10.camel@danespc.home>
	<20080421203031.GE27155@crankycanuck.ca>
Message-ID: <603apfndfg.fsf@dba2.int.libertyrms.com>

Andrew Sullivan <ajs@crankycanuck.ca> writes:
> On Mon, Apr 21, 2008 at 12:39:19PM -0700, Dane Miller wrote:
>> Andrew Sullivan wrote:
>> > You need to modify your schema for real.  That feature of Slony is
>> > going away.  It caused too much grief.
>> 
>> Thanks for the warning Andrew.  Can you point me to more info on this
>> issue?
>
> If you look in the CAUTION box of
> http://slony.info/documentation/stmttableaddkey.html, you'll see
> that it warns you that this sort of thing is a sign that your schema
> needs fixing anyway, and that there's no support for this in log
> shipping (and no support is contemplated).  I thought I remembered a
> plan actually to rip this functionality out, but so far I don't see
> that it actually has been. Nevertheless, it's definitely deprecated.
> Having some database component modify your schema is a good way to
> be surprised later.

It is torn out in CVS HEAD, and has been for quite a while.

http://lists.slony.info/pipermail/slony1-commit/2007-April/001686.html
-- 
output = reverse("gro.mca" "@" "enworbbc")
http://linuxdatabases.info/info/
"If you haven't settled on your final year project, perhaps you would
like to  write a C compiler that  turns code into Turing  machines : I
don't see anything wrong with that" -- Arthur Norman
From cbbrowne at ca.afilias.info  Mon Apr 21 13:57:27 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Apr 21 13:57:40 2008
Subject: [Slony1-general] Network Partitioning
In-Reply-To: <1208808424.25299.30.camel@danespc.home> (Dane Miller's message
	of "Mon, 21 Apr 2008 13:07:04 -0700")
References: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
	<20080420123156.8c9bc048.wmoran@collaborativefusion.com>
	<D003B3E8-080D-4AFD-9418-DBB4AC09E232@HTWM.De>
	<20080421090546.65a50421.wmoran@collaborativefusion.com>
	<E0807848-8FC0-49A8-9CB5-E7A637328B1E@khera.org>
	<60lk37npll.fsf@dba2.int.libertyrms.com>
	<1208808424.25299.30.camel@danespc.home>
Message-ID: <60y777lydk.fsf@dba2.int.libertyrms.com>

Dane Miller <dane@greatschools.net> writes:
> Christopher Browne wrote:
>> Consider:
>> - Nodes 1-3 are in a LAN at Data Centre A
>> - Nodes 4-6 are in a LAN at Data Centre B
>> 
>> There are constrictions...
>> - 1-3 can easily "talk amongst themselves."
>> - Likewise, 4-6 can easily "talk amongst themselves."
>> - However, we pick #3 and #4 as being the only nodes that are allowed
>>   to talk with one another across the WAN
>> 
>> There are configurations you cannot create, in such a case:
>> - You cannot have any configuration where nodes 5 or 6 subscribe
>> directly to
>>   1-3; they *MUST* go thru node 4
>> - Likewise, you cannot have any configuration where nodes 1 or 2
>>   subscribe directly to 4-6; they *MUST* go thru node 3 
>
> This is similar to a setup I was managing at my site until recently.  We
> gave up because, to follow this example, events from nodes 5 and 6 were
> making their way to nodes 1-3.  It was easy to configure the proper
> parent for each node, which determined the data path data.  But I wasn't
> sure how to setup Slony replication such that there were no listen paths
> between nodes 5, 6 and 1-3.
>
> Our requirement was that nodes 1-3 were not allowed to know about or be
> influenced by any events on nodes 5 and 6.  5 and 6 should communicate
> only with node 4, which in turn would communicate with nodes 1-3.  Is
> this possible?  Doesn't 'store path()' create listen paths between all
> cluster nodes?

You're fighting against how Slony-I was designed.

All nodes need to be aware of all other nodes; that's essential to
(for instance) how the data purging policy was designed.

Log data cannot be purged from nodes 1-3 until they *know* that the
events have been processed by nodes 4, 5, and 6.

If you "win the fight" and get Slony-I configured to *not* have listen
paths between 1-3 and 5,6, you'll find that things break down because
obsolete data won't ever get purged.
-- 
output = ("cbbrowne" "@" "cbbrowne.com")
http://cbbrowne.com/info/unix.html
Rules of the Evil Overlord #133.  "If I find my beautiful consort with
access to  my fortress has been  associating with the  hero, I'll have
her executed.  It's regrettable,  but new consorts  are easier  to get
than new fortresses  and maybe the next one will  pay attention at the
orientation meeting." <http://www.eviloverlord.com/>
From ajs at crankycanuck.ca  Mon Apr 21 14:32:01 2008
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Mon Apr 21 14:32:27 2008
Subject: [Slony1-general] Network Partitioning
In-Reply-To: <60y777lydk.fsf@dba2.int.libertyrms.com>
References: <AE078386-6391-4412-8322-71CDCDE0F7DC@htwm.de>
	<20080420123156.8c9bc048.wmoran@collaborativefusion.com>
	<D003B3E8-080D-4AFD-9418-DBB4AC09E232@HTWM.De>
	<20080421090546.65a50421.wmoran@collaborativefusion.com>
	<E0807848-8FC0-49A8-9CB5-E7A637328B1E@khera.org>
	<60lk37npll.fsf@dba2.int.libertyrms.com>
	<1208808424.25299.30.camel@danespc.home>
	<60y777lydk.fsf@dba2.int.libertyrms.com>
Message-ID: <20080421213201.GF27155@crankycanuck.ca>

On Mon, Apr 21, 2008 at 04:57:27PM -0400, Christopher Browne wrote:

> > Our requirement was that nodes 1-3 were not allowed to know about or be
> > influenced by any events on nodes 5 and 6.  5 and 6 should communicate
> > only with node 4, which in turn would communicate with nodes 1-3.  Is
> > this possible?  Doesn't 'store path()' create listen paths between all
> > cluster nodes?
> 
> 
> Log data cannot be purged from nodes 1-3 until they *know* that the
> events have been processed by nodes 4, 5, and 6.
> 
> If you "win the fight" and get Slony-I configured to *not* have listen
> paths between 1-3 and 5,6, you'll find that things break down because
> obsolete data won't ever get purged.

This discussion seems to be hinting at a cool feature, which is a certain
amount of node isolation.  I think it won't work today, but it'd be a nifty
enhancement.

If I read him right, the OP described a network wherein 1, 2, 3 can talk to
4, and 5, 6 can talk to 4.  Moreover, 1,2,3 can all talk to each other, and
5,6 can talk to each other.  But communication between any of 1,2,3 and any
of 5,6 is restricted.

What is interesting about this is that you can use 4 as a gateway for
"translucency", so that data in 5,6 can be replicated through 4 such that
1,2,3 can get summaries, but not everything; and conversely.  

Now, there's no reason in principle, I think, why you couldn't just decide
that 5,6 simply do not need to know all the things going on in 1,2,3.  They
get their reports of "doneness" from 4, and they accept 4's statements as
gospel.  This would solve the "no purging" problem.

Whether the niftiness of this feature (and its potential benefits in
limited-permission data exchanges) would be worth the probably significant
complication is another matter entirely.  But I can certainly see the
application.

A
From jc at oxado.com  Wed Apr 23 09:42:43 2008
From: jc at oxado.com (Jacques Caron)
Date: Wed Apr 23 09:43:08 2008
Subject: [Slony1-general] Catching up a large backlog: a few observations
Message-ID: <20080423164253.2CD91120F01B@zeus.directinfos.com>

Hi all,

There is a bit of an issue in the way slon gets events from the 
master when there is a (very) large backlog: the remote listener 
thread tries to read all the events available in memory, which means:
- the process can grow quite a lot, eat useful cache memory from the 
DB (if slon is running on the same instance as the DB which is the 
usual case), eventually start swapping, and it worsens the backlog
- and/or the process can actually exceed memory limits, exit and 
restart, fetching events again
- the initial load of all available events itself may never complete 
(if it exceeds memory limits), and thus no replication happens since 
it won't start working until this initial load is complete

One first and easy fix for the last problem is to add a simple "LIMIT 
x" in remoteListen_receive_events. This will at least allow slon to 
start handling events while more are loaded. In situations where 
events can still be read a lot faster than they are handled (which is 
usually the case), forcing a sleep in the loop helps, but I'm not 
sure how this could be made to work in the general case.

A further and better fix would be to also add a count of 
"outstanding" events (that would be incremented when new events are 
loaded and decremented once they have been handled), and to have the 
listener thread sleep a bit when that count exceeds a given 
threshold. No need to have tens of millions of events in memory (with 
the possible complications given above) if we handle at most a few 
thousand at a time...

I also found out that setting desired_sync_time to 0 and increasing 
significantly sync_group_maxsize helps a lot when catching up. Is 
there a specific reason to have a low default value for this? Since 
it's bounded by the number of available events anyway, I'm not sure 
how low values actually help anything -- at least when desired_sync_time=0.

Finally, when in some situations fetching from the log is slow (that 
can happen when trying to fetch log items that happened during a long 
transaction, as the bounds for the index search are quite large), I 
am not sure that the logic behind desired_sync_time and such works 
very well: here the time it takes is not proportional to the number 
of events (the time per event actually decreases when the number of 
events handled at once increases, as most of the time is spent 
-wasted?- in the initial fetch).

Obviously if there was a way to build an index that better matches 
the fetches it would help, but I'm not quite sure that is possible (I 
haven't quite figured the whole minxid/maxxid/xip etc. thing yet).

Comments?

Jacques.

From cbbrowne at ca.afilias.info  Wed Apr 23 11:56:13 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Apr 23 11:56:25 2008
Subject: [Slony1-general] Catching up a large backlog: a few observations
In-Reply-To: <20080423164253.2CD91120F01B@zeus.directinfos.com> (Jacques
	Caron's message of "Wed, 23 Apr 2008 18:42:43 +0200")
References: <20080423164253.2CD91120F01B@zeus.directinfos.com>
Message-ID: <604p9s9z8y.fsf@dba2.int.libertyrms.com>

Jacques Caron <jc@oxado.com> writes:
> Hi all,
>
> There is a bit of an issue in the way slon gets events from the master
> when there is a (very) large backlog: the remote listener thread tries
> to read all the events available in memory, which means:
> - the process can grow quite a lot, eat useful cache memory from the
> DB (if slon is running on the same instance as the DB which is the
> usual case), eventually start swapping, and it worsens the backlog
> - and/or the process can actually exceed memory limits, exit and
> restart, fetching events again
> - the initial load of all available events itself may never complete
> (if it exceeds memory limits), and thus no replication happens since
> it won't start working until this initial load is complete
>
> One first and easy fix for the last problem is to add a simple "LIMIT
> x" in remoteListen_receive_events. This will at least allow slon to
> start handling events while more are loaded. In situations where
> events can still be read a lot faster than they are handled (which is
> usually the case), forcing a sleep in the loop helps, but I'm not sure
> how this could be made to work in the general case.

That sounds pretty plausible.

I don't see any reason in the code why limiting the number of events
processed should break anything.  I think I'd want to set the limit
based on a configuration parameter, but at first blush, the following
seems reasonable:

Index: remote_listen.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/remote_listen.c,v
retrieving revision 1.40
diff -c -u -r1.40 remote_listen.c
cvs diff: conflicting specifications of output style
--- remote_listen.c	6 Feb 2008 20:20:50 -0000	1.40
+++ remote_listen.c	23 Apr 2008 18:29:14 -0000
@@ -1,4 +1,4 @@
-/* ----------------------------------------------------------------------
+* ----------------------------------------------------------------------
  * remote_listen.c
  *
  *	Implementation of the thread listening for events on
@@ -697,7 +697,7 @@
 	{
 		slon_appendquery(&query, ")");
 	}
-	slon_appendquery(&query, " order by e.ev_origin, e.ev_seqno");
+	slon_appendquery(&query, " order by e.ev_origin, e.ev_seqno limit 2000");
 
 	rtcfg_unlock();
 


> A further and better fix would be to also add a count of "outstanding"
> events (that would be incremented when new events are loaded and
> decremented once they have been handled), and to have the listener
> thread sleep a bit when that count exceeds a given threshold. No need
> to have tens of millions of events in memory (with the possible
> complications given above) if we handle at most a few thousand at a
> time...

That's not a bad thought...

This would *definitely* point at adding a config parameter or two...

Yes, indeed, we maintain a variable on the queue (or perhaps across
queues???), so that we have a count of the number of outstanding
messages.

- Every time a message is added to the queue in remote_listen.c, we
  add to the counter

- Every time a message is processed from the queue in remote_worker.c,
  we decrement the counter

- In remote_listen.c, any time the size of the queue is larger than
  "os_event_threshold" (defaults to > the LIMIT used in the query in
  remote_listen.c), then we sleep for "os_event_sleep" milliseconds
  before processing another iteration of the "event search loop."

Alternatively, this could get more sophisticated, with some extra
config parms:

 * os_event_limit            - How many events to pull at a time,
                               and the threshold for further stuff
 * os_event_initialsleep     - If os_events > limit, then,
                               initially, sleep this many ms
 * os_event_increment        - When os_events continues to be > 
                               os_event_limit, add this to the
                               sleep time
 * os_event_maxsleep         - Don't let sleep time exceed this

With defaults...
  os_event_limit = 2000
  os_event_initialsleep = 2000
  os_event_increment = 500    # add 0.5s each time
  os_event_maxsleep = 15000   

Any time the queue shrinks below os_event_limit, then we reset the
sleep time back to os_event_initialsleep.

> I also found out that setting desired_sync_time to 0 and increasing
> significantly sync_group_maxsize helps a lot when catching up. Is
> there a specific reason to have a low default value for this? Since
> it's bounded by the number of available events anyway, I'm not sure
> how low values actually help anything -- at least when
> desired_sync_time=0.

There is a reason, if you're running log shipping; you might want to
be sure that each SYNC is kept separate, so that you could most
closely associate the set of data with its SYNC time.

> Finally, when in some situations fetching from the log is slow (that
> can happen when trying to fetch log items that happened during a
> long transaction, as the bounds for the index search are quite
> large), I am not sure that the logic behind desired_sync_time and
> such works very well: here the time it takes is not proportional to
> the number of events (the time per event actually decreases when the
> number of events handled at once increases, as most of the time is
> spent -wasted?- in the initial fetch).
>
> Obviously if there was a way to build an index that better matches
> the fetches it would help, but I'm not quite sure that is possible
> (I haven't quite figured the whole minxid/maxxid/xip etc. thing
> yet).
>
> Comments?

There are some improvements in 2.0 to the query on the log table,
notably for the special case where you have a really long running
transaction.

For sure, the "desired_sync_time" is only an approximation.  It has
the implicit assumption that run time time for a set of SYNCs is be
roughly proportional to the number of SYNCs, which isn't always true.

Any policy that is applied here is necessarily an approximation, so I
don't know that it is too likely to see *huge* improvements from a
substitute policy.  If you can describe another that is readily coded,
I'll certainly listen :-).
-- 
let name="cbbrowne" and tld="linuxdatabases.info" in String.concat "@" [name;tld];;
http://linuxfinances.info/info/x.html
"When campaigning, be swift as  the wind; in leisurely march, majestic
as the forest; in raiding and plundering, like fire; in standing, firm
as  the  mountains.   As  unfathomable  as the  clouds,  move  like  a
thunderbolt."  -- Sun Tzu, "The Art of War"
From jeff at frostconsultingllc.com  Wed Apr 23 15:07:00 2008
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Wed Apr 23 15:07:24 2008
Subject: [Slony1-general] typo in configure-replication.txt
Message-ID: <Pine.LNX.4.64.0804231505330.21805@discord.home.frostconsultingllc.com>

I noticed that in tools/configure-replication.txt, it says this:

2.  create_set.slonik

     This is the first script to run; it sets up the requested nodes as
     being Slony-I nodes, adding in some Slony-I-specific config tables
     and such.

But, it should say:

2.  create_nodes.slonik

     This is the first script to run; it sets up the requested nodes as
     being Slony-I nodes, adding in some Slony-I-specific config tables
     and such.


-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From jc at oxado.com  Wed Apr 23 16:28:44 2008
From: jc at oxado.com (Jacques Caron)
Date: Wed Apr 23 16:32:05 2008
Subject: [Slony1-general] Catching up a large backlog: a few observations
In-Reply-To: <604p9s9z8y.fsf@dba2.int.libertyrms.com>
References: <20080423164253.2CD91120F01B@zeus.directinfos.com>
	<604p9s9z8y.fsf@dba2.int.libertyrms.com>
Message-ID: <20080423233143.C9B50120F025@zeus.directinfos.com>

At 20:56 23/04/2008, Christopher Browne wrote:
>I don't see any reason in the code why limiting the number of events
>processed should break anything.  I think I'd want to set the limit
>based on a configuration parameter, but at first blush, the following
>seems reasonable:
>
>Index: remote_listen.c
>===================================================================
>RCS file: /home/cvsd/slony1/slony1-engine/src/slon/remote_listen.c,v
>retrieving revision 1.40
>diff -c -u -r1.40 remote_listen.c
>cvs diff: conflicting specifications of output style
>--- remote_listen.c     6 Feb 2008 20:20:50 -0000       1.40
>+++ remote_listen.c     23 Apr 2008 18:29:14 -0000
>@@ -1,4 +1,4 @@
>-/* ----------------------------------------------------------------------
>+* ----------------------------------------------------------------------
>   * remote_listen.c
>   *
>   *     Implementation of the thread listening for events on
>@@ -697,7 +697,7 @@
>         {
>                 slon_appendquery(&query, ")");
>         }
>-       slon_appendquery(&query, " order by e.ev_origin, e.ev_seqno");
>+       slon_appendquery(&query, " order by e.ev_origin, e.ev_seqno 
>limit 2000");
>
>         rtcfg_unlock();


I've been running slon with a similar change for a little while 
(finally catching up on a huge backlog) and it seems not to have 
caused any problems. But indeed a configuration parameter may be a good idea.

>- Every time a message is added to the queue in remote_listen.c, we
>   add to the counter
>
>- Every time a message is processed from the queue in remote_worker.c,
>   we decrement the counter
>
>- In remote_listen.c, any time the size of the queue is larger than
>   "os_event_threshold" (defaults to > the LIMIT used in the query in
>   remote_listen.c), then we sleep for "os_event_sleep" milliseconds
>   before processing another iteration of the "event search loop."

Sounds good. There could be a check that keeps the thread in a sleep 
loop until the counter comes below said threshold as well. Or the 
limit in the select could be (threshold - count). Obviously if 
count > threshold we want to skip the select and go back to sleep 
(and of course care must be taken with the poll/listen switches).

>Alternatively, this could get more sophisticated, with some extra
>config parms:
>
>  * os_event_limit            - How many events to pull at a time,
>                                and the threshold for further stuff
>  * os_event_initialsleep     - If os_events > limit, then,
>                                initially, sleep this many ms
>  * os_event_increment        - When os_events continues to be >
>                                os_event_limit, add this to the
>                                sleep time
>  * os_event_maxsleep         - Don't let sleep time exceed this

Don't know if we need that much "complexity"? I think the above logic 
("only get as much as we need") might be simpler and requires less 
tuning (and less default values to pick!).

> > I also found out that setting desired_sync_time to 0 and increasing
> > significantly sync_group_maxsize helps a lot when catching up. Is
> > there a specific reason to have a low default value for this? Since
> > it's bounded by the number of available events anyway, I'm not sure
> > how low values actually help anything -- at least when
> > desired_sync_time=0.
>
>There is a reason, if you're running log shipping; you might want to
>be sure that each SYNC is kept separate, so that you could most
>closely associate the set of data with its SYNC time.

So it should be either 1 or a relatively large value, then? Not sure 
the current default makes much sense? But I haven't had much 
experience with this other than watching slon trying to cope with 
this backlog :-( Not sure how things work out in a "normal" situation.

Also, something stupid: the code has:

max_sync = ((last_sync_group_size * 200) / 100) + 1;

I'm quite sure this can be simplified as:

max_sync = last_sync_group_size * 2 + 1;

without changing the result (actually the compiler probably does it 
already). Either that or the intended result got lost somewhere :-)

>For sure, the "desired_sync_time" is only an approximation.  It has
>the implicit assumption that run time time for a set of SYNCs is be
>roughly proportional to the number of SYNCs, which isn't always true.
>
>Any policy that is applied here is necessarily an approximation, so I
>don't know that it is too likely to see *huge* improvements from a
>substitute policy.  If you can describe another that is readily coded,
>I'll certainly listen :-).

I don't have any good suggestions for that yet, I've been doing the 
catching up with desired_sync_time = 0 so that code is effectively 
disabled :-) One possible option, though, would be to split the "time 
for first fetch" from the rest, and maybe consider that as a 
"constant" in the computation. I.e. consider that:

estimated_times_it_takes_to_handle_n_syncs = time_for_first_fetch + n 
* time_for_remainder_of_last_run / number_of_syncs_in_last_run

rather than n * time_of_last_run / number_of_syncs_in_last_run as I 
believe it is right now? I'm wild-guessing here :-)

Jacques.

From cbbrowne at ca.afilias.info  Thu Apr 24 08:12:08 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Apr 24 08:12:17 2008
Subject: [Slony1-general] typo in configure-replication.txt
In-Reply-To: <Pine.LNX.4.64.0804231505330.21805@discord.home.frostconsultingllc.com>
	(Jeff Frost's message of "Wed, 23 Apr 2008 15:07:00 -0700 (PDT)")
References: <Pine.LNX.4.64.0804231505330.21805@discord.home.frostconsultingllc.com>
Message-ID: <60mynj8eyf.fsf@dba2.int.libertyrms.com>

Jeff Frost <jeff@frostconsultingllc.com> writes:
> I noticed that in tools/configure-replication.txt, it says this:
>
> 2.  create_set.slonik
>
>     This is the first script to run; it sets up the requested nodes as
>     being Slony-I nodes, adding in some Slony-I-specific config tables
>     and such.
>
> But, it should say:
>
> 2.  create_nodes.slonik
>
>     This is the first script to run; it sets up the requested nodes as
>     being Slony-I nodes, adding in some Slony-I-specific config tables
>     and such.

Fixed in 1.2 and HEAD.  Thanks!
-- 
let name="cbbrowne" and tld="ca.afilias.info" in String.concat "@" [name;tld];;
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)
From cbbrowne at ca.afilias.info  Thu Apr 24 08:54:12 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Apr 24 08:54:20 2008
Subject: [Slony1-general] Catching up a large backlog: a few observations
In-Reply-To: <20080423233143.C9B50120F025@zeus.directinfos.com> (Jacques
	Caron's message of "Thu, 24 Apr 2008 01:28:44 +0200")
References: <20080423164253.2CD91120F01B@zeus.directinfos.com>
	<604p9s9z8y.fsf@dba2.int.libertyrms.com>
	<20080423233143.C9B50120F025@zeus.directinfos.com>
Message-ID: <60iqy78d0b.fsf@dba2.int.libertyrms.com>

Jacques Caron <jc@oxado.com> writes:
> At 20:56 23/04/2008, Christopher Browne wrote:
>>I don't see any reason in the code why limiting the number of events
>>processed should break anything.  I think I'd want to set the limit
>>based on a configuration parameter, but at first blush, the following
>>seems reasonable:
>>
>>Index: remote_listen.c
>>===================================================================
>>RCS file: /home/cvsd/slony1/slony1-engine/src/slon/remote_listen.c,v
>>retrieving revision 1.40
>>diff -c -u -r1.40 remote_listen.c
>>cvs diff: conflicting specifications of output style
>>--- remote_listen.c     6 Feb 2008 20:20:50 -0000       1.40
>>+++ remote_listen.c     23 Apr 2008 18:29:14 -0000
>>@@ -1,4 +1,4 @@
>>-/* ----------------------------------------------------------------------
>>+* ----------------------------------------------------------------------
>>   * remote_listen.c
>>   *
>>   *     Implementation of the thread listening for events on
>>@@ -697,7 +697,7 @@
>>         {
>>                 slon_appendquery(&query, ")");
>>         }
>>-       slon_appendquery(&query, " order by e.ev_origin, e.ev_seqno");
>> +       slon_appendquery(&query, " order by e.ev_origin, e.ev_seqno
>> limit 2000");
>>
>>         rtcfg_unlock();
>
> I've been running slon with a similar change for a little while
> (finally catching up on a huge backlog) and it seems not to have
> caused any problems. But indeed a configuration parameter may be a
> good idea.

It's not very hard to make it configurable, and that eliminates the
need for a config change to require a recompile, which is of decidedly
non-zero value :-).

>>- Every time a message is added to the queue in remote_listen.c, we
>>   add to the counter
>>
>>- Every time a message is processed from the queue in remote_worker.c,
>>   we decrement the counter
>>
>>- In remote_listen.c, any time the size of the queue is larger than
>>   "os_event_threshold" (defaults to > the LIMIT used in the query in
>>   remote_listen.c), then we sleep for "os_event_sleep" milliseconds
>>   before processing another iteration of the "event search loop."
>
> Sounds good. There could be a check that keeps the thread in a sleep
> loop until the counter comes below said threshold as well. Or the
> limit in the select could be (threshold - count). Obviously if count >
> threshold we want to skip the select and go back to sleep (and of
> course care must be taken with the poll/listen switches).

I'm not sure we want to stop queueing events altogether for any
extended period of time.  *That* seems like a risky thing to do.

>>Alternatively, this could get more sophisticated, with some extra
>>config parms:
>>
>>  * os_event_limit            - How many events to pull at a time,
>>                                and the threshold for further stuff
>>  * os_event_initialsleep     - If os_events > limit, then,
>>                                initially, sleep this many ms
>>  * os_event_increment        - When os_events continues to be >
>>                                os_event_limit, add this to the
>>                                sleep time
>>  * os_event_maxsleep         - Don't let sleep time exceed this
>
> Don't know if we need that much "complexity"? I think the above logic
> ("only get as much as we need") might be simpler and requires less
> tuning (and less default values to pick!).

If the defaults are reasonable, almost nobody ever need touch it :-).

And it seems to me that if we put in *some* delays, that's likely to
be enough to resolve 95% of the problem cases.  I'm reluctant to take
the approach of stopping queueing altogether for a extended period.

- If the problem is that there is a backlog of irrelevant SYNCs
  because some node was out of commission for a while, the "LIMIT N"
  combined with having just about *any* sort of delay in the listener
  loop should enable painless catchup.

- If the problem is that there is a backlog of SYNCs that *will* need
  to be processed, then metering them in, via "LIMIT N" + some delays,
  should prevent the slon from blowing up.  If it *does* blow up, it'll
  restart, *hopefully* after getting some work done.

The alternative solution is to do "strict metering" where we don't
allow the queue to grow past some pre-defined size.  But I'm not sure
what that size should be.

>> > I also found out that setting desired_sync_time to 0 and increasing
>> > significantly sync_group_maxsize helps a lot when catching up. Is
>> > there a specific reason to have a low default value for this? Since
>> > it's bounded by the number of available events anyway, I'm not sure
>> > how low values actually help anything -- at least when
>> > desired_sync_time=0.
>>
>>There is a reason, if you're running log shipping; you might want to
>>be sure that each SYNC is kept separate, so that you could most
>>closely associate the set of data with its SYNC time.
>
> So it should be either 1 or a relatively large value, then? Not sure
> the current default makes much sense?

That seems right.  Maybe we should increase the default in 2.0...

> But I haven't had much experience with this other than watching slon
> trying to cope with this backlog :-( Not sure how things work out in
> a "normal" situation.
>
> Also, something stupid: the code has:
>
> max_sync = ((last_sync_group_size * 200) / 100) + 1;
>
> I'm quite sure this can be simplified as:
>
> max_sync = last_sync_group_size * 2 + 1;
>
> without changing the result (actually the compiler probably does it
> already). Either that or the intended result got lost somewhere :-)

Hmm.  At some point, some of the calculations used larger
numerator/denominator to avoid accidentally truncating an integer to
0.  That was evidently not one of the places where that was necessary.

>>For sure, the "desired_sync_time" is only an approximation.  It has
>>the implicit assumption that run time time for a set of SYNCs is be
>>roughly proportional to the number of SYNCs, which isn't always true.
>>
>>Any policy that is applied here is necessarily an approximation, so I
>>don't know that it is too likely to see *huge* improvements from a
>>substitute policy.  If you can describe another that is readily coded,
>>I'll certainly listen :-).
>
> I don't have any good suggestions for that yet, I've been doing the
> catching up with desired_sync_time = 0 so that code is effectively
> disabled :-) One possible option, though, would be to split the "time
> for first fetch" from the rest, and maybe consider that as a
> "constant" in the computation. I.e. consider that:
>
> estimated_times_it_takes_to_handle_n_syncs = time_for_first_fetch + n
> * time_for_remainder_of_last_run / number_of_syncs_in_last_run
>
> rather than n * time_of_last_run / number_of_syncs_in_last_run as I
> believe it is right now? I'm wild-guessing here :-)
>
> Jacques.

Ah, you could be right there.  Yes, it may be that the "time for first
fetch" is nearly constant, and so should be taken out of the estimate.

Mind you, we may be "gilding buggy whips" here; trying to improve an
estimate that is fundamentally flawed.  There is the fundamental flaw
that there is no real reason to expect two SYNCs to be equally
expensive, if there is variation in system load.
-- 
"cbbrowne","@","linuxfinances.info"
http://cbbrowne.com/info/linuxxian.html
If a hole in the street is a manhole, is a hole in a man a streethole?
From jc at oxado.com  Thu Apr 24 09:43:55 2008
From: jc at oxado.com (Jacques Caron)
Date: Thu Apr 24 09:44:54 2008
Subject: [Slony1-general] Catching up a large backlog: a few observations
In-Reply-To: <60iqy78d0b.fsf@dba2.int.libertyrms.com>
References: <20080423164253.2CD91120F01B@zeus.directinfos.com>
	<604p9s9z8y.fsf@dba2.int.libertyrms.com>
	<20080423233143.C9B50120F025@zeus.directinfos.com>
	<60iqy78d0b.fsf@dba2.int.libertyrms.com>
Message-ID: <20080424164438.CB6B2120F029@zeus.directinfos.com>

Hi,

At 17:54 24/04/2008, Christopher Browne wrote:
>I'm not sure we want to stop queueing events altogether for any
>extended period of time.  *That* seems like a risky thing to do.

I'm not quite sure why? I'd rather have them stay untouched in the DB 
rather than have slon grow (potentially a lot) for no good reason.

>- If the problem is that there is a backlog of SYNCs that *will* need
>   to be processed, then metering them in, via "LIMIT N" + some delays,
>   should prevent the slon from blowing up.  If it *does* blow up, it'll
>   restart, *hopefully* after getting some work done.

It does indeed, but in the meantime you have requested lots of events 
that ended up not being used (and which you will fetch again on the 
next run), you have used memory that could be more useful as OS 
cache, and in many cases you actually end up stopping slon quite 
abruptly while it's fetching data, with postgres continuing to work 
on that fetch while you start a new one. And really the "oh anyway it 
will crash and restart" approach gives be goose bumps for something 
related to DB replication!

>The alternative solution is to do "strict metering" where we don't
>allow the queue to grow past some pre-defined size.  But I'm not sure
>what that size should be.

n x sync_group_maxsize? With n somewhere between 2 and 10, I'd say.

>Ah, you could be right there.  Yes, it may be that the "time for first
>fetch" is nearly constant, and so should be taken out of the estimate.

It's at least somewhat constant for periods of time, when the index 
isn't selective enough and the initial fetch needs a lot of work. 
Over longer periods it does vary quite significantly.

>Mind you, we may be "gilding buggy whips" here; trying to improve an
>estimate that is fundamentally flawed.  There is the fundamental flaw
>that there is no real reason to expect two SYNCs to be equally
>expensive, if there is variation in system load.

Over consecutive runs I would expect them to be quite consistent, 
there would just be an issue at the point where the load changes 
(start or end of a batch job, etc.). Obviously for a system with lots 
of short spikes and low values of desired_sync_time it would not make 
much sense, but then I'm not sure the desired_sync_time would make 
much sense either?

Jacques.

From dba at richyen.com  Thu Apr 24 16:24:26 2008
From: dba at richyen.com (Richard Yen)
Date: Thu Apr 24 16:24:41 2008
Subject: [Slony1-general] slony_logshipper needs fix?
Message-ID: <CF6B695B-42F5-4B7A-99CB-E711456FC7F4@richyen.com>

Hi,

Currently using slony-1.2.12

I was having issues with slony_logshipper reading in at_counter  
incorrectly from the logfiles.  I moved parser.y:337 to line 332  
(right under the slon_mkquery call).  Things seem to work now.  Seems  
like the free() calls come too early?

Is this an known issue, or maybe it's just me?  That snipped of code  
is the same in 1.2.13

Also, as the logshipping runs, it looks like the logfiles that get  
generated are not handling the single quotes properly?  Output below:

ERROR 2008-04-24 16:17:32 > PGRES_FATAL_ERROR: ERROR:  syntax error at  
or near "Cahier"
LINE 1: ..._count, compare_to_database) values ('1969048', ''Cahier  
d'u...
                                                              ^
Query was: insert into "public"."m_object_paper" (id, title,  
x_firstname, x_lastname, char_length, word_count, grade, grade_note,  
overwriteflag, is_indexed, folder, "assignment", "owner", node,  
page_count, compare_to_database) values ('1969048', ''Cahier d'un  
retour au pays natal' is prinicpally defined by violence. Discuss',  
'Charlotte', 'Byrne', '10937', '1689', NULL, NULL, 't', 'f', '0',  
'88981', '445800', '2', NULL, '1000100000000000000000100000000000101');
WARN  2008-04-24 16:17:32 > waiting for resume

--Richard
From shahaf at redfin.com  Tue Apr 29 14:12:53 2008
From: shahaf at redfin.com (Shahaf Abileah)
Date: Tue Apr 29 14:15:01 2008
Subject: [Slony1-general] node is on archive counter 44,
	this archive log expects 45
Message-ID: <082D8A131DF72A4D88C908A1AD3DEB2202ED5624@mail-1.rf.lan>

Hello,

 

I'm trying to use the slony_logshipper tool to update a log-shipped
slave.  I kicked off the process and monitored the log file.  After a
short time, I noticed this in the log:

 

ERROR 2008-04-29 13:56:24 > PGRES_FATAL_ERROR: ERROR:  Slony-I: node is
on archive counter 44, this archive log expects 45

Query was: select "_shahaf_cluster".archiveTracking_offline('46',
'2008-04-29 13:41:46.204843');

WARN  2008-04-29 13:56:24 > waiting for resume

 

I can see the archiveTracking_offline function in the dump file I got
using slony1_dump.sh, the one I used to initialize my logshipped slave.
But I'm not familiar with the details of this replication scheme, so I'm
not sure why the archive counter would have gotten out of sync (whatever
that means).

 

Can anyone offer suggestions on how to fix this issue or how to analyze
it further?

 

Thanks,

 

--S

 

 

Shahaf Abileah | Lead Software Developer - Data Team

shahaf@redfin.com <mailto:shahaf@redfin.com>  | tel: 206.859.2869 |
cell: 206.331.2057 | www.redfin.com <http://www.redfin.com> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080429/0003e6da/attachment.htm
From shoaibmir at gmail.com  Tue Apr 29 16:47:33 2008
From: shoaibmir at gmail.com (Shoaib Mir)
Date: Tue Apr 29 16:47:49 2008
Subject: [Slony1-general] Slony version 1.2.14?
Message-ID: <bf54be870804291647y74c65e72r87d63de466d894db@mail.gmail.com>

Hi List,

There is currently a problem with version 1.2.13 where in a cascaded setup
if you do a failover or switchover the whole cluster gets messed up. For
example the nodes are like this:

1->2->3->4 (where all are cascaded)

if you switch 4 to 1 as master then everything goes bad. It is currently in
the todo fix list of 1.2.14, I will like to know when can we expect a stable
release of version 1.2.14?

Regards,
Shoaib
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20080430/=
fad6cb32/attachment.htm
From shahaf at redfin.com  Tue Apr 29 17:23:00 2008
From: shahaf at redfin.com (Shahaf Abileah)
Date: Tue Apr 29 17:25:10 2008
Subject: [Slony1-general] node is on archive counter 44,
	this archive log expects 45
In-Reply-To: <4817B19B.3090608@sun.stanford.edu>
References: <082D8A131DF72A4D88C908A1AD3DEB2202ED5624@mail-1.rf.lan>
	<4817B19B.3090608@sun.stanford.edu>
Message-ID: <082D8A131DF72A4D88C908A1AD3DEB2202ED58AE@mail-1.rf.lan>

Hi Jennifer,

Thanks for the info!

Indeed, when I query the sl_archive_tracking table, I see that the most
recently applied SQL file is #44:

shahaf_logshipped_slave=# select * from
_shahaf_cluster.sl_archive_tracking;
 at_counter |        at_created         |         at_applied
------------+---------------------------+----------------------------
         44 | 2008-04-29 13:41:26.20039 | 2008-04-29 13:56:24.255029
(1 row)

So, it makes sense that the logshipped slave would want #45 next.

To produce the SQL files I simply used the -a flag on the slon process
for my regular slave, as described here:
http://lists.slony.info/documentation/logshipping.html

I have a directory (/data/tmp/shahaf/logshipping/SYNC) that now includes
several hundred files like this:

[root@idb SYNC]# ls | more
slony1_log_10_00000000000000000001.sql
slony1_log_10_00000000000000000002.sql
slony1_log_10_00000000000000000003.sql
slony1_log_10_00000000000000000004.sql
slony1_log_10_00000000000000000005.sql

And, this directory does in fact contain files for the segment where the
problem occurred...

<snip>
slony1_log_10_00000000000000000043.sql
slony1_log_10_00000000000000000044.sql
slony1_log_10_00000000000000000045.sql
slony1_log_10_00000000000000000046.sql
slony1_log_10_00000000000000000047.sql
<snip>

Also, I verified that the file name and the contents are in sync.  In
other words, the file that ends in 045.sql includes the following:

select "_shahaf_cluster".archiveTracking_offline('45', '2008-04-29
13:41:36.201339');

To apply these logs, I'm using the /usr/bin/slony_logshipper tool, also
described here:
http://lists.slony.info/documentation/logshipping.html

So, either something is wrong with my setup, or there's something wrong
with the slony_logshipper tool.

To dig a little further, I tried an experiment.  I started with a fresh
shahaf_logshipped_slave DB and I applied the DB dump to it (the one I
got from the slony1_dump.sh script).  I then checked the
sl_archive_tracking table and found that at_counter = 34.  Then I
manually applied the scripts from the SYNC directory by feeding them
into psql one by one, starting with 035.sql.  This worked.  I was able
to go as high as 050.sql and I didn't see the issue described below.

Then I repeated my experiment by once again starting with a fresh DB on
which I applied the dump.  This time I went back to using the
slony_logshipper tool to do the work of choosing and applying the
scripts, one by one.  And once it failed with the same issue, only this
time it happened at #42/43 instead of #44/45.  Here's what I see in the
log file produced by the slony_logshipper tool:

INFO  2008-04-29 17:18:07 > Processing archive file
./SYNC/slony1_log_10_00000000000000000040.sql
INFO  2008-04-29 17:18:07 > NOTICE:  Slony-I: Process archive with
counter 40 created 2008-04-29 13:40:46.188066
INFO  2008-04-29 17:18:07 > Processing archive file
./SYNC/slony1_log_10_00000000000000000041.sql
INFO  2008-04-29 17:18:07 > NOTICE:  Slony-I: Process archive with
counter 41 created 2008-04-29 13:40:56.191449
INFO  2008-04-29 17:18:07 > Processing archive file
./SYNC/slony1_log_10_00000000000000000042.sql
WARN  2008-04-29 17:18:07 > skip archive with counter (r)V - already
applied
INFO  2008-04-29 17:18:07 > Processing archive file
./SYNC/slony1_log_10_00000000000000000043.sql
ERROR 2008-04-29 17:18:07 > PGRES_FATAL_ERROR: ERROR:  Slony-I: node is
on archive counter 41, this archive log expects 42
Query was: select "_shahaf_cluster".archiveTracking_offline('43',
'2008-04-29 13:41:16.196712');
WARN  2008-04-29 17:18:07 > waiting for resume

So, something went sideways when the tool tried to process file #42.  It
decided to skip it (I'm not sure what "counter (r)V" is all about).  As
a result, #43 failed.

How do you go about running the SQL scripts on your logshipped slave?

Thanks,

--S


-----Original Message-----
From: Jennifer Spencer [mailto:jennifer@sun.Stanford.EDU] 
Sent: Tuesday, April 29, 2008 4:39 PM
To: Shahaf Abileah
Cc: slony1-general@lists.slony.info
Subject: Re: [Slony1-general] node is on archive counter 44, this
archive log expects 45

Hi Shahaf,

I have a similar setup, using log shipping.  I have noticed that this
particular error message is not 
as helpful as you might want.  In fact, the log-shipper may actually
want log #46 or #246.  Just not 
the one you gave it (#44).  I think the error message just gives you
N+1, where N is the number of the 
log you tried to feed it.

Your log-shipped slave has a table called
_shahaf_cluster.sl_archive_tracking.  It should have been 
created by the slony1_dump.sh script.  That table will contain one row,
and the "at counter" (first 
field there) is the log number it ingested last.  It wants the
at_counter + 1.  So, in the slavedb, 
select * from _sharaf_cluster.sl_archive_tracking;

Your slony logs should be numbered, monotonically increasing, and you
should have that next log number 
in the directory where those logs live.  If you have that correct log,
have you tried applying it?

Which script are you using to apply the logs, anyway?

As to how it got "off" from the correct order, I am not sure.  You'd
have to check any logging 
programs you have, whose names are hopefully in the log-application
script.

-Jennifer Spencer

Shahaf Abileah wrote:
> Hello,
> 
>  
> 
> I'm trying to use the slony_logshipper tool to update a log-shipped
> slave.  I kicked off the process and monitored the log file.  After a
> short time, I noticed this in the log:
> 
>  
> 
> ERROR 2008-04-29 13:56:24 > PGRES_FATAL_ERROR: ERROR:  Slony-I: node
is
> on archive counter 44, this archive log expects 45
> 
> Query was: select "_shahaf_cluster".archiveTracking_offline('46',
> '2008-04-29 13:41:46.204843');
> 
> WARN  2008-04-29 13:56:24 > waiting for resume
> 
>  
> 
> I can see the archiveTracking_offline function in the dump file I got
> using slony1_dump.sh, the one I used to initialize my logshipped
slave.
> But I'm not familiar with the details of this replication scheme, so
I'm
> not sure why the archive counter would have gotten out of sync
(whatever
> that means).
> 
>  
> 
> Can anyone offer suggestions on how to fix this issue or how to
analyze
> it further?
> 
>  
> 
> Thanks,
> 
>  
> 
> --S
> 
>  
> 
>  
> 
> Shahaf Abileah | Lead Software Developer - Data Team
> 
> shahaf@redfin.com <mailto:shahaf@redfin.com>  | tel: 206.859.2869 |
> cell: 206.331.2057 | www.redfin.com <http://www.redfin.com> 
> 
> 
> 
> 
>
------------------------------------------------------------------------
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


From sangsuan.gam at gmail.com  Wed Apr 30 02:25:38 2008
From: sangsuan.gam at gmail.com (ssgam)
Date: Wed Apr 30 02:26:03 2008
Subject: re[Slony1-general] try: subscrptions lost after move set ?
Message-ID: <16978891.post@talk.nabble.com>


-- nabble is telling me that my messages is pending ... trying again ... ---

Hi,

i'm experimenting with Slony-i and was trying the the following
configurations:

# A. one origin node (N1), one subscriber (N2); same host.        
(simple,local)
#
# B. A + remote node (N3) subscribing directly from origin node.
(simple,local) +
#                                                                                                
(remote)
#
# C. B + remote node (N4), getting cascade events from N2.     
(simple,local) +
#                                                                                                
(remote,cascade)
#
# D. modify C:        N3   getting cascade events from N2.            (swap
provider)
#
# E. modify D:        N2   becomes origin,
#                           N1   becomes subscriber,
#                           getting cascade events from N2.                   
(swap master)
#
# F. failover:        N3   becomes origin,
#                         N1   subscribing directly from origin node, N3.
#                         N4   subscribing directly from origin node, N3.
#                         N2   dropped from configuration.

The slonik commands works as expected until I try to test E:
moving the origin of the set from N1 to N2.

the commands i executed are :

> $ cat mod_master.sk
> #! /opt/postgresql-8.2.5/bin/slonik
>
> include <preamble.sk>;
>
> lock set ( id = @SID_1,     origin = @SC6_1 );
> move set ( id = @SID_1, old origin = @SC6_1, new origin = @SC6_2 );>
>
> $ cat mod_subsets.sk
> #! /opt/postgresql-8.2.5/bin/slonik
>
> include <preamble.sk>;
>
> subscribe set ( id = @SID_1, provider = @SC6_2, receiver = @SC6_1, forward
> = yes );
>
>
> $

after running the 2 scripts above, the origin was moved from N1 to N2.
i was able to update a row in a table in the set on N2, and the change
was reflected on N1.

however, N3 and N4 cannot see any changes after the "move set".

what are additional commands i need to invoke ?

N1 and N2 are on one machine, while N3 and N4 are on another.

Thanks Very Much in advance!
cheers,
sam
-- 
View this message in context: http://www.nabble.com/retry%3A-subscrptions-lost-after-move-set---tp16978891p16978891.html
Sent from the Slony-I -- General mailing list archive at Nabble.com.

From scetbon at echo.fr  Wed Apr 30 06:15:21 2008
From: scetbon at echo.fr (Cyril SCETBON)
Date: Wed Apr 30 06:15:26 2008
Subject: [Slony1-general] "DEBUG2: remoteWorkerThread_%d: copy table %s"
	does not appear
Message-ID: <481870E9.7030207@echo.fr>

Hi,

We have two differents configurations (2 clusters) with the same slon 
binaries. However on the second one we have debug2 logs and even if we 
see finishTableAfterCopy calls (in postgresql logs) we don't have any 
"DEBUG2: remoteWorkerThread_%d: copy table %s" message in slony logs

What can cause this behaviour ?

PS: we use debian packages

thanks
-- 
Cyril SCETBON
From cbbrowne at ca.afilias.info  Wed Apr 30 14:31:08 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Apr 30 14:31:22 2008
Subject: [Slony1-general] Catching up a large backlog: a few observations
In-Reply-To: <20080424164438.CB6B2120F029@zeus.directinfos.com> (Jacques
	Caron's message of "Thu, 24 Apr 2008 18:43:55 +0200")
References: <20080423164253.2CD91120F01B@zeus.directinfos.com>
	<604p9s9z8y.fsf@dba2.int.libertyrms.com>
	<20080423233143.C9B50120F025@zeus.directinfos.com>
	<60iqy78d0b.fsf@dba2.int.libertyrms.com>
	<20080424164438.CB6B2120F029@zeus.directinfos.com>
Message-ID: <60bq3r3u8z.fsf@dba2.int.libertyrms.com>

Jacques Caron <jc@oxado.com> writes:
> Hi,
>
> At 17:54 24/04/2008, Christopher Browne wrote:
>>I'm not sure we want to stop queueing events altogether for any
>>extended period of time.  *That* seems like a risky thing to do.
>
> I'm not quite sure why? I'd rather have them stay untouched in the DB
> rather than have slon grow (potentially a lot) for no good reason.

After a chat with Jan, I have to back away from suggesting it's
particularly risky.  It shouldn't be.

>>- If the problem is that there is a backlog of SYNCs that *will* need
>>   to be processed, then metering them in, via "LIMIT N" + some delays,
>>   should prevent the slon from blowing up.  If it *does* blow up, it'll
>>   restart, *hopefully* after getting some work done.
>
> It does indeed, but in the meantime you have requested lots of events
> that ended up not being used (and which you will fetch again on the
> next run), you have used memory that could be more useful as OS cache,
> and in many cases you actually end up stopping slon quite abruptly
> while it's fetching data, with postgres continuing to work on that
> fetch while you start a new one. And really the "oh anyway it will
> crash and restart" approach gives be goose bumps for something related
> to DB replication!

That *seems* fair.

My counterargument is that it looks as though implementing this
throttling may be done in one of two ways:

  a) In the exact way you suggest, which seems as though it would
     require quite a lot of code change, as collecting the necessary
     data would require touching quite a lot of code.

  b) If, instead, we use an inexact heuristic, then we have the
     benefit of being able to localize the changes to a small portion of
     program logic.

It looks as though collecting all the data needed for this would be
quite intrusive, and I'm loathe to add the complication for something
that people aren't complaining about, when a simpler heuristic might
well be good enough.     

>>The alternative solution is to do "strict metering" where we don't
>>allow the queue to grow past some pre-defined size.  But I'm not sure
>>what that size should be.
>
> n x sync_group_maxsize? With n somewhere between 2 and 10, I'd say.

Ah, yes, that seems pretty plausible.  That cuts down on the need for
configuration, as the existing config (sync_group_maxsize) can indeed
reasonably imply this already.

[Rummaging through code...]

Hmm.  It'll be a bit of a pain to implement this in any strict
fashion, as the queues are maintained on a per-node basis, and I don't
see too terribly much value in being really strict about exact
handling (e.g. - to the point of walking thru *all* the nodes'
configuration to analyze this).

Simpler seems better, particularly in that this will (regardless) have
some complicating effects on the code base.  If I can keep the logic
in one spot, that will make this change *way* more maintainable.

Suggestion:

- With 2 variables, I can store the number of event rows pulled for
  this and the last iteration, last_events, and current_events

- We set the query to do "limit (2*sync_group_maxsize)"

- If (last_events + current_events) = 4*sync_group_maxsize, then we
  sleep for a configurable period, *and* drop back into LISTENing mode.

That allows all of this logic to take place at the end of
remoteListen_receive_events().

It means that the slon never completely ceases to add events to the
queue, but:

 a) The events aren't enormously big, so we should be running out of
    memory due to other things way before running out due to event
    bloat;

 b) If we decelerate it sufficiently, that should be helpful enough.

I'll see about a patch for this.

>>Ah, you could be right there.  Yes, it may be that the "time for first
>>fetch" is nearly constant, and so should be taken out of the estimate.
>
> It's at least somewhat constant for periods of time, when the index
> isn't selective enough and the initial fetch needs a lot of work. Over
> longer periods it does vary quite significantly.
>
>>Mind you, we may be "gilding buggy whips" here; trying to improve an
>>estimate that is fundamentally flawed.  There is the fundamental flaw
>>that there is no real reason to expect two SYNCs to be equally
>>expensive, if there is variation in system load.
>
> Over consecutive runs I would expect them to be quite consistent,
> there would just be an issue at the point where the load changes
> (start or end of a batch job, etc.). Obviously for a system with lots
> of short spikes and low values of desired_sync_time it would not make
> much sense, but then I'm not sure the desired_sync_time would make
> much sense either?

The trouble with changing this to be terribly much more intelligent,
much like the listener case, is that the more sophisticated we get
about this, the more intrusive the code needs to be.

And I'm not just meaning in a "reluctance to alter existing code"
sense.  If it requires a LOT of additional instrumentation, and code
strewn around everywhere, that makes Slony-I harder to maintain, which
is no good thing.
-- 
let name="cbbrowne" and tld="cbbrowne.com" in String.concat "@" [name;tld];;
http://linuxfinances.info/info/nonrdbms.html
"...In my phone conversation with Microsoft's lawyer I copped to the
fact that just maybe his client might see me as having been in the
past just a bit critical of their products and business
practices. This was too bad, he said with a sigh, because they were
having a very hard time finding a reporter who both knew the industry
well enough to be called an expert and who hadn't written a negative
article about Microsoft." -- Robert X. Cringely
From cbbrowne at ca.afilias.info  Wed Apr 30 15:04:15 2008
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Apr 30 15:04:29 2008
Subject: [Slony1-general] Catching up a large backlog: a few observations
In-Reply-To: <60bq3r3u8z.fsf@dba2.int.libertyrms.com> (Christopher Browne's
	message of "Wed, 30 Apr 2008 17:31:08 -0400")
References: <20080423164253.2CD91120F01B@zeus.directinfos.com>
	<604p9s9z8y.fsf@dba2.int.libertyrms.com>
	<20080423233143.C9B50120F025@zeus.directinfos.com>
	<60iqy78d0b.fsf@dba2.int.libertyrms.com>
	<20080424164438.CB6B2120F029@zeus.directinfos.com>
	<60bq3r3u8z.fsf@dba2.int.libertyrms.com>
Message-ID: <607ief3sps.fsf@dba2.int.libertyrms.com>

Christopher Browne <cbbrowne@ca.afilias.info> writes:
> Suggestion:
>
> - With 2 variables, I can store the number of event rows pulled for
>   this and the last iteration, last_events, and current_events
>
> - We set the query to do "limit (2*sync_group_maxsize)"
>
> - If (last_events + current_events) = 4*sync_group_maxsize, then we
>   sleep for a configurable period, *and* drop back into LISTENing mode.
>
> That allows all of this logic to take place at the end of
> remoteListen_receive_events().
>
> It means that the slon never completely ceases to add events to the
> queue, but:
>
>  a) The events aren't enormously big, so we should be running out of
>     memory due to other things way before running out due to event
>     bloat;
>
>  b) If we decelerate it sufficiently, that should be helpful enough.
>
> I'll see about a patch for this.

Actually, it's a bit simpler than I thought; I already had "ntuples"
to work with, so it's only requiring one extra variable.

Index: remote_listen.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/remote_listen.c,v
retrieving revision 1.43
diff -c -u -r1.43 remote_listen.c
--- remote_listen.c	23 Apr 2008 22:29:12 -0000	1.43
+++ remote_listen.c	30 Apr 2008 22:02:47 -0000
@@ -65,6 +65,8 @@
 extern char *lag_interval;
 int remote_listen_timeout;
 
+static int last_event_sel = 0;
+
 /* ----------
  * slon_remoteListenThread
  *
@@ -697,7 +699,11 @@
 	{
 		slon_appendquery(&query, ")");
 	}
-	slon_appendquery(&query, " order by e.ev_origin, e.ev_seqno");
+	/* Limit the result set size to:
+            sync_group_maxsize * 2, if it's set
+			100, if sync_group_maxsize isn't set */
+	slon_appendquery(&query, " order by e.ev_origin, e.ev_seqno limit %d",
+					 (sync_group_maxsize>0)? sync_group_maxsize * 2 : 100);
 
 	rtcfg_unlock();
 
@@ -785,24 +791,25 @@
 	}
 
 	if (ntuples > 0) {
-		poll_sleep = 0;
-		poll_state = SLON_POLLSTATE_POLL;
+			if ((ntuples + last_event_sel) >= (4 * sync_group_maxsize)) {
+					poll_state = SLON_POLLSTATE_LISTEN;
+					slon_log(SLON_INFO, "remoteListenThread_%d: events queued in two iterations (%d) > sync_group_maxsize*4 (%d)\n",
+							 node->no_id, (ntuples + last_event_sel), (4 * sync_group_maxsize));
+					slon_log(SLON_INFO, "remoteListenThread_%d: sleep 10s, return to LISTEN mode\n",
+							 node->no_id, (ntuples + last_event_sel), (4 * sync_group_maxsize));
+					sched_msleep(node, 10000);
+			} else {
+					poll_sleep = 0;
+					poll_state = SLON_POLLSTATE_POLL;
+			}
 	} else {
-		poll_sleep = poll_sleep * 2 + sync_interval;
-		if (poll_sleep > sync_interval_timeout) {
-			poll_sleep = sync_interval_timeout;
-			poll_state = SLON_POLLSTATE_LISTEN;
-		}
+			poll_sleep = poll_sleep * 2 + sync_interval;
+			if (poll_sleep > sync_interval_timeout) {
+					poll_sleep = sync_interval_timeout;
+					poll_state = SLON_POLLSTATE_LISTEN;
+			}
 	}
 	PQclear(res);
-
+	last_event_sel = ntuples;
 	return 0;
 }
-
-/*
- * Local Variables:
- *	tab-width: 4
- *	c-indent-level: 4
- *	c-basic-offset: 4
- * End:
- */
-- 
(reverse (concatenate 'string "ofni.sailifa.ac" "@" "enworbbc"))
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)
From drees76 at gmail.com  Wed Apr 30 19:16:49 2008
From: drees76 at gmail.com (David Rees)
Date: Wed Apr 30 19:17:07 2008
Subject: [Slony1-general] try: subscrptions lost after move set ?
Message-ID: <72dbd3150804301916r201cef6cna4610516a7b97ffc@mail.gmail.com>

On Wed, Apr 30, 2008 at 2:25 AM, ssgam <sangsuan.gam@gmail.com> wrote:
>  after running the 2 scripts above, the origin was moved from N1 to N2.
>  i was able to update a row in a table in the set on N2, and the change
>  was reflected on N1.

What version of Slony? According this message[1] there is a bug when
failing over in 1.2.13 - I wonder if this is the bug you are hitting.
Can you try the latest from CVS?

-Dave

[1] http://www.nabble.com/Slony-version-1.2.14--to16972969.html
From msmith at crsinc.com  Thu Apr  3 08:15:55 2008
From: msmith at crsinc.com (stuntmusic)
Date: Thu Sep 25 08:27:15 2008
Subject: [Slony1-general] Data from slaves pushed back to master - Can it be
	done?
Message-ID: <16467554.post@talk.nabble.com>


I have an office that works on the master database of our application and I
want to set up a way for these users to work on a slave DB to keep them off
the production 'wire'

It appears that Slony-I can replicate the data DOWN to the slave easily
enough, but can it also handle replication UP, back to the production db?

For example, a user here needs to modify a record. They make the mod on the
slave DB. When or how does Slony-I get that mod back to the Master? Is there
a setting that allows me to set the refresh up to the master, or is it a
built in interval?

Thanks in advance.

- Marc
-- 
View this message in context: http://www.nabble.com/Data-from-slaves-pushed-back-to-master---Can-it-be-done--tp16467554p16467554.html
Sent from the Slony-I -- General mailing list archive at Nabble.com.

From hannu at krosing.net  Fri Apr  4 04:49:20 2008
From: hannu at krosing.net (Hannu Krosing)
Date: Thu Sep 25 08:27:16 2008
Subject: [Slony1-general] Feature request for next slony version:
	initial replication of large DBs
In-Reply-To: <60myob2evz.fsf@dba2.int.libertyrms.com>
References: <64706.196.23.181.69.1207031605.squirrel@zenmail.co.za>
	<47F1FFB2.40602@echo.fr>  <60myob2evz.fsf@dba2.int.libertyrms.com>
Message-ID: <1207309723.17862.1.camel@huvostro>


On Thu, 2008-04-03 at 10:26 -0400, Christopher Browne wrote:
> Cyril SCETBON <scetbon@echo.fr> writes:
> > As said Christopher Brown new commands are coming : CLONE PREPARE and
> > CLONE FINISH to bypass this mecanism
> >
> > see http://lists.slony.info/pipermail/slony1-commit/2008-January/002145.html
> 
> They do, to a degree, but not completely.  The CLONE commands operate
> on subscribers, so you need to have at least one subscriber in order
> to start cloning.
> 
> It would be in principle possible to do a "clone" against a master; we
> prepared a gedanken experiment as to how this would be done...  It
> would require a slight outage to establish a synchronization point,
> which makes it somewhat problematic, and which is why we haven't
> pursued the more extensive cloning.

Will an outage of 100 msec be enough ?

You just need a point where there is no active transactions ?

Maybe one should look, how this was achieved fro CONCURRENT VACUUM; 

----------
Hannu


From sangsuan.gam at gmail.com  Mon Apr 28 02:52:26 2008
From: sangsuan.gam at gmail.com (ssgam)
Date: Thu Sep 25 08:27:17 2008
Subject: [Slony1-general] subscrptions lost after move set ?
Message-ID: <16935639.post@talk.nabble.com>


Hi,

i'm experimenting with Slony-i and was trying the the following
configurations:

# A. one origin node (N1), one subscriber (N2); same host.        
(simple,local)
#
# B. A + remote node (N3) subscribing directly from origin node.
(simple,local) +
#                                                                                                
(remote)
#
# C. B + remote node (N4), getting cascade events from N2.     
(simple,local) +
#                                                                                                
(remote,cascade)
#
# D. modify C:        N3   getting cascade events from N2.            (swap
provider)
#
# E. modify D:        N2   becomes origin,
#                           N1   becomes subscriber,
#                           getting cascade events from N2.                   
(swap master)
#
# F. failover:        N3   becomes origin,
#                         N1   subscribing directly from origin node, N3.
#                         N4   subscribing directly from origin node, N3.
#                         N2   dropped from configuration.

The slonik commands works as expected until I try to test E:
moving the origin of the set from N1 to N2.

the commands i executed are :

> $ cat mod_master.sk
> #! /opt/postgresql-8.2.5/bin/slonik
>
> include <preamble.sk>;
> 
> lock set ( id = @SID_1,     origin = @SC6_1 );
> move set ( id = @SID_1, old origin = @SC6_1, new origin = @SC6_2 );>
>
> $ cat mod_subsets.sk
> #! /opt/postgresql-8.2.5/bin/slonik
> 
> include <preamble.sk>;
> 
> subscribe set ( id = @SID_1, provider = @SC6_2, receiver = @SC6_1, forward
> = yes );
>
>
> $

after running the 2 scripts above, the origin was moved from N1 to N2.
i was able to update a row in a table in the set on N2, and the change
was reflected on N1.

however, N3 and N4 cannot see any changes after the "move set".

what are additional commands i need to invoke ? 

N1 and N2 are on one machine, while N3 and N4 are on another.

Thanks Very Much in advance!
cheers,
sam
-- 
View this message in context: http://www.nabble.com/subscrptions-lost-after-move-set---tp16935639p16935639.html
Sent from the Slony-I -- General mailing list archive at Nabble.com.

From jennifer at sun.Stanford.EDU  Tue Apr 29 16:39:20 2008
From: jennifer at sun.Stanford.EDU (Jennifer Spencer)
Date: Thu Sep 25 08:27:17 2008
Subject: [Slony1-general] node is on archive counter 44,	this archive
	log expects 45
In-Reply-To: <082D8A131DF72A4D88C908A1AD3DEB2202ED5624@mail-1.rf.lan>
References: <082D8A131DF72A4D88C908A1AD3DEB2202ED5624@mail-1.rf.lan>
Message-ID: <4817B19B.3090608@sun.stanford.edu>

Hi Shahaf,

I have a similar setup, using log shipping.  I have noticed that this particular error message is not 
as helpful as you might want.  In fact, the log-shipper may actually want log #46 or #246.  Just not 
the one you gave it (#44).  I think the error message just gives you N+1, where N is the number of the 
log you tried to feed it.

Your log-shipped slave has a table called _shahaf_cluster.sl_archive_tracking.  It should have been 
created by the slony1_dump.sh script.  That table will contain one row, and the "at counter" (first 
field there) is the log number it ingested last.  It wants the at_counter + 1.  So, in the slavedb, 
select * from _sharaf_cluster.sl_archive_tracking;

Your slony logs should be numbered, monotonically increasing, and you should have that next log number 
in the directory where those logs live.  If you have that correct log, have you tried applying it?

Which script are you using to apply the logs, anyway?

As to how it got "off" from the correct order, I am not sure.  You'd have to check any logging 
programs you have, whose names are hopefully in the log-application script.

-Jennifer Spencer

Shahaf Abileah wrote:
> Hello,
> 
>  
> 
> I'm trying to use the slony_logshipper tool to update a log-shipped
> slave.  I kicked off the process and monitored the log file.  After a
> short time, I noticed this in the log:
> 
>  
> 
> ERROR 2008-04-29 13:56:24 > PGRES_FATAL_ERROR: ERROR:  Slony-I: node is
> on archive counter 44, this archive log expects 45
> 
> Query was: select "_shahaf_cluster".archiveTracking_offline('46',
> '2008-04-29 13:41:46.204843');
> 
> WARN  2008-04-29 13:56:24 > waiting for resume
> 
>  
> 
> I can see the archiveTracking_offline function in the dump file I got
> using slony1_dump.sh, the one I used to initialize my logshipped slave.
> But I'm not familiar with the details of this replication scheme, so I'm
> not sure why the archive counter would have gotten out of sync (whatever
> that means).
> 
>  
> 
> Can anyone offer suggestions on how to fix this issue or how to analyze
> it further?
> 
>  
> 
> Thanks,
> 
>  
> 
> --S
> 
>  
> 
>  
> 
> Shahaf Abileah | Lead Software Developer - Data Team
> 
> shahaf@redfin.com <mailto:shahaf@redfin.com>  | tel: 206.859.2869 |
> cell: 206.331.2057 | www.redfin.com <http://www.redfin.com> 
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
From jennifer at sun.Stanford.EDU  Tue Apr 29 16:52:49 2008
From: jennifer at sun.Stanford.EDU (Jennifer Spencer)
Date: Thu Sep 25 08:27:18 2008
Subject: [Slony1-general] node is on archive counter 44,	this archive
	log expects 45
In-Reply-To: <4817B19B.3090608@sun.stanford.edu>
References: <082D8A131DF72A4D88C908A1AD3DEB2202ED5624@mail-1.rf.lan>
	<4817B19B.3090608@sun.stanford.edu>
Message-ID: <4817B4C4.4050904@sun.stanford.edu>

Hi Shahaf,

I have a similar setup, using log shipping.  I have noticed that this particular error message is not 
as helpful as you might want.  In fact, the log-shipper may actually want log #46 or #246.  Just not 
the one you gave it (#44).  I think the error message just gives you N+1, where N is the number of the 
log you tried to feed it.

Your log-shipped slave has a table called _shahaf_cluster.sl_archive_tracking.  It should have been 
created by the slony1_dump.sh script.  That table will contain one row, and the "at counter" (first 
field there) is the log number it ingested last.  It wants the at_counter + 1.  So, in the slavedb, 
select * from _sharaf_cluster.sl_archive_tracking;

Your slony logs should be numbered, monotonically increasing, and you should have that next log number 
in the directory where those logs live.  If you have that correct log, have you tried applying it?

Which script are you using to apply the logs, anyway?

As to how it got "off" from the correct order, I am not sure.  You'd have to check any logging 
programs you have, whose names are hopefully in the log-application script.

-Jennifer Spencer
