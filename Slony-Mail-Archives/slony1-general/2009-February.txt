From m.perugini at 4it.it  Sun Feb  1 08:47:08 2009
From: m.perugini at 4it.it (marco perugini)
Date: Sun Feb  1 08:47:19 2009
Subject: [Slony1-general] Re: pg_config for slony1 install
Message-ID: <4985D20C.4010105@4it.it>

hi madan thapa, i had the same problem.. i solved it installing the =

devel rpm also;
so this is my rpm-postgres-list:
# rpm -qa | grep post
postgresql-contrib-8.3.5-1PGDG.rhel5
postgresql-libs-8.3.5-1PGDG.rhel5
postgresql-devel-8.3.5-1PGDG.rhel5
postgresql-server-8.3.5-1PGDG.rhel5
postgresql-8.3.5-1PGDG.rhel5

if you install the devel rpm you'll find pg_config in /usr/bin
# find / -name pg_config
/usr/bin/pg_config

good luck! ;)
marco


Madan Thapa ha scritto:
>
>
>     I have installed postgresql using yum.
>
>
>     -bash-3.2# rpm -qa |  grep postgres
>     postgresql-libs-8.3.5-1PGDG.
>     rhel5
>     postgresql-8.3.5-1PGDG.rhel5
>     postgresql-server-8.3.5-1PGDG.rhel5
>     compat-postgresql-libs-4-1PGDG.rhel5
>
>
>
>     -bash-3.2# ps faux |  egrep 'pgsql|postgres'
>     postgres 23733  0.0  0.7  40716  4108 ?        S    Jan29   0:02
>     /usr/bin/postmaster -p 5432 -D /var/lib/pgsql/data
>     postgres 23758  0.0  0.1  12040   888 ?        Ss   Jan29   0:00 =

>     \_ postgres: logger process
>     postgres 23761  0.0  0.2  40716  1228 ?        Ss   Jan29   0:00 =

>     \_ postgres: writer process
>     postgres 23763  0.0  0.1  40716  1028 ?        Ss   Jan29   0:00 =

>     \_ postgres: wal writer process
>     postgres 23764  0.0  0.2  40848  1136 ?        Ss   Jan29   0:00 =

>     \_ postgres: autovacuum launcher process
>     postgres 23765  0.0  0.1  12036   920 ?        Ss   Jan29   0:00 =

>     \_ postgres: stats collector process
>     root     11393  0.0  0.1   2992   704 pts/0    S+   05:44  =

>     0:00      \_ egrep pgsql|postgres
>     -bash-3.2#
>
>
>
>
>     Now to install slony what would be pg_config path ?
>
>     Docs sasy:
>     /Normally,/ it ought to be sufficient to run configure
>     |--with-pgconfigdir=3D/some/path/somewhere|, where
>     /some/path/somewhere is the place where the PostgreSQL program
>     *pg_config* is located. >From *pg_config*, the configure script
>     can determine the various locations where PostgreSQL components
>     are found, which indicates where the essential components of
>     Slony-I must be installed.
>
>
>     -bash-3.2# locate pg_config
>     locate: can not open `/var/lib/mlocate/mlocate.db': No such file
>     or directory
>     -bash-3.2# updatedb
>     -bash-3.2# locate pg_config
>     -bash-3.2# ls /var/lib/pgsql/data/
>     base    pg_clog      pg_ident.conf  pg_multixact  pg_tblspc   =

>     PG_VERSION  postgresql.conf  postmaster.pid
>     global  pg_hba.conf  pg_log         pg_subtrans   pg_twophase =

>     pg_xlog     postmaster.opts
>     -bash-3.2#
>
>
>
>     -bash-3.2# find / -name pg_config
>     -bash-3.2#
>     -bash-3.2#
>
>
>
>
>
>     Path of some important binaries on my system are
>     #################################################
>     /usr/bin/psql
>     /usr/bin/createdb
>     /usr/bin/createlang
>     /usr/bin/createuser
>     /usr/bin/pg_dump
>
>
>
>
>     Please advise.
>
>
>     Thanks
>
>
> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D>
>
> *yum install slony1   did it*
>
>
> -bash-3.2# yum install slony1
> pgdg83                    100% |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D| 1.9 kB    00:00
> rpmforge                  100% |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D| 1.1 kB    00:00
> base                      100% |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D| 1.1 kB    00:00
> updates                   100% |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|  951 B    00:00
> addons                    100% |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|  951 B    00:00
> extras                    100% |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D| 1.1 kB    00:00
> Setting up Install Process
> Parsing package install arguments
> Resolving Dependencies
> --> Running transaction check
> ---> Package slony1.i386 0:1.2.15-3.rhel5 set to be updated
> --> Processing Dependency: perl(DBI) for package: slony1
> --> Processing Dependency: perl-DBD-Pg for package: slony1
> --> Running transaction check
> ---> Package perl-DBD-Pg.i386 0:2.11.5-1.el5.rf set to be updated
> --> Processing Dependency: perl(version) for package: perl-DBD-Pg
> ---> Package perl-DBI.i386 0:1.607-1.el5.rf set to be updated
> --> Processing Dependency: perl(RPC::PlServer) >=3D 0.2001 for package: =

> perl-DBI
> --> Processing Dependency: perl(RPC::PlClient) >=3D 0.2000 for package: =

> perl-DBI
> --> Running transaction check
> ---> Package perl-version.i386 0:0.74-1.el5.rf set to be updated
> ---> Package perl-PlRPC.noarch 0:0.2020-1.el5.rf set to be updated
> --> Processing Dependency: perl(Net::Daemon) for package: perl-PlRPC
> --> Processing Dependency: perl(Net::Daemon::Log) for package: perl-PlRPC
> --> Processing Dependency: perl(Net::Daemon::Test) for package: perl-PlRPC
> --> Running transaction check
> ---> Package perl-Net-Daemon.noarch 0:0.43-1.el5.rf set to be updated
> --> Finished Dependency Resolution
>
> Dependencies Resolved
>
> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D
>  Package                 Arch       Version          Repository        =

> Size
> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D
> Installing:
>  slony1                  i386       1.2.15-3.rhel5   pgdg83            =

> 267 k
> Installing for dependencies:
>  perl-DBD-Pg             i386       2.11.5-1.el5.rf  rpmforge          =

> 301 k
>  perl-DBI                i386       1.607-1.el5.rf   rpmforge          =

> 866 k
>  perl-Net-Daemon         noarch     0.43-1.el5.rf    =

> rpmforge           44 k
>  perl-PlRPC              noarch     0.2020-1.el5.rf  =

> rpmforge           33 k
>  perl-version            i386       0.74-1.el5.rf    =

> rpmforge           76 k
>
> Transaction Summary
> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D
> Install      6 Package(s)
> Update       0 Package(s)
> Remove       0 Package(s)
>
> Total download size: 1.6 M
> Is this ok [y/N]: y
> Downloading Packages:
> (1/6): slony1-1.2.15-3.rh 100% |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D| 267 kB    00:00
> (2/6): perl-PlRPC-0.2020- 100% |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|  33 kB    00:00
> (3/6): perl-version-0.74- 100% |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|  76 kB    00:00
> (4/6): perl-Net-Daemon-0. 100% |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|  44 kB    00:00
> (5/6): perl-DBD-Pg-2.11.5 100% |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D| 301 kB    00:00
> (6/6): perl-DBI-1.607-1.e 100% |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D| 866 kB    00:02
> Running rpm_check_debug
> Running Transaction Test
> Finished Transaction Test
> Transaction Test Succeeded
> Running Transaction
>   Installing: perl-version                 ######################### [1/6]
>   Installing: perl-Net-Daemon              ######################### [2/6]
>   Installing: perl-PlRPC                   ######################### [3/6]
>   Installing: perl-DBI                     ######################### [4/6]
>   Installing: perl-DBD-Pg                  ######################### [5/6]
>   Installing: slony1                       ######################### [6/6]
>
> Installed: slony1.i386 0:1.2.15-3.rhel5
> Dependency Installed: perl-DBD-Pg.i386 0:2.11.5-1.el5.rf perl-DBI.i386 =

> 0:1.607-1.el5.rf perl-Net-Daemon.noarch 0:0.43-1.el5.rf =

> perl-PlRPC.noarch 0:0.2020-1.el5.rf perl-version.i386 0:0.74-1.el5.rf
> Complete!
>
>
>
> -bash-3.2# slo
> slogin                          slonik_drop_set                 =

> slonik_subscribe_set
> slon                            slonik_drop_table               =

> slonik_uninstall_nodes
> slon_kill                       slonik_execute_script           =

> slonik_unsubscribe_set
> slon_start                      slonik_failover                 =

> slonik_update_nodes
> slon_watchdog                   slonik_init_cluster             =

> slony-cluster-analysis-mass.sh
> slon_watchdog2                  slonik_merge_sets               =

> slony-cluster-analysis.sh
> slonik                          slonik_move_set                 =

> slony1_dump.sh
> slonik_build_env                slonik_print_preamble           =

> slony1_extract_schema.sh
> slonik_create_set               slonik_restart_node             =

> slony_logshipper
> slonik_drop_node                slonik_store_node               =

> slony_show_configuration
> -bash-3.2# slo
> slogin                          slonik_drop_set                 =

> slonik_subscribe_set
> slon                            slonik_drop_table               =

> slonik_uninstall_nodes
> slon_kill                       slonik_execute_script           =

> slonik_unsubscribe_set
> slon_start                      slonik_failover                 =

> slonik_update_nodes
> slon_watchdog                   slonik_init_cluster             =

> slony-cluster-analysis-mass.sh
> slon_watchdog2                  slonik_merge_sets               =

> slony-cluster-analysis.sh
> slonik                          slonik_move_set                 =

> slony1_dump.sh
> slonik_build_env                slonik_print_preamble           =

> slony1_extract_schema.sh
> slonik_create_set               slonik_restart_node             =

> slony_logshipper
> slonik_drop_node                slonik_store_node               =

> slony_show_configuration
> -bash-3.2#
>
>
>
>
>
>
>
>
>
> ------------------------------------------------------------------------
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>   =



-- =


4it

	=


*4IT **S.r.l.
**Marco Perugini* *| junior-little-newbie-baby-mini-system-administrator** *
---------------------------------------------------------
Via Udine 30-36, 00161 Roma
Phone +39 06 97601680
Mobile +39 339.39.81.246
Fax +39 06 97601683
m.perugini@4it.it <mailto:m.perugini@4it.it>
www.4it.it <http://www.4it.it/>

"Il presente messaggio e gli eventuali allegati sono di natura =

confidenziale. Qualora vi fosse pervenuto per errore, vi preghiamo di =

cancellarlo immediatamente dal vostro sistema e di avvisare il mittente. =

Grazie."

"This electronic mail transmission and any accompanying attachments =

contain confidential information. If you have received this =

communication in error, please immediately delete the E-mail and either =

notify the sender. Thank you."


-------------- next part --------------
Skipped content of type multipart/related
From madan.feedback at gmail.com  Sun Feb  1 15:09:22 2009
From: madan.feedback at gmail.com (Madan Thapa)
Date: Sun Feb  1 15:09:36 2009
Subject: [Slony1-general] Re: pg_config for slony1 install
In-Reply-To: <4985D20C.4010105@4it.it>
References: <4985D20C.4010105@4it.it>
Message-ID: <3a4237470902011509u1cafede4g341cb9d012f16eb1@mail.gmail.com>

On Sun, Feb 1, 2009 at 10:17 PM, marco perugini <m.perugini@4it.it> wrote:

>  hi madan thapa, i had the same problem.. i solved it installing the devel
> rpm also;
> so this is my rpm-postgres-list:
>
> # rpm -qa | grep post
> postgresql-contrib-8.3.5-1PGDG.rhel5
> postgresql-libs-8.3.5-1PGDG.rhel5
> postgresql-devel-8.3.5-1PGDG.rhel5
> postgresql-server-8.3.5-1PGDG.rhel5
> postgresql-8.3.5-1PGDG.rhel5
>
> if you install the devel rpm you'll find pg_config in /usr/bin
> # find / -name pg_config
> /usr/bin/pg_config
>
> good luck! ;)
> marco
>




Thanks  Marco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090202/=
fc053707/attachment.htm
From m.perugini at 4it.it  Mon Feb  2 02:49:59 2009
From: m.perugini at 4it.it (marco perugini)
Date: Mon Feb  2 02:50:33 2009
Subject: [Slony1-general] trigger and stored procedure
In-Reply-To: <4982A79A.3090202@lelarge.info>
References: <49819E3D.8000106@4it.it> <4981BC19.5030605@postgresqlfr.org>
	<498245B8.3030705@4it.it> <4982A79A.3090202@lelarge.info>
Message-ID: <4986CFD7.5010506@4it.it>

you're so right!!! someone changed trigger's db target without advising me..
merci guillaume and thanks to st=E9phane :)
marco

Guillaume Lelarge ha scritto:
> marco perugini a =E9crit :
>   =

>> does Slony deactivate already existing triggers on the master also? this
>> should be a problem.. :(
>>
>>     =

>
> No, only on the slaves.
>
>
>   =



-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090202/=
6bfa8b28/attachment.htm
From cbbrowne at ca.afilias.info  Mon Feb  2 14:50:25 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Feb  2 14:50:42 2009
Subject: [Slony1-general] setup where slave nodes can not connect each
	other
In-Reply-To: <4983283C.7000001@collax.com> (Tilman Baumann's message of "Fri, 
	30 Jan 2009 17:18:04 +0100")
References: <4983283C.7000001@collax.com>
Message-ID: <87fxiwcv2m.fsf@dba2.int.libertyrms.com>

Tilman Baumann <tilman.baumann@collax.com> writes:
> My cluster has gone out of sync since I added another node.
>
> The setup has one master and two slaves. The master can connect both
> slaves but each of the slaves can only connect to the master not the
> other slave.
> Is this setup feasible?
>
> The Master has a store path for each of the slaves. But the slaves
> have only one to the master.
> But each node Listens every other. This was created by the slonik
> command subscribe set.
> Am I right in assuming that listen does not necessaryly implies dorect
> db connection aka. store path?

If you run all of the slon processes on the "master" server, then
there won't be any issue; the slons will have access to all nodes.
That seems like the simplest resolution to this...
-- 
"cbbrowne","@","ca.afilias.info"
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)
From tilman.baumann at collax.com  Mon Feb  2 14:54:15 2009
From: tilman.baumann at collax.com (Tilman Baumann)
Date: Mon Feb  2 14:54:43 2009
Subject: [Slony1-general] setup where slave nodes can not connect each
	other
In-Reply-To: <87fxiwcv2m.fsf@dba2.int.libertyrms.com>
References: <4983283C.7000001@collax.com>
	<87fxiwcv2m.fsf@dba2.int.libertyrms.com>
Message-ID: <8F2E1662-467C-446C-A8BC-06C964883868@collax.com>


Am 02.02.2009 um 23:50 schrieb Christopher Browne:

> Tilman Baumann <tilman.baumann@collax.com> writes:
>> My cluster has gone out of sync since I added another node.
>>
>> The setup has one master and two slaves. The master can connect both
>> slaves but each of the slaves can only connect to the master not the
>> other slave.
>> Is this setup feasible?
>>
>> The Master has a store path for each of the slaves. But the slaves
>> have only one to the master.
>> But each node Listens every other. This was created by the slonik
>> command subscribe set.
>> Am I right in assuming that listen does not necessaryly implies  
>> dorect
>> db connection aka. store path?
>
> If you run all of the slon processes on the "master" server, then
> there won't be any issue; the slons will have access to all nodes.
> That seems like the simplest resolution to this...

Brilliant idea.
This would also keep the passwords off the slaves.Great.
From troy at troywolf.com  Wed Feb  4 14:46:35 2009
From: troy at troywolf.com (TroyWolf)
Date: Wed Feb  4 14:46:50 2009
Subject: [Slony1-general] Patch to have a defined table lock order
In-Reply-To: <BAYC1-PASMTP086FC2AFC1A8D76095CEDFAC760@CEZ.ICE>
References: <20071121233542.C2BA1116593E@zeus.directinfos.com>
	<474A1D23.9030504@Yahoo.com>
	<60y7cldmrc.fsf@dba2.int.libertyrms.com>
	<20071126163752.51D71116595D@zeus.directinfos.com>
	<BAYC1-PASMTP086FC2AFC1A8D76095CEDFAC760@CEZ.ICE>
Message-ID: <21841419.post@talk.nabble.com>



Steve Singer-2 wrote:
> 
> On Mon, 26 Nov 2007, Jacques Caron wrote:
>> One thing that would actually add more complexity, but would probably be 
>> quite useful: add options to EXECUTE SCRIPT to only lock (and 
>> un-trigger/re-trigger) specific tables (i.e. the ones that are actually 
>> affected, but manually specified in the options of EXECUTE SCRIPT). No
>> sense 
>> locking everybody, removing and restoring trigger all over the place, if
>> you 
>> only change one table with no side effects (no constraints, triggers,
>> etc.).
> 

This is an under-handed attempt to get attention for something slightly
related from people who may know something about it. Slony locking is
killing us, and I desperately want to understand what and why Slony locks
what it does.

PostgreSQL 8.2, Slony 1.2.12

I don't think I've ever found a good answer to this question: Why does Slony
lock ALL tables in the database regardless of whether those tables have
anything to do with the objects in the replication set? I explained a
real-world issue in detail in a post to this group, but never received any
real help. (See
http://www.nabble.com/Re:-Slony-locks-tables-that-are-not-even-in-replication-sets--td15677103.html#a15677103)

The issue that is killing us goes like this....Slony is doing nothing more
than it's every 10 minute cleanupEvents and a rare occasional tiny row
change to replicate. During the evening, we have batch processes that import
large quantities of data into huge history tables and then build indexes on
those tables. Those tables are not in the replication set and do not have
any relationships to or from any other tables. A typical index build may run
30 minutes or more--this is normal and expected. However, on occasion, Slony
will start to do SOMETHING that apparently locks some tables but then gets
stuck behind another transaction---like that long running index build.
During this entire time Slony is waiting, the locks he took out on the other
tables prevents other processes from accessing those tables. These other,
locked tables are also NOT IN ANY REPLICATION SET. The fact that these other
processes are blocked is a terrible problem for us. I cannot think of any
reason Slony needs to lock those tables.

So my questions are:

1. When and What tables does Slony lock?
2. Why does Slony lock non-replicated tables?
3. Does Slony 2 alleviate any of these locking issues? (move to PostgreSQL
8.3 required)

While I have your eyes, I wonder if anyone has tips on solving the
logshipping file access BUG I described in detail here:
http://www.nabble.com/BUG--?Logshipping-causes-failure-?when-slony-waiting-on-older-?transactions-to-finish-?td21503953.html 

I eagerly hope for a reply, and thank you very much for your time. Thank you
for giving us a pg replication solution!

-- 
View this message in context: http://www.nabble.com/Patch-to-have-a-defined-table-lock-order-tp13888289p21841419.html
Sent from the Slony-I -- General mailing list archive at Nabble.com.

From bipintigga at gmail.com  Thu Feb  5 00:39:18 2009
From: bipintigga at gmail.com (Bipin Tigga)
Date: Thu Feb  5 00:39:43 2009
Subject: [Slony1-general] Unable to fetch any rows from a given view
Message-ID: <9775e22f0902050039m4a98730bn4b38a94c162ebd25@mail.gmail.com>

Hi,

I am unable to fetch any rows from a given view.
Syntax of my query:

#SELECT * FROM <view_name>;

st_origin | st_received | st_last_event | st_last_event_ts |
st_last_received | st_last_received_ts | st_last_received_event_ts |
st_lag_num_events | st_lag_time
-----------+-------------+---------------+------------------+--------------=
----+---------------------+---------------------------+-------------------+=
-------------
(0 rows)

Kindly suggest how should I proceed and what to look for to resolve the
issue.

Thanks & Regards,
Bipin Tigga
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090205/=
48683f18/attachment.htm
From ajs at crankycanuck.ca  Thu Feb  5 06:20:02 2009
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Thu Feb  5 06:20:10 2009
Subject: [Slony1-general] Patch to have a defined table lock order
In-Reply-To: <21841419.post@talk.nabble.com>
References: <20071121233542.C2BA1116593E@zeus.directinfos.com>
	<474A1D23.9030504@Yahoo.com>
	<60y7cldmrc.fsf@dba2.int.libertyrms.com>
	<20071126163752.51D71116595D@zeus.directinfos.com>
	<BAYC1-PASMTP086FC2AFC1A8D76095CEDFAC760@CEZ.ICE>
	<21841419.post@talk.nabble.com>
Message-ID: <20090205142001.GF61414@shinkuro.com>

On Wed, Feb 04, 2009 at 02:46:35PM -0800, TroyWolf wrote:
> 
> I don't think I've ever found a good answer to this question: Why does Slony
> lock ALL tables in the database regardless of whether those tables have
> anything to do with the objects in the replication set? I explained a
> real-world issue in detail in a post to this group, but never received any
> real help. (See
> http://www.nabble.com/Re:-Slony-locks-tables-that-are-not-even-in-replication-sets--td15677103.html#a15677103)

The link you post there doesn't suggest that slony _does_ lock all
tables, and indeed that link includes a quote from me asking for more
information, which you didn't provide.  We can't give you "real help"
if we don't have enough data.

There are several levels of lock in Postgres, and I'm not even sure
that what you are attributing to Slony is its fault.  Slony should
_not_ lock tables that it doesn't know about.  

But you should understand that Slony needs access to tables.  Index
creation is a blocking operation.  There may, however, be a clue in
what you say.

> 30 minutes or more--this is normal and expected. However, on occasion, Slony
> will start to do SOMETHING that apparently locks some tables but then gets
> stuck behind another transaction---like that long running index build.
> During this entire time Slony is waiting, the locks he took out on the other
> tables prevents other processes from accessing those tables. These other,
> locked tables are also NOT IN ANY REPLICATION SET. The fact that these other
> processes are blocked is a terrible problem for us. I cannot think of any
> reason Slony needs to lock those tables.

Are there any foreign keys involved?  Remember that the FK stuff is
implemented with triggers that themselves attempt locks.  If Slony's
transaction causes such a lock to fire, it'll have to wait in line to
do what it wants.  It also has to wait in line behind something else
that has a lock blocking Slony writes.  You seem to think that Slony
might be trying to "lock" something, but I suspect what's really
happening is that Slony is trying to get a low-level lock, and can't.

All of this is rank speculation, however, without accurate details
from pg_locks and access to the system catalogue to understand what's
locked and how.

A


-- 
Andrew Sullivan
ajs@crankycanuck.ca
From kerdezixe at gmail.com  Tue Feb 10 04:51:35 2009
From: kerdezixe at gmail.com (Laurent Laborde)
Date: Tue Feb 10 04:52:09 2009
Subject: [Slony1-general] A few event not confirmed on one node
Message-ID: <8a1bfe660902100451h3c98298bgb7916ea5e546cdb0@mail.gmail.com>

Friendly greetings !


We have one master and many slave.
All slave have forward=true;

Slony : 1.2.15
Postgresql : 8.3.5

For some unknown reason one of the slave have old unconfirmed events.

master=# select * from _replication.sl_confirm order by con_timestamp limit 100;


 con_origin | con_received | con_seqno |       con_timestamp
------------+--------------+-----------+----------------------------
         17 |           23 |    121020 | 2009-02-03 12:05:21.170571
         17 |           21 |    121021 | 2009-02-03 12:05:31.172798
         17 |           24 |    121021 | 2009-02-03 12:05:31.220636
         17 |           25 |    121021 | 2009-02-03 12:05:31.398649
         17 |           12 |    121021 | 2009-02-03 12:05:31.462134
         17 |            2 |    121021 | 2009-02-03 12:05:31.53767
         17 |           27 |    121021 | 2009-02-03 12:05:33.104655
         17 |           26 |    121021 | 2009-02-03 12:05:33.191155
         17 |           16 |    121021 | 2009-02-03 12:05:35.335947
         17 |            5 |    121021 | 2009-02-03 12:05:46.437873
         16 |           25 |    851571 | 2009-02-10 13:33:38.684834
         16 |           24 |    851571 | 2009-02-10 13:33:38.754192
         16 |           22 |    851571 | 2009-02-10 13:33:38.780222
         16 |            2 |    851571 | 2009-02-10 13:33:38.78589
         16 |           12 |    851571 | 2009-02-10 13:33:38.786113
         16 |           17 |    851571 | 2009-02-10 13:33:38.787333
         16 |           27 |    851571 | 2009-02-10 13:33:38.820739
         16 |           26 |    851571 | 2009-02-10 13:33:38.827202
         16 |            5 |    851571 | 2009-02-10 13:33:38.83443
         16 |           23 |    851571 | 2009-02-10 13:33:38.896735
         16 |           21 |    851571 | 2009-02-10 13:33:38.90098

As you can see, there is some old unconfirmed event at 2009-02-03
12:05, and only from 17.
(17 is one of the slave)

i restarted slony, everywhere. restarted slony on the node 17 too.
Tried a cleanupEvent (which is done when a slond restart anyway)
Still here ...

i don't have any old event in sl_event, and the replication doesn't lag.

but i receive those messages (check_slony_state.pl in crontab) :

Node: 17 Confirmations not propagating from 17 to 12
================================================
Confirmations not propagating quickly in sl_confirm -

For origin node 17, receiver node 12, earliest propagated
confirmation has age 6 days 22:06:00 > 00:30:00

Are slons running for both nodes?

Could listen paths be missing so that confirmations are not propagating?

[...]

What can i do to solve this problem ?

Thank you :)

-- 
F4FQM
Kerunix Flan
Laurent Laborde
From quzhengping at gmail.com  Wed Feb 11 18:30:36 2009
From: quzhengping at gmail.com (Jumping)
Date: Wed Feb 11 18:30:57 2009
Subject: [Slony1-general] errors messages of compiling slony1 2.0.0 on
	debian etch(2.6.18-6-amd64)
Message-ID: <c640ff2f0902111830o24662101kb9152a23a5cfef1a@mail.gmail.com>

slony_logshipper.c: In function 'main':
slony_logshipper.c:476: warning: 'destfname.data' may be used
uninitialized in this function
gcc -g -O2 -Wall -Wmissing-prototypes -Wmissing-declarations -I../..
-DPGSHARE="\"/opt/mookr/po                stgresql-8.3.5/share/\""
-I/opt/mookr/postgresql-8.3.5/include/ -I/opt/mookr/postgresql-8.3.5/
              include/server/  -c -o dbutil.o dbutil.c
gcc -g -O2 -Wall -Wmissing-prototypes -Wmissing-declarations -I../..
-DPGSHARE="\"/opt/mookr/po                stgresql-8.3.5/share/\""
-I/opt/mookr/postgresql-8.3.5/include/ -I/opt/mookr/postgresql-8.3.5/
              include/server/  -c -o ipcutil.o ipcutil.c
bison -y -d  parser.y
mv -f y.tab.c parser.c
flex  -o'scan.c' scan.l
scan.l:438: warning, rule cannot be matched
gcc -g -O2 -Wall -Wmissing-prototypes -Wmissing-declarations -I../..
-DPGSHARE="\"/opt/mookr/po                stgresql-8.3.5/share/\""
-I/opt/mookr/postgresql-8.3.5/include/ -I/opt/mookr/postgresql-8.3.5/
              include/server/  -c -o parser.o parser.c
In file included from parser.y:1101:
scan.c:2506: warning: no previous prototype for 'yyget_lineno'
scan.c:2515: warning: no previous prototype for 'yyget_in'
scan.c:2523: warning: no previous prototype for 'yyget_out'
scan.c:2531: warning: no previous prototype for 'yyget_leng'
scan.c:2540: warning: no previous prototype for 'yyget_text'
scan.c:2549: warning: no previous prototype for 'yyset_lineno'
scan.c:2561: warning: no previous prototype for 'yyset_in'
scan.c:2566: warning: no previous prototype for 'yyset_out'
scan.c:2571: warning: no previous prototype for 'yyget_debug'
scan.c:2576: warning: no previous prototype for 'yyset_debug'
scan.c:2613: warning: no previous prototype for 'yylex_destroy'
gcc -g -O2 -Wall -Wmissing-prototypes -Wmissing-declarations -I../..
-DPGSHARE="\"/opt/mookr/po                stgresql-8.3.5/share/\""
slony_logshipper.o dbutil.o ipcutil.o parser.o  ../parsestatements/sc
              anner.o -L/opt/mookr/postgresql-8.3.5/lib/
-L/opt/mookr/postgresql-8.3.5/lib/ -lpq  -Wl,-rpath,
/opt/mookr/postgresql-8.3.5/lib/ -o slony_logshipper
make[2]: Leaving directory
`/home/jumping/slony/slony1-2.0.0/src/slony_logshipper'
make[1]: Leaving directory `/home/jumping/slony/slony1-2.0.0/src'
make[1]: Entering directory `/home/jumping/slony/slony1-2.0.0/tools'
for subdir in altperl ; do \
          make -C $subdir all || exit; \
        done
make[2]: Entering directory `/home/jumping/slony/slony1-2.0.0/tools/altperl'
make[2]: Nothing to be done for `all'.
make[2]: Leaving directory `/home/jumping/slony/slony1-2.0.0/tools/altperl'
make[1]: Leaving directory `/home/jumping/slony/slony1-2.0.0/tools'

-------------
Best Regards,
Jumping Qu
----------------------------------------------------------------------
Don't tell me how many enemies we have, but where they are!
(ADV:Perl -- It's like Java, only it lets you deliver on time and under budget.)
From vivek at khera.org  Wed Feb 11 19:18:35 2009
From: vivek at khera.org (Vick Khera)
Date: Wed Feb 11 19:18:57 2009
Subject: [Slony1-general] errors messages of compiling slony1 2.0.0 on 
	debian etch(2.6.18-6-amd64)
In-Reply-To: <c640ff2f0902111830o24662101kb9152a23a5cfef1a@mail.gmail.com>
References: <c640ff2f0902111830o24662101kb9152a23a5cfef1a@mail.gmail.com>
Message-ID: <2968dfd60902111918l2042e705s4f2e8c2e35e533ff@mail.gmail.com>

I don't see any *errors*, and it appears the build ran to completion.
From quzhengping at gmail.com  Wed Feb 11 20:09:39 2009
From: quzhengping at gmail.com (Jumping)
Date: Wed Feb 11 20:10:02 2009
Subject: [Slony1-general] errors messages of compiling slony1 2.0.0 on 
	debian etch(2.6.18-6-amd64)
In-Reply-To: <2968dfd60902111918l2042e705s4f2e8c2e35e533ff@mail.gmail.com>
References: <c640ff2f0902111830o24662101kb9152a23a5cfef1a@mail.gmail.com>
	<2968dfd60902111918l2042e705s4f2e8c2e35e533ff@mail.gmail.com>
Message-ID: <c640ff2f0902112009h1dc366edh389b27322ca3551b@mail.gmail.com>

the warnings drive me nuts.

On Thu, Feb 12, 2009 at 11:18 AM, Vick Khera <vivek@khera.org> wrote:
> I don't see any *errors*, and it appears the build ran to completion.
>



-- 
Best Regards,
Jumping Qu
------
Don't tell me how many enemies we have, but where they are!
(ADV:Perl -- It's like Java, only it lets you deliver on time and under budget.)
From glynastill at yahoo.co.uk  Thu Feb 12 01:37:11 2009
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Thu Feb 12 01:37:43 2009
Subject: [Slony1-general] errors messages of compiling slony1 2.0.0 on
	debian etch(2.6.18-6-amd64)
In-Reply-To: <c640ff2f0902112009h1dc366edh389b27322ca3551b@mail.gmail.com>
Message-ID: <561226.84139.qm@web23605.mail.ird.yahoo.com>

I get the same compiling on etch. The warnings that come out of a perfectly fine postgres compile are also a total c*nt.

> From: Jumping <quzhengping@gmail.com>
> the warnings drive me nuts.
> 
> On Thu, Feb 12, 2009 at 11:18 AM, Vick Khera
> <vivek@khera.org> wrote:
> > I don't see any *errors*, and it appears the build
> ran to completion.



      
From mark.hagger at m-spatial.com  Thu Feb 12 03:47:43 2009
From: mark.hagger at m-spatial.com (Mark Hagger)
Date: Thu Feb 12 03:48:20 2009
Subject: [Slony1-general] slony 1.2.x to 2.y upgrade status?
Message-ID: <1234439263.9270.4.camel@giga.cambridge.m-spatial.com>

Hi,

Has anyone had any more thoughts on being able to upgrade from 1.2.x to
2.0, without having to drop
all replication and recreate it?  I'm sort of reluctant to do a
drop/recreate because we have a large number
of databases being replicated and it sounds a little tedious, and I
assume will mean it'll have to re-sync from scratch.

Mark



________________________________________________________________________
This e-mail and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are addressed. The opinions expressed in this e-mail are those of the author and do not necessarily represent the views of m-spatial Ltd, mxData Ltd or any affiliates. No reliance may be placed on this e-mail without the written confirmation from an expressed representative of m-spatial Ltd or mxData Ltd. Any prices or terms expressed within this e-mail are subject to contract. If you are not the intended recipient of this email, please notify the postmaster@mxdata.co.uk.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090212/37c04542/attachment.htm
From cbbrowne at ca.afilias.info  Tue Feb 17 08:32:57 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Feb 17 08:33:06 2009
Subject: [Slony1-general] slony 1.2.x to 2.y upgrade status?
In-Reply-To: <1234439263.9270.4.camel@giga.cambridge.m-spatial.com> (Mark
	Hagger's message of "Thu, 12 Feb 2009 11:47:43 +0000")
References: <1234439263.9270.4.camel@giga.cambridge.m-spatial.com>
Message-ID: <871vtx81mu.fsf@dba2.int.libertyrms.com>

Mark Hagger <mark.hagger@m-spatial.com> writes:
> Has anyone had any more thoughts on being able to upgrade from 1.2.x
> to 2.0, without having to drop all replication and recreate it?? I'm
> sort of reluctant to do a drop/recreate because we have a large
> number of databases being replicated and it sounds a little tedious,
> and I assume will mean it'll have to re-sync from scratch.

I had a chat with Jan and others recently about this, and arrived at a
strategy that I intend to refine this week.

The "grand challenge" in said upgrade is that the format of the
transaction identification information has changed, so that
sl_log_[12], sl_confirm, sl_setsync, and sl_event all change in
format.

Trying to convert the values in these tables would actually be
counterproductive, as it would mean that, rather than 2.0 eliminating
the need for the "xxid" type and functions of 1.2, it would *increase*
the set, as we'd need the existing type, as well as C functions to
translate xxid values and combinations into txid_snapshot values.

Therefore, trying a *direct* conversion seems like a terrible idea.

Instead, what I propose doing is writing a script (or perhaps scripts)
that, in rough terms, does the following:

 1.  Locks all replication sets (akin to how MOVE SET works), so we
     can make certain that replication stops for a bit.

 2.  Waits for that to propagate everywhere, therefore establishing
     that all nodes are up to date.

 3.  Tells the administrator, "go ahead, install upgraded Slony-I."

 4.  Then, we go to each node, in turn, and, within a transaction, do
     the following:

     - First, load a function that does the work that follows,
       transforming from 1.2.16-ish to a "pre-2.0" state, *for the
       tables.* It does *not* load new functions; that's a subsequent
       step, #6.

     - It redoes the stored triggers on the tables, dropping the old
       ones, cleaning up FK triggers, and such.  (There's more detail
       to fill in here - nothing frightening, I don't think, just more
       detail!)

     - It runs TRUNCATE against the 4 tables mentioned earlier.

     - It inserts an sl_setsync entry, just as happens in copy_set()
       in src/slon/remote_worker.c, to indicate, for each replication
       set, that it is freshly copied on each subscriber node.

     - There will probably be a custom UPGRADE function; it can be
       dropped out at this point as it is never needed again.

     - Finally, we set this up to be a prepared truncation...
        PREPARE TRANSACTION "Slony-I 1.2 to 2.0 upgrade - @CLUSTER@";

     Note that at this point, that node is Pretty Locked Down.  This
     transaction has acquired locks on ALL tables involved in
     replication, including the application tables.

 5. If step #4 works successfully on all nodes, then we know we have a
    successful upgrade, and can safely go to each node and run COMMIT
    PREPARED on that transaction on each node.

    If any of them fail, then we should prefer to roll back all of the
    prepared transactions, undoing all of the work of step #4, go fix
    whatever was broken, and retry.

 6. Now, we need to update the functions.

    A slonik script runs UPDATE FUNCTIONS against all nodes.

At the "grand steps" level, that seems like it covers what needs to be
done.  I'll be going over the details in more detail this week; I
would welcome comments on anything I may have missed.
-- 
"cbbrowne","@","cbbrowne.com"
http://cbbrowne.com/info/wp.html
"...Yet terrible as Unix addiction  is, there are worse fates. If Unix
is the heroin of operating systems, then VMS is barbiturate addiction,
the Mac is MDMA, and MS-DOS is sniffing glue. (Windows is filling your
sinuses  with  lucite and  letting  it set.)   You  owe  the Oracle  a
twelve-step program."  --The Usenet Oracle
From cbbrowne at ca.afilias.info  Tue Feb 17 10:01:45 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Feb 17 10:01:55 2009
Subject: [Slony1-general] errors messages of compiling slony1 2.0.0 on
	debian etch(2.6.18-6-amd64)
In-Reply-To: <c640ff2f0902111830o24662101kb9152a23a5cfef1a@mail.gmail.com>
	(Jumping's message of "Thu, 12 Feb 2009 10:30:36 +0800")
References: <c640ff2f0902111830o24662101kb9152a23a5cfef1a@mail.gmail.com>
Message-ID: <87eixx6iye.fsf@dba2.int.libertyrms.com>

Jumping <quzhengping@gmail.com> writes:
> slony_logshipper.c: In function 'main':
> slony_logshipper.c:476: warning: 'destfname.data' may be used
> uninitialized in this function
> gcc -g -O2 -Wall -Wmissing-prototypes -Wmissing-declarations -I../..
> -DPGSHARE="\"/opt/mookr/po                stgresql-8.3.5/share/\""
> -I/opt/mookr/postgresql-8.3.5/include/ -I/opt/mookr/postgresql-8.3.5/
>               include/server/  -c -o dbutil.o dbutil.c
> gcc -g -O2 -Wall -Wmissing-prototypes -Wmissing-declarations -I../..
> -DPGSHARE="\"/opt/mookr/po                stgresql-8.3.5/share/\""
> -I/opt/mookr/postgresql-8.3.5/include/ -I/opt/mookr/postgresql-8.3.5/
>               include/server/  -c -o ipcutil.o ipcutil.c
> bison -y -d  parser.y
> mv -f y.tab.c parser.c
> flex  -o'scan.c' scan.l
> scan.l:438: warning, rule cannot be matched
> gcc -g -O2 -Wall -Wmissing-prototypes -Wmissing-declarations -I../..
> -DPGSHARE="\"/opt/mookr/po                stgresql-8.3.5/share/\""
> -I/opt/mookr/postgresql-8.3.5/include/ -I/opt/mookr/postgresql-8.3.5/
>               include/server/  -c -o parser.o parser.c
> In file included from parser.y:1101:
> scan.c:2506: warning: no previous prototype for 'yyget_lineno'
> scan.c:2515: warning: no previous prototype for 'yyget_in'
> scan.c:2523: warning: no previous prototype for 'yyget_out'
> scan.c:2531: warning: no previous prototype for 'yyget_leng'
> scan.c:2540: warning: no previous prototype for 'yyget_text'
> scan.c:2549: warning: no previous prototype for 'yyset_lineno'
> scan.c:2561: warning: no previous prototype for 'yyset_in'
> scan.c:2566: warning: no previous prototype for 'yyset_out'
> scan.c:2571: warning: no previous prototype for 'yyget_debug'
> scan.c:2576: warning: no previous prototype for 'yyset_debug'
> scan.c:2613: warning: no previous prototype for 'yylex_destroy'

These aren't actually errors - they are the pretty standard sorts of
irritations that fall out of using Bison :-(.

It would be nice to eliminate the -Wmissing-prototypes option to GCC
there, but I think that's about the best you could get as an
improvement.
-- 
output = ("cbbrowne" "@" "linuxfinances.info")
http://cbbrowne.com/info/languages.html
"I can't escape the sensation  that  I have  already been thinking  in
Lisp all   my programming  career,  but forcing    the ideas into  the
constraints of  bad  languages,  which   explode those  ideas  into  a
bewildering array  of details, most of  which are workarounds  for the
language." -- Kaz Kylheku
From karl at flightaware.com  Tue Feb 17 13:22:17 2009
From: karl at flightaware.com (Karl Lehenbauer)
Date: Tue Feb 17 13:22:32 2009
Subject: [Slony1-general] permission denied for sequence sl_action_seq -
	revisited
Message-ID: <E77D4E52-5000-4CB5-B32E-7F9B344ECEF6@flightaware.com>

Hi Slony People,

We have a 30 gigabyte database handling about 100M queries a day.  We  
recently started load balancing with slony and pgpool and it's working  
pretty well.  (I've documented a lot of stuff in our wiki -- will  
definitely turn it into a post.)

Anyway we have been getting a few "permission denied for sequence  
sl_action_seq" and had come across http://www.mail-archive.com/slony1-general@gborg.postgresql.org/msg03302.html 
  where it was asserted that "Calling lastval() instead of currval()  
is not safe against concurrent clients to begin with" and :However,  
unless you've stumbled across a bug in Postgres itself, there is  
nothing there that would cause any of the code to access a sequence  
different from the one your application specifies in the call."

I'm pretty sure neither statement is quite true. We determined that  
using currval and lastval *without explicitly stating the sequence*  
will substitute a sequence from the slony schema behind your back.

I've pasted an example here. In the first case, we select lastval and  
we a sequence from slony instead of what we want. (This is on the  
master.) In the second case where we explicitly name the sequence, it  
works.

I don't know that this is a bug or what it would take to fix it, but  
it should probably be documented that you can't use lastval() without  
an explicit sequence ID when doing slony, or something, anyway.

Thanks for great software.

Karl

sdidata=# BEGIN;
BEGIN
asdidata=# INSERT INTO ad_campaign(user_id,type,target)  
values(1,'airport','KMOO');
INSERT 0 1
asdidata=# SELECT lastval();
lastval
---------
157122
(1 row)
asdidata=# ROLLBACK;
ROLLBACK
asdidata=#
old way.
asdidata=# begin;
BEGIN
asdidata=# INSERT INTO ad_campaign(user_id,type,target)  
values(1,'airport','KMOO');
INSERT 0 1
asdidata=# SELECT currval('ad_campaign_id_seq');
currval
---------
122
(1 row)
asdidata=# ROLLBACK;
ROLLBACK
asdidata=#
new way


From plk.zuber at gmail.com  Tue Feb 17 18:14:50 2009
From: plk.zuber at gmail.com (=?UTF-8?Q?Filip_Rembia=C5=82kowski?=)
Date: Tue Feb 17 18:15:14 2009
Subject: [Slony1-general] permission denied for sequence sl_action_seq - 
	revisited
In-Reply-To: <E77D4E52-5000-4CB5-B32E-7F9B344ECEF6@flightaware.com>
References: <E77D4E52-5000-4CB5-B32E-7F9B344ECEF6@flightaware.com>
Message-ID: <92869e660902171814l1197d7e4v1475b2945d58e121@mail.gmail.com>
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From karl at flightaware.com  Tue Feb 17 19:44:21 2009
From: karl at flightaware.com (Karl Lehenbauer)
Date: Tue Feb 17 19:44:45 2009
Subject: [Slony1-general] permission denied for sequence sl_action_seq -
	revisited
In-Reply-To: <92869e660902171814l1197d7e4v1475b2945d58e121@mail.gmail.com>
References: <E77D4E52-5000-4CB5-B32E-7F9B344ECEF6@flightaware.com>
	<92869e660902171814l1197d7e4v1475b2945d58e121@mail.gmail.com>
Message-ID: <E05CA367-9F29-4274-B8A7-8BEFD9824642@flightaware.com>
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=
From lists at serioustechnology.com  Wed Feb 18 07:30:13 2009
From: lists at serioustechnology.com (Geoffrey)
Date: Wed Feb 18 07:30:19 2009
Subject: [Slony1-general] adding a field to a replicated table
Message-ID: <499C2985.8060805@serioustechnology.com>

As I've noted in the past, because of our software design, I can not use 
the 'execute script' process for adding a field to a table.  That being 
said, I'm looking for an alternative approach.  As it stands, when we 
need to add a table, we plan to shut slony down, create a new set for 
that table and restart slony.

What would be the best way to add a field to a replicated table using 
this scenario?  That is, shutting slony down, making the change and 
starting slony back up.  I'm assuming that I can't simply add the field 
to both nodes and restart slony, but if that would work, that would be 
great.

Thanks for any insights.

-- 
Until later, Geoffrey

Those who would give up essential Liberty, to purchase a little
temporary Safety, deserve neither Liberty nor Safety.
  - Benjamin Franklin
From karl at flightaware.com  Wed Feb 18 09:08:37 2009
From: karl at flightaware.com (Karl Lehenbauer)
Date: Wed Feb 18 09:08:47 2009
Subject: [Slony1-general] Dropping a slony-used index causes replication to
	fail completely
Message-ID: <02094AF1-3DC2-4882-89C8-EB9927326264@flightaware.com>

We ran across a problem where we wanted to delete a column in a table  
and didn't recognize that that column was used as a unique key index  
(nonprimary) by slony.

We did the "best practice" of testing it inside a BEGIN-ROLLBACK to  
make sure that it would go and then pushed it through  
slonik_execute_script and the effect was that all the slony triggers  
got dropped on the master.

We won't make that mistake again.

I guess this is impossible to easily detect and refuse to perform as  
you can't put triggers on "alter table" but could it maybe be made to  
still restore the triggers?

Just a thought...

Karl

From martin.marques at gmail.com  Wed Feb 18 09:52:46 2009
From: martin.marques at gmail.com (=?UTF-8?B?TWFydMOtbiBNYXJxdcOpcw==?=)
Date: Wed Feb 18 09:52:55 2009
Subject: [Slony1-general] Replication of a whole DB
Message-ID: <e73de96e0902180952y7ada8b11o5bba70faa469ba9d@mail.gmail.com>

Is there any easier/faster way of configuring Slony for replication of
a whole DB? The DB we are going to replicate has 3 schemas, 73 tables
and 111 sequences. It's gonna be a long slon_tools.conf file. :-(

-- 
Mart?n Marqu?s
select 'martin.marques' || '@' || 'gmail.com'
DBA, Programador, Administrador
From vivek at khera.org  Wed Feb 18 09:55:28 2009
From: vivek at khera.org (Vick Khera)
Date: Wed Feb 18 09:55:37 2009
Subject: [Slony1-general] Dropping a slony-used index causes replication 
	to fail completely
In-Reply-To: <02094AF1-3DC2-4882-89C8-EB9927326264@flightaware.com>
References: <02094AF1-3DC2-4882-89C8-EB9927326264@flightaware.com>
Message-ID: <2968dfd60902180955n2cdd52cbuf9c218962d817e8d@mail.gmail.com>

i think the real lesson is always have a PK, and get slony to use that
instead of using the misfeature to let slony use another column. :-)

On Wed, Feb 18, 2009 at 12:08 PM, Karl Lehenbauer <karl@flightaware.com> wrote:
> We ran across a problem where we wanted to delete a column in a table and
> didn't recognize that that column was used as a unique key index
> (nonprimary) by slony.
>
From cbbrowne at ca.afilias.info  Wed Feb 18 15:15:22 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Feb 18 15:15:42 2009
Subject: [Slony1-general] permission denied for sequence sl_action_seq -
	revisited
In-Reply-To: <E05CA367-9F29-4274-B8A7-8BEFD9824642@flightaware.com> (Karl
	Lehenbauer's message of "Tue, 17 Feb 2009 21:44:21 -0600")
References: <E77D4E52-5000-4CB5-B32E-7F9B344ECEF6@flightaware.com>
	<92869e660902171814l1197d7e4v1475b2945d58e121@mail.gmail.com>
	<E05CA367-9F29-4274-B8A7-8BEFD9824642@flightaware.com>
Message-ID: <87skmb5oc5.fsf@dba2.int.libertyrms.com>

Karl Lehenbauer <karl@flightaware.com> writes:
> Thanks for the reply, Filip. ?I don't get that it's a bug either,
> insofar as I can't even speculate on the amount of work to "fix" it,
> but it is a gotcha and could be a good thing to document in the
> FAQ. ?In any case, hopefully someone will find even this email
> exchange by googling and will save themselves some time when it
> happens to them.

It doesn't strike me as a terribly resolvable matter; yes, indeed, you
may readily capture, with lastval(), a value from one of the
Slony-I-internal sequences.

If you know which sequence whose value you want, I'd imagine you'd
want to "name that sequence."  To get "the last sequence updated"
seems *way* too nondeterministic for comfort!  If I have several
sequences in play, it could get pretty unpredictable which one I'd get
a value for, and the notion of grabbing whichever was the "last
updated" one is the sort of thing I'd want to smack our developers for
if they tried it ;-).

The very thought of using lastval() leaves me mighty queasy; lastval()
may be expected to be affected by *any* trigger that might get fired
along the way, and Slony-I's not the only thing one might introduce
like that.

I'll certainly see about noting this issue in the FAQ.  I'm not sure
it's quite "frequently asked," but there you go ;-).
-- 
(reverse (concatenate 'string "moc.enworbbc" "@" "enworbbc"))
http://www3.sympatico.ca/cbbrowne/languages.html
If a hole in the street is a manhole, is a hole in a man a streethole?
From stuart at stuartbishop.net  Wed Feb 18 23:48:39 2009
From: stuart at stuartbishop.net (Stuart Bishop)
Date: Wed Feb 18 23:49:07 2009
Subject: [Slony1-general] Replication of a whole DB
In-Reply-To: <e73de96e0902180952y7ada8b11o5bba70faa469ba9d@mail.gmail.com>
References: <e73de96e0902180952y7ada8b11o5bba70faa469ba9d@mail.gmail.com>
Message-ID: <6bc73d4c0902182348m321db214gb6fd24489c54f39a@mail.gmail.com>

On Thu, Feb 19, 2009 at 12:52 AM, Mart?n Marqu?s
<martin.marques@gmail.com> wrote:
> Is there any easier/faster way of configuring Slony for replication of
> a whole DB? The DB we are going to replicate has 3 schemas, 73 tables
> and 111 sequences. It's gonna be a long slon_tools.conf file. :-(

IIRC, slon_tools.conf is executed Perl and I had it building the table
and sequences list dynamically. Before I decided it was much easier in
our environment to ignore the perl scripts and stick with just slonik
and generating slonik scripts.

-- 
Stuart Bishop <stuart@stuartbishop.net>
http://www.stuartbishop.net/
From cbbrowne at ca.afilias.info  Thu Feb 19 09:26:41 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Feb 19 09:26:49 2009
Subject: [Slony1-general] Replication of a whole DB
In-Reply-To: <e73de96e0902180952y7ada8b11o5bba70faa469ba9d@mail.gmail.com>
	(UTF's message of "Wed, 18 Feb 2009 15:52:46 -0200")
References: <e73de96e0902180952y7ada8b11o5bba70faa469ba9d@mail.gmail.com>
Message-ID: <87hc2q5odq.fsf@dba2.int.libertyrms.com>

"=?UTF-8?B?TWFydMOtbiBNYXJxdcOpcw==?=" <martin.marques@gmail.com> writes:
> Is there any easier/faster way of configuring Slony for replication of
> a whole DB? The DB we are going to replicate has 3 schemas, 73 tables
> and 111 sequences. It's gonna be a long slon_tools.conf file. :-(

I'd do it as follows:

TABLES=`psql -d mydatabase -At -c "select  quote_ident(table_schema) || '.' || quote_ident(table_name) from information_schema.tables where table_type = 'BASE TABLE' and table_schema not in ('pg_catalog', 'information_schema');"` SEQUENCES=`psql -d mydatabase -At -c "select  quote_ident(sequence_schema) || '.' || quote_ident(sequence_name) from information_schema.sequences where sequence_schema not in ('pg_catalog', 'information_schema');"` sh tools/configure-replication.sh

./configure-replication.sh has generated Slony-I slonik scripts to initialize replication for SlonyTest.

Cluster name: PG83
Number of nodes: 2
Scripts are in /tmp/slonytest-temp.idUrMP
=====================

total 44
-rw-r--r-- 1 chris chris   165 2009-02-19 12:21 create_nodes.slonik
-rw-r--r-- 1 chris chris 24609 2009-02-19 12:21 create_set.slonik
-rw-r--r-- 1 chris chris   184 2009-02-19 12:21 preamble.slonik
-rw-r--r-- 1 chris chris   255 2009-02-19 12:21 store_paths.slonik
-rw-r--r-- 1 chris chris   113 2009-02-19 12:21 subscribe_set_2.slonik

=====================
Be sure to verify that the contents of /tmp/slonytest-temp.idUrMP/preamble.slonik very carefully, as
the configuration there is used widely in the other scripts.
=====================

That generated the slonik scripts described, and, as you can see by
the size of create_set.slonik, I had quite a few tables in that
database!  :-)

See tools/configure-replication.txt for more notes on the (many!) 
additional options that can be set.

I decline to add functionality into slonik or the Slony-I engine that
can, as is shown above, may be accomplished using the existing tools
via ONE SINGLE LINE of shell script.  (I admit it's a pretty long
line! ;-))
-- 
select 'cbbrowne' || '@' || 'cbbrowne.com';
http://linuxdatabases.info/info/linuxdistributions.html
Who wants to remember  that escape-x-alt-control-left shift-b puts you
into super-edit-debug-compile mode?  (Discussion in comp.os.linux.misc
on the intuitiveness of commands, especially Emacs.)
From cbbrowne at ca.afilias.info  Thu Feb 19 10:10:16 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Feb 19 10:10:26 2009
Subject: [Slony1-general] adding a field to a replicated table
In-Reply-To: <499C2985.8060805@serioustechnology.com> (Geoffrey's message of
	"Wed, 18 Feb 2009 10:30:13 -0500")
References: <499C2985.8060805@serioustechnology.com>
Message-ID: <874oyq5md3.fsf@dba2.int.libertyrms.com>

Geoffrey <lists@serioustechnology.com> writes:
> As I've noted in the past, because of our software design, I can not
> use the 'execute script' process for adding a field to a table.  That
> being said, I'm looking for an alternative approach.  As it stands,
> when we need to add a table, we plan to shut slony down, create a new
> set for that table and restart slony.
>
> What would be the best way to add a field to a replicated table using
> this scenario?  That is, shutting slony down, making the change and
> starting slony back up.  I'm assuming that I can't simply add the
> field to both nodes and restart slony, but if that would work, that
> would be great.

Well, what you need to do, underneath it all, is to make sure that the
"shape" of the replication configuration for the table gets set up
properly on all nodes.

The "minimal relevant" bits seem to be be that:

 - Obviously, the attribute needs to be added to the table
   :-)

 - The logtrigger needs to be set up properly on the origin node

   Take a look at function alterTableForReplication(tab_id) in
   src/backend/slony1_funcs.sql

 - All of this needs to take place at a compatible place in the
   "update stream" so that you don't have some updates sitting in
   sl_log_* with the "old" schema and other with the "new, altered,
   with-extra-column" schema.

   Actually, that part shouldn't be a *big* deal; sl_log_* store fully
   qualified inserts and such, so hopefully that will "just work," as
   long as updates don't hit the subscriber until the new column has
   gotten added.

Now, I should be clear to disclaim any "warrantee" on this; if you
choose NOT to use the build-in mechanisms like "EXECUTE SCRIPT," you
have to accept that you're doing your own "open heart surgery" by
hand, and that this is decidedly more risky.

If you have expressly accepted development practices that don't
conform to how Slony-I works, then that's a pretty strong hint that
there's not a particularly good fit there.  I'd not be offended if you
concluded that "Slony-I is not suitable because we do X, Y and Z..."

The amount of "surgery" you seem to want to do concerns me somewhat...
It sounds likely to lead to an unhappy ending, and unhappy users
aren't what we want.
-- 
"cbbrowne","@","linuxdatabases.info"
http://linuxfinances.info/info/nonrdbms.html
Change is inevitable, except from a vending machine. 
From cbbrowne at ca.afilias.info  Thu Feb 19 10:18:23 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Feb 19 10:18:32 2009
Subject: [Slony1-general] Dropping a slony-used index causes replication
	to fail completely
In-Reply-To: <02094AF1-3DC2-4882-89C8-EB9927326264@flightaware.com> (Karl
	Lehenbauer's message of "Wed, 18 Feb 2009 11:08:37 -0600")
References: <02094AF1-3DC2-4882-89C8-EB9927326264@flightaware.com>
Message-ID: <87y6w247f4.fsf@dba2.int.libertyrms.com>

Karl Lehenbauer <karl@flightaware.com> writes:
> We ran across a problem where we wanted to delete a column in a table
> and didn't recognize that that column was used as a unique key index
> (nonprimary) by slony.
>
> We did the "best practice" of testing it inside a BEGIN-ROLLBACK to
> make sure that it would go and then pushed it through
> slonik_execute_script and the effect was that all the slony triggers
> got dropped on the master.
>
> We won't make that mistake again.
>
> I guess this is impossible to easily detect and refuse to perform as
> you can't put triggers on "alter table" but could it maybe be made to
> still restore the triggers?
>
> Just a thought...

That suggests a DDL regression test :-).

I would *think* that if you drop that column, thereby making the
"candidate PK" go away, this should lead to an exception, thereby
causing the EXECUTE SCRIPT to roll back *without harm.*

I love the idea of adding a DDL script test where, as part of the DDL
script, we drop out the candidate PK, and validate that this EXECUTE
SCRIPT request fails.

In looking at alterTableForReplication(), it *looks* like it ought to
notice, and reject, this problem, but I'm certainly inclined to add a
test to make sure it does so.

Does that strategy sound useful?
-- 
"cbbrowne","@","acm.org"
http://www3.sympatico.ca/cbbrowne/linuxdistributions.html
In the name of the Lord-High mutant, we sacrifice this suburban girl
-- `Future Schlock'
From martin.marques at gmail.com  Fri Feb 20 12:36:01 2009
From: martin.marques at gmail.com (=?UTF-8?B?TWFydMOtbiBNYXJxdcOpcw==?=)
Date: Fri Feb 20 12:36:14 2009
Subject: [Slony1-general] pkeyedtables and sequences
Message-ID: <e73de96e0902201236y154db6b1p43f7e97a7982761d@mail.gmail.com>

Maybe a stupid question, but I can't find the info in the documentation.

When I add tables that have PK defined to a replication set, are the
sequnces of SERIAL PKs replicated as well, or do I have to add them to
the set?

Also, what's the meaning of table_id and sequence_id in SLONY_SETS in
slon_tools.conf?

-- 
Mart?n Marqu?s
select 'martin.marques' || '@' || 'gmail.com'
DBA, Programador, Administrador
From vivek at khera.org  Fri Feb 20 13:55:24 2009
From: vivek at khera.org (Vick Khera)
Date: Fri Feb 20 13:55:39 2009
Subject: [Slony1-general] pkeyedtables and sequences
In-Reply-To: <e73de96e0902201236y154db6b1p43f7e97a7982761d@mail.gmail.com>
References: <e73de96e0902201236y154db6b1p43f7e97a7982761d@mail.gmail.com>
Message-ID: <2968dfd60902201355r1c15ee09j776855777e0b65e9@mail.gmail.com>

On Fri, Feb 20, 2009 at 3:36 PM, Mart?n Marqu?s
<martin.marques@gmail.com> wrote:
> When I add tables that have PK defined to a replication set, are the
> sequnces of SERIAL PKs replicated as well, or do I have to add them to
> the set?

no. you have to add sequences explicitly to slony.

>
> Also, what's the meaning of table_id and sequence_id in SLONY_SETS in
> slon_tools.conf?

dunno about slon_tools.conf, but in slony proper they are ID numbers
to identify the tables.  Just assign them sequentially for best
results.
From cbbrowne at ca.afilias.info  Fri Feb 20 13:58:29 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri Feb 20 13:58:44 2009
Subject: [Slony1-general] pkeyedtables and sequences
In-Reply-To: <e73de96e0902201236y154db6b1p43f7e97a7982761d@mail.gmail.com>
	(UTF's message of "Fri, 20 Feb 2009 18:36:01 -0200")
References: <e73de96e0902201236y154db6b1p43f7e97a7982761d@mail.gmail.com>
Message-ID: <87k57k3h4q.fsf@dba2.int.libertyrms.com>

"=?UTF-8?B?TWFydMOtbiBNYXJxdcOpcw==?=" <martin.marques@gmail.com> writes:
> Maybe a stupid question, but I can't find the info in the documentation.
>
> When I add tables that have PK defined to a replication set, are the
> sequnces of SERIAL PKs replicated as well, or do I have to add them to
> the set?

You need to add them to a replication set, otherwise they will not be
replicated.

> Also, what's the meaning of table_id and sequence_id in SLONY_SETS in
> slon_tools.conf?

This indicates where the in-Slony identifiers for tables and sequences
starts its count.

If you see docs for SET ADD TABLE and SET ADD SEQUENCE...
http://slony.info/adminguide/slony1-1.2.13/doc/adminguide/stmtsetaddtable.html
http://slony.info/adminguide/slony1-1.2.13/doc/adminguide/stmtsetaddsequence.html

One of the parameters to those commands is the "ID".  That is a
unique-across-the-replication-cluster identifier for the table or
sequence.

slon-tools assigns values for these via a counter; by default,
starting at 1 is usually a reasonable idea.

If you are adding *additional* tables or sequences, at some later
time, you'll need to change the starting point, otherwise the slonik
code that is generated will try to do SET ADD TABLE (ID = 1, ...),
which would fail because there's already a table with ID=1.
-- 
let name="cbbrowne" and tld="linuxfinances.info" in name ^ "@" ^ tld;;
http://linuxfinances.info/info/multiplexor.html
Signs  of  a Klingon  Programmer  #10:  "You cannot  really appreciate
Dilbert unless you've read it in the original Klingon."
From steve at greengecko.co.nz  Fri Feb 20 15:26:32 2009
From: steve at greengecko.co.nz (Steve Holdoway)
Date: Fri Feb 20 15:26:57 2009
Subject: [Slony1-general] Firing a trigger on a slony replicated table...
Message-ID: <20090221122632.da16f795.steve@greengecko.co.nz>

Hey all, I'm trying to get a trigger to fire when an event happens on a slave table, replicated through slony 2.0.0. I know that the triggers work when I bulk load from file ( insert or copy syntax ), but when the table's under the control of slony, the addition of a row to the table doesn't trigger the event - which is a reformat of incoming data, and publishing to a new table.

I've tried adding the trigger before insert or update or delete, and after same, but to no avail.

Has anyone any ideas??

Cheers,

Steve
-- 
Steve Holdoway <steve@greengecko.co.nz>
From glynastill at yahoo.co.uk  Fri Feb 20 16:38:43 2009
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Fri Feb 20 16:39:03 2009
Subject: [Slony1-general] Firing a trigger on a slony replicated table...
In-Reply-To: <20090221122632.da16f795.steve@greengecko.co.nz>
Message-ID: <229875.54045.qm@web23603.mail.ird.yahoo.com>

Which version of slony? In 1.2.X use sloniks STORE TRIGGER command, in 2.0 use postgres ENABLE ALWAYS TRIGGER 


--- On Fri, 20/2/09, Steve Holdoway <steve@greengecko.co.nz> wrote:

> From: Steve Holdoway <steve@greengecko.co.nz>
> Subject: [Slony1-general] Firing a trigger on a slony replicated table...
> To: slony1-general@lists.slony.info
> Date: Friday, 20 February, 2009, 11:26 PM
> Hey all, I'm trying to get a trigger to fire when an
> event happens on a slave table, replicated through slony
> 2.0.0. I know that the triggers work when I bulk load from
> file ( insert or copy syntax ), but when the table's
> under the control of slony, the addition of a row to the
> table doesn't trigger the event - which is a reformat of
> incoming data, and publishing to a new table.
> 
> I've tried adding the trigger before insert or update
> or delete, and after same, but to no avail.
> 
> Has anyone any ideas??
> 
> Cheers,
> 
> Steve
> -- 
> Steve Holdoway <steve@greengecko.co.nz>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


      
From glynastill at yahoo.co.uk  Fri Feb 20 16:40:20 2009
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Fri Feb 20 16:40:49 2009
Subject: [Slony1-general] Firing a trigger on a slony replicated table...
In-Reply-To: <229875.54045.qm@web23603.mail.ird.yahoo.com>
Message-ID: <826239.54045.qm@web23603.mail.ird.yahoo.com>

Sorry it appears I cannot read. You said 2.0


--- On Sat, 21/2/09, Glyn Astill <glynastill@yahoo.co.uk> wrote:

> From: Glyn Astill <glynastill@yahoo.co.uk>
> Subject: Re: [Slony1-general] Firing a trigger on a slony replicated table...
> To: slony1-general@lists.slony.info, "Steve Holdoway" <steve@greengecko.co.nz>
> Date: Saturday, 21 February, 2009, 12:38 AM
> Which version of slony? In 1.2.X use sloniks STORE TRIGGER
> command, in 2.0 use postgres ENABLE ALWAYS TRIGGER 
> 
> 
> --- On Fri, 20/2/09, Steve Holdoway
> <steve@greengecko.co.nz> wrote:
> 
> > From: Steve Holdoway <steve@greengecko.co.nz>
> > Subject: [Slony1-general] Firing a trigger on a slony
> replicated table...
> > To: slony1-general@lists.slony.info
> > Date: Friday, 20 February, 2009, 11:26 PM
> > Hey all, I'm trying to get a trigger to fire when
> an
> > event happens on a slave table, replicated through
> slony
> > 2.0.0. I know that the triggers work when I bulk load
> from
> > file ( insert or copy syntax ), but when the
> table's
> > under the control of slony, the addition of a row to
> the
> > table doesn't trigger the event - which is a
> reformat of
> > incoming data, and publishing to a new table.
> > 
> > I've tried adding the trigger before insert or
> update
> > or delete, and after same, but to no avail.
> > 
> > Has anyone any ideas??
> > 
> > Cheers,
> > 
> > Steve
> > -- 
> > Steve Holdoway <steve@greengecko.co.nz>
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general@lists.slony.info
> >
> http://lists.slony.info/mailman/listinfo/slony1-general
> 
> 
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


      
From steve at greengecko.co.nz  Fri Feb 20 19:47:43 2009
From: steve at greengecko.co.nz (Steve Holdoway)
Date: Fri Feb 20 19:48:13 2009
Subject: [Slony1-general] Firing a trigger on a slony replicated table...
In-Reply-To: <20090221122632.da16f795.steve@greengecko.co.nz>
References: <20090221122632.da16f795.steve@greengecko.co.nz>
Message-ID: <20090221164743.b49cf8e9.steve@greengecko.co.nz>

On Sat, 21 Feb 2009 12:26:32 +1300
Steve Holdoway <steve@greengecko.co.nz> wrote:

with thanks offlist pointing me to the ENABLE ALWAYS TRIGGER , I'm moving slowly forwards. I'm now getting slony errors about violating unique keys when the insert statement to add to the table outside the replication - same database, separate schema. If I log in to the database from the command line, and copy/paste the statement posted as violating the unique key, it works fine.

Is there a decent writeup anywhere of that the environmental differences that I need to take into account to get this software working? 

In this case, I'm using an EXECUTE 'INSERT INTO...' syntax, as it's a dynamic string. If it's more efficient ( and available in pl/pgsql ), then I could use prepared statements instead...

Cheers,


Steve 
-- 
Steve Holdoway <steve@greengecko.co.nz>
From tam.mclaughlin at gmail.com  Mon Feb 23 08:25:14 2009
From: tam.mclaughlin at gmail.com (Tam McLaughlin)
Date: Mon Feb 23 09:13:58 2009
Subject: [Slony1-general] slony rep error on start up: Slony-I:
	setAddTable_int():
Message-ID: <fa4c18050902230825u6f7b7484j32d10c9afdb069a9@mail.gmail.com>

Hello,

I am having trouble with slony 1-2 as follows:

I was testing slony a few months back and was able to get replication
working. However, after upgrading slony by dropping all the replications and
recreating databases and configd, I keep getting a few errors, the most
recent and first error in the logs as follows:

GMT ERROR  remoteWorkerThread_1: "select "_mesrep".setAddTable_int(1, 1,
'"uk7501"."chart_data"', 'chart_data_pk', 'Table uk7501.chart_data with
primary key'); " PGRES_FATAL_ERROR ERROR:  Slony-I: setAddTable_int(): table
"uk7501"."chart_data" has no index chart_data_pk

Slony is:  v 1-2.0.0
Postgres is: 8.3.3
OS: centos 5.2

I have rebuilt slony from source and relocated the binaries to a different
directory.
The database I have used is a copy of a live db and have also dropped this,
recreated the db a few times and the replication. The only thing that I have
manually done is remove xxid.so so that it get's rebuilt but saw in the docs
that it is no longer used.

A previous error I kept getting was this:

GMT,"mes","MES",19171,"10.191.2.123:40188",48fdd267.4ae3,58,"UPDATE",2008-1=
0-21
14:00:23 BST,5/526583,2916342,ERROR,42703,"column ""log_xid"" of relation
""sl_log_1"" does not exist",,,"INSERT INTO _mescluster.sl_log_1
(log_origin, log_xid, log_tableid, log_actionseq, log_cmdtype, log_cmddata)
VALUES (1, $1, $2, nextval('_mescluster.sl_action_seq'), $3,
$4);",47,,"update UK4628.entity_

I am not sure what info you need in order to offer help, so I have included
extracts from my slony config and log files and the chart_data below.
Any help would be appreciated.

Thanks
Tam

Slony Config
-----------
if ($ENV{"SLONYNODES"}) {
    require $ENV{"SLONYNODES"};
} else {
    $CLUSTER_NAME =3D 'mesrep';
    $LOGDIR =3D '/var/log/slony';
    $MASTERNODE =3D 1;
    $DEBUGLEVEL =3D 4;
    add_node(node     =3D> 1,
             host     =3D> 'uklnxmes-cl',
             dbname   =3D> 'tam1',
             port     =3D> 5432,
             parent   =3D> 1,
             user     =3D> 'xxxxxx',
             password =3D> 'xxxxxx');
    add_node(node     =3D> 2,
             host     =3D> 'uklnxdisp1',
             dbname   =3D> 'tam1',
             port     =3D> 5432,
             parent   =3D> 1,
             user     =3D> 'xxxxxx',
             password =3D> 'xxxxxx');
}
$SLONY_SETS =3D {
    "set1" =3D> { "set_id"       =3D> 1,
                "table_id"     =3D> 1,
                "sequence_id"  =3D> 1,
                "pkeyedtables" =3D> [ "uk7501.chart_data",
                                    "uk7501.chart_error_actions",
                                    "uk7501.charts",
                                    "uk7501.entities",
                                    "uk7501.entities_history_data",
                                    "uk7501.entity_attr_data",
                                         <snip>
                                   "uk7501.tables",
                                    "uk4628.calendar",
                                    "uk4628.chart_data",
                                    "uk4628.chart_error_actions",
                                    "uk4628.charts",
                                    <snip>
                                    "uk4628.table_data",
                                    "uk4628.tables"
                                  ],
                "keyedtables"   =3D>  {},
                "serialtables"  =3D>  [],
                "sequences"     =3D> [ "uk7501.dbkeys",
                                     "uk7501.txid",
                                     "uk4628.dbkeys",
                                     "uk4628.txid"
                                   ]
              }
};
if ($ENV{"SLONYSET"}) {
    require $ENV{"SLONYSET"};
}
# Please do not add or change anything below this point.
1;


log file for node2:  error at bottom
--------------------
--------------------
2009-02-23 15:34:58 GMT CONFIG main: slon version 2.0.0 starting up
2009-02-23 15:34:58 GMT INFO   slon: watchdog process started
2009-02-23 15:34:58 GMT CONFIG slon: watchdog ready - pid =3D 28747
<snip>
2009-02-23 15:34:58 GMT CONFIG main: Boolean option log_timestamp =3D 1
2009-02-23 15:34:58 GMT CONFIG main: Boolean option cleanup_deletelogs =3D 0
2009-02-23 15:34:58 GMT CONFIG main: Real option real_placeholder =3D 0.000=
000
2009-02-23 15:34:58 GMT CONFIG main: String option cluster_name =3D mesrep
2009-02-23 15:34:58 GMT CONFIG main: String option conn_info =3D
host=3Duklnxdisp1 dbname=3Dtam1 user=3Dxxxxxx port=3D5432 password=3Dxxxxxx
2009-02-23 15:34:58 GMT CONFIG main: String option pid_file =3D (null)
2009-02-23 15:34:58 GMT CONFIG main: String option log_timestamp_format =3D
%Y-%m-%d %H:%M:%S %Z
2009-02-23 15:34:58 GMT CONFIG main: String option archive_dir =3D (null)
2009-02-23 15:34:58 GMT CONFIG main: String option sql_on_connection =3D
(null)
2009-02-23 15:34:58 GMT CONFIG main: String option lag_interval =3D (null)
2009-02-23 15:34:58 GMT CONFIG main: String option command_on_logarchive =
=3D
(null)
2009-02-23 15:34:58 GMT CONFIG main: String option syslog_facility =3D LOCA=
L0
2009-02-23 15:34:58 GMT CONFIG main: String option syslog_ident =3D slon
2009-02-23 15:34:58 GMT CONFIG main: String option cleanup_interval =3D 10
minutes
2009-02-23 15:34:58 GMT CONFIG slon: worker process created - pid =3D 28749
2009-02-23 15:34:58 GMT CONFIG main: local node id =3D 2
2009-02-23 15:34:58 GMT INFO   main: main process started
2009-02-23 15:34:58 GMT CONFIG main: launching sched_start_mainloop
2009-02-23 15:34:58 GMT CONFIG main: loading current cluster configuration
2009-02-23 15:34:58 GMT CONFIG storeNode: no_id=3D1 no_comment=3D'Node 1 -
tam1@uklnxmes-cl'
2009-02-23 15:34:58 GMT DEBUG2 setNodeLastEvent: no_id=3D1 event_seq=3D1
2009-02-23 15:34:58 GMT CONFIG storePath: pa_server=3D1 pa_client=3D2
pa_conninfo=3D"host=3Duklnxmes-cl dbname=3Dtam1 user=3Dxxxxxx port=3D5432
password=3Dxxxxxx" pa_connretry=3D10
2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=3D1 li_receiver=3D2
li_provider=3D1
2009-02-23 15:34:58 GMT CONFIG main: last local event sequence =3D 1
2009-02-23 15:34:58 GMT CONFIG main: configuration complete - starting
threads
2009-02-23 15:34:58 GMT INFO   localListenThread: thread starts
2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxdisp1 dbname=3Dtam1
user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
2009-02-23 15:34:58 GMT DEBUG1 local_listen "host=3Duklnxdisp1 dbname=3Dtam1
user=3Dxx2009-02-23 15:34:58 GMT INFO   remoteWorkerThread_1: thread starts
2009-02-23 15:34:58 GMT CONFIG cleanupThread: thread starts
2009-02-23 15:34:58 GMT CONFIG cleanupThread: bias =3D 35383
2009-02-23 15:34:58 GMT INFO   remoteListenThread_1: thread starts
2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: start listening for
event origin 1
2009-02-23 15:34:58 GMT INFO   main: running scheduler mainloop
2009-02-23 15:34:58 GMT INFO   syncThread: thread starts
2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxmes-cl dbname=3Dtam1
user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
2009-02-23 15:34:58 GMT DEBUG1 node_1_listen "host=3Duklnxmes-cl dbname=3Dt=
am1
user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 28764
2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxdisp1 dbname=3Dtam1
user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
2009-02-23 15:34:58 GMT DEBUG1 local_sync "host=3Duklnxdisp1 dbname=3Dtam1
user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 8067
2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxdisp1 dbname=3Dtam1
user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxdisp1 dbname=3Dtam1
user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
2009-02-23 15:34:58 GMT DEBUG1 local_cleanup "host=3Duklnxdisp1 dbname=3Dta=
m1
user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 8068
2009-02-23 15:34:58 GMT DEBUG1 remoteListenThread_1: connected to
'host=3Duklnxmes-cl dbname=3Dtam1 user=3Dxxxxxx port=3D5432 password=3Dxxxx=
xx'
2009-02-23 15:34:58 GMT DEBUG1 remoteWorkerThread_1 "host=3Duklnxdisp1
dbname=3Dtam1 user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D=
 8066
2009-02-23 15:34:58 GMT CONFIG remoteWorkerThread_1: update provider
configuration
2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,2
STORE_NODE
2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,3
ENABLE_NODE
2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,4
STORE_PATH
2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,5 SYNC
2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
2 type:STORE_NODE
TODO: ********** remoteWorkerThread: node 1 - EVENT 1,2 STORE_NODE - unknown
event type
2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=3D1 li_receiver=3D2
li_provider=3D1
2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads +
worker signaled)
2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads +
worker signaled)
2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: forward confirm 2,1
received by 1
2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
3 type:ENABLE_NODE
xxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 8065
TODO: ********** remoteWorkerThread: node 1 - EVENT 1,3 ENABLE_NODE -
unknown event type
2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=3D1 li_receiver=3D2
li_provider=3D1
2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads +
worker signaled)
2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads +
worker signaled)
2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
4 type:STORE_PATH
2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=3D1 li_receiver=3D2
li_provider=3D1
2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads +
worker signaled)
2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads +
worker signaled)
2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
5 type:SYNC
2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: SYNC 5 processing
2009-02-23 15:34:58 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
for this event
2009-02-23 15:34:58 GMT CONFIG remoteWorkerThread_1: update provider
configuration
2009-02-23 15:34:59 GMT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 2
2009-02-23 15:35:01 GMT DEBUG2 localListenThread: Received event 2,2 SYNC
2009-02-23 15:35:02 GMT DEBUG2 remoteWorkerThread_1: forward confirm 2,2
received by 1
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,6
STORE_SET
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,7
SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
6 type:STORE_SET
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,8
SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,9
SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,10
SET_ADD_TABLE
<snip
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,18
SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,19
SET_ADD_TABLE
2009-02-23 15:35:29 GMT CONFIG storeSet: set_id=3D1 set_origin=3D1
set_comment=3D'Set 1 for mesrep'
2009-02-23 15:35:29 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads +
worker signaled)
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,20
SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,21
SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,22
SET_ADD_TABLE
<snip>
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,117
SET_ADD_SEQUENCE
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,118
SET_ADD_SEQUENCE
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,119
SET_ADD_SEQUENCE
2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,120 SYNC
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
7 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
8 type:SET_ADD_TABLE

2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
12 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
13 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
14 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
15 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
16 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
17 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
18 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT CONFIG remoteWorkerThread_1: update provider
configuration
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
19 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
20 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
21 type:SET_ADD_TABLE
<snip>
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
113 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
114 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
115 type:SET_ADD_TABLE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
116 type:SET_ADD_SEQUENCE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
117 type:SET_ADD_SEQUENCE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
118 type:SET_ADD_SEQUENCE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
119 type:SET_ADD_SEQUENCE
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
120 type:SYNC
2009-02-23 15:35:29 GMT DEBUG1 calc sync size - last time: 1 last length:
31050 ideal: 1 proposed size: 1
2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: SYNC 120 processing
2009-02-23 15:35:29 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
for this event
2009-02-23 15:35:40 GMT DEBUG2 remoteListenThread_1: queue event 1,121 SYNC
2009-02-23 15:35:40 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
121 type:SYNC
2009-02-23 15:35:40 GMT DEBUG1 calc sync size - last time: 1 last length:
10941 ideal: 5 proposed size: 3
2009-02-23 15:35:40 GMT DEBUG2 remoteWorkerThread_1: SYNC 121 processing
2009-02-23 15:35:40 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
for this event
2009-02-23 15:35:51 GMT DEBUG2 remoteListenThread_1: queue event 1,122 SYNC
2009-02-23 15:35:51 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
122 type:SYNC
2009-02-23 15:35:51 GMT DEBUG1 calc sync size - last time: 1 last length:
11002 ideal: 5 proposed size: 3
2009-02-23 15:35:51 GMT DEBUG2 remoteWorkerThread_1: SYNC 122 processing
2009-02-23 15:35:51 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
for this event
2009-02-23 15:36:02 GMT DEBUG2 remoteListenThread_1: queue event 1,123 SYNC
2009-02-23 15:36:02 GMT DEBUG2 remoteListenThread_1: queue event 1,124
SUBSCRIBE_SET
2009-02-23 15:36:02 GMT DEBUG2 remoteListenThread_1: queue event 1,125
ENABLE_SUBSCRIPTION
2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
123 type:SYNC
2009-02-23 15:36:02 GMT DEBUG1 calc sync size - last time: 1 last length:
11002 ideal: 5 proposed size: 3
2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: SYNC 123 processing
2009-02-23 15:36:02 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
for this event
2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
124 type:SUBSCRIBE_SET
2009-02-23 15:36:02 GMT CONFIG storeSubscribe: sub_set=3D1 sub_provider=3D1
sub_forward=3D't'
2009-02-23 15:36:02 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads +
worker signaled)
2009-02-23 15:36:02 GMT CONFIG storeListen: li_origin=3D1 li_receiver=3D2
li_provider=3D1
2009-02-23 15:36:02 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads +
worker signaled)
2009-02-23 15:36:02 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads +
worker signaled)
2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
125 type:ENABLE_SUBSCRIPTION
2009-02-23 15:36:02 GMT INFO   copy_set 1
2009-02-23 15:36:02 GMT CONFIG version for "host=3Duklnxmes-cl dbname=3Dtam1
user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
2009-02-23 15:36:02 GMT DEBUG1 copy_set_1 "host=3Duklnxmes-cl dbname=3Dtam1
user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 29445
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: connected to provider
DB
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
"uk7501"."chart_data"
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
"uk7501"."chart_error_actions"
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
"uk7501"."charts"
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
"uk7501"."entities"
<snip>
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
"uk4628"."script_version"
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
"uk4628"."scripts"
   2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy
table "uk4628"."scriptsteps"
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
"uk4628"."table_data"
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
"uk4628"."tables"
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: all tables for set 1
found on subscriber
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
"uk7501"."dbkeys"
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
"uk7501"."txid"
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
"uk4628"."dbkeys"
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
"uk4628"."txid"
2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy table
"uk7501"."chart_data"
2009-02-23 15:36:02 GMT ERROR  remoteWorkerThread_1: "select
"_mesrep".setAddTable_int(1, 1, '"uk7501"."chart_data"', 'chart_data_pk',
'Table uk7501.chart_data with primary key'); " PGRES_FATAL_ERROR ERROR:
Slony-I: setAddTable_int(): table "uk7501"."chart_data" has no index
chart_data_pk
2009-02-23 15:36:02 GMT WARN   remoteWorkerThread_1: data copy for set 1
failed - sleep 15 seconds
2009-02-23 15:36:13 GMT DEBUG2 remoteListenThread_1: queue event 1,126 SYNC
2009-02-23 15:36:17 GMT INFO   copy_set 1






chart_date schema
-----------------
SET default_with_oids =3D false;
CREATE TABLE chart_data (
    chart character varying(20) NOT NULL,
    entry integer NOT NULL,
    value real,
    value_2 real,
    violations character varying(8),
    violations_2 character varying(8),
    flags character varying(8),
    lots text,
    entity character varying(20),
    operator character varying(20),
    datetime timestamp without time zone,
    txid bigint,
    comments text
);

ALTER TABLE uk7501.chart_data OWNER TO mes;
ALTER TABLE ONLY chart_data
    ADD CONSTRAINT chart_data_pk PRIMARY KEY (chart, entry);

CREATE TRIGGER _mesrep_denyaccess
    BEFORE INSERT OR DELETE OR UPDATE ON chart_data
    FOR EACH ROW
    EXECUTE PROCEDURE _mesrep.denyaccess('_mesrep');
ALTER TABLE chart_data DISABLE TRIGGER _mesrep_denyaccess;
CREATE TRIGGER _mesrep_logtrigger
    AFTER INSERT OR DELETE OR UPDATE ON chart_data
    FOR EACH ROW
    EXECUTE PROCEDURE _mesrep.logtrigger('_mesrep', '1', 'kk');
ALTER TABLE ONLY chart_data
REVOKE ALL ON TABLE chart_data FROM PUBLIC;
REVOKE ALL ON TABLE chart_data FROM mes;
GRANT ALL ON TABLE chart_data TO mes;
GRANT SELECT ON TABLE chart_data TO mesview;
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090223/=
09215ac0/attachment-0001.htm
From jeff at frostconsultingllc.com  Mon Feb 23 09:23:15 2009
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Mon Feb 23 09:24:16 2009
Subject: [Slony1-general] slony rep error on start up: Slony-I:
	setAddTable_int():
In-Reply-To: <fa4c18050902230825u6f7b7484j32d10c9afdb069a9@mail.gmail.com>
References: <fa4c18050902230825u6f7b7484j32d10c9afdb069a9@mail.gmail.com>
Message-ID: <EMEWEMEW2_DELIMl1MBNH86f607571dca6a1131bceb,
	jeff@frostconsultingllc.com,
	Pine.LNX.4.64.0902230922440.15472@discord>

On Mon, 23 Feb 2009, Tam McLaughlin wrote:

> Hello,
>
> I am having trouble with slony 1-2 as follows:
>
> I was testing slony a few months back and was able to get replication
> working. However, after upgrading slony by dropping all the replications and
> recreating databases and configd, I keep getting a few errors, the most
> recent and first error in the logs as follows:
>
> GMT ERROR  remoteWorkerThread_1: "select "_mesrep".setAddTable_int(1, 1,
> '"uk7501"."chart_data"', 'chart_data_pk', 'Table uk7501.chart_data with
> primary key'); " PGRES_FATAL_ERROR ERROR:  Slony-I: setAddTable_int(): table
> "uk7501"."chart_data" has no index chart_data_pk

That sure looks like you are missing the chart_data_pk (primary key?) index on 
chart_data.  What does \d chart_data yield in psql?

>
> Slony is:  v 1-2.0.0
> Postgres is: 8.3.3
> OS: centos 5.2
>
> I have rebuilt slony from source and relocated the binaries to a different
> directory.
> The database I have used is a copy of a live db and have also dropped this,
> recreated the db a few times and the replication. The only thing that I have
> manually done is remove xxid.so so that it get's rebuilt but saw in the docs
> that it is no longer used.
>
> A previous error I kept getting was this:
>
> GMT,"mes","MES",19171,"10.191.2.123:40188",48fdd267.4ae3,58,"UPDATE",2008-10-21
> 14:00:23 BST,5/526583,2916342,ERROR,42703,"column ""log_xid"" of relation
> ""sl_log_1"" does not exist",,,"INSERT INTO _mescluster.sl_log_1
> (log_origin, log_xid, log_tableid, log_actionseq, log_cmdtype, log_cmddata)
> VALUES (1, $1, $2, nextval('_mescluster.sl_action_seq'), $3,
> $4);",47,,"update UK4628.entity_
>
> I am not sure what info you need in order to offer help, so I have included
> extracts from my slony config and log files and the chart_data below.
> Any help would be appreciated.
>
> Thanks
> Tam
>
> Slony Config
> -----------
> if ($ENV{"SLONYNODES"}) {
>    require $ENV{"SLONYNODES"};
> } else {
>    $CLUSTER_NAME = 'mesrep';
>    $LOGDIR = '/var/log/slony';
>    $MASTERNODE = 1;
>    $DEBUGLEVEL = 4;
>    add_node(node     => 1,
>             host     => 'uklnxmes-cl',
>             dbname   => 'tam1',
>             port     => 5432,
>             parent   => 1,
>             user     => 'xxxxxx',
>             password => 'xxxxxx');
>    add_node(node     => 2,
>             host     => 'uklnxdisp1',
>             dbname   => 'tam1',
>             port     => 5432,
>             parent   => 1,
>             user     => 'xxxxxx',
>             password => 'xxxxxx');
> }
> $SLONY_SETS = {
>    "set1" => { "set_id"       => 1,
>                "table_id"     => 1,
>                "sequence_id"  => 1,
>                "pkeyedtables" => [ "uk7501.chart_data",
>                                    "uk7501.chart_error_actions",
>                                    "uk7501.charts",
>                                    "uk7501.entities",
>                                    "uk7501.entities_history_data",
>                                    "uk7501.entity_attr_data",
>                                         <snip>
>                                   "uk7501.tables",
>                                    "uk4628.calendar",
>                                    "uk4628.chart_data",
>                                    "uk4628.chart_error_actions",
>                                    "uk4628.charts",
>                                    <snip>
>                                    "uk4628.table_data",
>                                    "uk4628.tables"
>                                  ],
>                "keyedtables"   =>  {},
>                "serialtables"  =>  [],
>                "sequences"     => [ "uk7501.dbkeys",
>                                     "uk7501.txid",
>                                     "uk4628.dbkeys",
>                                     "uk4628.txid"
>                                   ]
>              }
> };
> if ($ENV{"SLONYSET"}) {
>    require $ENV{"SLONYSET"};
> }
> # Please do not add or change anything below this point.
> 1;
>
>
> log file for node2:  error at bottom
> --------------------
> --------------------
> 2009-02-23 15:34:58 GMT CONFIG main: slon version 2.0.0 starting up
> 2009-02-23 15:34:58 GMT INFO   slon: watchdog process started
> 2009-02-23 15:34:58 GMT CONFIG slon: watchdog ready - pid = 28747
> <snip>
> 2009-02-23 15:34:58 GMT CONFIG main: Boolean option log_timestamp = 1
> 2009-02-23 15:34:58 GMT CONFIG main: Boolean option cleanup_deletelogs = 0
> 2009-02-23 15:34:58 GMT CONFIG main: Real option real_placeholder = 0.000000
> 2009-02-23 15:34:58 GMT CONFIG main: String option cluster_name = mesrep
> 2009-02-23 15:34:58 GMT CONFIG main: String option conn_info =
> host=uklnxdisp1 dbname=tam1 user=xxxxxx port=5432 password=xxxxxx
> 2009-02-23 15:34:58 GMT CONFIG main: String option pid_file = (null)
> 2009-02-23 15:34:58 GMT CONFIG main: String option log_timestamp_format =
> %Y-%m-%d %H:%M:%S %Z
> 2009-02-23 15:34:58 GMT CONFIG main: String option archive_dir = (null)
> 2009-02-23 15:34:58 GMT CONFIG main: String option sql_on_connection =
> (null)
> 2009-02-23 15:34:58 GMT CONFIG main: String option lag_interval = (null)
> 2009-02-23 15:34:58 GMT CONFIG main: String option command_on_logarchive =
> (null)
> 2009-02-23 15:34:58 GMT CONFIG main: String option syslog_facility = LOCAL0
> 2009-02-23 15:34:58 GMT CONFIG main: String option syslog_ident = slon
> 2009-02-23 15:34:58 GMT CONFIG main: String option cleanup_interval = 10
> minutes
> 2009-02-23 15:34:58 GMT CONFIG slon: worker process created - pid = 28749
> 2009-02-23 15:34:58 GMT CONFIG main: local node id = 2
> 2009-02-23 15:34:58 GMT INFO   main: main process started
> 2009-02-23 15:34:58 GMT CONFIG main: launching sched_start_mainloop
> 2009-02-23 15:34:58 GMT CONFIG main: loading current cluster configuration
> 2009-02-23 15:34:58 GMT CONFIG storeNode: no_id=1 no_comment='Node 1 -
> tam1@uklnxmes-cl'
> 2009-02-23 15:34:58 GMT DEBUG2 setNodeLastEvent: no_id=1 event_seq=1
> 2009-02-23 15:34:58 GMT CONFIG storePath: pa_server=1 pa_client=2
> pa_conninfo="host=uklnxmes-cl dbname=tam1 user=xxxxxx port=5432
> password=xxxxxx" pa_connretry=10
> 2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=1 li_receiver=2
> li_provider=1
> 2009-02-23 15:34:58 GMT CONFIG main: last local event sequence = 1
> 2009-02-23 15:34:58 GMT CONFIG main: configuration complete - starting
> threads
> 2009-02-23 15:34:58 GMT INFO   localListenThread: thread starts
> 2009-02-23 15:34:58 GMT CONFIG version for "host=uklnxdisp1 dbname=tam1
> user=xxxxxx port=5432 password=xxxxxx" is 80303
> 2009-02-23 15:34:58 GMT DEBUG1 local_listen "host=uklnxdisp1 dbname=tam1
> user=xx2009-02-23 15:34:58 GMT INFO   remoteWorkerThread_1: thread starts
> 2009-02-23 15:34:58 GMT CONFIG cleanupThread: thread starts
> 2009-02-23 15:34:58 GMT CONFIG cleanupThread: bias = 35383
> 2009-02-23 15:34:58 GMT INFO   remoteListenThread_1: thread starts
> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: start listening for
> event origin 1
> 2009-02-23 15:34:58 GMT INFO   main: running scheduler mainloop
> 2009-02-23 15:34:58 GMT INFO   syncThread: thread starts
> 2009-02-23 15:34:58 GMT CONFIG version for "host=uklnxmes-cl dbname=tam1
> user=xxxxxx port=5432 password=xxxxxx" is 80303
> 2009-02-23 15:34:58 GMT DEBUG1 node_1_listen "host=uklnxmes-cl dbname=tam1
> user=xxxxxx port=5432 password=xxxxxx": backend pid = 28764
> 2009-02-23 15:34:58 GMT CONFIG version for "host=uklnxdisp1 dbname=tam1
> user=xxxxxx port=5432 password=xxxxxx" is 80303
> 2009-02-23 15:34:58 GMT DEBUG1 local_sync "host=uklnxdisp1 dbname=tam1
> user=xxxxxx port=5432 password=xxxxxx": backend pid = 8067
> 2009-02-23 15:34:58 GMT CONFIG version for "host=uklnxdisp1 dbname=tam1
> user=xxxxxx port=5432 password=xxxxxx" is 80303
> 2009-02-23 15:34:58 GMT CONFIG version for "host=uklnxdisp1 dbname=tam1
> user=xxxxxx port=5432 password=xxxxxx" is 80303
> 2009-02-23 15:34:58 GMT DEBUG1 local_cleanup "host=uklnxdisp1 dbname=tam1
> user=xxxxxx port=5432 password=xxxxxx": backend pid = 8068
> 2009-02-23 15:34:58 GMT DEBUG1 remoteListenThread_1: connected to
> 'host=uklnxmes-cl dbname=tam1 user=xxxxxx port=5432 password=xxxxxx'
> 2009-02-23 15:34:58 GMT DEBUG1 remoteWorkerThread_1 "host=uklnxdisp1
> dbname=tam1 user=xxxxxx port=5432 password=xxxxxx": backend pid = 8066
> 2009-02-23 15:34:58 GMT CONFIG remoteWorkerThread_1: update provider
> configuration
> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,2
> STORE_NODE
> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,3
> ENABLE_NODE
> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,4
> STORE_PATH
> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,5 SYNC
> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 2 type:STORE_NODE
> TODO: ********** remoteWorkerThread: node 1 - EVENT 1,2 STORE_NODE - unknown
> event type
> 2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=1 li_receiver=2
> li_provider=1
> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=1 (0 threads +
> worker signaled)
> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=1 (0 threads +
> worker signaled)
> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: forward confirm 2,1
> received by 1
> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 3 type:ENABLE_NODE
> xxxx port=5432 password=xxxxxx": backend pid = 8065
> TODO: ********** remoteWorkerThread: node 1 - EVENT 1,3 ENABLE_NODE -
> unknown event type
> 2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=1 li_receiver=2
> li_provider=1
> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=1 (0 threads +
> worker signaled)
> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=1 (0 threads +
> worker signaled)
> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 4 type:STORE_PATH
> 2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=1 li_receiver=2
> li_provider=1
> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=1 (0 threads +
> worker signaled)
> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=1 (0 threads +
> worker signaled)
> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 5 type:SYNC
> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: SYNC 5 processing
> 2009-02-23 15:34:58 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
> for this event
> 2009-02-23 15:34:58 GMT CONFIG remoteWorkerThread_1: update provider
> configuration
> 2009-02-23 15:34:59 GMT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 2
> 2009-02-23 15:35:01 GMT DEBUG2 localListenThread: Received event 2,2 SYNC
> 2009-02-23 15:35:02 GMT DEBUG2 remoteWorkerThread_1: forward confirm 2,2
> received by 1
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,6
> STORE_SET
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,7
> SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 6 type:STORE_SET
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,8
> SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,9
> SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,10
> SET_ADD_TABLE
> <snip
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,18
> SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,19
> SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT CONFIG storeSet: set_id=1 set_origin=1
> set_comment='Set 1 for mesrep'
> 2009-02-23 15:35:29 GMT DEBUG2 sched_wakeup_node(): no_id=1 (0 threads +
> worker signaled)
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,20
> SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,21
> SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,22
> SET_ADD_TABLE
> <snip>
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,117
> SET_ADD_SEQUENCE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,118
> SET_ADD_SEQUENCE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,119
> SET_ADD_SEQUENCE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,120 SYNC
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 7 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 8 type:SET_ADD_TABLE
>
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 12 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 13 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 14 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 15 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 16 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 17 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 18 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT CONFIG remoteWorkerThread_1: update provider
> configuration
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 19 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 20 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 21 type:SET_ADD_TABLE
> <snip>
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 113 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 114 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 115 type:SET_ADD_TABLE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 116 type:SET_ADD_SEQUENCE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 117 type:SET_ADD_SEQUENCE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 118 type:SET_ADD_SEQUENCE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 119 type:SET_ADD_SEQUENCE
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 120 type:SYNC
> 2009-02-23 15:35:29 GMT DEBUG1 calc sync size - last time: 1 last length:
> 31050 ideal: 1 proposed size: 1
> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: SYNC 120 processing
> 2009-02-23 15:35:29 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
> for this event
> 2009-02-23 15:35:40 GMT DEBUG2 remoteListenThread_1: queue event 1,121 SYNC
> 2009-02-23 15:35:40 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 121 type:SYNC
> 2009-02-23 15:35:40 GMT DEBUG1 calc sync size - last time: 1 last length:
> 10941 ideal: 5 proposed size: 3
> 2009-02-23 15:35:40 GMT DEBUG2 remoteWorkerThread_1: SYNC 121 processing
> 2009-02-23 15:35:40 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
> for this event
> 2009-02-23 15:35:51 GMT DEBUG2 remoteListenThread_1: queue event 1,122 SYNC
> 2009-02-23 15:35:51 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 122 type:SYNC
> 2009-02-23 15:35:51 GMT DEBUG1 calc sync size - last time: 1 last length:
> 11002 ideal: 5 proposed size: 3
> 2009-02-23 15:35:51 GMT DEBUG2 remoteWorkerThread_1: SYNC 122 processing
> 2009-02-23 15:35:51 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
> for this event
> 2009-02-23 15:36:02 GMT DEBUG2 remoteListenThread_1: queue event 1,123 SYNC
> 2009-02-23 15:36:02 GMT DEBUG2 remoteListenThread_1: queue event 1,124
> SUBSCRIBE_SET
> 2009-02-23 15:36:02 GMT DEBUG2 remoteListenThread_1: queue event 1,125
> ENABLE_SUBSCRIPTION
> 2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 123 type:SYNC
> 2009-02-23 15:36:02 GMT DEBUG1 calc sync size - last time: 1 last length:
> 11002 ideal: 5 proposed size: 3
> 2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: SYNC 123 processing
> 2009-02-23 15:36:02 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
> for this event
> 2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 124 type:SUBSCRIBE_SET
> 2009-02-23 15:36:02 GMT CONFIG storeSubscribe: sub_set=1 sub_provider=1
> sub_forward='t'
> 2009-02-23 15:36:02 GMT DEBUG2 sched_wakeup_node(): no_id=1 (0 threads +
> worker signaled)
> 2009-02-23 15:36:02 GMT CONFIG storeListen: li_origin=1 li_receiver=2
> li_provider=1
> 2009-02-23 15:36:02 GMT DEBUG2 sched_wakeup_node(): no_id=1 (0 threads +
> worker signaled)
> 2009-02-23 15:36:02 GMT DEBUG2 sched_wakeup_node(): no_id=1 (0 threads +
> worker signaled)
> 2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: Received event #1 from
> 125 type:ENABLE_SUBSCRIPTION
> 2009-02-23 15:36:02 GMT INFO   copy_set 1
> 2009-02-23 15:36:02 GMT CONFIG version for "host=uklnxmes-cl dbname=tam1
> user=xxxxxx port=5432 password=xxxxxx" is 80303
> 2009-02-23 15:36:02 GMT DEBUG1 copy_set_1 "host=uklnxmes-cl dbname=tam1
> user=xxxxxx port=5432 password=xxxxxx": backend pid = 29445
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: connected to provider
> DB
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
> "uk7501"."chart_data"
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
> "uk7501"."chart_error_actions"
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
> "uk7501"."charts"
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
> "uk7501"."entities"
> <snip>
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
> "uk4628"."script_version"
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
> "uk4628"."scripts"
>   2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy
> table "uk4628"."scriptsteps"
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
> "uk4628"."table_data"
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy table
> "uk4628"."tables"
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: all tables for set 1
> found on subscriber
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
> "uk7501"."dbkeys"
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
> "uk7501"."txid"
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
> "uk4628"."dbkeys"
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
> "uk4628"."txid"
> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy table
> "uk7501"."chart_data"
> 2009-02-23 15:36:02 GMT ERROR  remoteWorkerThread_1: "select
> "_mesrep".setAddTable_int(1, 1, '"uk7501"."chart_data"', 'chart_data_pk',
> 'Table uk7501.chart_data with primary key'); " PGRES_FATAL_ERROR ERROR:
> Slony-I: setAddTable_int(): table "uk7501"."chart_data" has no index
> chart_data_pk
> 2009-02-23 15:36:02 GMT WARN   remoteWorkerThread_1: data copy for set 1
> failed - sleep 15 seconds
> 2009-02-23 15:36:13 GMT DEBUG2 remoteListenThread_1: queue event 1,126 SYNC
> 2009-02-23 15:36:17 GMT INFO   copy_set 1
>
>
>
>
>
>
> chart_date schema
> -----------------
> SET default_with_oids = false;
> CREATE TABLE chart_data (
>    chart character varying(20) NOT NULL,
>    entry integer NOT NULL,
>    value real,
>    value_2 real,
>    violations character varying(8),
>    violations_2 character varying(8),
>    flags character varying(8),
>    lots text,
>    entity character varying(20),
>    operator character varying(20),
>    datetime timestamp without time zone,
>    txid bigint,
>    comments text
> );
>
> ALTER TABLE uk7501.chart_data OWNER TO mes;
> ALTER TABLE ONLY chart_data
>    ADD CONSTRAINT chart_data_pk PRIMARY KEY (chart, entry);
>
> CREATE TRIGGER _mesrep_denyaccess
>    BEFORE INSERT OR DELETE OR UPDATE ON chart_data
>    FOR EACH ROW
>    EXECUTE PROCEDURE _mesrep.denyaccess('_mesrep');
> ALTER TABLE chart_data DISABLE TRIGGER _mesrep_denyaccess;
> CREATE TRIGGER _mesrep_logtrigger
>    AFTER INSERT OR DELETE OR UPDATE ON chart_data
>    FOR EACH ROW
>    EXECUTE PROCEDURE _mesrep.logtrigger('_mesrep', '1', 'kk');
> ALTER TABLE ONLY chart_data
> REVOKE ALL ON TABLE chart_data FROM PUBLIC;
> REVOKE ALL ON TABLE chart_data FROM mes;
> GRANT ALL ON TABLE chart_data TO mes;
> GRANT SELECT ON TABLE chart_data TO mesview;
>

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 916-647-6411	FAX: 916-405-4032
From martin.marques at gmail.com  Mon Feb 23 10:57:33 2009
From: martin.marques at gmail.com (=?UTF-8?B?TWFydMOtbiBNYXJxdcOpcw==?=)
Date: Mon Feb 23 10:57:44 2009
Subject: [Slony1-general] Silence slony in logs
Message-ID: <e73de96e0902231057t16002cdfocc87b9e068eb42e@mail.gmail.com>

I'm on my development server working with slony and I would like to
know if it's possible to silence all the slon connections, so that I
can see only the commands that come from my applications, and not from
the slon connections?

-- 
Mart?n Marqu?s
select 'martin.marques' || '@' || 'gmail.com'
DBA, Programador, Administrador
From martin.marques at gmail.com  Mon Feb 23 11:11:25 2009
From: martin.marques at gmail.com (=?UTF-8?B?TWFydMOtbiBNYXJxdcOpcw==?=)
Date: Mon Feb 23 11:11:35 2009
Subject: [Slony1-general] Re: Silence slony in logs
In-Reply-To: <e73de96e0902231057t16002cdfocc87b9e068eb42e@mail.gmail.com>
References: <e73de96e0902231057t16002cdfocc87b9e068eb42e@mail.gmail.com>
Message-ID: <e73de96e0902231111p59348557yde75fd6406fad907@mail.gmail.com>

2009/2/23 Mart?n Marqu?s <martin.marques@gmail.com>:
> I'm on my development server working with slony and I would like to
> know if it's possible to silence all the slon connections, so that I
> can see only the commands that come from my applications, and not from
> the slon connections?

Sorry, should have looked harder. :-(

ALTER USER slony set log_statement to 'none';

-- 
Mart?n Marqu?s
select 'martin.marques' || '@' || 'gmail.com'
DBA, Programador, Administrador
From cbbrowne at ca.afilias.info  Mon Feb 23 11:20:18 2009
From: cbbrowne at ca.afilias.info (cbbrowne)
Date: Mon Feb 23 11:20:29 2009
Subject: [Slony1-general] Silence slony in logs
In-Reply-To: <e73de96e0902231057t16002cdfocc87b9e068eb42e@mail.gmail.com>
References: <e73de96e0902231057t16002cdfocc87b9e068eb42e@mail.gmail.com>
Message-ID: <49A2F6F2.3040302@ca.afilias.info>

Mart?n Marqu?s wrote:
> I'm on my development server working with slony and I would like to
> know if it's possible to silence all the slon connections, so that I
> can see only the commands that come from my applications, and not from
> the slon connections?
>
>   
There are a couple of ways to do this...

1.  Alter the user running replication:

alter user slony set log_statement to NONE;

2.  Configure the GUC in slon.conf file:

sql_on_connection="SET log_statement to NONE;"

-- 
(reverse (concatenate 'string "ofni.sailifa.ac" "@" "enworbbc"))
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)

From steve at greengecko.co.nz  Mon Feb 23 13:58:55 2009
From: steve at greengecko.co.nz (Steve Holdoway)
Date: Mon Feb 23 13:59:18 2009
Subject: [Slony1-general] triggering the population of a non-replicated
 table from a replicated one.
Message-ID: <20090224105855.efcad892.steve@greengecko.co.nz>

Hey,

I'm having a real problem getting this to work. What I'm trying to do is to use a trigger on the replicated table to reformat the information and add this to a dable in the same database, but a separate schema. The trigger is firing, and the data is formatted into an INSERT statement that is EXECUTEd. This fails with a duplicate key ( on the remote table ) error.

If I cut/paste the statement in error, and login to the replicated database I can add the row to the non-replicated table with no problem at all, so it must be an environmental thing that's wrong, not the data???

If I drop the trigger, the replication works great.

This is driving me crazy! Can anyone suggest where I'm going wrong: It's postgres 8.3.6 and slony 2.0.0.

Many thanks IA!

Steve

Here's the slony log (anonymised, so smelling misfakes will be mine)...

2009-02-24 10:22:34 NZDT CONFIG version for "dbname=dbase host=1.2.3.4 user=postgres password=password sslmode=require" is 80306
2009-02-24 10:22:34 NZDT CONFIG enableNode: no_id=1
2009-02-24 10:22:34 NZDT INFO   remoteWorkerThread_1: thread starts
2009-02-24 10:22:34 NZDT INFO   remoteListenThread_1: thread starts
2009-02-24 10:22:34 NZDT CONFIG cleanupThread: thread starts
2009-02-24 10:22:34 NZDT CONFIG cleanupThread: bias = 35383
2009-02-24 10:22:34 NZDT INFO   syncThread: thread starts
2009-02-24 10:22:34 NZDT INFO   main: running scheduler mainloop
2009-02-24 10:22:34 NZDT CONFIG version for "dbname=dbase host=localhost  user=postgres password=password sslmode=require" is 80306
2009-02-24 10:22:34 NZDT CONFIG version for "dbname=dbase host=1.2.3.4 user=postgres password=password sslmode=require" is 80306
2009-02-24 10:22:34 NZDT CONFIG version for "dbname=dbase host=1.2.3.4 user=postgres password=password sslmode=require" is 80306
2009-02-24 10:22:34 NZDT CONFIG version for "dbname=dbase host=1.2.3.4 user=postgres password=password sslmode=require" is 80306
2009-02-24 10:22:34 NZDT CONFIG remoteWorkerThread_1: update provider configuration
TODO: ********** remoteWorkerThread: node 1 - EVENT 1,6 STORE_NODE - unknown event type
2009-02-24 10:22:34 NZDT CONFIG storeListen: li_origin=1 li_receiver=10 li_provider=1
TODO: ********** remoteWorkerThread: node 1 - EVENT 1,7 ENABLE_NODE - unknown event type
2009-02-24 10:22:34 NZDT CONFIG storeListen: li_origin=1 li_receiver=10 li_provider=1
2009-02-24 10:22:34 NZDT CONFIG storeListen: li_origin=1 li_receiver=10 li_provider=1
2009-02-24 10:22:34 NZDT CONFIG storeSubscribe: sub_set=1 sub_provider=1 sub_forward='t'
2009-02-24 10:22:34 NZDT CONFIG storeListen: li_origin=1 li_receiver=10 li_provider=1
2009-02-24 10:22:34 NZDT INFO   copy_set 1
2009-02-24 10:22:34 NZDT CONFIG version for "dbname=dbase host=localhost  user=postgres password=password sslmode=require" is 80306 
2009-02-24 10:22:34 NZDT CONFIG remoteWorkerThread_1: connected to provider DB
2009-02-24 10:22:34 NZDT CONFIG remoteWorkerThread_1: prepare to copy table "dbase"."table1"
2009-02-24 10:22:34 NZDT CONFIG remoteWorkerThread_1: prepare to copy table "dbase"."table2"
2009-02-24 10:22:34 NZDT CONFIG remoteWorkerThread_1: prepare to copy table "dbase"."table3"
2009-02-24 10:22:34 NZDT CONFIG remoteWorkerThread_1: all tables for set 1 found on subscriber
2009-02-24 10:22:34 NZDT CONFIG remoteWorkerThread_1: copy table "dbase"."table1"
2009-02-24 10:22:34 NZDT CONFIG remoteWorkerThread_1: Begin COPY of table "dbase"."table1"
NOTICE:  truncate of "dbase"."table1" succeeded
2009-02-24 10:22:41 NZDT ERROR  remoteWorkerThread_1: copy from stdin on local node - PGRES_FATAL_ERROR ERROR:  duplicate key value violates unique constraint "remote_data1_key"
CONTEXT:  SQL statement "insert into remote.remtab(col1,col2,col3) values ('data1', 'data2', 'data3')"
PL/pgSQL function "addtoremtab" line 35 at EXECUTE statement

Line 35 of the trigger is ( after the parts are catenated  )

EXECUTE 'insert into remote.remtab(col1,col2,col3) values (''data1'', ''data2'', ''data3'')';


remtab is ( created in a remote schema which is in the search path for postgres )

CREATE TABLE remtab (
    id integer NOT NULL,
    data1 character varying(255) NOT NULL,
    data2 character varying(255) NOT NULL,
    data3 character varying(255) NOT NULL
);

CREATE SEQUENCE remtab_id_seq
    INCREMENT BY 1
    NO MAXVALUE
    NO MINVALUE
    CACHE 1;

ALTER SEQUENCE remtab_id_seq OWNED BY remtab.id;

ALTER TABLE remtab ALTER COLUMN id SET DEFAULT nextval('remtab.remtab_id_seq'::regclass);

ALTER TABLE ONLY remtab
    ADD CONSTRAINT remote_data1_key UNIQUE (data1);


-- 
Steve Holdoway <steve@greengecko.co.nz>
From ajs at crankycanuck.ca  Tue Feb 24 06:31:17 2009
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Tue Feb 24 06:31:29 2009
Subject: [Slony1-general] triggering the population of a non-replicated
	table from a replicated one.
In-Reply-To: <20090224105855.efcad892.steve@greengecko.co.nz>
References: <20090224105855.efcad892.steve@greengecko.co.nz>
Message-ID: <20090224143117.GB8372@shinkuro.com>

On Tue, Feb 24, 2009 at 10:58:55AM +1300, Steve Holdoway wrote:

> I'm having a real problem getting this to work. What I'm trying to
> do is to use a trigger on the replicated table to reformat the
> information and add this to a dable in the same database, but a
> separate schema. The trigger is firing, and the data is formatted
> into an INSERT statement that is EXECUTEd. This fails with a
> duplicate key ( on the remote table ) error.

Sounds like you have something wrong with your trigger function --
maybe it's not doing what you think.  My bet is that your duplicate
key is because something is firing more than once, but using the same
values for something.

A


-- 
Andrew Sullivan
ajs@crankycanuck.ca
From tam.mclaughlin at gmail.com  Tue Feb 24 01:12:51 2009
From: tam.mclaughlin at gmail.com (Tam McLaughlin)
Date: Tue Feb 24 07:26:53 2009
Subject: [Slony1-general] slony rep error on start up: Slony-I: 
	setAddTable_int():
In-Reply-To: <-6317270047098186484@unknownmsgid>
References: <fa4c18050902230825u6f7b7484j32d10c9afdb069a9@mail.gmail.com>
	<-6317270047098186484@unknownmsgid>
Message-ID: <fa4c18050902240112p32a691b9mcc85646560ce63d1@mail.gmail.com>

Thanks for your reply:

Index "chart_data_pk"  does seem to be there!

tam1=3D# \d "uk7501".chart_data;
               Table "uk7501.chart_data"
    Column    |            Type                 | Modifiers
 --------------+-----------------------------+-----------
 chart           | character varying(20)    | not null
 entry           | integer                          | not null
 value          | real                              |
 value_2       | real                              |
 violations    | character varying(8)      |
 violations_2 | character varying(8)     |
 flags            | character varying(8)    |
 lots              | text                             |
 entity           | character varying(20)   |
 operator      | character varying(20)   |
 datetime      | timestamp without time zone |
 txid              | bigint                           |
 comments    | text                              |
Indexes:
    "chart_data_pk" PRIMARY KEY, btree (chart, entry)
Foreign-key constraints:
    "chart_data_chart_fkey" FOREIGN KEY (chart) REFERENCES
uk7501.charts(chart)
Triggers:
    _mesrep_logtrigger AFTER INSERT OR DELETE OR UPDATE ON uk7501.chart_data
FOR EACH ROW EXECUTE PROCEDURE _mesrep.logtrigger('_mesrep', '1', 'kk')
Disabled triggers:
    _mesrep_denyaccess BEFORE INSERT OR DELETE OR UPDATE ON
uk7501.chart_data FOR EACH ROW EXECUTE PROCEDURE
_mesrep.denyaccess('_mesrep')



On Mon, Feb 23, 2009 at 5:23 PM, Jeff Frost <jeff@frostconsultingllc.com>wr=
ote:

> On Mon, 23 Feb 2009, Tam McLaughlin wrote:
>
>  Hello,
>>
>> I am having trouble with slony 1-2 as follows:
>>
>> I was testing slony a few months back and was able to get replication
>> working. However, after upgrading slony by dropping all the replications
>> and
>> recreating databases and configd, I keep getting a few errors, the most
>> recent and first error in the logs as follows:
>>
>> GMT ERROR  remoteWorkerThread_1: "select "_mesrep".setAddTable_int(1, 1,
>> '"uk7501"."chart_data"', 'chart_data_pk', 'Table uk7501.chart_data with
>> primary key'); " PGRES_FATAL_ERROR ERROR:  Slony-I: setAddTable_int():
>> table
>> "uk7501"."chart_data" has no index chart_data_pk
>>
>
> That sure looks like you are missing the chart_data_pk (primary key?) ind=
ex
> on chart_data.  What does \d chart_data yield in psql?
>
>
>
>> Slony is:  v 1-2.0.0
>> Postgres is: 8.3.3
>> OS: centos 5.2
>>
>> I have rebuilt slony from source and relocated the binaries to a differe=
nt
>> directory.
>> The database I have used is a copy of a live db and have also dropped
>> this,
>> recreated the db a few times and the replication. The only thing that I
>> have
>> manually done is remove xxid.so so that it get's rebuilt but saw in the
>> docs
>> that it is no longer used.
>>
>> A previous error I kept getting was this:
>>
>> GMT,"mes","MES",19171,"10.191.2.123:40188
>> ",48fdd267.4ae3,58,"UPDATE",2008-10-21
>> 14:00:23 BST,5/526583,2916342,ERROR,42703,"column ""log_xid"" of relation
>> ""sl_log_1"" does not exist",,,"INSERT INTO _mescluster.sl_log_1
>> (log_origin, log_xid, log_tableid, log_actionseq, log_cmdtype,
>> log_cmddata)
>> VALUES (1, $1, $2, nextval('_mescluster.sl_action_seq'), $3,
>> $4);",47,,"update UK4628.entity_
>>
>> I am not sure what info you need in order to offer help, so I have
>> included
>> extracts from my slony config and log files and the chart_data below.
>> Any help would be appreciated.
>>
>> Thanks
>> Tam
>>
>> Slony Config
>> -----------
>> if ($ENV{"SLONYNODES"}) {
>>   require $ENV{"SLONYNODES"};
>> } else {
>>   $CLUSTER_NAME =3D 'mesrep';
>>   $LOGDIR =3D '/var/log/slony';
>>   $MASTERNODE =3D 1;
>>   $DEBUGLEVEL =3D 4;
>>   add_node(node     =3D> 1,
>>            host     =3D> 'uklnxmes-cl',
>>            dbname   =3D> 'tam1',
>>            port     =3D> 5432,
>>            parent   =3D> 1,
>>            user     =3D> 'xxxxxx',
>>            password =3D> 'xxxxxx');
>>   add_node(node     =3D> 2,
>>            host     =3D> 'uklnxdisp1',
>>            dbname   =3D> 'tam1',
>>            port     =3D> 5432,
>>            parent   =3D> 1,
>>            user     =3D> 'xxxxxx',
>>            password =3D> 'xxxxxx');
>> }
>> $SLONY_SETS =3D {
>>   "set1" =3D> { "set_id"       =3D> 1,
>>               "table_id"     =3D> 1,
>>               "sequence_id"  =3D> 1,
>>               "pkeyedtables" =3D> [ "uk7501.chart_data",
>>                                   "uk7501.chart_error_actions",
>>                                   "uk7501.charts",
>>                                   "uk7501.entities",
>>                                   "uk7501.entities_history_data",
>>                                   "uk7501.entity_attr_data",
>>                                        <snip>
>>                                  "uk7501.tables",
>>                                   "uk4628.calendar",
>>                                   "uk4628.chart_data",
>>                                   "uk4628.chart_error_actions",
>>                                   "uk4628.charts",
>>                                   <snip>
>>                                   "uk4628.table_data",
>>                                   "uk4628.tables"
>>                                 ],
>>               "keyedtables"   =3D>  {},
>>               "serialtables"  =3D>  [],
>>               "sequences"     =3D> [ "uk7501.dbkeys",
>>                                    "uk7501.txid",
>>                                    "uk4628.dbkeys",
>>                                    "uk4628.txid"
>>                                  ]
>>             }
>> };
>> if ($ENV{"SLONYSET"}) {
>>   require $ENV{"SLONYSET"};
>> }
>> # Please do not add or change anything below this point.
>> 1;
>>
>>
>> log file for node2:  error at bottom
>> --------------------
>> --------------------
>> 2009-02-23 15:34:58 GMT CONFIG main: slon version 2.0.0 starting up
>> 2009-02-23 15:34:58 GMT INFO   slon: watchdog process started
>> 2009-02-23 15:34:58 GMT CONFIG slon: watchdog ready - pid =3D 28747
>> <snip>
>> 2009-02-23 15:34:58 GMT CONFIG main: Boolean option log_timestamp =3D 1
>> 2009-02-23 15:34:58 GMT CONFIG main: Boolean option cleanup_deletelogs =
=3D 0
>> 2009-02-23 15:34:58 GMT CONFIG main: Real option real_placeholder =3D
>> 0.000000
>> 2009-02-23 15:34:58 GMT CONFIG main: String option cluster_name =3D mesr=
ep
>> 2009-02-23 15:34:58 GMT CONFIG main: String option conn_info =3D
>> host=3Duklnxdisp1 dbname=3Dtam1 user=3Dxxxxxx port=3D5432 password=3Dxxx=
xxx
>> 2009-02-23 15:34:58 GMT CONFIG main: String option pid_file =3D (null)
>> 2009-02-23 15:34:58 GMT CONFIG main: String option log_timestamp_format =
=3D
>> %Y-%m-%d %H:%M:%S %Z
>> 2009-02-23 15:34:58 GMT CONFIG main: String option archive_dir =3D (null)
>> 2009-02-23 15:34:58 GMT CONFIG main: String option sql_on_connection =3D
>> (null)
>> 2009-02-23 15:34:58 GMT CONFIG main: String option lag_interval =3D (nul=
l)
>> 2009-02-23 15:34:58 GMT CONFIG main: String option command_on_logarchive=
 =3D
>> (null)
>> 2009-02-23 15:34:58 GMT CONFIG main: String option syslog_facility =3D
>> LOCAL0
>> 2009-02-23 15:34:58 GMT CONFIG main: String option syslog_ident =3D slon
>> 2009-02-23 15:34:58 GMT CONFIG main: String option cleanup_interval =3D =
10
>> minutes
>> 2009-02-23 15:34:58 GMT CONFIG slon: worker process created - pid =3D 28=
749
>> 2009-02-23 15:34:58 GMT CONFIG main: local node id =3D 2
>> 2009-02-23 15:34:58 GMT INFO   main: main process started
>> 2009-02-23 15:34:58 GMT CONFIG main: launching sched_start_mainloop
>> 2009-02-23 15:34:58 GMT CONFIG main: loading current cluster configurati=
on
>> 2009-02-23 15:34:58 GMT CONFIG storeNode: no_id=3D1 no_comment=3D'Node 1=
 -
>> tam1@uklnxmes-cl'
>> 2009-02-23 15:34:58 GMT DEBUG2 setNodeLastEvent: no_id=3D1 event_seq=3D1
>> 2009-02-23 15:34:58 GMT CONFIG storePath: pa_server=3D1 pa_client=3D2
>> pa_conninfo=3D"host=3Duklnxmes-cl dbname=3Dtam1 user=3Dxxxxxx port=3D5432
>> password=3Dxxxxxx" pa_connretry=3D10
>> 2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=3D1 li_receiver=3D2
>> li_provider=3D1
>> 2009-02-23 15:34:58 GMT CONFIG main: last local event sequence =3D 1
>> 2009-02-23 15:34:58 GMT CONFIG main: configuration complete - starting
>> threads
>> 2009-02-23 15:34:58 GMT INFO   localListenThread: thread starts
>> 2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxdisp1 dbname=3Dt=
am1
>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
>> 2009-02-23 15:34:58 GMT DEBUG1 local_listen "host=3Duklnxdisp1 dbname=3D=
tam1
>> user=3Dxx2009-02-23 15:34:58 GMT INFO   remoteWorkerThread_1: thread sta=
rts
>> 2009-02-23 15:34:58 GMT CONFIG cleanupThread: thread starts
>> 2009-02-23 15:34:58 GMT CONFIG cleanupThread: bias =3D 35383
>> 2009-02-23 15:34:58 GMT INFO   remoteListenThread_1: thread starts
>> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: start listening for
>> event origin 1
>> 2009-02-23 15:34:58 GMT INFO   main: running scheduler mainloop
>> 2009-02-23 15:34:58 GMT INFO   syncThread: thread starts
>> 2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxmes-cl dbname=3D=
tam1
>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
>> 2009-02-23 15:34:58 GMT DEBUG1 node_1_listen "host=3Duklnxmes-cl dbname=
=3Dtam1
>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 28764
>> 2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxdisp1 dbname=3Dt=
am1
>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
>> 2009-02-23 15:34:58 GMT DEBUG1 local_sync "host=3Duklnxdisp1 dbname=3Dta=
m1
>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 8067
>> 2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxdisp1 dbname=3Dt=
am1
>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
>> 2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxdisp1 dbname=3Dt=
am1
>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
>> 2009-02-23 15:34:58 GMT DEBUG1 local_cleanup "host=3Duklnxdisp1 dbname=
=3Dtam1
>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 8068
>> 2009-02-23 15:34:58 GMT DEBUG1 remoteListenThread_1: connected to
>> 'host=3Duklnxmes-cl dbname=3Dtam1 user=3Dxxxxxx port=3D5432 password=3Dx=
xxxxx'
>> 2009-02-23 15:34:58 GMT DEBUG1 remoteWorkerThread_1 "host=3Duklnxdisp1
>> dbname=3Dtam1 user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =
=3D 8066
>> 2009-02-23 15:34:58 GMT CONFIG remoteWorkerThread_1: update provider
>> configuration
>> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,2
>> STORE_NODE
>> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,3
>> ENABLE_NODE
>> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,4
>> STORE_PATH
>> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,5 SYNC
>> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 2 type:STORE_NODE
>> TODO: ********** remoteWorkerThread: node 1 - EVENT 1,2 STORE_NODE -
>> unknown
>> event type
>> 2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=3D1 li_receiver=3D2
>> li_provider=3D1
>> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads=
 +
>> worker signaled)
>> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads=
 +
>> worker signaled)
>> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: forward confirm 2,1
>> received by 1
>> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 3 type:ENABLE_NODE
>> xxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 8065
>> TODO: ********** remoteWorkerThread: node 1 - EVENT 1,3 ENABLE_NODE -
>> unknown event type
>> 2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=3D1 li_receiver=3D2
>> li_provider=3D1
>> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads=
 +
>> worker signaled)
>> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads=
 +
>> worker signaled)
>> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 4 type:STORE_PATH
>> 2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=3D1 li_receiver=3D2
>> li_provider=3D1
>> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads=
 +
>> worker signaled)
>> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads=
 +
>> worker signaled)
>> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 5 type:SYNC
>> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: SYNC 5 processing
>> 2009-02-23 15:34:58 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
>> for this event
>> 2009-02-23 15:34:58 GMT CONFIG remoteWorkerThread_1: update provider
>> configuration
>> 2009-02-23 15:34:59 GMT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 2
>> 2009-02-23 15:35:01 GMT DEBUG2 localListenThread: Received event 2,2 SYNC
>> 2009-02-23 15:35:02 GMT DEBUG2 remoteWorkerThread_1: forward confirm 2,2
>> received by 1
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,6
>> STORE_SET
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,7
>> SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 6 type:STORE_SET
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,8
>> SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,9
>> SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,10
>> SET_ADD_TABLE
>> <snip
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,18
>> SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,19
>> SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT CONFIG storeSet: set_id=3D1 set_origin=3D1
>> set_comment=3D'Set 1 for mesrep'
>> 2009-02-23 15:35:29 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads=
 +
>> worker signaled)
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,20
>> SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,21
>> SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,22
>> SET_ADD_TABLE
>> <snip>
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,117
>> SET_ADD_SEQUENCE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,118
>> SET_ADD_SEQUENCE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,119
>> SET_ADD_SEQUENCE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,120
>> SYNC
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 7 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 8 type:SET_ADD_TABLE
>>
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 12 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 13 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 14 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 15 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 16 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 17 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 18 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT CONFIG remoteWorkerThread_1: update provider
>> configuration
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 19 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 20 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 21 type:SET_ADD_TABLE
>> <snip>
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 113 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 114 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 115 type:SET_ADD_TABLE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 116 type:SET_ADD_SEQUENCE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 117 type:SET_ADD_SEQUENCE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 118 type:SET_ADD_SEQUENCE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 119 type:SET_ADD_SEQUENCE
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 120 type:SYNC
>> 2009-02-23 15:35:29 GMT DEBUG1 calc sync size - last time: 1 last length:
>> 31050 ideal: 1 proposed size: 1
>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: SYNC 120 processing
>> 2009-02-23 15:35:29 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
>> for this event
>> 2009-02-23 15:35:40 GMT DEBUG2 remoteListenThread_1: queue event 1,121
>> SYNC
>> 2009-02-23 15:35:40 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 121 type:SYNC
>> 2009-02-23 15:35:40 GMT DEBUG1 calc sync size - last time: 1 last length:
>> 10941 ideal: 5 proposed size: 3
>> 2009-02-23 15:35:40 GMT DEBUG2 remoteWorkerThread_1: SYNC 121 processing
>> 2009-02-23 15:35:40 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
>> for this event
>> 2009-02-23 15:35:51 GMT DEBUG2 remoteListenThread_1: queue event 1,122
>> SYNC
>> 2009-02-23 15:35:51 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 122 type:SYNC
>> 2009-02-23 15:35:51 GMT DEBUG1 calc sync size - last time: 1 last length:
>> 11002 ideal: 5 proposed size: 3
>> 2009-02-23 15:35:51 GMT DEBUG2 remoteWorkerThread_1: SYNC 122 processing
>> 2009-02-23 15:35:51 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
>> for this event
>> 2009-02-23 15:36:02 GMT DEBUG2 remoteListenThread_1: queue event 1,123
>> SYNC
>> 2009-02-23 15:36:02 GMT DEBUG2 remoteListenThread_1: queue event 1,124
>> SUBSCRIBE_SET
>> 2009-02-23 15:36:02 GMT DEBUG2 remoteListenThread_1: queue event 1,125
>> ENABLE_SUBSCRIPTION
>> 2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 123 type:SYNC
>> 2009-02-23 15:36:02 GMT DEBUG1 calc sync size - last time: 1 last length:
>> 11002 ideal: 5 proposed size: 3
>> 2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: SYNC 123 processing
>> 2009-02-23 15:36:02 GMT DEBUG1 remoteWorkerThread_1: no sets need syncing
>> for this event
>> 2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 124 type:SUBSCRIBE_SET
>> 2009-02-23 15:36:02 GMT CONFIG storeSubscribe: sub_set=3D1 sub_provider=
=3D1
>> sub_forward=3D't'
>> 2009-02-23 15:36:02 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads=
 +
>> worker signaled)
>> 2009-02-23 15:36:02 GMT CONFIG storeListen: li_origin=3D1 li_receiver=3D2
>> li_provider=3D1
>> 2009-02-23 15:36:02 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads=
 +
>> worker signaled)
>> 2009-02-23 15:36:02 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 threads=
 +
>> worker signaled)
>> 2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>> from
>> 125 type:ENABLE_SUBSCRIPTION
>> 2009-02-23 15:36:02 GMT INFO   copy_set 1
>> 2009-02-23 15:36:02 GMT CONFIG version for "host=3Duklnxmes-cl dbname=3D=
tam1
>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
>> 2009-02-23 15:36:02 GMT DEBUG1 copy_set_1 "host=3Duklnxmes-cl dbname=3Dt=
am1
>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 29445
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: connected to provid=
er
>> DB
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy tab=
le
>> "uk7501"."chart_data"
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy tab=
le
>> "uk7501"."chart_error_actions"
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy tab=
le
>> "uk7501"."charts"
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy tab=
le
>> "uk7501"."entities"
>> <snip>
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy tab=
le
>> "uk4628"."script_version"
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy tab=
le
>> "uk4628"."scripts"
>>  2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy
>> table "uk4628"."scriptsteps"
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy tab=
le
>> "uk4628"."table_data"
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy tab=
le
>> "uk4628"."tables"
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: all tables for set 1
>> found on subscriber
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
>> "uk7501"."dbkeys"
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
>> "uk7501"."txid"
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
>> "uk4628"."dbkeys"
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
>> "uk4628"."txid"
>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy table
>> "uk7501"."chart_data"
>> 2009-02-23 15:36:02 GMT ERROR  remoteWorkerThread_1: "select
>> "_mesrep".setAddTable_int(1, 1, '"uk7501"."chart_data"', 'chart_data_pk',
>> 'Table uk7501.chart_data with primary key'); " PGRES_FATAL_ERROR ERROR:
>> Slony-I: setAddTable_int(): table "uk7501"."chart_data" has no index
>> chart_data_pk
>> 2009-02-23 15:36:02 GMT WARN   remoteWorkerThread_1: data copy for set 1
>> failed - sleep 15 seconds
>> 2009-02-23 15:36:13 GMT DEBUG2 remoteListenThread_1: queue event 1,126
>> SYNC
>> 2009-02-23 15:36:17 GMT INFO   copy_set 1
>>
>>
>>
>>
>>
>>
>> chart_date schema
>> -----------------
>> SET default_with_oids =3D false;
>> CREATE TABLE chart_data (
>>   chart character varying(20) NOT NULL,
>>   entry integer NOT NULL,
>>   value real,
>>   value_2 real,
>>   violations character varying(8),
>>   violations_2 character varying(8),
>>   flags character varying(8),
>>   lots text,
>>   entity character varying(20),
>>   operator character varying(20),
>>   datetime timestamp without time zone,
>>   txid bigint,
>>   comments text
>> );
>>
>> ALTER TABLE uk7501.chart_data OWNER TO mes;
>> ALTER TABLE ONLY chart_data
>>   ADD CONSTRAINT chart_data_pk PRIMARY KEY (chart, entry);
>>
>> CREATE TRIGGER _mesrep_denyaccess
>>   BEFORE INSERT OR DELETE OR UPDATE ON chart_data
>>   FOR EACH ROW
>>   EXECUTE PROCEDURE _mesrep.denyaccess('_mesrep');
>> ALTER TABLE chart_data DISABLE TRIGGER _mesrep_denyaccess;
>> CREATE TRIGGER _mesrep_logtrigger
>>   AFTER INSERT OR DELETE OR UPDATE ON chart_data
>>   FOR EACH ROW
>>   EXECUTE PROCEDURE _mesrep.logtrigger('_mesrep', '1', 'kk');
>> ALTER TABLE ONLY chart_data
>> REVOKE ALL ON TABLE chart_data FROM PUBLIC;
>> REVOKE ALL ON TABLE chart_data FROM mes;
>> GRANT ALL ON TABLE chart_data TO mes;
>> GRANT SELECT ON TABLE chart_data TO mesview;
>>
>>
> --
> Jeff Frost, Owner       <jeff@frostconsultingllc.com>
> Frost Consulting, LLC   http://www.frostconsultingllc.com/
> Phone: 916-647-6411     FAX: 916-405-4032
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090224/=
945accb1/attachment-0001.htm
From tam.mclaughlin at gmail.com  Tue Feb 24 07:07:31 2009
From: tam.mclaughlin at gmail.com (Tam McLaughlin)
Date: Tue Feb 24 07:26:54 2009
Subject: [Slony1-general] slony rep error on start up: Slony-I: 
	setAddTable_int():
In-Reply-To: <fa4c18050902240112p32a691b9mcc85646560ce63d1@mail.gmail.com>
References: <fa4c18050902230825u6f7b7484j32d10c9afdb069a9@mail.gmail.com>
	<-6317270047098186484@unknownmsgid>
	<fa4c18050902240112p32a691b9mcc85646560ce63d1@mail.gmail.com>
Message-ID: <fa4c18050902240707v6217c8c1i34c91744d5204ca3@mail.gmail.com>

I have now resolved the problem.
The primary key, and hence index did not exist on the subscriber node. I am
not sure why this happened as I build the schema doing:

pg_dump -s -h host1  tam1 -U user1 -W | psql -U user1  tam1

I dropped and recreated the database and it worked fine.

Thanks.


On Tue, Feb 24, 2009 at 9:12 AM, Tam McLaughlin <tam.mclaughlin@gmail.com>w=
rote:

> Thanks for your reply:
>
> Index "chart_data_pk"  does seem to be there!
>
> tam1=3D# \d "uk7501".chart_data;
>                Table "uk7501.chart_data"
>     Column    |            Type                 | Modifiers
>  --------------+-----------------------------+-----------
>  chart           | character varying(20)    | not null
>  entry           | integer                          | not null
>  value          | real                              |
>  value_2       | real                              |
>  violations    | character varying(8)      |
>  violations_2 | character varying(8)     |
>  flags            | character varying(8)    |
>  lots              | text                             |
>  entity           | character varying(20)   |
>  operator      | character varying(20)   |
>  datetime      | timestamp without time zone |
>  txid              | bigint                           |
>  comments    | text                              |
> Indexes:
>     "chart_data_pk" PRIMARY KEY, btree (chart, entry)
> Foreign-key constraints:
>     "chart_data_chart_fkey" FOREIGN KEY (chart) REFERENCES
> uk7501.charts(chart)
> Triggers:
>     _mesrep_logtrigger AFTER INSERT OR DELETE OR UPDATE ON
> uk7501.chart_data FOR EACH ROW EXECUTE PROCEDURE
> _mesrep.logtrigger('_mesrep', '1', 'kk')
> Disabled triggers:
>     _mesrep_denyaccess BEFORE INSERT OR DELETE OR UPDATE ON
> uk7501.chart_data FOR EACH ROW EXECUTE PROCEDURE
> _mesrep.denyaccess('_mesrep')
>
>
>
>
> On Mon, Feb 23, 2009 at 5:23 PM, Jeff Frost <jeff@frostconsultingllc.com>=
wrote:
>
>> On Mon, 23 Feb 2009, Tam McLaughlin wrote:
>>
>>  Hello,
>>>
>>> I am having trouble with slony 1-2 as follows:
>>>
>>> I was testing slony a few months back and was able to get replication
>>> working. However, after upgrading slony by dropping all the replications
>>> and
>>> recreating databases and configd, I keep getting a few errors, the most
>>> recent and first error in the logs as follows:
>>>
>>> GMT ERROR  remoteWorkerThread_1: "select "_mesrep".setAddTable_int(1, 1,
>>> '"uk7501"."chart_data"', 'chart_data_pk', 'Table uk7501.chart_data with
>>> primary key'); " PGRES_FATAL_ERROR ERROR:  Slony-I: setAddTable_int():
>>> table
>>> "uk7501"."chart_data" has no index chart_data_pk
>>>
>>
>> That sure looks like you are missing the chart_data_pk (primary key?)
>> index on chart_data.  What does \d chart_data yield in psql?
>>
>>
>>
>>> Slony is:  v 1-2.0.0
>>> Postgres is: 8.3.3
>>> OS: centos 5.2
>>>
>>> I have rebuilt slony from source and relocated the binaries to a
>>> different
>>> directory.
>>> The database I have used is a copy of a live db and have also dropped
>>> this,
>>> recreated the db a few times and the replication. The only thing that I
>>> have
>>> manually done is remove xxid.so so that it get's rebuilt but saw in the
>>> docs
>>> that it is no longer used.
>>>
>>> A previous error I kept getting was this:
>>>
>>> GMT,"mes","MES",19171,"10.191.2.123:40188
>>> ",48fdd267.4ae3,58,"UPDATE",2008-10-21
>>> 14:00:23 BST,5/526583,2916342,ERROR,42703,"column ""log_xid"" of relati=
on
>>> ""sl_log_1"" does not exist",,,"INSERT INTO _mescluster.sl_log_1
>>> (log_origin, log_xid, log_tableid, log_actionseq, log_cmdtype,
>>> log_cmddata)
>>> VALUES (1, $1, $2, nextval('_mescluster.sl_action_seq'), $3,
>>> $4);",47,,"update UK4628.entity_
>>>
>>> I am not sure what info you need in order to offer help, so I have
>>> included
>>> extracts from my slony config and log files and the chart_data below.
>>> Any help would be appreciated.
>>>
>>> Thanks
>>> Tam
>>>
>>> Slony Config
>>> -----------
>>> if ($ENV{"SLONYNODES"}) {
>>>   require $ENV{"SLONYNODES"};
>>> } else {
>>>   $CLUSTER_NAME =3D 'mesrep';
>>>   $LOGDIR =3D '/var/log/slony';
>>>   $MASTERNODE =3D 1;
>>>   $DEBUGLEVEL =3D 4;
>>>   add_node(node     =3D> 1,
>>>            host     =3D> 'uklnxmes-cl',
>>>            dbname   =3D> 'tam1',
>>>            port     =3D> 5432,
>>>            parent   =3D> 1,
>>>            user     =3D> 'xxxxxx',
>>>            password =3D> 'xxxxxx');
>>>   add_node(node     =3D> 2,
>>>            host     =3D> 'uklnxdisp1',
>>>            dbname   =3D> 'tam1',
>>>            port     =3D> 5432,
>>>            parent   =3D> 1,
>>>            user     =3D> 'xxxxxx',
>>>            password =3D> 'xxxxxx');
>>> }
>>> $SLONY_SETS =3D {
>>>   "set1" =3D> { "set_id"       =3D> 1,
>>>               "table_id"     =3D> 1,
>>>               "sequence_id"  =3D> 1,
>>>               "pkeyedtables" =3D> [ "uk7501.chart_data",
>>>                                   "uk7501.chart_error_actions",
>>>                                   "uk7501.charts",
>>>                                   "uk7501.entities",
>>>                                   "uk7501.entities_history_data",
>>>                                   "uk7501.entity_attr_data",
>>>                                        <snip>
>>>                                  "uk7501.tables",
>>>                                   "uk4628.calendar",
>>>                                   "uk4628.chart_data",
>>>                                   "uk4628.chart_error_actions",
>>>                                   "uk4628.charts",
>>>                                   <snip>
>>>                                   "uk4628.table_data",
>>>                                   "uk4628.tables"
>>>                                 ],
>>>               "keyedtables"   =3D>  {},
>>>               "serialtables"  =3D>  [],
>>>               "sequences"     =3D> [ "uk7501.dbkeys",
>>>                                    "uk7501.txid",
>>>                                    "uk4628.dbkeys",
>>>                                    "uk4628.txid"
>>>                                  ]
>>>             }
>>> };
>>> if ($ENV{"SLONYSET"}) {
>>>   require $ENV{"SLONYSET"};
>>> }
>>> # Please do not add or change anything below this point.
>>> 1;
>>>
>>>
>>> log file for node2:  error at bottom
>>> --------------------
>>> --------------------
>>> 2009-02-23 15:34:58 GMT CONFIG main: slon version 2.0.0 starting up
>>> 2009-02-23 15:34:58 GMT INFO   slon: watchdog process started
>>> 2009-02-23 15:34:58 GMT CONFIG slon: watchdog ready - pid =3D 28747
>>> <snip>
>>> 2009-02-23 15:34:58 GMT CONFIG main: Boolean option log_timestamp =3D 1
>>> 2009-02-23 15:34:58 GMT CONFIG main: Boolean option cleanup_deletelogs =
=3D
>>> 0
>>> 2009-02-23 15:34:58 GMT CONFIG main: Real option real_placeholder =3D
>>> 0.000000
>>> 2009-02-23 15:34:58 GMT CONFIG main: String option cluster_name =3D mes=
rep
>>> 2009-02-23 15:34:58 GMT CONFIG main: String option conn_info =3D
>>> host=3Duklnxdisp1 dbname=3Dtam1 user=3Dxxxxxx port=3D5432 password=3Dxx=
xxxx
>>> 2009-02-23 15:34:58 GMT CONFIG main: String option pid_file =3D (null)
>>> 2009-02-23 15:34:58 GMT CONFIG main: String option log_timestamp_format=
 =3D
>>> %Y-%m-%d %H:%M:%S %Z
>>> 2009-02-23 15:34:58 GMT CONFIG main: String option archive_dir =3D (nul=
l)
>>> 2009-02-23 15:34:58 GMT CONFIG main: String option sql_on_connection =
=3D
>>> (null)
>>> 2009-02-23 15:34:58 GMT CONFIG main: String option lag_interval =3D (nu=
ll)
>>> 2009-02-23 15:34:58 GMT CONFIG main: String option command_on_logarchive
>>> =3D
>>> (null)
>>> 2009-02-23 15:34:58 GMT CONFIG main: String option syslog_facility =3D
>>> LOCAL0
>>> 2009-02-23 15:34:58 GMT CONFIG main: String option syslog_ident =3D slon
>>> 2009-02-23 15:34:58 GMT CONFIG main: String option cleanup_interval =3D=
 10
>>> minutes
>>> 2009-02-23 15:34:58 GMT CONFIG slon: worker process created - pid =3D 2=
8749
>>> 2009-02-23 15:34:58 GMT CONFIG main: local node id =3D 2
>>> 2009-02-23 15:34:58 GMT INFO   main: main process started
>>> 2009-02-23 15:34:58 GMT CONFIG main: launching sched_start_mainloop
>>> 2009-02-23 15:34:58 GMT CONFIG main: loading current cluster
>>> configuration
>>> 2009-02-23 15:34:58 GMT CONFIG storeNode: no_id=3D1 no_comment=3D'Node =
1 -
>>> tam1@uklnxmes-cl'
>>> 2009-02-23 15:34:58 GMT DEBUG2 setNodeLastEvent: no_id=3D1 event_seq=3D1
>>> 2009-02-23 15:34:58 GMT CONFIG storePath: pa_server=3D1 pa_client=3D2
>>> pa_conninfo=3D"host=3Duklnxmes-cl dbname=3Dtam1 user=3Dxxxxxx port=3D54=
32
>>> password=3Dxxxxxx" pa_connretry=3D10
>>> 2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=3D1 li_receiver=
=3D2
>>> li_provider=3D1
>>> 2009-02-23 15:34:58 GMT CONFIG main: last local event sequence =3D 1
>>> 2009-02-23 15:34:58 GMT CONFIG main: configuration complete - starting
>>> threads
>>> 2009-02-23 15:34:58 GMT INFO   localListenThread: thread starts
>>> 2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxdisp1 dbname=3D=
tam1
>>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
>>> 2009-02-23 15:34:58 GMT DEBUG1 local_listen "host=3Duklnxdisp1 dbname=
=3Dtam1
>>> user=3Dxx2009-02-23 15:34:58 GMT INFO   remoteWorkerThread_1: thread st=
arts
>>> 2009-02-23 15:34:58 GMT CONFIG cleanupThread: thread starts
>>> 2009-02-23 15:34:58 GMT CONFIG cleanupThread: bias =3D 35383
>>> 2009-02-23 15:34:58 GMT INFO   remoteListenThread_1: thread starts
>>> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: start listening for
>>> event origin 1
>>> 2009-02-23 15:34:58 GMT INFO   main: running scheduler mainloop
>>> 2009-02-23 15:34:58 GMT INFO   syncThread: thread starts
>>> 2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxmes-cl dbname=
=3Dtam1
>>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
>>> 2009-02-23 15:34:58 GMT DEBUG1 node_1_listen "host=3Duklnxmes-cl
>>> dbname=3Dtam1
>>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 28764
>>> 2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxdisp1 dbname=3D=
tam1
>>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
>>> 2009-02-23 15:34:58 GMT DEBUG1 local_sync "host=3Duklnxdisp1 dbname=3Dt=
am1
>>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 8067
>>> 2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxdisp1 dbname=3D=
tam1
>>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
>>> 2009-02-23 15:34:58 GMT CONFIG version for "host=3Duklnxdisp1 dbname=3D=
tam1
>>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
>>> 2009-02-23 15:34:58 GMT DEBUG1 local_cleanup "host=3Duklnxdisp1 dbname=
=3Dtam1
>>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 8068
>>> 2009-02-23 15:34:58 GMT DEBUG1 remoteListenThread_1: connected to
>>> 'host=3Duklnxmes-cl dbname=3Dtam1 user=3Dxxxxxx port=3D5432 password=3D=
xxxxxx'
>>> 2009-02-23 15:34:58 GMT DEBUG1 remoteWorkerThread_1 "host=3Duklnxdisp1
>>> dbname=3Dtam1 user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid=
 =3D 8066
>>> 2009-02-23 15:34:58 GMT CONFIG remoteWorkerThread_1: update provider
>>> configuration
>>> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,2
>>> STORE_NODE
>>> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,3
>>> ENABLE_NODE
>>> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,4
>>> STORE_PATH
>>> 2009-02-23 15:34:58 GMT DEBUG2 remoteListenThread_1: queue event 1,5 SY=
NC
>>> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 2 type:STORE_NODE
>>> TODO: ********** remoteWorkerThread: node 1 - EVENT 1,2 STORE_NODE -
>>> unknown
>>> event type
>>> 2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=3D1 li_receiver=
=3D2
>>> li_provider=3D1
>>> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 thread=
s +
>>> worker signaled)
>>> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 thread=
s +
>>> worker signaled)
>>> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: forward confirm 2,1
>>> received by 1
>>> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 3 type:ENABLE_NODE
>>> xxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 8065
>>> TODO: ********** remoteWorkerThread: node 1 - EVENT 1,3 ENABLE_NODE -
>>> unknown event type
>>> 2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=3D1 li_receiver=
=3D2
>>> li_provider=3D1
>>> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 thread=
s +
>>> worker signaled)
>>> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 thread=
s +
>>> worker signaled)
>>> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 4 type:STORE_PATH
>>> 2009-02-23 15:34:58 GMT CONFIG storeListen: li_origin=3D1 li_receiver=
=3D2
>>> li_provider=3D1
>>> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 thread=
s +
>>> worker signaled)
>>> 2009-02-23 15:34:58 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 thread=
s +
>>> worker signaled)
>>> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 5 type:SYNC
>>> 2009-02-23 15:34:58 GMT DEBUG2 remoteWorkerThread_1: SYNC 5 processing
>>> 2009-02-23 15:34:58 GMT DEBUG1 remoteWorkerThread_1: no sets need synci=
ng
>>> for this event
>>> 2009-02-23 15:34:58 GMT CONFIG remoteWorkerThread_1: update provider
>>> configuration
>>> 2009-02-23 15:34:59 GMT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 2
>>> 2009-02-23 15:35:01 GMT DEBUG2 localListenThread: Received event 2,2 SY=
NC
>>> 2009-02-23 15:35:02 GMT DEBUG2 remoteWorkerThread_1: forward confirm 2,2
>>> received by 1
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,6
>>> STORE_SET
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,7
>>> SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 6 type:STORE_SET
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,8
>>> SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,9
>>> SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,10
>>> SET_ADD_TABLE
>>> <snip
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,18
>>> SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,19
>>> SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT CONFIG storeSet: set_id=3D1 set_origin=3D1
>>> set_comment=3D'Set 1 for mesrep'
>>> 2009-02-23 15:35:29 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 thread=
s +
>>> worker signaled)
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,20
>>> SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,21
>>> SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,22
>>> SET_ADD_TABLE
>>> <snip>
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,117
>>> SET_ADD_SEQUENCE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,118
>>> SET_ADD_SEQUENCE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,119
>>> SET_ADD_SEQUENCE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteListenThread_1: queue event 1,120
>>> SYNC
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 7 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 8 type:SET_ADD_TABLE
>>>
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 12 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 13 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 14 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 15 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 16 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 17 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 18 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT CONFIG remoteWorkerThread_1: update provider
>>> configuration
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 19 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 20 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 21 type:SET_ADD_TABLE
>>> <snip>
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 113 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 114 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 115 type:SET_ADD_TABLE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 116 type:SET_ADD_SEQUENCE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 117 type:SET_ADD_SEQUENCE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 118 type:SET_ADD_SEQUENCE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 119 type:SET_ADD_SEQUENCE
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 120 type:SYNC
>>> 2009-02-23 15:35:29 GMT DEBUG1 calc sync size - last time: 1 last lengt=
h:
>>> 31050 ideal: 1 proposed size: 1
>>> 2009-02-23 15:35:29 GMT DEBUG2 remoteWorkerThread_1: SYNC 120 processing
>>> 2009-02-23 15:35:29 GMT DEBUG1 remoteWorkerThread_1: no sets need synci=
ng
>>> for this event
>>> 2009-02-23 15:35:40 GMT DEBUG2 remoteListenThread_1: queue event 1,121
>>> SYNC
>>> 2009-02-23 15:35:40 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 121 type:SYNC
>>> 2009-02-23 15:35:40 GMT DEBUG1 calc sync size - last time: 1 last lengt=
h:
>>> 10941 ideal: 5 proposed size: 3
>>> 2009-02-23 15:35:40 GMT DEBUG2 remoteWorkerThread_1: SYNC 121 processing
>>> 2009-02-23 15:35:40 GMT DEBUG1 remoteWorkerThread_1: no sets need synci=
ng
>>> for this event
>>> 2009-02-23 15:35:51 GMT DEBUG2 remoteListenThread_1: queue event 1,122
>>> SYNC
>>> 2009-02-23 15:35:51 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 122 type:SYNC
>>> 2009-02-23 15:35:51 GMT DEBUG1 calc sync size - last time: 1 last lengt=
h:
>>> 11002 ideal: 5 proposed size: 3
>>> 2009-02-23 15:35:51 GMT DEBUG2 remoteWorkerThread_1: SYNC 122 processing
>>> 2009-02-23 15:35:51 GMT DEBUG1 remoteWorkerThread_1: no sets need synci=
ng
>>> for this event
>>> 2009-02-23 15:36:02 GMT DEBUG2 remoteListenThread_1: queue event 1,123
>>> SYNC
>>> 2009-02-23 15:36:02 GMT DEBUG2 remoteListenThread_1: queue event 1,124
>>> SUBSCRIBE_SET
>>> 2009-02-23 15:36:02 GMT DEBUG2 remoteListenThread_1: queue event 1,125
>>> ENABLE_SUBSCRIPTION
>>> 2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 123 type:SYNC
>>> 2009-02-23 15:36:02 GMT DEBUG1 calc sync size - last time: 1 last lengt=
h:
>>> 11002 ideal: 5 proposed size: 3
>>> 2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: SYNC 123 processing
>>> 2009-02-23 15:36:02 GMT DEBUG1 remoteWorkerThread_1: no sets need synci=
ng
>>> for this event
>>> 2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 124 type:SUBSCRIBE_SET
>>> 2009-02-23 15:36:02 GMT CONFIG storeSubscribe: sub_set=3D1 sub_provider=
=3D1
>>> sub_forward=3D't'
>>> 2009-02-23 15:36:02 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 thread=
s +
>>> worker signaled)
>>> 2009-02-23 15:36:02 GMT CONFIG storeListen: li_origin=3D1 li_receiver=
=3D2
>>> li_provider=3D1
>>> 2009-02-23 15:36:02 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 thread=
s +
>>> worker signaled)
>>> 2009-02-23 15:36:02 GMT DEBUG2 sched_wakeup_node(): no_id=3D1 (0 thread=
s +
>>> worker signaled)
>>> 2009-02-23 15:36:02 GMT DEBUG2 remoteWorkerThread_1: Received event #1
>>> from
>>> 125 type:ENABLE_SUBSCRIPTION
>>> 2009-02-23 15:36:02 GMT INFO   copy_set 1
>>> 2009-02-23 15:36:02 GMT CONFIG version for "host=3Duklnxmes-cl dbname=
=3Dtam1
>>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx" is 80303
>>> 2009-02-23 15:36:02 GMT DEBUG1 copy_set_1 "host=3Duklnxmes-cl dbname=3D=
tam1
>>> user=3Dxxxxxx port=3D5432 password=3Dxxxxxx": backend pid =3D 29445
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: connected to
>>> provider
>>> DB
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy
>>> table
>>> "uk7501"."chart_data"
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy
>>> table
>>> "uk7501"."chart_error_actions"
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy
>>> table
>>> "uk7501"."charts"
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy
>>> table
>>> "uk7501"."entities"
>>> <snip>
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy
>>> table
>>> "uk4628"."script_version"
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy
>>> table
>>> "uk4628"."scripts"
>>>  2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy
>>> table "uk4628"."scriptsteps"
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy
>>> table
>>> "uk4628"."table_data"
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: prepare to copy
>>> table
>>> "uk4628"."tables"
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: all tables for set=
 1
>>> found on subscriber
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
>>> "uk7501"."dbkeys"
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
>>> "uk7501"."txid"
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
>>> "uk4628"."dbkeys"
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy sequence
>>> "uk4628"."txid"
>>> 2009-02-23 15:36:02 GMT CONFIG remoteWorkerThread_1: copy table
>>> "uk7501"."chart_data"
>>> 2009-02-23 15:36:02 GMT ERROR  remoteWorkerThread_1: "select
>>> "_mesrep".setAddTable_int(1, 1, '"uk7501"."chart_data"', 'chart_data_pk=
',
>>> 'Table uk7501.chart_data with primary key'); " PGRES_FATAL_ERROR ERROR:
>>> Slony-I: setAddTable_int(): table "uk7501"."chart_data" has no index
>>> chart_data_pk
>>> 2009-02-23 15:36:02 GMT WARN   remoteWorkerThread_1: data copy for set 1
>>> failed - sleep 15 seconds
>>> 2009-02-23 15:36:13 GMT DEBUG2 remoteListenThread_1: queue event 1,126
>>> SYNC
>>> 2009-02-23 15:36:17 GMT INFO   copy_set 1
>>>
>>>
>>>
>>>
>>>
>>>
>>> chart_date schema
>>> -----------------
>>> SET default_with_oids =3D false;
>>> CREATE TABLE chart_data (
>>>   chart character varying(20) NOT NULL,
>>>   entry integer NOT NULL,
>>>   value real,
>>>   value_2 real,
>>>   violations character varying(8),
>>>   violations_2 character varying(8),
>>>   flags character varying(8),
>>>   lots text,
>>>   entity character varying(20),
>>>   operator character varying(20),
>>>   datetime timestamp without time zone,
>>>   txid bigint,
>>>   comments text
>>> );
>>>
>>> ALTER TABLE uk7501.chart_data OWNER TO mes;
>>> ALTER TABLE ONLY chart_data
>>>   ADD CONSTRAINT chart_data_pk PRIMARY KEY (chart, entry);
>>>
>>> CREATE TRIGGER _mesrep_denyaccess
>>>   BEFORE INSERT OR DELETE OR UPDATE ON chart_data
>>>   FOR EACH ROW
>>>   EXECUTE PROCEDURE _mesrep.denyaccess('_mesrep');
>>> ALTER TABLE chart_data DISABLE TRIGGER _mesrep_denyaccess;
>>> CREATE TRIGGER _mesrep_logtrigger
>>>   AFTER INSERT OR DELETE OR UPDATE ON chart_data
>>>   FOR EACH ROW
>>>   EXECUTE PROCEDURE _mesrep.logtrigger('_mesrep', '1', 'kk');
>>> ALTER TABLE ONLY chart_data
>>> REVOKE ALL ON TABLE chart_data FROM PUBLIC;
>>> REVOKE ALL ON TABLE chart_data FROM mes;
>>> GRANT ALL ON TABLE chart_data TO mes;
>>> GRANT SELECT ON TABLE chart_data TO mesview;
>>>
>>>
>> --
>> Jeff Frost, Owner       <jeff@frostconsultingllc.com>
>> Frost Consulting, LLC   http://www.frostconsultingllc.com/
>> Phone: 916-647-6411     FAX: 916-405-4032
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090224/=
38c53b62/attachment-0001.htm
From steve at greengecko.co.nz  Tue Feb 24 09:56:20 2009
From: steve at greengecko.co.nz (Steve Holdoway)
Date: Tue Feb 24 09:56:48 2009
Subject: [Slony1-general] triggering the population of a non-replicated
	table from a replicated one.
In-Reply-To: <20090224143117.GB8372@shinkuro.com>
References: <20090224105855.efcad892.steve@greengecko.co.nz>
	<20090224143117.GB8372@shinkuro.com>
Message-ID: <20090225065620.4bef01d0.steve@greengecko.co.nz>

On Tue, 24 Feb 2009 09:31:17 -0500
Andrew Sullivan <ajs@crankycanuck.ca> wrote:

> On Tue, Feb 24, 2009 at 10:58:55AM +1300, Steve Holdoway wrote:
> 
> > I'm having a real problem getting this to work. What I'm trying to
> > do is to use a trigger on the replicated table to reformat the
> > information and add this to a dable in the same database, but a
> > separate schema. The trigger is firing, and the data is formatted
> > into an INSERT statement that is EXECUTEd. This fails with a
> > duplicate key ( on the remote table ) error.
> 
> Sounds like you have something wrong with your trigger function --
> maybe it's not doing what you think.  My bet is that your duplicate
> key is because something is firing more than once, but using the same
> values for something.
> 
> A
> 
> 
> -- 
> Andrew Sullivan
> ajs@crankycanuck.ca
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
Hi Andrew,

It works fine if I test it on an un replicated table, performing a bulk load either from a copy or multiple insert statements, which has sort of led me to dismiss that probability, and concentrate on environmental differences. If I remove the offending unique index, it fails on the next similar insert into a remote table, but there is still no data in the initial one...

I'm confused!

Steve 

-- 
Steve Holdoway <steve@greengecko.co.nz>
From ajs at crankycanuck.ca  Wed Feb 25 10:32:13 2009
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Wed Feb 25 10:32:26 2009
Subject: [Slony1-general] triggering the population of a non-replicated
	table from a replicated one.
In-Reply-To: <20090225065620.4bef01d0.steve@greengecko.co.nz>
References: <20090224105855.efcad892.steve@greengecko.co.nz>
	<20090224143117.GB8372@shinkuro.com>
	<20090225065620.4bef01d0.steve@greengecko.co.nz>
Message-ID: <20090225183212.GA11049@shinkuro.com>

On Wed, Feb 25, 2009 at 06:56:20AM +1300, Steve Holdoway wrote:
> 
> It works fine if I test it on an un replicated table, performing a bulk load either from a copy or multiple insert statements, which has sort of led me to dismiss that probability, and concentrate on environmental differences. If I remove the offending unique index, it fails on the next similar insert into a remote table, but there is still no data in the initial one...
> 

Well, without looking at the actual case, I'm not sure what else to
suggest.  But I'd bet a pretty good lunch that something is causing
the trigger to fire twice for the same data, which is what's causing
your duplicate problem.

A

-- 
Andrew Sullivan
ajs@crankycanuck.ca
From steve at greengecko.co.nz  Wed Feb 25 11:10:14 2009
From: steve at greengecko.co.nz (Steve Holdoway)
Date: Wed Feb 25 11:10:36 2009
Subject: [Slony1-general] triggering the population of a non-replicated
	table from a replicated one.
In-Reply-To: <20090225183212.GA11049@shinkuro.com>
References: <20090224105855.efcad892.steve@greengecko.co.nz>
	<20090224143117.GB8372@shinkuro.com>
	<20090225065620.4bef01d0.steve@greengecko.co.nz>
	<20090225183212.GA11049@shinkuro.com>
Message-ID: <20090226081014.67e21b06.steve@greengecko.co.nz>

On Wed, 25 Feb 2009 13:32:13 -0500
Andrew Sullivan <ajs@crankycanuck.ca> wrote:

> On Wed, Feb 25, 2009 at 06:56:20AM +1300, Steve Holdoway wrote:
> > 
> > It works fine if I test it on an un replicated table, performing a bulk load either from a copy or multiple insert statements, which has sort of led me to dismiss that probability, and concentrate on environmental differences. If I remove the offending unique index, it fails on the next similar insert into a remote table, but there is still no data in the initial one...
> > 
> 
> Well, without looking at the actual case, I'm not sure what else to
> suggest.  But I'd bet a pretty good lunch that something is causing
> the trigger to fire twice for the same data, which is what's causing
> your duplicate problem.
> 
> A
Looks like the EXECUTE 'INSERT ...' syntax is at the core of the problem. I'm getting there slowly, replacing them with specific functions that use plain INSERTs on the passed parameters instead.

My sanity is returning. Slowly. Thanks for your help.

Steve
-- 
Steve Holdoway <steve@greengecko.co.nz>
From wmoran at potentialtech.com  Fri Feb 27 05:58:13 2009
From: wmoran at potentialtech.com (Bill Moran)
Date: Fri Feb 27 05:58:20 2009
Subject: [Slony1-general] duplicate key sl_nodelock-pkey
Message-ID: <20090227085813.eade10e7.wmoran@potentialtech.com>


I'm seeing a problem similar to that described in this thread:
http://lists.slony.info/pipermail/slony1-general/2008-August/008492.html

However, I was unable to isolate the cause.  The solution was to restart
the slons on all nodes, which unstuck things and all tests show that
the cluster is replicating happily again.

I'm trying to determine how/why the problem happened.  In this case it
was triggered by moving an origin around (as part of a routine disaster
drill).  The set moved to the backup without problem, but we didn't notice
that the slon on node 2 had died until we went to move things back.  At
that point, the move set hung, and eventually bailed with "timeout exceeded
while waiting for event confirmation"

If anyone has any insight into this, I'm all ears.  Otherwise, I can set
up a test bed if there's anything I can do to provide more information.

Some basic details:
FreeBSD 6.3
PostgreSQL 8.3.5
Slony 1.2.15

Cluster =
node 1: masterdb in facil0
node 2: localslavedb in facil0
node 3: remoteslavedb in facil1

2009 Feb 27 06:31:43 -05:00 localslavedb [slon][55583] [local2] [err] slon[55583]: [8393-1] [55583] CONFIG moveSet: set_id=1 old_origin=1 new_origin=3
2009 Feb 27 06:31:43 -05:00 localslavedb [slon][55583] [local2] [debug] slon[55583]: [8394-1] [55583] DEBUG1 remoteWorkerThread_3: helper thread for provider 3 created
2009 Feb 27 06:31:43 -05:00 localslavedb [slon][55583] [local2] [err] slon[55583]: [8395-1] [55583] CONFIG storeListen: li_origin=1 li_receiver=2 li_provider=1
2009 Feb 27 06:31:43 -05:00 localslavedb [slon][55583] [local2] [err] slon[55583]: [8396-1] [55583] CONFIG storeListen: li_origin=1 li_receiver=2 li_provider=3
2009 Feb 27 06:31:43 -05:00 localslavedb [slon][55583] [local2] [err] slon[55583]: [8397-1] [55583] CONFIG storeListen: li_origin=3 li_receiver=2 li_provider=3
2009 Feb 27 06:31:43 -05:00 localslavedb [slon][55583] [local2] [debug] slon[55583]: [8398-1] [55583] DEBUG1 remoteWorkerThread_1: helper thread for provider 1 terminated
2009 Feb 27 06:31:43 -05:00 localslavedb [slon][55583] [local2] [debug] slon[55583]: [8399-1] [55583] DEBUG1 remoteWorkerThread_1: disconnecting from data provider 1
2009 Feb 27 06:31:52 -05:00 localslavedb [slon][55583] [local2] [debug] slon[55583]: [8400-1] [55583] DEBUG1 remoteWorkerThread_3: connected to data provider 3 on 'dbname=database_name_prod host=remoteslavedb-ifx.bdb.facil1
2009 Feb 27 06:31:52 -05:00 localslavedb [slon][55583] [local2] [debug] slon[55583]: [8400-2] user=database_name_slony password=[redacted]'
2009 Feb 27 06:32:01 -05:00 localslavedb [slon][55583] [local2] [info] slon[55583]: [8401-1] [55583] INFO localListenThread: got restart notification
2009 Feb 27 06:32:01 -05:00 localslavedb [slon][1058] [local2] [debug] slon[1058]: [2-1] [1058] DEBUG1 slon: retry requested
2009 Feb 27 06:32:01 -05:00 localslavedb [slon][55583] [local2] [debug] slon[55583]: [8402-1] [55583] DEBUG1 main: scheduler mainloop returned
2009 Feb 27 06:32:01 -05:00 localslavedb [slon][55583] [local2] [info] slon[55583]: [8403-1] [55583] INFO remoteListenThread_3: disconnecting from 'dbname=database_name_prod host=remoteslavedb-ifx.bdb.facil1
2009 Feb 27 06:32:01 -05:00 localslavedb [slon][55583] [local2] [info] slon[55583]: [8403-2] user=database_name_slony password=[redacted]'
2009 Feb 27 06:32:01 -05:00 localslavedb [slon][55583] [local2] [info] slon[55583]: [8404-1] [55583] INFO remoteListenThread_1: disconnecting from 'dbname=database_name_prod host=masterdb-db.cluster00.facil0
2009 Feb 27 06:32:01 -05:00 localslavedb [slon][55583] [local2] [info] slon[55583]: [8404-2] user=database_name_slony password=[redacted]'
2009 Feb 27 06:32:01 -05:00 localslavedb [slon][55583] [local2] [debug] slon[55583]: [8405-1] [55583] DEBUG1 syncThread: thread done
2009 Feb 27 06:32:01 -05:00 localslavedb [slon][55583] [local2] [debug] slon[55583]: [8406-1] [55583] DEBUG1 cleanupThread: thread done
2009 Feb 27 06:32:01 -05:00 localslavedb [slon][55583] [local2] [debug] slon[55583]: [8407-1] [55583] DEBUG1 remoteWorkerThread_1: thread done
2009 Feb 27 06:32:02 -05:00 localslavedb [slon][55583] [local2] [debug] slon[55583]: [8408-1] [55583] DEBUG1 remoteListenThread_3: thread done
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][55583] [local2] [debug] slon[55583]: [8409-1] [55583] DEBUG1 remoteListenThread_1: thread done
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][55583] [local2] [debug] slon[55583]: [8410-1] [55583] DEBUG1 main: done
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][1058] [local2] [debug] slon[1058]: [3-1] [1058] DEBUG1 slon: restart of worker
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][1058] [local2] [err] slon[1058]: [1-1] [1058] CONFIG main: slon version 1.2.15 starting up
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [2-1] [27776] CONFIG main: local node id = 2
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [3-1] [27776] CONFIG main: launching sched_start_mainloop
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [4-1] [27776] CONFIG main: loading current cluster configuration
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [5-1] [27776] CONFIG storeNode: no_id=1 no_comment='Master node'
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [6-1] [27776] CONFIG storeNode: no_id=3 no_comment='remote slave node'
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [7-1] [27776] CONFIG storePath: pa_server=1 pa_client=2 pa_conninfo="dbname=database_name_prod host=masterdb-db.cluster00.facil0
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [7-2] user=database_name_slony password=[redacted]" pa_connretry=10
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [8-1] [27776] CONFIG storePath: pa_server=3 pa_client=2 pa_conninfo="dbname=database_name_prod host=remoteslavedb-ifx.bdb.facil1
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [8-2] user=database_name_slony password=[redacted]" pa_connretry=10
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [9-1] [27776] CONFIG storeListen: li_origin=1 li_receiver=2 li_provider=1
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [10-1] [27776] CONFIG storeListen: li_origin=1 li_receiver=2 li_provider=3
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [11-1] [27776] CONFIG storeListen: li_origin=3 li_receiver=2 li_provider=3
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [12-1] [27776] CONFIG storeSet: set_id=1 set_origin=3 set_comment='All tables'
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [warning] slon[27776]: [13-1] [27776] WARN remoteWorker_wakeup: node 3 - no worker thread
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [14-1] [27776] CONFIG storeSubscribe: sub_set=1 sub_provider=3 sub_forward='t'
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [warning] slon[27776]: [15-1] [27776] WARN remoteWorker_wakeup: node 3 - no worker thread
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [16-1] [27776] CONFIG enableSubscription: sub_set=1
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [warning] slon[27776]: [17-1] [27776] WARN remoteWorker_wakeup: node 3 - no worker thread
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [18-1] [27776] CONFIG main: configuration complete - starting threads
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [debug] slon[27776]: [19-1] [27776] DEBUG1 localListenThread: thread starts
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [20-1] [27776] FATAL localListenThread: "select "_database_name_prod".cleanupNodelock(); insert into
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [20-2] "_database_name_prod".sl_nodelock values ( 2, 0, "pg_catalog".pg_backend_pid()); " - ERROR: duplicate key value violates
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][27776] [local2] [err] slon[27776]: [20-3] unique constraint "sl_nodelock-pkey"
2009 Feb 27 06:32:04 -05:00 localslavedb [slon][1058] [local2] [debug] slon[1058]: [2-1] [1058] DEBUG1 slon: shutdown requested
2009 Feb 27 06:32:24 -05:00 localslavedb [slon][1058] [local2] [debug] slon[1058]: [3-1] [1058] DEBUG1 slon: child termination timeout - kill child
2009 Feb 27 06:32:24 -05:00 localslavedb [slon][1058] [local2] [debug] slon[1058]: [4-1] [1058] DEBUG1 slon: done

-- 
Bill Moran
http://www.potentialtech.com
http://people.collaborativefusion.com/~wmoran/
From niels.olson at gmail.com  Fri Feb 27 20:43:24 2009
From: niels.olson at gmail.com (Niels Olson)
Date: Fri Feb 27 20:43:46 2009
Subject: [Slony1-general] how to sync laptop master to server slave?
Message-ID: <af7537690902272043m57b957bn215609fd505c0925@mail.gmail.com>

I'm a medical student running a wiki on my laptop for notes, it's
critical to have access offline.

book + computer = good
book + internet = bad

Offline access is more important than online access. But it would be
awfully nice to have online access when I can't get to my laptop. I
have identical versions of Postgres (8.3.6) and wiki software. Would
Slony be able to help with that? Are there any problems with the
laptop being a laptop, frequently on small local networks without
valid NAT?

Should I run it the server as master and the laptop as slave?

Niels Olson
Tulane School of Medicine
Class of 2009
niels.olson@gmail.com
h/c: (410) 212-1281
alt:  (443) 221-4648
http://nielsolson.us

This message may contain private information for persons named above.
Please don't share that information with anyone without a need to
know. If you received confidential information without a PGP wrapper,
assume it was compromised, delete it, tell the sender, and try to tell
the victim. Please don't send someone else's private information if
you're not reasonably certain the recipient has a need to know and
that the message will be kept private. Plain email is not private. In
some cases, such as health information protected under the US HIPAA
law or information protected under the US Privacy Act, plain email may
be illegal. If you must relate a person's identity to their private
information in email, use Hushmail or insist your recipients provide
you their PGP public key. My public key is here:
http://nielsolson.us/contact.html.
From niels.olson at gmail.com  Sat Feb 28 07:38:32 2009
From: niels.olson at gmail.com (Niels Olson)
Date: Sat Feb 28 07:38:38 2009
Subject: [Slony1-general] sync laptop postgres database with server?
Message-ID: <af7537690902280738t16a4a606sac37580fa5fddd37@mail.gmail.com>

I'm a medical student running a wiki on my laptop for notes, it's
critical to have access offline.

book + computer = world's most coherent noteset
book + internet = wasted time

Offline access is more important than online access. But it would be
awfully nice to have online access when I can't get to my laptop. I
have identical versions of Postgres (8.3.6) and wiki software. Would
Slony be able to help with that? Are there any problems with the
laptop being a laptop, frequently on small local networks without
valid NAT?

Should I run it the server as master and the laptop as slave?

Niels Olson
Tulane School of Medicine
Class of 2009
niels.olson@gmail.com
h/c: (410) 212-1281
alt:  (443) 221-4648
http://nielsolson.us

This message may contain private information for persons named above.
Please don't share that information with anyone without a need to
know. If you received confidential information without a PGP wrapper,
assume it was compromised, delete it, tell the sender, and try to tell
the victim. Please don't send someone else's private information if
you're not reasonably certain the recipient has a need to know and
that the message will be kept private. Plain email is not private. In
some cases, such as health information protected under the US HIPAA
law or information protected under the US Privacy Act, plain email may
be illegal. If you must relate a person's identity to their private
information in email, use Hushmail or insist your recipients provide
you their PGP public key. My public key is here:
http://nielsolson.us/contact.html.
