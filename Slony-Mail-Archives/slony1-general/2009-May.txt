From melvin6925 at yahoo.com  Fri May  1 06:43:18 2009
From: melvin6925 at yahoo.com (Melvin Davidson)
Date: Fri May  1 06:43:25 2009
Subject: [Slony1-general] ERROR in analyze on slony schema in cleanup thread
Message-ID: <907008.8087.qm@web53001.mail.re2.yahoo.com>

2009-04-29 09:42:45 EDT ERROR=A0 cleanupThread: " analyze "_mas_rep".sl_seq=
log;" - 2009-04-29 09:42:45 EDT DEBUG1 cleanupThread:=A0 analyze
 "_mas_rep".sl_archive_counter;
2009-04-29 09:42:45 EDT ERROR=A0 cleanupThread: " analyze "_mas_rep".sl_arc=
hive_counter;" - 2009-04-29 09:42:45 EDT DEBUG1 cleanupThread:=A0 analyze "=
pg_catalog".pg_listener;
2009-04-29 09:42:45 EDT ERROR=A0 cleanupThread: " analyze "pg_catalog".pg_l=
istener;" - 2009-04-29 09:42:45 EDT DEBUG1 cleanupThread:=A0 analyze "pg_ca=
talog".pg_statistic;
2009-04-29 09:42:45 EDT ERROR=A0 cleanupThread: " analyze "pg_catalog".pg_s=
tatistic;" - 2009-04-29 09:42:45 EDT INFO=A0=A0 cleanupThread:=A0=A0=A0 0.0=
07 seconds for vacuuming

I still have no clue as to why this is occurring. These errors are only rep=
orted in the slony log, The postgres log shows nothing related.

Could it possibly be related to the O/S? It is CentOS-5.3. Once again I am =
using Slony version 2.0.1.

Melvin Davidson =

 Home 720-870-9595 =

 =A0=A0=A0 Cell 720-320-0155  =





      =

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090501/=
bf4aada8/attachment.htm
From ajs at crankycanuck.ca  Fri May  1 06:47:45 2009
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Fri May  1 06:47:53 2009
Subject: [Slony1-general] ERROR in analyze on slony schema in cleanup
	thread
In-Reply-To: <907008.8087.qm@web53001.mail.re2.yahoo.com>
References: <907008.8087.qm@web53001.mail.re2.yahoo.com>
Message-ID: <20090501134742.GA403@shinkuro.com>

On Fri, May 01, 2009 at 06:43:18AM -0700, Melvin Davidson wrote:
> 2009-04-29 09:42:45 EDT ERROR? cleanupThread: " analyze "_mas_rep".sl_seqlog;" - 2009-04-29 09:42:45 EDT DEBUG1 cleanupThread:? analyze
>  "_mas_rep".sl_archive_counter;
> 2009-04-29 09:42:45 EDT ERROR? cleanupThread: " analyze "_mas_rep".sl_archive_counter;" - 2009-04-29 09:42:45 EDT DEBUG1 cleanupThread:? analyze "pg_catalog".pg_listener;
> 2009-04-29 09:42:45 EDT ERROR? cleanupThread: " analyze "pg_catalog".pg_listener;" - 2009-04-29 09:42:45 EDT DEBUG1 cleanupThread:? analyze "pg_catalog".pg_statistic;
> 2009-04-29 09:42:45 EDT ERROR? cleanupThread: " analyze "pg_catalog".pg_statistic;" - 2009-04-29 09:42:45 EDT INFO?? cleanupThread:??? 0.007 seconds for vacuuming
> 
> I still have no clue as to why this is occurring. These errors are only reported in the slony log, The postgres log shows nothing related.
> 

What's your log level in Postgres?  Also, I don't see what the actual
error is here.  Maybe Slony's just reporting what ought to be INFO on
the ERROR channel?

A

-- 
Andrew Sullivan
ajs@crankycanuck.ca
From melvin6925 at yahoo.com  Fri May  1 07:02:30 2009
From: melvin6925 at yahoo.com (Melvin Davidson)
Date: Fri May  1 07:02:37 2009
Subject: [Slony1-general] ERROR in analyze on slony schema in cleanup thread
In-Reply-To: <20090501134742.GA403@shinkuro.com>
Message-ID: <118127.95049.qm@web53010.mail.re2.yahoo.com>

>What's your log level in Postgres?  Also, I don't see what the actual
>error is here.  Maybe Slony's just reporting what ought to be INFO on
?the ERROR channel?
If Slony is reporting an ERROR instead of INFO, I consider that a bug. But the big question is, why is no one else seeing this problem?

I have the following log settings in postgresql.conf.

client_min_messages = notice 
log_min_messages = notice 
log_error_verbosity = default
log_min_error_statement = error
log_statement = 'none'

All other log related settings are at default.

Melvin Davidson 
 




      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090501/f64a2b6e/attachment.htm
From ajs at crankycanuck.ca  Fri May  1 07:14:44 2009
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Fri May  1 07:14:51 2009
Subject: [Slony1-general] Re: ERROR in analyze on slony schema in cleanup
	thread
In-Reply-To: <118127.95049.qm@web53010.mail.re2.yahoo.com>
References: <20090501134742.GA403@shinkuro.com>
	<118127.95049.qm@web53010.mail.re2.yahoo.com>
Message-ID: <20090501141444.GB403@shinkuro.com>

On Fri, May 01, 2009 at 07:02:30AM -0700, Melvin Davidson wrote:
> >What's your log level in Postgres?  Also, I don't see what the actual
> >error is here.  Maybe Slony's just reporting what ought to be INFO on
> ?the ERROR channel?
> If Slony is reporting an ERROR instead of INFO, I consider that a
> bug. 

Agreed.
 
> I have the following log settings in postgresql.conf.
> 
> client_min_messages = notice 
> log_min_messages = notice 
> log_error_verbosity = default
> log_min_error_statement = error
> log_statement = 'none'
> 
> All other log related settings are at default.

Hrm.  Try setting log_min_error_statement = notice.  That maybe will
show up the same statements as are in the slony log you have, which
would at least confirm that slony is logging what's really a notice.

A

-- 
Andrew Sullivan
ajs@crankycanuck.ca
From melvin6925 at yahoo.com  Fri May  1 07:49:47 2009
From: melvin6925 at yahoo.com (Melvin Davidson)
Date: Fri May  1 07:49:54 2009
Subject: [Slony1-general] ERROR in analyze on slony schema in cleanup thread
In-Reply-To: <20090501141444.GB403@shinkuro.com>
Message-ID: <37194.9157.qm@web53012.mail.re2.yahoo.com>

Oh great! After resetting log_min_error_statement =3D notice, doing pg_ctl =
reload & stopping & restarting slon on both master & slave, the problem no =
longer occurs. Isn't that a strange cowinkydink? :)=A0 fyi, I had done mult=
iple restarts of slon prior to this, so it seems strange that just changing=
 log_min_error_statement would resolve.

At any rate, thanks very much for the suggestion and I'll keep monitoring t=
o see if the problem reoccurs.

Melvin Davidson =

 =

Hrm.  Try setting log_min_error_statement =3D notice.  That maybe will
show up the same statements as are in the slony log you have, which
would at least confirm that slony is logging what's really a notice.

A

-- =

Andrew Sullivan
ajs@crankycanuck.ca
_______________________________________________
Slony1-general mailing list
Slony1-general@lists.slony.info
http://lists.slony.info/mailman/listinfo/slony1-general



      =

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090501/=
302e6caa/attachment.htm
From cbbrowne at ca.afilias.info  Fri May  1 08:17:13 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri May  1 08:17:22 2009
Subject: [Slony1-general] ERROR in analyze on slony schema in cleanup
	thread
In-Reply-To: <907008.8087.qm@web53001.mail.re2.yahoo.com> (Melvin Davidson's
	message of "Fri, 1 May 2009 06:43:18 -0700 (PDT)")
References: <907008.8087.qm@web53001.mail.re2.yahoo.com>
Message-ID: <87ljpgetty.fsf@dba2.int.libertyrms.com>

Melvin Davidson <melvin6925@yahoo.com> writes:
>  2009-04-29 09:42:45 EDT ERROR? cleanupThread: " analyze "_mas_rep".sl_seqlog;" - 2009-04-29 09:42:45 EDT DEBUG1 cleanupThread:? analyze "_mas_r 
>  2009-04-29 09:42:45 EDT ERROR? cleanupThread: " analyze "_mas_rep".sl_archive_counter;" - 2009-04-29 09:42:45 EDT DEBUG1 cleanupThread:? analyz 
>  2009-04-29 09:42:45 EDT ERROR? cleanupThread: " analyze "pg_catalog".pg_listener;" - 2009-04-29 09:42:45 EDT DEBUG1 cleanupThread:? analyze "pg 
>  2009-04-29 09:42:45 EDT ERROR? cleanupThread: " analyze "pg_catalog".pg_statistic;" - 2009-04-29 09:42:45 EDT INFO?? cleanupThread:??? 0.007 se 
>  I still have no clue as to why this is occurring. These errors are only reported in the slony log, The postgres log shows nothing related.      
>  Could it possibly be related to the O/S? It is CentOS-5.3. Once again I am using Slony version 2.0.1.                                           

I found it; it's not a terribly big deal.

The problem is that the result code coming back from the vacuum was
being interpreted badly, though fortunately, the only result was the
spurious error message you were getting.  No damage is being done,
save for spurious error messages in the log file.

Here's the patch I'm putting in to clean this up:

% cvs diff -u cleanup_thread.c
Index: cleanup_thread.c
===================================================================
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/cleanup_thread.c,v
retrieving revision 1.45
diff -c -u -r1.45 cleanup_thread.c
cvs diff: conflicting specifications of output style
--- cleanup_thread.c	28 May 2008 19:09:37 -0000	1.45
+++ cleanup_thread.c	1 May 2009 15:14:51 -0000
@@ -189,6 +189,7 @@
 			{
 				char	   *tab_nspname = PQgetvalue(res, t, 0);
 				char	   *tab_relname = PQgetvalue(res, t, 1);
+				ExecStatusType vrc;
 
 				slon_log(SLON_DEBUG1, "cleanupThread: %s analyze \"%s\".%s;\n",
 						 vacuum_action, tab_nspname, tab_relname);
@@ -196,15 +197,23 @@
 				slon_mkquery(&query_pertbl, "%s analyze \"%s\".%s;",
 							 vacuum_action, tab_nspname, tab_relname);
 				res2 = PQexec(dbconn, dstring_data(&query_pertbl));
-				if (PQresultStatus(res) != PGRES_COMMAND_OK)	/* query error */
+				vrc = PQresultStatus(res);
+				if (vrc == PGRES_FATAL_ERROR)
 				{
 					slon_log(SLON_ERROR,
 							 "cleanupThread: \"%s\" - %s",
-					dstring_data(&query_pertbl), PQresultErrorMessage(res2));
+							 dstring_data(&query_pertbl), PQresultErrorMessage(res2));
 
 					/*
 					 * slon_retry(); break;
 					 */
+				} else {
+					if (vrc == PGRES_NONFATAL_ERROR) {
+						slon_log(SLON_WARN,
+								 "cleanupThread: \"%s\" - %s",
+								 dstring_data(&query_pertbl), PQresultErrorMessage(res2));
+						
+					}
 				}
 				PQclear(res2);
 				dstring_reset(&query_pertbl);

-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"
From melvin6925 at yahoo.com  Fri May  1 08:23:19 2009
From: melvin6925 at yahoo.com (Melvin Davidson)
Date: Fri May  1 08:23:30 2009
Subject: [Slony1-general] ERROR in analyze on slony schema in cleanup thread
In-Reply-To: <87ljpgetty.fsf@dba2.int.libertyrms.com>
Message-ID: <10985.4312.qm@web53006.mail.re2.yahoo.com>

Thanks Christopher!=A0 I'll wait for the next version and stick with the gl=
itch for now. Strange, you'd think someone else would have reported this by=
 now.

Melvin Davidson =


--- On Fri, 5/1/09, Christopher Browne <cbbrowne@ca.afilias.info> wrote:
From: Christopher Browne <cbbrowne@ca.afilias.info>
Subject: Re: [Slony1-general] ERROR in analyze on slony schema in cleanup t=
hread
To: melvin6925@yahoo.com
Cc: slony1-general@lists.slony.info
Date: Friday, May 1, 2009, 9:17 AM

Melvin Davidson <melvin6925@yahoo.com> writes:
>  2009-04-29 09:42:45 EDT ERROR=A0 cleanupThread: " analyze
"_mas_rep".sl_seqlog;" - 2009-04-29 09:42:45 EDT DEBUG1
cleanupThread:=A0 analyze "_mas_r =

>  2009-04-29 09:42:45 EDT ERROR=A0 cleanupThread: " analyze
"_mas_rep".sl_archive_counter;" - 2009-04-29 09:42:45 EDT DEBUG1
cleanupThread:=A0 analyz =

>  2009-04-29 09:42:45 EDT ERROR=A0 cleanupThread: " analyze
"pg_catalog".pg_listener;" - 2009-04-29 09:42:45 EDT DEBUG1
cleanupThread:=A0 analyze "pg =

>  2009-04-29 09:42:45 EDT ERROR=A0 cleanupThread: " analyze
"pg_catalog".pg_statistic;" - 2009-04-29 09:42:45 EDT INFO=A0=A0
cleanupThread:=A0=A0=A0 0.007 se =

>  I still have no clue as to why this is occurring. These errors are only
reported in the slony log, The postgres log shows nothing related.      =

>  Could it possibly be related to the O/S? It is CentOS-5.3. Once again I
am using Slony version 2.0.1.                                           =


I found it; it's not a terribly big deal.

The problem is that the result code coming back from the vacuum was
being interpreted badly, though fortunately, the only result was the
spurious error message you were getting.  No damage is being done,
save for spurious error messages in the log file.

Here's the patch I'm putting in to clean this up:

% cvs diff -u cleanup_thread.c
Index: cleanup_thread.c
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
RCS file: /home/cvsd/slony1/slony1-engine/src/slon/cleanup_thread.c,v
retrieving revision 1.45
diff -c -u -r1.45 cleanup_thread.c
cvs diff: conflicting specifications of output style
--- cleanup_thread.c	28 May 2008 19:09:37 -0000	1.45
+++ cleanup_thread.c	1 May 2009 15:14:51 -0000
@@ -189,6 +189,7 @@
 			{
 				char	   *tab_nspname =3D PQgetvalue(res, t, 0);
 				char	   *tab_relname =3D PQgetvalue(res, t, 1);
+				ExecStatusType vrc;
 =

 				slon_log(SLON_DEBUG1, "cleanupThread: %s analyze
\"%s\".%s;\n",
 						 vacuum_action, tab_nspname, tab_relname);
@@ -196,15 +197,23 @@
 				slon_mkquery(&query_pertbl, "%s analyze
\"%s\".%s;",
 							 vacuum_action, tab_nspname, tab_relname);
 				res2 =3D PQexec(dbconn, dstring_data(&query_pertbl));
-				if (PQresultStatus(res) !=3D PGRES_COMMAND_OK)	/* query error */
+				vrc =3D PQresultStatus(res);
+				if (vrc =3D=3D PGRES_FATAL_ERROR)
 				{
 					slon_log(SLON_ERROR,
 							 "cleanupThread: \"%s\" - %s",
-					dstring_data(&query_pertbl), PQresultErrorMessage(res2));
+							 dstring_data(&query_pertbl), PQresultErrorMessage(res2));
 =

 					/*
 					 * slon_retry(); break;
 					 */
+				} else {
+					if (vrc =3D=3D PGRES_NONFATAL_ERROR) {
+						slon_log(SLON_WARN,
+								 "cleanupThread: \"%s\" - %s",
+								 dstring_data(&query_pertbl), PQresultErrorMessage(res2));
+						=

+					}
 				}
 				PQclear(res2);
 				dstring_reset(&query_pertbl);

-- =

select 'cbbrowne' || '@' || 'ca.afilias.info';
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes =

and lock phasers on the Heffalump, Piglet, meet me in transporter room thre=
e"



      =

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090501/=
fceb040d/attachment-0001.htm
From melvin6925 at yahoo.com  Fri May  1 10:31:35 2009
From: melvin6925 at yahoo.com (Melvin Davidson)
Date: Fri May  1 10:31:47 2009
Subject: [Slony1-general] ERROR in analyze on slony schema in cleanup thread
Message-ID: <656969.38448.qm@web53011.mail.re2.yahoo.com>

OK, slight correction. The errors are still occurring. It's just that they =
take 30 minutes before the cleanup cycles start. However, Christopher Brown=
e has already verified this is a minor bug in the code due to a bad return =
code and he has created a patch to fix.

Much thanks to all who helped.

Melvin Davidson =

 Home 720-870-9595 =

 =A0=A0=A0 Cell 720-320-0155  =




--- On Fri, 5/1/09, Melvin Davidson <melvin6925@yahoo.com> wrote:
From: Melvin Davidson <melvin6925@yahoo.com>
Subject: ERROR in analyze on slony schema in cleanup thread
To: slony1-general@lists.slony.info, "Andrew Sullivan" <ajs@crankycanuck.ca>
Date: Friday, May 1, 2009, 8:49 AM

Oh great! After resetting log_min_error_statement =3D notice, doing pg_ctl =
reload & stopping & restarting slon on both master & slave, the problem no =
longer occurs. Isn't that a strange cowinkydink? :)=A0 fyi, I had done mult=
iple restarts of slon prior to this, so it seems strange that just changing=
 log_min_error_statement would resolve.

At any rate, thanks very much for the suggestion and I'll keep monitoring t=
o see if the problem reoccurs.

Melvin Davidson =

 =



      =



      =

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090501/=
1a7ad45f/attachment.htm
From vivek at khera.org  Fri May  1 12:49:52 2009
From: vivek at khera.org (Vick Khera)
Date: Fri May  1 12:50:04 2009
Subject: [Slony1-general] ERROR in analyze on slony schema in cleanup 
	thread
In-Reply-To: <907008.8087.qm@web53001.mail.re2.yahoo.com>
References: <907008.8087.qm@web53001.mail.re2.yahoo.com>
Message-ID: <2968dfd60905011249p7279cb85u781bf6e0c9c53f04@mail.gmail.com>

I concur with Andrew's analysis that slony is somehow logging
everything to ERROR that it sends to DEBUG1 or INFO.
From post at bastian-voigt.de  Mon May  4 02:05:19 2009
From: post at bastian-voigt.de (Bastian Voigt)
Date: Mon May  4 02:05:49 2009
Subject: [Slony1-general] Another problem with slony1-ctl
Message-ID: <5638A604-F222-4FCA-A93F-96D046B7FAD5@bastian-voigt.de>

Hi *,

in my database I have one very large table wich is partioned using  
PG's inheritance feature. To maintain this table, I have a cron script  
that runs every month, creates a new table and modifies the insert  
trigger. Now that my DB is being upgraded to a slony master-slave  
setup I need to modify this monthly script, so that it adds the newly  
created table to the repliation set.

I tried to do this from perl:

system("/opt/slony1-ctl/slony-ctl/outils/11_create_addobj.sh -c  
vesseltracker -s 1 -f $filename") or die $!;
exec("/opt/slony1-ctl/slony-ctl/outils/12_exec_addobj.sh -c  
vesseltracker -s 1") or die $!;

The first script works, the second one gives me an error:

"Inappropriate ioctl for device at /scripts/trackingtables.pl line 124"

Any idea where that might come from?



Kind regards
Bastian
From post at bastian-voigt.de  Mon May  4 04:34:53 2009
From: post at bastian-voigt.de (Bastian Voigt)
Date: Mon May  4 04:35:27 2009
Subject: [Slony1-general] Another problem with slony1-ctl
In-Reply-To: <5638A604-F222-4FCA-A93F-96D046B7FAD5@bastian-voigt.de>
References: <5638A604-F222-4FCA-A93F-96D046B7FAD5@bastian-voigt.de>
Message-ID: <7932B163-5CF1-4D50-B142-0A98B3334B62@bastian-voigt.de>

I did some further investigation on this one, and this is what I found  
out:

It seems that the scripts (11_create_addobj and 12_exec_addobj)  
generate bad return values, even though they executed successfully.  
When I leave out the "or die" in my perl script, both scripts are  
executed fine.

Any explanation for this behaviour?


Cheers
Bastian


Am 04.05.2009 um 11:05 schrieb Bastian Voigt:

> Hi *,
>
> in my database I have one very large table wich is partioned using  
> PG's inheritance feature. To maintain this table, I have a cron  
> script that runs every month, creates a new table and modifies the  
> insert trigger. Now that my DB is being upgraded to a slony master- 
> slave setup I need to modify this monthly script, so that it adds  
> the newly created table to the repliation set.
>
> I tried to do this from perl:
>
> system("/opt/slony1-ctl/slony-ctl/outils/11_create_addobj.sh -c  
> vesseltracker -s 1 -f $filename") or die $!;
> exec("/opt/slony1-ctl/slony-ctl/outils/12_exec_addobj.sh -c  
> vesseltracker -s 1") or die $!;
>
> The first script works, the second one gives me an error:
>
> "Inappropriate ioctl for device at /scripts/trackingtables.pl line  
> 124"
>
> Any idea where that might come from?
>
>
>
> Kind regards
> Bastian
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>

From storm at iparadigms.com  Mon May  4 18:54:54 2009
From: storm at iparadigms.com (Christian Storm)
Date: Mon May  4 18:55:16 2009
Subject: [Slony1-general] Stability of Slony 2.01
Message-ID: <3c2d02c90905041854g2a7a49bclac033d19d31f3acb@mail.gmail.com>

What is the general consensus concerning the stability of Slony 2.01.  We
want to upgrade but am typically wary of adopting major revision upgrades
too soon.  Are there any outstanding issues/patches?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090504/=
03ec78dd/attachment.htm
From storm at iparadigms.com  Mon May  4 18:55:04 2009
From: storm at iparadigms.com (Christian Storm)
Date: Mon May  4 18:55:28 2009
Subject: [Slony1-general] Stability of Slony 2.01
In-Reply-To: <3c2d02c90905041854g2a7a49bclac033d19d31f3acb@mail.gmail.com>
References: <3c2d02c90905041854g2a7a49bclac033d19d31f3acb@mail.gmail.com>
Message-ID: <3c2d02c90905041855q6bddc60dm38e1b331bff43f04@mail.gmail.com>

What is the general consensus concerning the stability of Slony 2.01.  We
want to upgrade but am typically wary of adopting major revision upgrades
too soon.  Are there any outstanding issues/patches?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090504/=
ccaf86fd/attachment.htm
From jks at selectacast.net  Mon May  4 21:03:56 2009
From: jks at selectacast.net (Joseph S)
Date: Mon May  4 21:04:25 2009
Subject: [Slony1-general] replication reindexing forever after initial copy
Message-ID: <49FFBAAC.6040909@selectacast.net>

I set up a slony cluster to replicate from an 8.2.13 database to a 8.3.7 
database (slony 1.2.15) . During the initial copy this has been going on 
for over 3 hours:
select "_prod".finishTableAfterCopy(29); analyze "public"."el";

gdb shows:

(gdb) bt
#0 0x0000003c144c54f0 in __read_nocancel () from /lib64/libc.so.6
#1 0x00000000005919c6 in FileRead (file=<value optimized out>, 
buffer=0x1fd08bcc "\t",
amount=<value optimized out>) at fd.c:1039
#2 0x0000000000592223 in BufFileRead (file=0x1fd08ba0, ptr=0x212af860, 
size=8192) at buffile.c:237
#3 0x000000000065cca8 in ltsReadBlock (lts=0x21245a00, blocknum=149704, 
buffer=0x212af860) at logtape.c:227
#4 0x000000000065d5fe in LogicalTapeRead (lts=0x21245a00, tapenum=<value 
optimized out>, ptr=0x2121ebe0, size=24)
at logtape.c:796
#5 0x000000000065f624 in readtup_index (state=0x1f905300, 
stup=0x7fff7f710ef0, tapenum=52,
len=<value optimized out>) at tuplesort.c:2797
#6 0x000000000065e3ac in mergeprereadone (state=0x1f905300, srcTape=52) 
at tuplesort.c:1936
#7 0x000000000065e461 in mergepreread (state=0x97) at tuplesort.c:1904
#8 0x00000000006608d8 in tuplesort_performsort (state=0x1f905300) at 
tuplesort.c:1753
#9 0x0000000000469bb0 in _bt_leafbuild (btspool=0x1fbb1be0, 
btspool2=0x1fd08bcc) at nbtsort.c:203
#10 0x0000000000466c36 in btbuild (fcinfo=<value optimized out>) at 
nbtree.c:136
#11 0x0000000000648827 in OidFunctionCall3 (functionId=<value optimized 
out>, arg1=47722312327280,
arg2=47722312268368, arg3=532345328) at fmgr.c:1586
#12 0x0000000000492819 in index_build (heapRelation=0x2b6737796070, 
indexRelation=0x2b6737787a50,
indexInfo=0x1fbaf1f0, isprimary=0 '\0') at index.c:1366
#13 0x000000000049330c in reindex_index (indexId=16904) at index.c:2284
#14 0x000000000049356e in reindex_relation (relid=<value optimized out>, 
toast_too=1 '\001') at index.c:2393
#15 0x00000000004e2c02 in ReindexTable (relation=0x1fb15da0) at 
indexcmds.c:1344
#16 0x000000000052d1ad in _SPI_execute_plan (plan=0x7fff7f711890, 
Values=0x0, Nulls=0x0, snapshot=0x0,
crosscheck_snapshot=0x0, read_only=0 '\0', fire_triggers=1 '\001', 
tcount=<value optimized out>) at spi.c:1700
#17 0x000000000052d931 in SPI_execute (src=0x1fb6d260 "reindex table 
\"public\".\"eventlog\"", read_only=0 '\0',
tcount=0) at spi.c:342
#18 0x00002b67377b0413 in exec_stmt_dynexecute (estate=0x7fff7f711ba0, 
stmt=0x1faa3f90) at pl_exec.c:2688
#19 0x00002b67377b1ac7 in exec_stmts (estate=0x7fff7f711ba0, 
stmts=<value optimized out>) at pl_exec.c:1264
#20 0x00002b67377b31d5 in exec_stmt_block (estate=0x7fff7f711ba0, 
block=0x1faa40b0) at pl_exec.c:1114
#21 0x00002b67377b3b4f in plpgsql_exec_function (func=0x1fa8efb0, 
fcinfo=0x7fff7f711e00) at pl_exec.c:291
#22 0x00002b67377aaaae in plpgsql_call_handler (fcinfo=0x7fff7f711e00) 
at pl_handler.c:95
#23 0x000000000051837e in ExecMakeFunctionResult (fcache=0x1f97a740, 
econtext=0x1f97a630, isNull=0x1f97ad48 " ?]",
---Type <return> to continue, or q <return> to quit---
isDone=0x1f97adf0) at execQual.c:1351
#24 0x00000000005168e3 in ExecProject (projInfo=<value optimized out>, 
isDone=0x7fff7f7122ac) at execQual.c:4610
#25 0x0000000000527203 in ExecResult (node=0x1f97a520) at nodeResult.c:155
#26 0x0000000000516356 in ExecProcNode (node=0x1f97a520) at 
execProcnode.c:319
#27 0x00000000005155df in ExecutorRun (queryDesc=<value optimized out>, 
direction=ForwardScanDirection, count=0)
at execMain.c:1335
#28 0x00000000005a68e1 in PortalRunSelect (portal=0x1f9032f0, 
forward=<value optimized out>, count=0,
dest=0x1f8c32f0) at pquery.c:943
#29 0x00000000005a7ab9 in PortalRun (portal=0x1f9032f0, 
count=9223372036854775807, isTopLevel=0 '\0',
dest=0x1f8c32f0, altdest=0x1f8c32f0, completionTag=0x7fff7f7125b0 "") at 
pquery.c:769
#30 0x00000000005a38a4 in exec_simple_query (
query_string=0x1f8c1fa0 "select \"_prod\".finishTableAfterCopy(29); 
analyze \"public\".\"el\"; ")
at postgres.c:1004
#31 0x00000000005a44f8 in PostgresMain (argc=4, argv=<value optimized 
out>, username=0x1f820a10 "postgres")
at postgres.c:3631
#32 0x000000000057b16a in ServerLoop () at postmaster.c:3207
#33 0x000000000057bc2f in PostmasterMain (argc=2, argv=0x1f81bb90) at 
postmaster.c:1029
#34 0x00000000005353de in main (argc=2, argv=<value optimized out>) at 
main.c:188
(gdb) quit


What is going on here? This reindexing has been going on for far longer 
than the initial copy time. Any why is it reindexing? 
finishTableAfterCopy() should be a noop.
From admin at bitnoize.co.cc  Tue May  5 03:44:45 2009
From: admin at bitnoize.co.cc (Philipp Haselwarter)
Date: Tue May  5 03:45:18 2009
Subject: [Slony1-general] Setting up slony 2.01 on Win2003 Server
Message-ID: <77cdc54b0905050344m5e6dbd10se73c67156eb40616@mail.gmail.com>

Hi list,

I'm trying to get slony-I (v2.0.1) running with postgres 8.3 on  Windows
Server 2003.
I found a lot of documentation but much of it seems to be outdated, written
for UNIX, contradicting other instructions or simpely not working for me.

So far I installed postgres 8.3 using the installer and put the binaries
from http://developer.pgadmin.org/~hiroshi/Slony-I/ into the respective
directories (c:/program files/postgresql/8.3/..) and registered slon as a
service using the command line as local administrator and " sc create
Slony-I binPath=3D "c:\Program Files\PostgreSQL\8.3\bin\slon.exe -service" =
".

What are the next steps to take?
If I open pgAdmin, connect to my localhost server and try to create a new
Slony-I cluster I get something like 'Slony-I creation scripts not
available; only joining possible'.
Where do I have to do further configuration, and in what order?

thanks, p.h.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090505/=
e981ea43/attachment.htm
From rod at iol.ie  Tue May  5 04:02:46 2009
From: rod at iol.ie (Raymond O'Donnell)
Date: Tue May  5 04:03:24 2009
Subject: [Slony1-general] Setting up slony 2.01 on Win2003 Server
In-Reply-To: <77cdc54b0905050344m5e6dbd10se73c67156eb40616@mail.gmail.com>
References: <77cdc54b0905050344m5e6dbd10se73c67156eb40616@mail.gmail.com>
Message-ID: <4A001CD6.7000304@iol.ie>

On 05/05/2009 11:44, Philipp Haselwarter wrote:
> So far I installed postgres 8.3 using the installer and put the binaries
> from http://developer.pgadmin.org/~hiroshi/Slony-I/ into the respective
> directories (c:/program files/postgresql/8.3/..) and registered slon as a
> service using the command line as local administrator and " sc create
> Slony-I binPath= "c:\Program Files\PostgreSQL\8.3\bin\slon.exe -service" ".
> 
> What are the next steps to take?

Sounds good so far..... From here, I think you do pretty much as in the
documentation - I found the section on "replicating your first database"
a good walk-through:

  http://www.slony.info/documentation/firstdb.html

I didn't do it with pgAdmin; instead, I wrote slonik scripts using the
ones in this example as templates, and it all worked fine. The only
difference for running on Windows is that instead of having separate
slons for each node, you have just one slon registered as a service (as
you've done), and then use the slon --addengine command to register each
node with the service. Once you've done that, restart the slon service
and cross your fingers! :-)

Ray.

------------------------------------------------------------------
Raymond O'Donnell, Director of Music, Galway Cathedral, Ireland
rod@iol.ie
Galway Cathedral Recitals: http://www.galwaycathedral.org/recitals
------------------------------------------------------------------
From bnichols at ca.afilias.info  Tue May  5 11:19:56 2009
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Tue May  5 11:20:07 2009
Subject: [Slony1-general] replication reindexing forever after initial copy
In-Reply-To: <49FFBAAC.6040909@selectacast.net>
References: <49FFBAAC.6040909@selectacast.net>
Message-ID: <1241547596.2848.7.camel@bnicholson-desktop>

On Tue, 2009-05-05 at 00:03 -0400, Joseph S wrote:
> I set up a slony cluster to replicate from an 8.2.13 database to a 8.3.7 
> database (slony 1.2.15) . During the initial copy this has been going on 
> for over 3 hours:
> select "_prod".finishTableAfterCopy(29); analyze "public"."el";
> 
> gdb shows:
> 
> (gdb) bt
> #0 0x0000003c144c54f0 in __read_nocancel () from /lib64/libc.so.6
> #1 0x00000000005919c6 in FileRead (file=<value optimized out>, 
> buffer=0x1fd08bcc "\t",
> amount=<value optimized out>) at fd.c:1039
> #2 0x0000000000592223 in BufFileRead (file=0x1fd08ba0, ptr=0x212af860, 
> size=8192) at buffile.c:237
> #3 0x000000000065cca8 in ltsReadBlock (lts=0x21245a00, blocknum=149704, 
> buffer=0x212af860) at logtape.c:227
> #4 0x000000000065d5fe in LogicalTapeRead (lts=0x21245a00, tapenum=<value 
> optimized out>, ptr=0x2121ebe0, size=24)
> at logtape.c:796
> #5 0x000000000065f624 in readtup_index (state=0x1f905300, 
> stup=0x7fff7f710ef0, tapenum=52,
> len=<value optimized out>) at tuplesort.c:2797
> #6 0x000000000065e3ac in mergeprereadone (state=0x1f905300, srcTape=52) 
> at tuplesort.c:1936
> #7 0x000000000065e461 in mergepreread (state=0x97) at tuplesort.c:1904
> #8 0x00000000006608d8 in tuplesort_performsort (state=0x1f905300) at 
> tuplesort.c:1753
> #9 0x0000000000469bb0 in _bt_leafbuild (btspool=0x1fbb1be0, 
> btspool2=0x1fd08bcc) at nbtsort.c:203
> #10 0x0000000000466c36 in btbuild (fcinfo=<value optimized out>) at 
> nbtree.c:136
> #11 0x0000000000648827 in OidFunctionCall3 (functionId=<value optimized 
> out>, arg1=47722312327280,
> arg2=47722312268368, arg3=532345328) at fmgr.c:1586
> #12 0x0000000000492819 in index_build (heapRelation=0x2b6737796070, 
> indexRelation=0x2b6737787a50,
> indexInfo=0x1fbaf1f0, isprimary=0 '\0') at index.c:1366
> #13 0x000000000049330c in reindex_index (indexId=16904) at index.c:2284
> #14 0x000000000049356e in reindex_relation (relid=<value optimized out>, 
> toast_too=1 '\001') at index.c:2393
> #15 0x00000000004e2c02 in ReindexTable (relation=0x1fb15da0) at 
> indexcmds.c:1344
> #16 0x000000000052d1ad in _SPI_execute_plan (plan=0x7fff7f711890, 
> Values=0x0, Nulls=0x0, snapshot=0x0,
> crosscheck_snapshot=0x0, read_only=0 '\0', fire_triggers=1 '\001', 
> tcount=<value optimized out>) at spi.c:1700
> #17 0x000000000052d931 in SPI_execute (src=0x1fb6d260 "reindex table 
> \"public\".\"eventlog\"", read_only=0 '\0',
> tcount=0) at spi.c:342
> #18 0x00002b67377b0413 in exec_stmt_dynexecute (estate=0x7fff7f711ba0, 
> stmt=0x1faa3f90) at pl_exec.c:2688
> #19 0x00002b67377b1ac7 in exec_stmts (estate=0x7fff7f711ba0, 
> stmts=<value optimized out>) at pl_exec.c:1264
> #20 0x00002b67377b31d5 in exec_stmt_block (estate=0x7fff7f711ba0, 
> block=0x1faa40b0) at pl_exec.c:1114
> #21 0x00002b67377b3b4f in plpgsql_exec_function (func=0x1fa8efb0, 
> fcinfo=0x7fff7f711e00) at pl_exec.c:291
> #22 0x00002b67377aaaae in plpgsql_call_handler (fcinfo=0x7fff7f711e00) 
> at pl_handler.c:95
> #23 0x000000000051837e in ExecMakeFunctionResult (fcache=0x1f97a740, 
> econtext=0x1f97a630, isNull=0x1f97ad48 " ?]",
> ---Type <return> to continue, or q <return> to quit---
> isDone=0x1f97adf0) at execQual.c:1351
> #24 0x00000000005168e3 in ExecProject (projInfo=<value optimized out>, 
> isDone=0x7fff7f7122ac) at execQual.c:4610
> #25 0x0000000000527203 in ExecResult (node=0x1f97a520) at nodeResult.c:155
> #26 0x0000000000516356 in ExecProcNode (node=0x1f97a520) at 
> execProcnode.c:319
> #27 0x00000000005155df in ExecutorRun (queryDesc=<value optimized out>, 
> direction=ForwardScanDirection, count=0)
> at execMain.c:1335
> #28 0x00000000005a68e1 in PortalRunSelect (portal=0x1f9032f0, 
> forward=<value optimized out>, count=0,
> dest=0x1f8c32f0) at pquery.c:943
> #29 0x00000000005a7ab9 in PortalRun (portal=0x1f9032f0, 
> count=9223372036854775807, isTopLevel=0 '\0',
> dest=0x1f8c32f0, altdest=0x1f8c32f0, completionTag=0x7fff7f7125b0 "") at 
> pquery.c:769
> #30 0x00000000005a38a4 in exec_simple_query (
> query_string=0x1f8c1fa0 "select \"_prod\".finishTableAfterCopy(29); 
> analyze \"public\".\"el\"; ")
> at postgres.c:1004
> #31 0x00000000005a44f8 in PostgresMain (argc=4, argv=<value optimized 
> out>, username=0x1f820a10 "postgres")
> at postgres.c:3631
> #32 0x000000000057b16a in ServerLoop () at postmaster.c:3207
> #33 0x000000000057bc2f in PostmasterMain (argc=2, argv=0x1f81bb90) at 
> postmaster.c:1029
> #34 0x00000000005353de in main (argc=2, argv=<value optimized out>) at 
> main.c:188
> (gdb) quit
> 
> 
> What is going on here? This reindexing has been going on for far longer 
> than the initial copy time. Any why is it reindexing? 
> finishTableAfterCopy() should be a noop.

I can think of a few reasons for this

Is something is accessing the table(s) and blocking the indexing?

Do you have a lot of indexes which simply take time to build than the
copy?

Is maintenance_work_mem is set to low?
-- 
Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.


From cbbrowne at ca.afilias.info  Tue May  5 11:34:14 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue May  5 11:34:27 2009
Subject: [Slony1-general] Stability of Slony 2.01
In-Reply-To: <3c2d02c90905041855q6bddc60dm38e1b331bff43f04@mail.gmail.com>
	(Christian Storm's message of "Mon, 4 May 2009 18:55:04 -0700")
References: <3c2d02c90905041854g2a7a49bclac033d19d31f3acb@mail.gmail.com>
	<3c2d02c90905041855q6bddc60dm38e1b331bff43f04@mail.gmail.com>
Message-ID: <87skjjcsbd.fsf@dba2.int.libertyrms.com>

Christian Storm <storm@iparadigms.com> writes:
> What is the general consensus concerning the stability of Slony
> 2.01. ?We want to upgrade but am typically wary of adopting major
> revision upgrades too soon. ?Are there any outstanding
> issues/patches?

Version 2.0.2 is pending Real Soon Now; it has a lot of little
changes, but nothing surrounding overall data integrity.

You can see release notes here:
   <http://main.slony.info/viewcvs/viewvc.cgi/slony1-engine/RELEASE?revision=1.3.2.11&view=markup>

There aren't any changes that surround "data integrity" issues,
indeed, there haven't been any such changes since 2.0.0 (which has
overall Very Material Changes from the 1.2 branch).
-- 
select 'cbbrowne' || '@' || 'ca.afilias.info';
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)
"Bother,"  said Pooh,  "Eeyore, ready  two photon  torpedoes  and lock
phasers on the Heffalump, Piglet, meet me in transporter room three"
From cbbrowne at ca.afilias.info  Tue May  5 11:44:10 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue May  5 11:44:24 2009
Subject: [Slony1-general] replication reindexing forever after initial copy
In-Reply-To: <49FFBAAC.6040909@selectacast.net> (Joseph S.'s message of "Tue, 
	05 May 2009 00:03:56 -0400")
References: <49FFBAAC.6040909@selectacast.net>
Message-ID: <87ocu7crut.fsf@dba2.int.libertyrms.com>

Joseph S <jks@selectacast.net> writes:
> What is going on here? This reindexing has been going on for far
> longer than the initial copy time. Any why is it reindexing? 
> finishTableAfterCopy() should be a noop.

finishTableAfterCopy is definitely NOT a no-op - it does indeed
properly need to reindex the table, because, in an earlier step
(prepareTableForCopy()), the indices were shut off.

It is *WAY* more efficient to recreate indices in bulk than it is to
load data in with the indices active.

I would presume that this table, "el", is one that is rather large,
and which has several indices?

We have seen cases where it took ~1hr to COPY data into an (unindexed)
table, then several hours to reindex it.  That may appear expensive,
but the point is that it's substantially *less* expensive than the
"several *additional* hours" that would be required to COPY the data
into the table *with* indices.  It isn't remarkable for it to take
much longer to generate indices than it does to COPY data into the
table; COPY is mighty efficient.

In short, this isn't a mistake, and if we did as you suggest, it would
be expected to take considerably longer than 4 hours to load the data
into that table.
-- 
let name="cbbrowne" and tld="linuxdatabases.info" in String.concat "@" [name;tld];;
http://cbbrowne.com/info/linux.html
Rules of the Evil Overlord #144. "I will order my guards to stand in a
line  when they shoot  at the  hero so  he cannot  duck and  have them
accidentally shoot each  other. Also, I will order  some to aim above,
below, and to the sides so he cannot jump out of the way."
<http://www.eviloverlord.com/>

From jks at selectacast.net  Tue May  5 12:09:41 2009
From: jks at selectacast.net (Joseph S)
Date: Tue May  5 12:09:57 2009
Subject: [Slony1-general] replication reindexing forever after initial copy
In-Reply-To: <87ocu7crut.fsf@dba2.int.libertyrms.com>
References: <49FFBAAC.6040909@selectacast.net>
	<87ocu7crut.fsf@dba2.int.libertyrms.com>
Message-ID: <4A008EF5.5040906@selectacast.net>

Christopher Browne wrote:
> Joseph S <jks@selectacast.net> writes:
>> What is going on here? This reindexing has been going on for far
>> longer than the initial copy time. Any why is it reindexing? 
>> finishTableAfterCopy() should be a noop.
> 
> finishTableAfterCopy is definitely NOT a no-op - it does indeed

I guess I was confused.  I grepped the slony source and found a 
finishTableAfterCopy() in tools/slony1_dump.sh that was a noop and 
assumed that was what slony was using.
From rindahl at lrcwe.com  Thu May  7 09:03:12 2009
From: rindahl at lrcwe.com (Bruce Rindahl)
Date: Thu May  7 09:03:21 2009
Subject: [Slony1-general] simple configuration files on Debian/Ubuntu
Message-ID: <4A030640.4050405@lrcwe.com>

I have slony running fine between several machines including Windows and 
Debian/Ubuntu.  The configuration is done via pgAdmin - not any script 
files.  On windows everything is straightforward but in Debian/Ubuntu I 
have to run the following command:
slon my_cluster_name "host=localhost dbname=myDBNAME user=slony"
When I do this (and redirect to /dev/null and in background) slony runs 
fine.  How do I put this information into a configuration file so the 
slony daemon reads this automatically on startup?
Thanks
Bruce
From rod at iol.ie  Thu May  7 10:47:25 2009
From: rod at iol.ie (Raymond O'Donnell)
Date: Thu May  7 10:47:42 2009
Subject: [Slony1-general] simple configuration files on Debian/Ubuntu
In-Reply-To: <4A030640.4050405@lrcwe.com>
References: <4A030640.4050405@lrcwe.com>
Message-ID: <4A031EAD.4020807@iol.ie>

On 07/05/2009 17:03, Bruce Rindahl wrote:
> slon my_cluster_name "host=localhost dbname=myDBNAME user=slony"
> When I do this (and redirect to /dev/null and in background) slony runs
> fine.  How do I put this information into a configuration file so the
> slony daemon reads this automatically on startup?

Use the -f option to specify the file:

  slon -f my_config_file (etc)

http://www.slony.info/documentation/slon.html

Ray.

------------------------------------------------------------------
Raymond O'Donnell, Director of Music, Galway Cathedral, Ireland
rod@iol.ie
Galway Cathedral Recitals: http://www.galwaycathedral.org/recitals
------------------------------------------------------------------
From glynastill at yahoo.co.uk  Thu May  7 10:48:17 2009
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Thu May  7 10:48:28 2009
Subject: [Slony1-general] simple configuration files on Debian/Ubuntu
In-Reply-To: <4A030640.4050405@lrcwe.com>
Message-ID: <658976.74016.qm@web23606.mail.ird.yahoo.com>


--- On Thu, 7/5/09, Bruce Rindahl <rindahl@lrcwe.com> wrote:

> When I do this (and redirect to /dev/null and in
> background) slony runs fine.  How do I put this information
> into a configuration file so the slony daemon reads this
> automatically on startup?


Hi Bruce,

You need to create an init script in /etc/init.d and then use update-rc.d to set the runlevels and order to run

Mine is pasted below, you'll need to edit it as appropriate. Note the use of slon.conf rather than passing the adminconinfo at the command line:

#!/bin/sh

# Name script
NAME=slony

# Source function library.
. /lib/lsb/init-functions

# Get function listing for cross-distribution logic.
TYPESET=`typeset -f|grep "declare"`

# Installation prefix
prefix=/usr/local/pgsql

# Data directory
PGDATA=/pgsql/postgres
SLONDATA=/pgsql/slony
LOGDATA=/pgsql/logs

# Slony user
PGUSER=slony

# Set defaults for configuration variables
SLONENGINE=$prefix/bin
SLONDAEMON=$SLONENGINE/slon
SLONCONF=$SLONDATA/slon.conf
SLONLOG=$LOGDATA/slon.log

# Grab the pid file from the conf file
SLONPIDLINE=`grep pid_file $SLONCONF | cut -d "#" -f 1 | grep "^[:space:]*pid_file='.*'"`
SLONPID=`echo $SLONPIDLINE | cut -d "=" -f 2 | cut -d "'" -f 2`


# Now, we know where the pid file is, if we find it we grab the 
# pid out of the file then we see if it's in the process list. 
# This should ensuire slon  restarts in the case of a crash.
if [ "x$SLONPID" == "x" ]; then
    echo "pid_file not found in slon conf file - $SLONCONF"
    exit 1
else
    if [ -f $SLONPID ]; then
       PID=`cat $SLONPID`
       FINDPID=`ps -p ${PID} | awk '{print $1}' | grep "^$PID\$"`
    fi
fi



test -x $SLONDAEMON || exit 5


script_result=0

start(){

	echo -n $"Starting ${NAME} service: "
	
	if [ ! -z "$FINDPID" ]
	then	
		echo "PID file ${SLONPID} indicates slon already running PID $PID : Not starting "
	else
		su - $PGUSER -c "$SLONDAEMON -f $SLONCONF > "$SLONLOG" 2>&1 &" < /dev/null
		sleep 5
	fi

	if [ -f $SLONPID ]; then
    	   PID=`cat $SLONPID`
    	   FINDPID=`ps -p ${PID} | awk '{print $1}' | grep "^$PID\$"`
    	fi

	if [ ! -z "$FINDPID" ]
	then
		echo "OK"
	else
		echo "Failed"
	fi
	
	RETVAL=$?
	echo
        return $RETVAL
}

stop(){

	echo -n $"Stopping ${NAME} service: "
	if [ ! -z "$FINDPID" ]
	then
		killall -s SIGTERM slon
		sleep 5
	
		PID=``
        	FINDPID=``
	else
		echo "Slon with PID ${PID} not found"
	fi

	if [ -f $SLONPID ]; then
    	   PID=`cat $SLONPID`
    	   FINDPID=`ps -p ${PID} | awk '{print $1}' | grep "^$PID\$"`
    	fi

	if [ ! -z "$FINDPID" ]
	then
		echo "Failed"
	else
		echo "OK"
	fi

	RETVAL=$?
	echo
	return $RETVAL
}

restart(){
    stop
    echo "Waiting for 10 seconds"
    sleep 10
    start
}


# See how we were called.
case "$1" in
  start)
        start
        ;;
  stop)
        stop
        ;;
  restart)
        restart
        ;;
  *)
        echo $"Usage: $0 {start|stop|restart}"
        exit 1
esac

exit $script_result



      
From glynastill at yahoo.co.uk  Fri May  8 02:51:12 2009
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Fri May  8 02:51:46 2009
Subject: [Slony1-general] MOVE SET confusion
Message-ID: <594526.17693.qm@web23603.mail.ird.yahoo.com>


Hi chaps,

We have a setup with 3 nodes. Initially nodes 2 and 3 were subscribed to 1, but last night I moved the origin to 2 as per the docs.

All seems to be well, but I'm confused with what the logs are showing. Node 1 has the following in it's logs for each set;

remoteWorkerThread_2: syncing set 2 with 43 table(s) from provider 2

But node 3 is saying this;

remoteWorkerThread_2: syncing set 2 with 43 table(s) from provider 1

Surely when I moved the origin from node 1 to 2, both nodes should be syncing from node 2?

Anyone?

Regards
Glyn


      
From varathasiva at gmail.com  Fri May  8 04:06:57 2009
From: varathasiva at gmail.com (Siva)
Date: Fri May  8 04:07:31 2009
Subject: [Slony1-general] (no subject)
Message-ID: <da7777050905080406v41137406ld7d40720ea66f357@mail.gmail.com>

can u stop this kind of email.i was in queue
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090508/=
41d7799a/attachment.htm
From glynastill at yahoo.co.uk  Fri May  8 04:14:30 2009
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Fri May  8 04:15:05 2009
Subject: [Slony1-general] MOVE SET confusion
In-Reply-To: <594526.17693.qm@web23603.mail.ird.yahoo.com>
Message-ID: <979011.25996.qm@web23606.mail.ird.yahoo.com>


Ah, obviously it'd help if I stated this is 1.2.15


--- On Fri, 8/5/09, Glyn Astill <glynastill@yahoo.co.uk> wrote:

> From: Glyn Astill <glynastill@yahoo.co.uk>
> Subject: [Slony1-general] MOVE SET confusion
> To: slony1-general@lists.slony.info
> Date: Friday, 8 May, 2009, 10:51 AM
> Hi chaps,
> 
> We have a setup with 3 nodes. Initially nodes 2 and 3 were
> subscribed to 1, but last night I moved the origin to 2 as
> per the docs.
> 
> All seems to be well, but I'm confused with what the
> logs are showing. Node 1 has the following in it's logs
> for each set;
> 
> remoteWorkerThread_2: syncing set 2 with 43 table(s) from
> provider 2
> 
> But node 3 is saying this;
> 
> remoteWorkerThread_2: syncing set 2 with 43 table(s) from
> provider 1
> 
> Surely when I moved the origin from node 1 to 2, both nodes
> should be syncing from node 2?
> 
> Anyone?
> 
> Regards
> Glyn
> 
> 
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


      
From glynastill at yahoo.co.uk  Sat May  9 02:49:18 2009
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Sat May  9 02:49:53 2009
Subject: [Slony1-general] MOVE SET confusion
In-Reply-To: <979011.25996.qm@web23606.mail.ird.yahoo.com>
Message-ID: <251181.57762.qm@web23603.mail.ird.yahoo.com>





--- On Fri, 8/5/09, Glyn Astill <glynastill@yahoo.co.uk> wrote:

> Ah, obviously it'd help if I stated this is 1.2.15
> 
> 
> --- On Fri, 8/5/09, Glyn Astill <glynastill@yahoo.co.uk> wrote:
> > 
> > We have a setup with 3 nodes. Initially nodes 2 and 3
> were
> > subscribed to 1, but last night I moved the origin to
> 2 as
> > per the docs.
> > 
> > All seems to be well, but I'm confused with what
> the
> > logs are showing. Node 1 has the following in it's
> logs
> > for each set;
> > 
> > remoteWorkerThread_2: syncing set 2 with 43 table(s)
> from
> > provider 2
> > 
> > But node 3 is saying this;
> > 
> > remoteWorkerThread_2: syncing set 2 with 43 table(s)
> from
> > provider 1
> > 
> > Surely when I moved the origin from node 1 to 2, both
> nodes
> > should be syncing from node 2?
> > 
> > Anyone?
> > 
> > Regards
> > Glyn
> > 

Anyone?


      
From stuart at stuartbishop.net  Sat May  9 04:05:09 2009
From: stuart at stuartbishop.net (Stuart Bishop)
Date: Sat May  9 04:05:44 2009
Subject: [Slony1-general] simple configuration files on Debian/Ubuntu
In-Reply-To: <4A030640.4050405@lrcwe.com>
References: <4A030640.4050405@lrcwe.com>
Message-ID: <6bc73d4c0905090405t49c77953yef6af9cbb04a6382@mail.gmail.com>

On Thu, May 7, 2009 at 11:03 PM, Bruce Rindahl <rindahl@lrcwe.com> wrote:
> I have slony running fine between several machines including Windows and
> Debian/Ubuntu. ?The configuration is done via pgAdmin - not any script
> files. ?On windows everything is straightforward but in Debian/Ubuntu I have
> to run the following command:
> slon my_cluster_name "host=localhost dbname=myDBNAME user=slony"
> When I do this (and redirect to /dev/null and in background) slony runs
> fine. ?How do I put this information into a configuration file so the slony
> daemon reads this automatically on startup?

If you are using the Debian or Ubuntu packages, the startup script it
/etc/init.d/slony1 and it looks in /etc/slony1 for the config files.
Create a directory in there for each node, containing its slon.conf
file.

-- 
Stuart Bishop <stuart@stuartbishop.net>
http://www.stuartbishop.net/
From rindahl at lrcwe.com  Sat May  9 10:02:45 2009
From: rindahl at lrcwe.com (rindahl@lrcwe.com)
Date: Sat May  9 10:02:55 2009
Subject: [Slony1-general] simple configuration files on Debian/Ubuntu
Message-ID: <4013.1241888565@lrcwe.com>

Perfect!
Thanks


On Sat May  9  6:05 , Stuart Bishop  sent:

>On Thu, May 7, 2009 at 11:03 PM, Bruce Rindahl rindahl@lrcwe.com> wrote:
>> I have slony running fine between several machines including Windows and
>> Debian/Ubuntu. ?The configuration is done via pgAdmin - not any script
>> files. ?On windows everything is straightforward but in Debian/Ubuntu I have
>> to run the following command:
>> slon my_cluster_name "host=localhost dbname=myDBNAME user=slony"
>> When I do this (and redirect to /dev/null and in background) slony runs
>> fine. ?How do I put this information into a configuration file so the slony
>> daemon reads this automatically on startup?
>
>If you are using the Debian or Ubuntu packages, the startup script it
>/etc/init.d/slony1 and it looks in /etc/slony1 for the config files.
>Create a directory in there for each node, containing its slon.conf
>file.
>
>-- 
>Stuart Bishop stuart@stuartbishop.net>
>http://www.stuartbishop.net/



From glynastill at yahoo.co.uk  Mon May 11 04:26:51 2009
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Mon May 11 04:27:27 2009
Subject: [Slony1-general] MOVE SET confusion
In-Reply-To: <979011.25996.qm@web23606.mail.ird.yahoo.com>
Message-ID: <71270.58589.qm@web23605.mail.ird.yahoo.com>


I'm still trying to figure this one out chaps.

>From what I can see the move set command moved the origin from 1 to 2 successfully, but why is node 3 still subscribed to node 1? Surely it should have had it's subscribtion moved to node 2?

Here's sl_subscribe

SEE=# select * from _main_replication.sl_subscribe order by sub_provider, sub_set;
 sub_set | sub_provider | sub_receiver | sub_forward | sub_active
---------+--------------+--------------+-------------+------------
       1 |            1 |            3 | t           | t
       2 |            1 |            3 | t           | t
       3 |            1 |            3 | t           | t
       4 |            1 |            3 | t           | t
       5 |            1 |            3 | t           | t
       6 |            1 |            3 | t           | t
       7 |            1 |            3 | t           | t
    1000 |            1 |            3 | t           | t
       1 |            2 |            1 | t           | t
       2 |            2 |            1 | t           | t
       3 |            2 |            1 | t           | t
       4 |            2 |            1 | t           | t
       5 |            2 |            1 | t           | t
       6 |            2 |            1 | t           | t
       7 |            2 |            1 | t           | t
    1000 |            2 |            1 | t           | t
(16 rows)

And here's what I did;

CLUSTER NAME = main_replication;
NODE 1 ADMIN CONNINFO = 'dbname=SEE host=192.168.240.10 user=slony';
NODE 2 ADMIN CONNINFO = 'dbname=SEE host=192.168.240.11 user=slony';
NODE 3 ADMIN CONNINFO = 'dbname=SEE host=192.168.240.12 user=slony';

DEFINE set_to_move 1;
DEFINE old_origin 1;
DEFINE new_origin 2;
DEFINE other_node 3;

LOCK SET ( ID = @set_to_move, ORIGIN = @old_origin);

WAIT FOR EVENT (ORIGIN = @old_origin, CONFIRMED = @new_origin);
WAIT FOR EVENT (ORIGIN = @old_origin, CONFIRMED = @other_node);

MOVE SET ( ID = @set_to_move, OLD ORIGIN = @old_origin, NEW ORIGIN = @new_origin);
WAIT FOR EVENT (ORIGIN = @old_origin, CONFIRMED = @new_origin);
WAIT FOR EVENT (ORIGIN = @old_origin, CONFIRMED = @other_node);


So for now everything is running, but what did I do wrong to leave node 3 still subscribed to node 1? 

What can I do to to move the subscription of node 3 over from noode 1 to 2?

Any ideas would be very much appreciated, I'm a little worried at the moment, especially with the silence.

Thanks
Glyn


--- On Fri, 8/5/09, Glyn Astill <glynastill@yahoo.co.uk> wrote:

> From: Glyn Astill <glynastill@yahoo.co.uk>
> Subject: Re: [Slony1-general] MOVE SET confusion
> To: slony1-general@lists.slony.info
> Date: Friday, 8 May, 2009, 12:14 PM
> Ah, obviously it'd help if I stated this is 1.2.15
> 
> 
> --- On Fri, 8/5/09, Glyn Astill
> <glynastill@yahoo.co.uk> wrote:
> 
> > From: Glyn Astill <glynastill@yahoo.co.uk>
> > Subject: [Slony1-general] MOVE SET confusion
> > To: slony1-general@lists.slony.info
> > Date: Friday, 8 May, 2009, 10:51 AM
> > Hi chaps,
> > 
> > We have a setup with 3 nodes. Initially nodes 2 and 3
> were
> > subscribed to 1, but last night I moved the origin to
> 2 as
> > per the docs.
> > 
> > All seems to be well, but I'm confused with what
> the
> > logs are showing. Node 1 has the following in it's
> logs
> > for each set;
> > 
> > remoteWorkerThread_2: syncing set 2 with 43 table(s)
> from
> > provider 2
> > 
> > But node 3 is saying this;
> > 
> > remoteWorkerThread_2: syncing set 2 with 43 table(s)
> from
> > provider 1
> > 
> > Surely when I moved the origin from node 1 to 2, both
> nodes
> > should be syncing from node 2?
> > 
> > Anyone?
> > 
> > Regards
> > Glyn
> > 
> > 
> > 
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general@lists.slony.info
> >
> http://lists.slony.info/mailman/listinfo/slony1-general
> 
> 
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


      
From stephane.schildknecht at postgresqlfr.org  Mon May 11 05:05:24 2009
From: stephane.schildknecht at postgresqlfr.org (=?ISO-8859-15?Q?=22St=E9phane_A=2E_Schildknecht=22?=)
Date: Mon May 11 05:05:28 2009
Subject: [Slony1-general] MOVE SET confusion
In-Reply-To: <71270.58589.qm@web23605.mail.ird.yahoo.com>
References: <71270.58589.qm@web23605.mail.ird.yahoo.com>
Message-ID: <4A081484.6020603@postgresqlfr.org>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi Glyn,

Glyn Astill a ?crit :
> I'm still trying to figure this one out chaps.
> 
>>From what I can see the move set command moved the origin from 1 to 2 successfully, but why is node 3 still subscribed to node 1? Surely it should have had it's subscribtion moved to node 2?
> 
> Here's sl_subscribe
> 
> SEE=# select * from _main_replication.sl_subscribe order by sub_provider, sub_set;
>  sub_set | sub_provider | sub_receiver | sub_forward | sub_active
> ---------+--------------+--------------+-------------+------------
>        1 |            1 |            3 | t           | t
>        2 |            1 |            3 | t           | t
>        3 |            1 |            3 | t           | t
>        4 |            1 |            3 | t           | t
>        5 |            1 |            3 | t           | t
>        6 |            1 |            3 | t           | t
>        7 |            1 |            3 | t           | t
>     1000 |            1 |            3 | t           | t
>        1 |            2 |            1 | t           | t
>        2 |            2 |            1 | t           | t
>        3 |            2 |            1 | t           | t
>        4 |            2 |            1 | t           | t
>        5 |            2 |            1 | t           | t
>        6 |            2 |            1 | t           | t
>        7 |            2 |            1 | t           | t
>     1000 |            2 |            1 | t           | t
> (16 rows)
> 
> And here's what I did;
> 
> CLUSTER NAME = main_replication;
> NODE 1 ADMIN CONNINFO = 'dbname=SEE host=192.168.240.10 user=slony';
> NODE 2 ADMIN CONNINFO = 'dbname=SEE host=192.168.240.11 user=slony';
> NODE 3 ADMIN CONNINFO = 'dbname=SEE host=192.168.240.12 user=slony';
> 
> DEFINE set_to_move 1;
> DEFINE old_origin 1;
> DEFINE new_origin 2;
> DEFINE other_node 3;
> 
> LOCK SET ( ID = @set_to_move, ORIGIN = @old_origin);
> 
> WAIT FOR EVENT (ORIGIN = @old_origin, CONFIRMED = @new_origin);
> WAIT FOR EVENT (ORIGIN = @old_origin, CONFIRMED = @other_node);
> 
> MOVE SET ( ID = @set_to_move, OLD ORIGIN = @old_origin, NEW ORIGIN = @new_origin);
> WAIT FOR EVENT (ORIGIN = @old_origin, CONFIRMED = @new_origin);
> WAIT FOR EVENT (ORIGIN = @old_origin, CONFIRMED = @other_node);
> 
> 
> So for now everything is running, but what did I do wrong to leave node 3 still subscribed to node 1? 
> 
> What can I do to to move the subscription of node 3 over from noode 1 to 2?

I think you could just subscribe node 3 to node 2 :

subscribe set (id=@set_to_move, provider=@new_origin, receiver=@other_node,
forward=yes);


> 
> Any ideas would be very much appreciated, I'm a little worried at the moment, especially with the silence.
> 
> Thanks
> Glyn
> 
> 
> --- On Fri, 8/5/09, Glyn Astill <glynastill@yahoo.co.uk> wrote:
> 
>> From: Glyn Astill <glynastill@yahoo.co.uk>
>> Subject: Re: [Slony1-general] MOVE SET confusion
>> To: slony1-general@lists.slony.info
>> Date: Friday, 8 May, 2009, 12:14 PM
>> Ah, obviously it'd help if I stated this is 1.2.15
>>
>>
>> --- On Fri, 8/5/09, Glyn Astill
>> <glynastill@yahoo.co.uk> wrote:
>>
>>> From: Glyn Astill <glynastill@yahoo.co.uk>
>>> Subject: [Slony1-general] MOVE SET confusion
>>> To: slony1-general@lists.slony.info
>>> Date: Friday, 8 May, 2009, 10:51 AM
>>> Hi chaps,
>>>
>>> We have a setup with 3 nodes. Initially nodes 2 and 3
>> were
>>> subscribed to 1, but last night I moved the origin to
>> 2 as
>>> per the docs.
>>>
>>> All seems to be well, but I'm confused with what
>> the
>>> logs are showing. Node 1 has the following in it's
>> logs
>>> for each set;
>>>
>>> remoteWorkerThread_2: syncing set 2 with 43 table(s)
>> from
>>> provider 2
>>>
>>> But node 3 is saying this;
>>>
>>> remoteWorkerThread_2: syncing set 2 with 43 table(s)
>> from
>>> provider 1
>>>
>>> Surely when I moved the origin from node 1 to 2, both
>> nodes
>>> should be syncing from node 2?
>>>
>>> Anyone?
>>>
>>> Regards
>>> Glyn
>>>

Hope that helps.

Regards,
- --
St?phane Schildknecht
PostgreSQLFr - http://www.postgresql.fr
Dalibo - http://www.dalibo.com
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFKCBSDA+REPKWGI0ERAtdnAJ4slyfzzgHeY2HjMLnD7rno8WmYmACdFpH2
MV9bZq2nXSgPXFymeO7Gb6s=
=Lq5L
-----END PGP SIGNATURE-----
From glynastill at yahoo.co.uk  Mon May 11 05:31:43 2009
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Mon May 11 05:31:48 2009
Subject: [Slony1-general] MOVE SET confusion
In-Reply-To: <4A081484.6020603@postgresqlfr.org>
Message-ID: <497858.8982.qm@web23605.mail.ird.yahoo.com>


Hi St?phane

--- On Mon, 11/5/09, "St?phane A. Schildknecht" <stephane.schildknecht@postgresqlfr.org> wrote:

> > So for now everything is running, but what did I do
> wrong to leave node 3 still subscribed to node 1? 
> > 
> > What can I do to to move the subscription of node 3
> over from noode 1 to 2?
> 
> I think you could just subscribe node 3 to node 2 :
> 
> subscribe set (id=@set_to_move, provider=@new_origin,
> receiver=@other_node,
> forward=yes);
> 

Aha thanks, I see that in toe docs now.  But I still wonder - did I don something wron in my move set operation or is this the expected behaviour?

Thanks
Glyn


      
From cbbrowne at ca.afilias.info  Mon May 11 07:51:46 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon May 11 07:51:55 2009
Subject: [Slony1-general] MOVE SET confusion
In-Reply-To: <594526.17693.qm@web23603.mail.ird.yahoo.com> (Glyn Astill's
	message of "Fri, 8 May 2009 09:51:12 +0000 (GMT)")
References: <594526.17693.qm@web23603.mail.ird.yahoo.com>
Message-ID: <87hbzrbsl9.fsf@dba2.int.libertyrms.com>

Glyn Astill <glynastill@yahoo.co.uk> writes:
> Hi chaps,
>
> We have a setup with 3 nodes. Initially nodes 2 and 3 were subscribed to 1, but last night I moved the origin to 2 as per the docs.
>
> All seems to be well, but I'm confused with what the logs are showing. Node 1 has the following in it's logs for each set;
>
> remoteWorkerThread_2: syncing set 2 with 43 table(s) from provider 2
>
> But node 3 is saying this;
>
> remoteWorkerThread_2: syncing set 2 with 43 table(s) from provider 1
>
> Surely when I moved the origin from node 1 to 2, both nodes should be syncing from node 2?
>
> Anyone?

Why should this be "surely"?

The subscription chain from the old origin to the new origin is
reversed (see <http://slony.info/documentation/stmtmoveset.html>).

The subscriptions for node #3 are only revised if they are members of
the chain from the old origin to the new one.  Since [1,3] is not part
of the [1,2] chain, there is no need to do so.
-- 
(reverse (concatenate 'string "ofni.secnanifxunil" "@" "enworbbc"))
http://www3.sympatico.ca/cbbrowne/sgml.html
Rules of  the Evil  Overlord #34. "I  will not  turn into a  snake. It
never helps." <http://www.eviloverlord.com/>
From aleksander.kmetec at intera.si  Mon May 11 08:10:06 2009
From: aleksander.kmetec at intera.si (Aleksander Kmetec)
Date: Mon May 11 08:10:16 2009
Subject: [Slony1-general] Multiple failover nodes
Message-ID: <4A083FCE.602@intera.si>

Hi,

I have a couple of questions about the following cluster shape (which I currently have on paper only):

Master node 1 contains two sets: A1 and A2
   Slave node 2 subscribes to set A1
   Slave node 3 subscribes to set A2

At one point the master (node 1) fails. Is there a way to make node2 the master for set A1 and node 3 the master for set 
A2 a the same time?

I'm asking this because the FAILOVER command only accepts one backup node as parameter.

What happens with set A2 on node 3 when I execute "FAILOVER (ID = 1, BACKUP NODE = 2);"?
Will this even work since set A2 doesn't even exist on node 2?

Regards,
Aleksander



From cbbrowne at ca.afilias.info  Mon May 11 08:32:37 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon May 11 08:32:46 2009
Subject: [Slony1-general] MOVE SET confusion
In-Reply-To: <71270.58589.qm@web23605.mail.ird.yahoo.com> (Glyn Astill's
	message of "Mon, 11 May 2009 11:26:51 +0000 (GMT)")
References: <71270.58589.qm@web23605.mail.ird.yahoo.com>
Message-ID: <877i0nbqp6.fsf@dba2.int.libertyrms.com>

Glyn Astill <glynastill@yahoo.co.uk> writes:
> So for now everything is running, but what did I do wrong to leave
> node 3 still subscribed to node 1?

You did not submit a SUBSCRIBE SET request to revise node #3's
subscriptions.

> What can I do to to move the subscription of node 3 over from noode
> 1 to 2?

Submit a slonik script to revise the subscription.

Presumably it would look somewhat like the following:

include <preamble.slonik>;   # Draw in ADMIN CONNINFO
subscribe set (id=1, provider=2, receiver=3, forward=yes);
subscribe set (id=2, provider=2, receiver=3, forward=yes);
-- 
output = reverse("gro.mca" "@" "enworbbc")
http://cbbrowne.com/info/internet.html
Rules of  the Evil  Overlord #138. "The  passageways to and  within my
domain will  be well-lit  with fluorescent lighting.  Regrettably, the
spooky atmosphere will  be lost, but my security  patrols will be more
effective."  <http://www.eviloverlord.com/>
From glynastill at yahoo.co.uk  Mon May 11 08:48:35 2009
From: glynastill at yahoo.co.uk (Glyn Astill)
Date: Mon May 11 08:48:43 2009
Subject: [Slony1-general] MOVE SET confusion
In-Reply-To: <87hbzrbsl9.fsf@dba2.int.libertyrms.com>
Message-ID: <722298.71196.qm@web23608.mail.ird.yahoo.com>


--- On Mon, 11/5/09, Christopher Browne <cbbrowne@ca.afilias.info> wrote:

> From: Christopher Browne <cbbrowne@ca.afilias.info>
> Subject: Re: [Slony1-general] MOVE SET confusion
> To: glynastill@yahoo.co.uk
> Cc: slony1-general@lists.slony.info
> Date: Monday, 11 May, 2009, 3:51 PM
> Glyn Astill <glynastill@yahoo.co.uk> writes:
> > Hi chaps,
> >
> > We have a setup with 3 nodes. Initially nodes 2 and 3
> were subscribed to 1, but last night I moved the origin to 2
> as per the docs.
> >
> > All seems to be well, but I'm confused with what
> the logs are showing. Node 1 has the following in it's
> logs for each set;
> >
> > remoteWorkerThread_2: syncing set 2 with 43 table(s)
> from provider 2
> >
> > But node 3 is saying this;
> >
> > remoteWorkerThread_2: syncing set 2 with 43 table(s)
> from provider 1
> >
> > Surely when I moved the origin from node 1 to 2, both
> nodes should be syncing from node 2?
> >
> > Anyone?
> 
> Why should this be "surely"?
> 
> The subscription chain from the old origin to the new
> origin is
> reversed (see
> <http://slony.info/documentation/stmtmoveset.html>).
> 
> The subscriptions for node #3 are only revised if they are
> members of
> the chain from the old origin to the new one.  Since [1,3]
> is not part
> of the [1,2] chain, there is no need to do so.

I think I just had the wrong picture of the operation in my head then. I assumed that a move set where node 1 is the origin and both nodes 2 and 3 subscribe to 1, i.e.

2---> 1 <---3

Would also move subscription along with the location of the origin set because node 1 was set as the provider for both nodes 2 and 3, i.e.

1---> 2 <---3

Obviously this isn't the way it's designed and to get that behavior I'd have to use the subscribe set command as well.

I guess this outlines the importance of understanding the difference between provider and origin when using move set then. 

You are *only* moving the origin of the set and *not* the provider. The provider only changes between the new and old origin. Correct?


      
From vivek at khera.org  Mon May 11 10:24:32 2009
From: vivek at khera.org (Vick Khera)
Date: Mon May 11 10:24:44 2009
Subject: [Slony1-general] Multiple failover nodes
In-Reply-To: <4A083FCE.602@intera.si>
References: <4A083FCE.602@intera.si>
Message-ID: <2968dfd60905111024t445942eei3cb3155beda2d58a@mail.gmail.com>

On Mon, May 11, 2009 at 11:10 AM, Aleksander Kmetec
<aleksander.kmetec@intera.si> wrote:
> Hi,
>
> I have a couple of questions about the following cluster shape (which I
> currently have on paper only):
>
> Master node 1 contains two sets: A1 and A2
> ?Slave node 2 subscribes to set A1
> ?Slave node 3 subscribes to set A2

Are both sets in the same cluster?  Because I don't know how you can
make one set in a cluster have a different origin than the other.

I'll assume they're in different clusters.  In this case, he failover
only applies to one cluster, so you have no conflict.  You just have
to issue two different failover commands being sure to specify the
correct cluster name each time.
From luch at ank-sia.com  Tue May 12 08:55:48 2009
From: luch at ank-sia.com (Alexey Luchko)
Date: Tue May 12 08:55:58 2009
Subject: [Slony1-general] PGRES_FATAL_ERROR load '$libdir/xxid';
 - ERROR:  access to library "$libdir/xxid" is not allowed
Message-ID: <4A099C04.9000400@ank-sia.com>

Hi, everyone!

I'm rather new to postgresql administration.
I'd like to use slony1 for replication,
but I'm getting an error trying to initiate a slony cluster:
"""
$ slonik.exe < master.slonik
<stdin>:21: PGRES_FATAL_ERROR load '$libdir/xxid';  - ERROR:  access to 
library "$libdir/xxid" is not allowed
<stdin>:21: Error: the extension for the xxid data type cannot be loaded in 
database 'dbname=test_master host=localhost port=1257 user=slon_replicator'
<stdin>:21: ERROR: no admin conninfo for node 7491568
"""

What is it about?

I'm running PostgreSQL 8.3.7 on Win2k (PostgresqlPlus by enterpricedb.com, 
pgplus-837-1-win.zip)
I checked permissions on the lib/xxid, they are ok.
I've tried to explicitly add bin\ and lib\ to %PATH.


Any pointers are welcome (:


Best regards,
Alexey
From melvin6925 at yahoo.com  Tue May 12 09:15:18 2009
From: melvin6925 at yahoo.com (Melvin Davidson)
Date: Tue May 12 09:16:32 2009
Subject: [Slony1-general] PGRES_FATAL_ERROR load '$libdir/xxid';
	- ERROR:  access to library "$libdir/xxid" is not allowed
In-Reply-To: <4A099C04.9000400@ank-sia.com>
Message-ID: <148921.8274.qm@web53008.mail.re2.yahoo.com>

This is a permission problem on the xxid.so program.
Most probably you either installed slony as root or postgres, but are tryin=
g to start slony as a different user.
Make sure that the user trying to start slony has execute permission for th=
at.





Melvin Davidson =

 Home 720-870-9595 =

 =A0=A0=A0 Cell 720-320-0155  =


I reserve the right to fantasize.=A0 Whether or not you =

 wish to share my fantasy is entirely up to you. =


www.youtube.com/unusedhero
 =

 Folk Alley - All Folk - 24 Hours a day =

www.folkalley.com



--- On Tue, 5/12/09, Alexey Luchko <luch@ank-sia.com> wrote:
From: Alexey Luchko <luch@ank-sia.com>
Subject: [Slony1-general] PGRES_FATAL_ERROR load '$libdir/xxid'; - ERROR:  =
access to library "$libdir/xxid" is not allowed
To: slony1-general@lists.slony.info
Date: Tuesday, May 12, 2009, 9:55 AM

Hi, everyone!

I'm rather new to postgresql administration.
I'd like to use slony1 for replication,
but I'm getting an error trying to initiate a slony cluster:
"""
$ slonik.exe < master.slonik
<stdin>:21: PGRES_FATAL_ERROR load '$libdir/xxid';  - ERROR: =

access to library "$libdir/xxid" is not allowed
<stdin>:21: Error: the extension for the xxid data type cannot be loaded
in database 'dbname=3Dtest_master host=3Dlocalhost port=3D1257
user=3Dslon_replicator'
<stdin>:21: ERROR: no admin conninfo for node 7491568
"""

What is it about?

I'm running PostgreSQL 8.3.7 on Win2k (PostgresqlPlus by enterpricedb.com,
pgplus-837-1-win.zip)
I checked permissions on the lib/xxid, they are ok.
I've tried to explicitly add bin\ and lib\ to %PATH.


Any pointers are welcome (:


Best regards,
Alexey
_______________________________________________
Slony1-general mailing list
Slony1-general@lists.slony.info
http://lists.slony.info/mailman/listinfo/slony1-general



      =

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090512/=
21327d38/attachment.htm
From kerdezixe at gmail.com  Wed May 13 06:11:03 2009
From: kerdezixe at gmail.com (Laurent Laborde)
Date: Wed May 13 06:11:08 2009
Subject: [Slony1-general] MOVE SET confusion
In-Reply-To: <722298.71196.qm@web23608.mail.ird.yahoo.com>
References: <87hbzrbsl9.fsf@dba2.int.libertyrms.com>
	<722298.71196.qm@web23608.mail.ird.yahoo.com>
Message-ID: <8a1bfe660905130611j4db1157bqf7b0dbf1c6ba81ab@mail.gmail.com>

Friendly greetings !

i did a switchover today, here is the plan :
- 4 set on 1 cluster
- many slave
- no cascading
- changing master from 1 to 2

slonik (all name, numbers changed or hidden) :
-------------------------------------------------------------
cluster name : foo
node 1 admin conninfo='blablabla';
node 2 admin conninfo='blablabla';
node 3 admin conninfo='blablabla';
node 4 admin conninfo='blablabla';
etc ...

echo 'Locking down set 1 on node 1';
lock set (id = 1, origin = 1);
echo 'Locked down - moving it';
move set (id = 1, old origin = 1, new origin = 2);
echo 'move set 1 done.';
# note : move set automatically do the "unlock set"

echo 'Locking down set 2 on node 1';
lock set (id = 2, origin = 1);
echo 'Locked down - moving it';
move set (id = 2, old origin = 1, new origin = 2);
echo 'move set 2 done.';
etc ...

#at this point. the new master is node 2, but all slave are still
subscribing to 1.
#replication still works because node 1 (old origin) is cascading the
replication to all slaves.

#time to resubscribe from node 2 now, so we can shutdown node 1
#some node (node 5 in the exemple) are not forwarding because they
will never become master (not powerfull enough)
#note : you don't need to resubscribe the old master, because the
"move set" automatically change the provider for this one
echo 'resubscribing all node';
subscribe set (id = 4, provider = 2, receiver = 3, forward = yes);
subscribe set (id = 3, provider = 2, receiver = 3, forward = yes);
subscribe set (id = 2, provider = 2, receiver = 3, forward = yes);
subscribe set (id = 1, provider = 2, receiver = 3, forward = yes);
subscribe set (id = 4, provider = 2, receiver = 4, forward = yes);
subscribe set (id = 3, provider = 2, receiver = 4, forward = yes);
subscribe set (id = 2, provider = 2, receiver = 4, forward = yes);
subscribe set (id = 1, provider = 2, receiver = 4, forward = yes);
subscribe set (id = 4, provider = 2, receiver = 5, forward = no);
subscribe set (id = 3, provider = 2, receiver = 5, forward = no);
subscribe set (id = 2, provider = 2, receiver = 5, forward = no);
subscribe set (id = 1, provider = 2, receiver = 5, forward = no);
etc ...

echo 'all done. Time to relax';

in fact, i did that in 2 step (and 2 files).
1) move set first, check in table foo.sl_subscribe if everything is ok
2) then resubscribe, and check again foo.sl_subscribe

Hope that help !

BIG PS : That was my biggest concern. i wasn't 100% that lock set will
or will not lock the slave too.
it never lock the slaves, so you can keep your slave in production
while moving the master :)
yay \o/

-- 
Laurent Laborde
Sysadmin & DBA at jfg://jfg-networks
http://www.over-blog.com/
From cbbrowne at ca.afilias.info  Wed May 13 07:46:55 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed May 13 07:47:04 2009
Subject: [Slony1-general] MOVE SET confusion
In-Reply-To: <8a1bfe660905130611j4db1157bqf7b0dbf1c6ba81ab@mail.gmail.com>
References: <87hbzrbsl9.fsf@dba2.int.libertyrms.com>	
	<722298.71196.qm@web23608.mail.ird.yahoo.com>
	<8a1bfe660905130611j4db1157bqf7b0dbf1c6ba81ab@mail.gmail.com>
Message-ID: <4A0ADD5F.3070108@ca.afilias.info>

Laurent Laborde wrote:
> BIG PS : That was my biggest concern. i wasn't 100% that lock set will
> or will not lock the slave too.
> it never lock the slaves, so you can keep your slave in production
> while moving the master :)
> yay \o/
>   
The really essential thing about LOCK SET is that it eliminates the 
ability to enter *new* replication data.  It locks the origin down so 
that there's no extra replication data to "slip in sideways" that could 
get lost when you switch the origin.

On subscriber nodes, the tables were already "locked" against updates 
(see the "denyaccess" triggers), so LOCK SET is effectively a no-op on them.
From moski666 at gmail.com  Mon May 18 09:28:30 2009
From: moski666 at gmail.com (Emiliano Moscato)
Date: Mon May 18 09:28:39 2009
Subject: [Slony1-general] xxid.so missing magic block
Message-ID: <4388f4180905180928p31552aaby8a58474d18c10516@mail.gmail.com>

Hi all,

I'm having troubles with slony updating postgres 8.1 -> 8.3
I'm running postgres 8.3 on FreeBSD 6.3 amd64 and slony 1.2.15.
I updated Postgres via portupgrade and then rebuilt slony from ports
(make clean; make; make deinstall; make install)

Everithing goes perfect, but when I run my slonik script to configure
my nodes I got the following error:

<stdin>:5: PGRES_FATAL_ERROR load '$libdir/xxid';  - ERROR:
incompatible library "/usr/local/lib/postgresql/xxid.so": missing
magic block
HINT:  Extension libraries are required to use the PG_MODULE_MAGIC
macro.
<stdin>:5: Error: the extension for the xxid data type cannot be
loaded in database 'dbname=sso host=replicabd.mecon.ar user=slony'

The line that is failing is:

  store node (id=$id_slavehost, comment='Nodo esclavo');

I saw if xxid.so were updated after rebuild and it is.
The thing that is suspicious to me is that the code of xxid.c includes
the call to PG_MODULE_MAGIC but does not include library fmgr.h

Here is the complete slonik script:

        cluster name = $slony_cluster;
??????? node $id_masterhost admin conninfo = 'dbname=$slony_masterdb
host=$slony_masterhost user=$slony_replicationuser';
??????? node $id_slavehost admin conninfo = 'dbname=$slony_slavedb
host=$slony_slavehost user=$slony_replicationuser';
??????? init cluster (id=$id_masterhost, comment='Nodo principal');
??????? store node (id=$id_slavehost, comment='Nodo esclavo');
??????? store path (server=$id_masterhost, client=$id_slavehost,
conninfo='dbname=$slony_masterdb host=$slony_masterhost
user=$slony_replicationuser');
??????? store path (server=$id_slavehost, client=$id_masterhost,
conninfo='dbname=$slony_slavedb host=$slony_slavehost
user=$slony_replicationuser');


Thanks in advance for any advice,

Greetings

Emiliano
From stephane.schildknecht at postgresqlfr.org  Wed May 20 06:53:15 2009
From: stephane.schildknecht at postgresqlfr.org (=?ISO-8859-15?Q?=22St=E9phane_A=2E_Schildknecht=22?=)
Date: Wed May 20 06:53:32 2009
Subject: [Slony1-general] Compilation of Slony 1.2.15 with PostgreSQL
	8.4 	beta 1 ?
In-Reply-To: <8a1bfe660904241130h63700c77k8011cc885eb158ac@mail.gmail.com>
References: <49F1B640.5060300@postgresqlfr.org>
	<8a1bfe660904241130h63700c77k8011cc885eb158ac@mail.gmail.com>
Message-ID: <4A140B4B.6060307@postgresqlfr.org>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Laurent Laborde a ?crit :
> On Fri, Apr 24, 2009 at 2:53 PM, Jean-Paul Argudo
> <jean-paul@postgresqlfr.org> wrote:
>> gcc -g -O2 -Wall -Wmissing-prototypes -Wmissing-declarations -fpic
>> -I../.. -I/usr/local/pgsql-beta/include/
>> -I/usr/local/pgsql-beta/include/server/  -c -o xxid.o xxid.c
>> xxid.c: In function '_Slony_I_getMinXid':
>> xxid.c:236: error: 'SerializableSnapshot' undeclared (first use in this
>> function)
>> xxid.c:236: error: (Each undeclared identifier is reported only once
>> xxid.c:236: error: for each function it appears in.)
>> xxid.c: In function '_Slony_I_getMaxXid':
>> xxid.c:249: error: 'SerializableSnapshot' undeclared (first use in this
>> function)
>> make[2]: *** [xxid.o] Error 1
>> make[2]: Leaving directory `/opt/appli/slony/sources/src/xxid'
>> make[1]: *** [all] Error 2
>> make[1]: Leaving directory `/opt/appli/slony/sources/src'
>> make: *** [all] Error 2
> 
> We tested together on IRC with Jean-Paul and we have exactly the same problem ;)
> 

Hi,

Any update on this?


Regards,
SAS
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFKFAtLA+REPKWGI0ERAr+eAJ0fC/mk+dGfHhQkwRHjcaZc3dO24QCgn6Qq
4DxF52tJlz+RlYX9v1+POT8=
=Asae
-----END PGP SIGNATURE-----
From cbbrowne at ca.afilias.info  Wed May 20 09:06:23 2009
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed May 20 09:06:31 2009
Subject: [Slony1-general] Compilation of Slony 1.2.15 with PostgreSQL
	8.4 	beta 1 ?
In-Reply-To: <4A140B4B.6060307@postgresqlfr.org>
References: <49F1B640.5060300@postgresqlfr.org>
	<8a1bfe660904241130h63700c77k8011cc885eb158ac@mail.gmail.com>
	<4A140B4B.6060307@postgresqlfr.org>
Message-ID: <20090520120623.14387hgua24ettvj@webmail.afilias.info>

Quoting "St?phane A. Schildknecht" <stephane.schildknecht@postgresqlfr.org>:
> Any update on this?

I had put this off, pending 1.2.16's release...

I'll see if I can come up with resolution to this problem this week.


From dba at richyen.com  Thu May 21 16:24:06 2009
From: dba at richyen.com (Richard Yen)
Date: Thu May 21 16:24:25 2009
Subject: [Slony1-general] serialization problem related to log shipping?
Message-ID: <5A11D3A7-24C5-46D4-8062-F3AC490ADE98@richyen.com>

Hi,

I've been noticing a lot of the following messages in my logs:

> serialization problem updating sl_archive_counter: restarting slon

It seems to be associated with turning on log shipping (adding a -a  
flag in the startup)

Would anyone know why this happens and how we can make it stop  
restarting like this?

Thanks!
--Richard
From dmitry at koterov.ru  Fri May 22 07:09:57 2009
From: dmitry at koterov.ru (Dmitry Koterov)
Date: Fri May 22 07:10:03 2009
Subject: [Slony1-general] About two mutually-compensating bugs in Slony core
Message-ID: <d7df81620905220709g2b7d63a3xcb8561ef30addfb3@mail.gmail.com>
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From lavalamp at spiritual-machines.org  Fri May 22 09:49:51 2009
From: lavalamp at spiritual-machines.org (Brian A. Seklecki)
Date: Fri May 22 09:50:00 2009
Subject: [Slony1-general] 
 sl_nodelock values ("pg_catalog".pg_backend_pid()); " - ERROR: 
 duplicate key value
Message-ID: <1243010991.638.1744.camel@soundwave.ws.pitbpa0.priv.collaborativefusion.com>

All:

So this problem with slon(8) daemons continues to vex us.  During a
switchover, we see "No Worker Thread" errors:

 2009 May 22 06:37:17 -04:00 bdb01 [slon][55352] [local2] [err] 
 slon[55352]: [12-1] [55352] CONFIG storeSet: set_id=1 set_origin=3
 set_comment='All CORES tables'
 2009 May 22 06:37:17 -04:00 bdb01 [slon][55352] [local2] [warning]
 slon[55352]: [13-1] [55352] WARN   remoteWorker_wakeup: node 3 - no
 worker thread

Followed by:


 2009 May 22 06:37:17 -04:00 bdb01 [slon][55352] [local2] [err]
 slon[55352]: [19-1] [55352] FATAL  localListenThread: "select 
 "_DBNAME".cleanupNodelock(); insert into
 2009 May 22 06:37:17 -04:00 bdb01 [slon][55352] [local2] [err]
 slon[55352]: [19-2]  "_DBNAME".sl_nodelock values (   
 2, 0, "pg_catalog".pg_backend_pid()); " - ERROR:  duplicate key value
 violates

The screwed up thing is that, as far as we know, all three slon(8)
daemons on all there configurations are active, healthy, and responding
before we execute the switchover.

We know because we have nagios watching SYNC events and watching that
sl_log table row counts are within acceptable ranges.

Any advice on further troubleshooting this?    Maybe attach a ktrace(8)
to the process and try to re-create the error.

We're running the latest Slony/PostgreSQL (postgresql-server-8.3.7 +
slony1-1.2.15) on FBSD6/amd64.

~BAS

From bnichols at ca.afilias.info  Fri May 22 11:33:55 2009
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Fri May 22 11:34:07 2009
Subject: [Slony1-general]  sl_nodelock values
	("pg_catalog".pg_backend_pid()); " - ERROR:  duplicate key value
In-Reply-To: <1243010991.638.1744.camel@soundwave.ws.pitbpa0.priv.collaborativefusion.com>
References: <1243010991.638.1744.camel@soundwave.ws.pitbpa0.priv.collaborativefusion.com>
Message-ID: <1243017235.25563.34.camel@bnicholson-desktop>

On Fri, 2009-05-22 at 12:49 -0400, Brian A. Seklecki wrote:
> All:
> 
> So this problem with slon(8) daemons continues to vex us.  During a
> switchover, we see "No Worker Thread" errors:
> 
>  2009 May 22 06:37:17 -04:00 bdb01 [slon][55352] [local2] [err] 
>  slon[55352]: [12-1] [55352] CONFIG storeSet: set_id=1 set_origin=3
>  set_comment='All CORES tables'
>  2009 May 22 06:37:17 -04:00 bdb01 [slon][55352] [local2] [warning]
>  slon[55352]: [13-1] [55352] WARN   remoteWorker_wakeup: node 3 - no
>  worker thread
> 
> Followed by:
> 
> 
>  2009 May 22 06:37:17 -04:00 bdb01 [slon][55352] [local2] [err]
>  slon[55352]: [19-1] [55352] FATAL  localListenThread: "select 
>  "_DBNAME".cleanupNodelock(); insert into
>  2009 May 22 06:37:17 -04:00 bdb01 [slon][55352] [local2] [err]
>  slon[55352]: [19-2]  "_DBNAME".sl_nodelock values (   
>  2, 0, "pg_catalog".pg_backend_pid()); " - ERROR:  duplicate key value
>  violates
> 
> The screwed up thing is that, as far as we know, all three slon(8)
> daemons on all there configurations are active, healthy, and responding
> before we execute the switchover.
> 
> We know because we have nagios watching SYNC events and watching that
> sl_log table row counts are within acceptable ranges.
> 
> Any advice on further troubleshooting this?    Maybe attach a ktrace(8)
> to the process and try to re-create the error.
> 
> We're running the latest Slony/PostgreSQL (postgresql-server-8.3.7 +
> slony1-1.2.15) on FBSD6/amd64.
> 
> ~BAS

This looks like the same issue that one of our guys was trying to figure
out.

Restarting the Slon let's the failover proceed, but it sort of sucks
that you have to do that.

-- 
Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.


From JanWieck at Yahoo.com  Fri May 22 10:03:44 2009
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Fri May 22 13:02:04 2009
Subject: [Slony1-general] sl_nodelock
	values	("pg_catalog".pg_backend_pid()); 
	" - ERROR:  duplicate key value
In-Reply-To: <1243017235.25563.34.camel@bnicholson-desktop>
References: <1243010991.638.1744.camel@soundwave.ws.pitbpa0.priv.collaborativefusion.com>
	<1243017235.25563.34.camel@bnicholson-desktop>
Message-ID: <4A16DAF0.8040607@Yahoo.com>

On 5/22/2009 2:33 PM, Brad Nicholson wrote:
> On Fri, 2009-05-22 at 12:49 -0400, Brian A. Seklecki wrote:
>> All:
>> 
>> So this problem with slon(8) daemons continues to vex us.  During a
>> switchover, we see "No Worker Thread" errors:
>> 
>>  2009 May 22 06:37:17 -04:00 bdb01 [slon][55352] [local2] [err] 
>>  slon[55352]: [12-1] [55352] CONFIG storeSet: set_id=1 set_origin=3
>>  set_comment='All CORES tables'
>>  2009 May 22 06:37:17 -04:00 bdb01 [slon][55352] [local2] [warning]
>>  slon[55352]: [13-1] [55352] WARN   remoteWorker_wakeup: node 3 - no
>>  worker thread
>> 
>> Followed by:
>> 
>> 
>>  2009 May 22 06:37:17 -04:00 bdb01 [slon][55352] [local2] [err]
>>  slon[55352]: [19-1] [55352] FATAL  localListenThread: "select 
>>  "_DBNAME".cleanupNodelock(); insert into
>>  2009 May 22 06:37:17 -04:00 bdb01 [slon][55352] [local2] [err]
>>  slon[55352]: [19-2]  "_DBNAME".sl_nodelock values (   
>>  2, 0, "pg_catalog".pg_backend_pid()); " - ERROR:  duplicate key value
>>  violates
>> 
>> The screwed up thing is that, as far as we know, all three slon(8)
>> daemons on all there configurations are active, healthy, and responding
>> before we execute the switchover.
>> 
>> We know because we have nagios watching SYNC events and watching that
>> sl_log table row counts are within acceptable ranges.
>> 
>> Any advice on further troubleshooting this?    Maybe attach a ktrace(8)
>> to the process and try to re-create the error.
>> 
>> We're running the latest Slony/PostgreSQL (postgresql-server-8.3.7 +
>> slony1-1.2.15) on FBSD6/amd64.
>> 
>> ~BAS
> 
> This looks like the same issue that one of our guys was trying to figure
> out.
> 
> Restarting the Slon let's the failover proceed, but it sort of sucks
> that you have to do that.
> 

It appears to me this is a race condition. During the switchover, the 
slon processes try to restart.

The call to cleanupNodeLock() is supposed to remove the stale entry. If 
memory serves, cleanupNodeLock() does check if the corresponding backend 
still exists via kill(backendpid, 0).

What I think happens is that the slon process is instructed to restart, 
so it drops the connection and instantaneously restarts, reconnects and 
tries to gain a node lock. But this may happen faster than the backend 
from the old connection had time to terminate and for postmaster to 
receive the exit code via wait. So the kill(backendpid, 0) tells 
(correctly) that the backend is still alive, assuming that this is a 
valid and active node lock in place.

I presume the correct way to fix this is to not be entirely dependent on 
cleanupNodeLock() for removing the lock. Just prior to closing the 
backend connection, the node should actually delete the lock entry itself.

Additionally we may want to introduce a little sleep+retry loop into 
cleanupNodeLock().


Jan

-- 
Anyone who trades liberty for security deserves neither
liberty nor security. -- Benjamin Franklin

From stephane.schildknecht at postgresqlfr.org  Tue May 26 03:04:28 2009
From: stephane.schildknecht at postgresqlfr.org (=?ISO-8859-15?Q?=22St=E9phane_A=2E_Schildknecht=22?=)
Date: Tue May 26 03:05:03 2009
Subject: [Slony1-general] Compilation of Slony 1.2.X with PostgreSQL 8.4
	beta?
In-Reply-To: <20090520120623.14387hgua24ettvj@webmail.afilias.info>
References: <49F1B640.5060300@postgresqlfr.org>	<8a1bfe660904241130h63700c77k8011cc885eb158ac@mail.gmail.com>	<4A140B4B.6060307@postgresqlfr.org>
	<20090520120623.14387hgua24ettvj@webmail.afilias.info>
Message-ID: <4A1BBEAC.1040909@postgresqlfr.org>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Christopher Browne a ?crit :
> Quoting "St?phane A. Schildknecht"
> <stephane.schildknecht@postgresqlfr.org>:
>> Any update on this?
> 
> I had put this off, pending 1.2.16's release...
> 
> I'll see if I can come up with resolution to this problem this week.

Hi,

I searched a little further.

Searching for SerializableSnapshot in 8.3 tree, I found:

../postgresql-8.3.7/src/backend/access/transam/xact.c:          if
(SerializableSnapshot)
../postgresql-8.3.7/src/backend/access/transam/xact.c:
SerializableSnapshot->curcid = currentCommandId;
../postgresql-8.3.7/src/backend/commands/variable.c:    if
(SerializableSnapshot != NULL)
../postgresql-8.3.7/src/backend/utils/time/tqual.c:static SnapshotData
SerializableSnapshotData = {HeapTupleSatisfiesMVCC};
../postgresql-8.3.7/src/backend/utils/time/tqual.c:Snapshot
SerializableSnapshot = NULL;
../postgresql-8.3.7/src/backend/utils/time/tqual.c: * The SerializableSnapshot
is the first one taken in a transaction.
../postgresql-8.3.7/src/backend/utils/time/tqual.c:     if
(SerializableSnapshot == NULL)
../postgresql-8.3.7/src/backend/utils/time/tqual.c:
SerializableSnapshot = GetSnapshotData(&SerializableSnapshotData, true);
../postgresql-8.3.7/src/backend/utils/time/tqual.c:             return
SerializableSnapshot;
../postgresql-8.3.7/src/backend/utils/time/tqual.c:             return
SerializableSnapshot;
../postgresql-8.3.7/src/backend/utils/time/tqual.c:     if
(SerializableSnapshot == NULL)
../postgresql-8.3.7/src/backend/utils/time/tqual.c:     SerializableSnapshot =
NULL;
../postgresql-8.3.7/src/include/utils/tqual.h:extern PGDLLIMPORT Snapshot
SerializableSnapshot;

I did not find it in 8.4 source tree.

So I tried to add that line in src/xxid/xxid.c and src/backend/slony1_func.c:

Snapshot     SerializableSnapshot = NULL;

Next error was in function getClusterStatus :

slony1_funcs.c: Dans la fonction ?getClusterStatus? :
slony1_funcs.c:1365: erreur: ?INT4OID? undeclared (first use in this function)
slony1_funcs.c:1365: erreur: (Each undeclared identifier is reported only once
slony1_funcs.c:1365: erreur: for each function it appears in.)
slony1_funcs.c:1388: erreur: ?TEXTOID? undeclared (first use in this function)

It seems to me that files included in Slony1-1.2.16 don't reflect one change
that happened in source tree between PG 8.3 and PG 8.4.

I don't know how to fix it yet, going on searching...

Regards,
- --
St?phane Schildknecht
PostgreSQLFr - http://www.postgresql.fr

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFKG76sA+REPKWGI0ERAnbCAKCxnHnL/ud2A16Y0mrgtUYyKa79VgCfX6G5
tuHOLEttx/D9M1dniiesBYE=
=gJsQ
-----END PGP SIGNATURE-----
From stephane.schildknecht at postgresqlfr.org  Tue May 26 05:24:19 2009
From: stephane.schildknecht at postgresqlfr.org (=?ISO-8859-15?Q?=22St=E9phane_A=2E_Schildknecht=22?=)
Date: Tue May 26 05:24:23 2009
Subject: [Slony1-general] Compilation of Slony 1.2.X with PostgreSQL 8.4
	beta?
In-Reply-To: <4A1BBEAC.1040909@postgresqlfr.org>
References: <49F1B640.5060300@postgresqlfr.org>	<8a1bfe660904241130h63700c77k8011cc885eb158ac@mail.gmail.com>	<4A140B4B.6060307@postgresqlfr.org>	<20090520120623.14387hgua24ettvj@webmail.afilias.info>
	<4A1BBEAC.1040909@postgresqlfr.org>
Message-ID: <4A1BDF73.1000602@postgresqlfr.org>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

St?phane A. Schildknecht a ?crit :
> Christopher Browne a ?crit :
>> Quoting "St?phane A. Schildknecht"
>> <stephane.schildknecht@postgresqlfr.org>:
>>> Any update on this?
>> I had put this off, pending 1.2.16's release...
> 
>> I'll see if I can come up with resolution to this problem this week.
> 
> Hi,
> 
> I searched a little further.
> 
> Searching for SerializableSnapshot in 8.3 tree, I found:
> 
> ../postgresql-8.3.7/src/backend/access/transam/xact.c:          if
> (SerializableSnapshot)
> ../postgresql-8.3.7/src/backend/access/transam/xact.c:
> SerializableSnapshot->curcid = currentCommandId;
> ../postgresql-8.3.7/src/backend/commands/variable.c:    if
> (SerializableSnapshot != NULL)
> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:static SnapshotData
> SerializableSnapshotData = {HeapTupleSatisfiesMVCC};
> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:Snapshot
> SerializableSnapshot = NULL;
> ../postgresql-8.3.7/src/backend/utils/time/tqual.c: * The SerializableSnapshot
> is the first one taken in a transaction.
> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:     if
> (SerializableSnapshot == NULL)
> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:
> SerializableSnapshot = GetSnapshotData(&SerializableSnapshotData, true);
> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:             return
> SerializableSnapshot;
> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:             return
> SerializableSnapshot;
> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:     if
> (SerializableSnapshot == NULL)
> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:     SerializableSnapshot =
> NULL;
> ../postgresql-8.3.7/src/include/utils/tqual.h:extern PGDLLIMPORT Snapshot
> SerializableSnapshot;
> 
> I did not find it in 8.4 source tree.
> 
> So I tried to add that line in src/xxid/xxid.c and src/backend/slony1_func.c:
> 
> Snapshot     SerializableSnapshot = NULL;
> 
> Next error was in function getClusterStatus :
> 
> slony1_funcs.c: Dans la fonction ?getClusterStatus? :
> slony1_funcs.c:1365: erreur: ?INT4OID? undeclared (first use in this function)
> slony1_funcs.c:1365: erreur: (Each undeclared identifier is reported only once
> slony1_funcs.c:1365: erreur: for each function it appears in.)
> slony1_funcs.c:1388: erreur: ?TEXTOID? undeclared (first use in this function)
> 
> It seems to me that files included in Slony1-1.2.16 don't reflect one change
> that happened in source tree between PG 8.3 and PG 8.4.
> 
> I don't know how to fix it yet, going on searching...
> 
> Regards,

Adding

#include "catalog/pg_type.h"

in src/backend/slony1_func.c let me compile the whole project.

Regards,
SAS
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFKG99zA+REPKWGI0ERArrWAKCXidZSWFejzaOcePwUCJ7n9ouGAgCfXR5Z
Xz7S1UcNqmLUzFYZTK9vgKc=
=2Zc+
-----END PGP SIGNATURE-----
From stephane.schildknecht at postgresqlfr.org  Tue May 26 07:45:56 2009
From: stephane.schildknecht at postgresqlfr.org (=?ISO-8859-15?Q?=22St=E9phane_A=2E_Schildknecht=22?=)
Date: Tue May 26 07:46:07 2009
Subject: [Slony1-general] Compilation of Slony 1.2.X with PostgreSQL 8.4
	beta?
In-Reply-To: <4A1BDF73.1000602@postgresqlfr.org>
References: <49F1B640.5060300@postgresqlfr.org>	<8a1bfe660904241130h63700c77k8011cc885eb158ac@mail.gmail.com>	<4A140B4B.6060307@postgresqlfr.org>	<20090520120623.14387hgua24ettvj@webmail.afilias.info>	<4A1BBEAC.1040909@postgresqlfr.org>
	<4A1BDF73.1000602@postgresqlfr.org>
Message-ID: <4A1C00A4.7080307@postgresqlfr.org>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

St?phane A. Schildknecht a ?crit :
> St?phane A. Schildknecht a ?crit :
>> Christopher Browne a ?crit :
>>> Quoting "St?phane A. Schildknecht"
>>> <stephane.schildknecht@postgresqlfr.org>:
>>>> Any update on this?
>>> I had put this off, pending 1.2.16's release...
>>> I'll see if I can come up with resolution to this problem this week.
>> Hi,
> 
>> I searched a little further.
> 
>> Searching for SerializableSnapshot in 8.3 tree, I found:
> 
>> ../postgresql-8.3.7/src/backend/access/transam/xact.c:          if
>> (SerializableSnapshot)
>> ../postgresql-8.3.7/src/backend/access/transam/xact.c:
>> SerializableSnapshot->curcid = currentCommandId;
>> ../postgresql-8.3.7/src/backend/commands/variable.c:    if
>> (SerializableSnapshot != NULL)
>> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:static SnapshotData
>> SerializableSnapshotData = {HeapTupleSatisfiesMVCC};
>> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:Snapshot
>> SerializableSnapshot = NULL;
>> ../postgresql-8.3.7/src/backend/utils/time/tqual.c: * The SerializableSnapshot
>> is the first one taken in a transaction.
>> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:     if
>> (SerializableSnapshot == NULL)
>> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:
>> SerializableSnapshot = GetSnapshotData(&SerializableSnapshotData, true);
>> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:             return
>> SerializableSnapshot;
>> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:             return
>> SerializableSnapshot;
>> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:     if
>> (SerializableSnapshot == NULL)
>> ../postgresql-8.3.7/src/backend/utils/time/tqual.c:     SerializableSnapshot =
>> NULL;
>> ../postgresql-8.3.7/src/include/utils/tqual.h:extern PGDLLIMPORT Snapshot
>> SerializableSnapshot;
> 
>> I did not find it in 8.4 source tree.
> 
>> So I tried to add that line in src/xxid/xxid.c and src/backend/slony1_func.c:
> 
>> Snapshot     SerializableSnapshot = NULL;

I had doubt it could work. Now, I know it does not :-(

<stdin>:13: PGRES_FATAL_ERROR select "_test2".initializeLocalNode(1, 'test2 : 1
- - test - localhost'); select "_test2".enableNode(1);  - ERREUR:  Slony-I:
SerializableSnapshot is NULL in createEvent()
CONTEXT:  PL/pgSQL function "enablenode" line 31 at RETURN
<stdin>:13: Possible unsupported PostgreSQL version (80400) 8.4, defaulting to
8.1 support


SAS
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFKHACjA+REPKWGI0ERAof+AJ0YRmNzTtEq/ZCVKMBcQRPS6uQ1ggCeMPcX
ERLBxABwMi9PJ6SkoPLh3H0=
=q72d
-----END PGP SIGNATURE-----
From melvin6925 at yahoo.com  Tue May 26 08:15:46 2009
From: melvin6925 at yahoo.com (Melvin Davidson)
Date: Tue May 26 08:15:52 2009
Subject: [Slony1-general] cleanup_interval parameter not working
Message-ID: <140258.93021.qm@web53009.mail.re2.yahoo.com>

CentOS-5.3
PostgreSQL 8.3.7
Slony 2.0.2

It appears that the cleanup_interval parameter is not being read from the slon.conf.

It is my understanding that if a parameter is not specified in the slon command line, it takes it from the slon.conf.

In my slon.conf I have:
=======================================================

Title = "slon"

# Which logfile group...
Logfile = /var/lib/pgsql/slony/slon.log
cleanup_interval="60 minutes"

# Only give lines pertaining to the sshd service...
*OnlyService = slon
*RemoveHeaders

=======================================================

My startup command is:

source $HOME/.bash_profile
slon -d1 -c0 -pslon_mas_1.pid $MAS_CLUSTER "dbname=$REPDB user=$REPLICATIONUSER host=$MASTERHOST port=$PGPORT" > slon.log &


Yet, when I check the slon.log, I see

2009-05-26 09:32:41 EDT CONFIG main: String option cleanup_interval = 10 minutes


So either the cleanup_interval parameter is not being accepted, or I have misread the documentation. Also, the documentation does not specify the intervals accepted. Ideally, I would like to set this to "24 hours" or "1 day" but I am not sure if that is permissible.

Melvin Davidson 
Folk Alley - All Folk - 24 Hours a day 
www.folkalley.com




      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090526/99e3f7d6/attachment.htm
From kevink at consistentstate.com  Tue May 26 08:23:44 2009
From: kevink at consistentstate.com (Kevin Kempter)
Date: Tue May 26 08:24:03 2009
Subject: [Slony1-general] cleanup_interval parameter not working
In-Reply-To: <140258.93021.qm@web53009.mail.re2.yahoo.com>
References: <140258.93021.qm@web53009.mail.re2.yahoo.com>
Message-ID: <200905260923.44974.kevink@consistentstate.com>



> CentOS-5.3
> PostgreSQL 8.3.7
> Slony 2.0.2
>
> It appears that the cleanup_interval parameter is not being read from the
> slon.conf.
>
> It is my understanding that if a parameter is not specified in the slon
> command line, it takes it from the slon.conf.
>
> In my slon.conf I have:
> =======================================================
>
> Title = "slon"
>
> # Which logfile group...
> Logfile = /var/lib/pgsql/slony/slon.log
> cleanup_interval="60 minutes"
>
> # Only give lines pertaining to the sshd service...
> *OnlyService = slon
> *RemoveHeaders
>
> =======================================================
>
> My startup command is:
>
> source $HOME/.bash_profile
> slon -d1 -c0 -pslon_mas_1.pid $MAS_CLUSTER "dbname=$REPDB
> user=$REPLICATIONUSER host=$MASTERHOST port=$PGPORT" > slon.log &
>
>
> Yet, when I check the slon.log, I see
>
> 2009-05-26 09:32:41 EDT CONFIG main: String option cleanup_interval = 10
> minutes
>
>
> So either the cleanup_interval parameter is not being accepted, or I have
> misread the documentation. Also, the documentation does not specify the
> intervals accepted. Ideally, I would like to set this to "24 hours" or "1
> day" but I am not sure if that is permissible.
>
> Melvin Davidson
> Folk Alley - All Folk - 24 Hours a day
> www.folkalley.com


Hi Melvin;

Did you install SLONY via RPM ? I've seen similar issues with RPM's on 
CentOS/Red Hat that were resolved once we installed SLONY via the source.



/Kevin

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090526/a705585e/attachment.htm
From melvin6925 at yahoo.com  Tue May 26 08:42:10 2009
From: melvin6925 at yahoo.com (Melvin Davidson)
Date: Tue May 26 08:42:18 2009
Subject: [Slony1-general] cleanup_interval parameter not working
Message-ID: <189943.13696.qm@web53010.mail.re2.yahoo.com>

Kevin,

I installed Slony from source. I rarely use RPM, so this is not the cause.
Slony 2.0.2 already contains a fix for a bug I found (ERROR in analyze on slony schema in cleanup thread), and since the clean_interval parameter is new to Slony 2, it's highly likely this is another one. 

Melvin Davidson 
 Folk Alley - All Folk - 24 Hours a day 
www.folkalley.com



--- On Tue, 5/26/09, Kevin Kempter <kevink@consistentstate.com> wrote:

From: Kevin Kempter <kevink@consistentstate.com>
Subject: Re: [Slony1-general] cleanup_interval parameter not working
To: slony1-general@lists.slony.info
Date: Tuesday, May 26, 2009, 9:23 AM

#yiv840926116 p, #yiv840926116 li {white-space:pre-wrap;}

> CentOS-5.3

> PostgreSQL 8.3.7

> Slony 2.0.2

>

> It appears that the cleanup_interval parameter is not being read from the

> slon.conf.

>

> It is my understanding that if a parameter is not specified in the slon

> command line, it takes it from the slon.conf.

>

> In my slon.conf I have:

> =======================================================

>

> Title = "slon"

>

> # Which logfile group...

> Logfile = /var/lib/pgsql/slony/slon.log

> cleanup_interval="60 minutes"

>

> # Only give lines pertaining to the sshd service...

> *OnlyService = slon

> *RemoveHeaders

>

> =======================================================

>

> My startup command is:

>

> source $HOME/.bash_profile

> slon -d1 -c0 -pslon_mas_1.pid $MAS_CLUSTER "dbname=$REPDB

> user=$REPLICATIONUSER host=$MASTERHOST port=$PGPORT" > slon.log &

>

>

> Yet, when I check the slon.log, I see

>

> 2009-05-26 09:32:41 EDT CONFIG main: String option cleanup_interval = 10

> minutes

>

>

> So either the cleanup_interval parameter is not being accepted, or I have

> misread the documentation. Also, the documentation does not specify the

> intervals accepted. Ideally, I would like to set this to "24 hours" or "1

> day" but I am not sure if that is permissible.

>

> Melvin Davidson

> Folk Alley - All Folk - 24 Hours a day

> www.folkalley.com



Hi Melvin;


Did you install SLONY via RPM ? I've seen similar issues with RPM's on CentOS/Red Hat that were resolved once we installed SLONY via the source.




/Kevin



-----Inline Attachment Follows-----

_______________________________________________
Slony1-general mailing list
Slony1-general@lists.slony.info
http://lists.slony.info/mailman/listinfo/slony1-general



      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090526/82aa1584/attachment-0001.htm
From rainer at ultra-secure.de  Thu May 28 18:21:05 2009
From: rainer at ultra-secure.de (Rainer Duffner)
Date: Thu May 28 18:21:27 2009
Subject: [Slony1-general] Problem running slonik on Solaris: slony1_funcs
	not found
Message-ID: <5E3A8BFF-FC9D-4772-B905-1F91984CBA72@ultra-secure.de>

Hi,

I have compiled slony1-2.0.2 on Solaris x86 10U6 with the SUN-supplied  
PostgreSQL 8.3.

When I want to run it, I get:
-bash-3.00# slonik < initcluster
<stdin>:6: PGRES_FATAL_ERROR load '$libdir/slony1_funcs';  - ERROR:   
could not access file "$libdir/slony1_funcs": No such file or directory
<stdin>:6: Error: the extension for the Slony-I C functions cannot be  
loaded in database 'host=localhost dbname=pgbench user=postgres  
port=5432'
-bash-3.00#


Is it possible to see where it's actually looking for that file?
It is available:
-bash-3.00# ls -l /usr/postgres/8.3/lib/slony1_funcs.so
-rwxr-xr-x   1 root     root       51376 Mai 28 03:06 /usr/postgres/ 
8.3/lib/slony1_funcs.so
-bash-3.00#


How do I debug that best?

I have installed:
-bash-3.00# pkginfo |grep postg
system      SUNWpostgr-82-libs             PostgreSQL 8.2 client  
libraries
system      SUNWpostgr-83-client           PostgreSQL client tools
system      SUNWpostgr-83-contrib          PostgreSQL community  
contributed tools not part of core product
system      SUNWpostgr-83-devel            PostgreSQL development  
tools and header files
system      SUNWpostgr-83-libs             PostgreSQL client libraries
system      SUNWpostgr-83-pl               PostgreSQL additional Perl,  
Python & TCL server procedural languages
system      SUNWpostgr-83-server           PostgreSQL database server
system      SUNWpostgr-83-server-data-root PostgreSQL database server  
data directories and root components
system      SUNWpostgr-83S                 PostgreSQL (Source)
system      SUNWpostgr-jdbc                JDBC drivers for PostgreSQL
-bash-3.00#



Regards,
Rainer
From ajs at crankycanuck.ca  Thu May 28 19:34:00 2009
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Thu May 28 19:34:24 2009
Subject: [Slony1-general] Problem running slonik on Solaris:
	slony1_funcs not found
In-Reply-To: <5E3A8BFF-FC9D-4772-B905-1F91984CBA72@ultra-secure.de>
References: <5E3A8BFF-FC9D-4772-B905-1F91984CBA72@ultra-secure.de>
Message-ID: <20090529023400.GB11608@shinkuro.com>

On Fri, May 29, 2009 at 03:21:05AM +0200, Rainer Duffner wrote:

> could not access file "$libdir/slony1_funcs": No such file or directory
> <stdin>:6: Error: the extension for the Slony-I C functions cannot be  
> loaded in database 'host=localhost dbname=pgbench user=postgres  
> port=5432'
> -bash-3.00#
>
>
> Is it possible to see where it's actually looking for that file?

What's your $libdir?  It's settable under Postgres.  You can see what
it's precompiled to be with pg_config --pkglibdir, but the
dynamic_library_path setting is what is used to change it.

A

-- 
Andrew Sullivan
ajs@crankycanuck.ca
From melvin6925 at yahoo.com  Thu May 28 19:38:26 2009
From: melvin6925 at yahoo.com (Melvin Davidson)
Date: Thu May 28 19:38:47 2009
Subject: [Slony1-general] Problem running slonik on Solaris: slony1_funcs
	not found
Message-ID: <750493.48172.qm@web53001.mail.re2.yahoo.com>

I can't say for sure if this will solve your problem, but try rebuilding/ r=
einstalling slony with the following options

First
locate pg_config
locate libpq.so

Then reconfigure with =

./configure --with-pgconfigdir=3D/usr/postgres/8.3 --with-pglibdir=3D/usr/p=
ostgres/8.3/lib

IOW =

--with-pgconfigdir=3D Location of the PostgreSQL pg_config program.
--with-pglibdir=3D=A0=A0=A0=A0=A0 Location of the PostgreSQL libs. (second =
locate)

make
make install

Melvin Davidson =

 =



--- On Thu, 5/28/09, Rainer Duffner <rainer@ultra-secure.de> wrote:

From: Rainer Duffner <rainer@ultra-secure.de>
Subject: [Slony1-general] Problem running slonik on Solaris: slony1_funcs n=
ot found
To: slony1-general@lists.slony.info
Date: Thursday, May 28, 2009, 7:21 PM

Hi,

I have compiled slony1-2.0.2 on Solaris x86 10U6 with the SUN-supplied Post=
greSQL 8.3.

When I want to run it, I get:
-bash-3.00# slonik < initcluster
<stdin>:6: PGRES_FATAL_ERROR load '$libdir/slony1_funcs';=A0 - ERROR:=A0 co=
uld not access file "$libdir/slony1_funcs": No such file or directory
<stdin>:6: Error: the extension for the Slony-I C functions cannot be loade=
d in database 'host=3Dlocalhost dbname=3Dpgbench user=3Dpostgres port=3D543=
2'
-bash-3.00#


Is it possible to see where it's actually looking for that file?
It is available:
-bash-3.00# ls -l /usr/postgres/8.3/lib/slony1_funcs.so
-rwxr-xr-x=A0=A0=A01 root=A0 =A0=A0=A0root=A0 =A0 =A0=A0=A051376 Mai 28 03:=
06 /usr/postgres/8.3/lib/slony1_funcs.so
-bash-3.00#


How do I debug that best?

I have installed:
-bash-3.00# pkginfo |grep postg
system=A0 =A0 =A0 SUNWpostgr-82-libs=A0 =A0 =A0 =A0 =A0 =A0=A0=A0PostgreSQL=
 8.2 client libraries
system=A0 =A0 =A0 SUNWpostgr-83-client=A0 =A0 =A0 =A0 =A0=A0=A0PostgreSQL c=
lient tools
system=A0 =A0 =A0 SUNWpostgr-83-contrib=A0 =A0 =A0 =A0 =A0 PostgreSQL commu=
nity contributed tools not part of core product
system=A0 =A0 =A0 SUNWpostgr-83-devel=A0 =A0 =A0 =A0 =A0 =A0 PostgreSQL dev=
elopment tools and header files
system=A0 =A0 =A0 SUNWpostgr-83-libs=A0 =A0 =A0 =A0 =A0 =A0=A0=A0PostgreSQL=
 client libraries
system=A0 =A0 =A0 SUNWpostgr-83-pl=A0 =A0 =A0 =A0 =A0 =A0 =A0=A0=A0PostgreS=
QL additional Perl, Python & TCL server procedural languages
system=A0 =A0 =A0 SUNWpostgr-83-server=A0 =A0 =A0 =A0 =A0=A0=A0PostgreSQL d=
atabase server
system=A0 =A0 =A0 SUNWpostgr-83-server-data-root PostgreSQL database server=
 data directories and root components
system=A0 =A0 =A0 SUNWpostgr-83S=A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0=A0=A0Postgr=
eSQL (Source)
system=A0 =A0 =A0 SUNWpostgr-jdbc=A0 =A0 =A0 =A0 =A0 =A0 =A0 =A0 JDBC drive=
rs for PostgreSQL
-bash-3.00#



Regards,
Rainer
_______________________________________________
Slony1-general mailing list
Slony1-general@lists.slony.info
http://lists.slony.info/mailman/listinfo/slony1-general



      =

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090528/=
400f85a9/attachment.htm
From rainer at ultra-secure.de  Thu May 28 23:27:01 2009
From: rainer at ultra-secure.de (Rainer Duffner)
Date: Thu May 28 23:27:29 2009
Subject: [Slony1-general] Problem running slonik on Solaris: slony1_funcs
	not found
In-Reply-To: <750493.48172.qm@web53001.mail.re2.yahoo.com>
References: <750493.48172.qm@web53001.mail.re2.yahoo.com>
Message-ID: <C16CD9F3-C3F0-4EB1-B29C-45C7D2658CAF@ultra-secure.de>


Am 29.05.2009 um 04:38 schrieb Melvin Davidson:

> I can't say for sure if this will solve your problem, but try  
> rebuilding/ reinstalling slony with the following options
>
> First
> locate pg_config
> locate libpq.so
>
> Then reconfigure with
> ./configure --with-pgconfigdir=/usr/postgres/8.3 --with-pglibdir=/ 
> usr/postgres/8.3/lib
>
> IOW
> --with-pgconfigdir= Location of the PostgreSQL pg_config program.
> --with-pglibdir=      Location of the PostgreSQL libs. (second locate)
>
> make
> make install
>


Well, that's what I did, more or less (it's Solaris, so I used gmake).

Also, I had to do:
./configure --with-pgconfigdir=/usr/postgres/8.3/bin --with-pglibdir=/ 
usr/postgres/8.3/lib
or else pgconfig wouldn't be found.


The error is still the same.



Best Regards,
Rainer
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090529/71ca6e55/attachment.htm
From rainer at ultra-secure.de  Thu May 28 23:29:32 2009
From: rainer at ultra-secure.de (Rainer Duffner)
Date: Thu May 28 23:30:00 2009
Subject: [Slony1-general] Problem running slonik on Solaris: slony1_funcs
	not found
In-Reply-To: <20090529023400.GB11608@shinkuro.com>
References: <5E3A8BFF-FC9D-4772-B905-1F91984CBA72@ultra-secure.de>
	<20090529023400.GB11608@shinkuro.com>
Message-ID: <DA2C2FAD-977C-4DDC-84FE-1BBCC5823A63@ultra-secure.de>


Am 29.05.2009 um 04:34 schrieb Andrew Sullivan:

> On Fri, May 29, 2009 at 03:21:05AM +0200, Rainer Duffner wrote:
>
>> could not access file "$libdir/slony1_funcs": No such file or  
>> directory
>> <stdin>:6: Error: the extension for the Slony-I C functions cannot be
>> loaded in database 'host=localhost dbname=pgbench user=postgres
>> port=5432'
>> -bash-3.00#
>>
>>
>> Is it possible to see where it's actually looking for that file?
>
> What's your $libdir?  It's settable under Postgres.  You can see what
> it's precompiled to be with pg_config --pkglibdir, but the
> dynamic_library_path setting is what is used to change it.
>


Hi,

what do you mean with that?

I have:
-bash-3.00# /usr/postgres/8.3/bin/pg_config --pkglibdir
/usr/postgres/8.3/lib
-bash-3.00# /usr/postgres/8.3/bin/pg_config --libdir
/usr/postgres/8.3/lib


and that's also where that slony1_funcs.so file is located...


Best Regards,
Rainer
From rainer at ultra-secure.de  Thu May 28 23:53:16 2009
From: rainer at ultra-secure.de (Rainer Duffner)
Date: Thu May 28 23:53:49 2009
Subject: [Slony1-general] Problem running slonik on Solaris:
	slony1_funcs	not found
In-Reply-To: <OF195F5820.C29FFD26-ON652575C5.0023B476-652575C5.0023CFFC@ibsplc.com>
References: <OF195F5820.C29FFD26-ON652575C5.0023B476-652575C5.0023CFFC@ibsplc.com>
Message-ID: <4145F68F-E894-4AF2-983F-237CDABC0E57@ultra-secure.de>


Am 29.05.2009 um 08:31 schrieb Jayadevan M:

> Hi,
> You could also try a 'file' command on that .so file to see if it is a
> 32-bit 64-bit confusion. I have faced that issue with other software.
> Regards,
> Jay




Aha.
It's 32bit.
Postgres is 64bit...
How do I compile it 64bit?



Best Regards,
Rainer
From rainer at ultra-secure.de  Fri May 29 00:15:59 2009
From: rainer at ultra-secure.de (Rainer Duffner)
Date: Fri May 29 00:16:28 2009
Subject: [Slony1-general] Problem running slonik on
	Solaris:	slony1_funcs	not found
In-Reply-To: <OF7B1E1AE3.FBB36E57-ON652575C5.00260BA5-652575C5.00271032@ibsplc.com>
References: <OF7B1E1AE3.FBB36E57-ON652575C5.00260BA5-652575C5.00271032@ibsplc.com>
Message-ID: <84A72F3B-F834-4D82-BE4F-397A2414B37D@ultra-secure.de>


Am 29.05.2009 um 09:06 schrieb Jayadevan M:

> If your .so is 32 bit, you need to get the right so (64 bit) and have
> everything in 64 bit mode.
> Sometimes both sets are present in the system and if you point it to
> the right one, it will work. Please try a find command for that .so
> file and see if both are available (32 bit and 64 bit). If they are,
> you can use the 64 bit so path during configure/compile.
> There is a switch available to compile in 64 bit mode.  Please see
> this link
> http://www.linuxquestions.org/questions/linux-software-2/compiling-php-on-rhel-5-64-bit-685606/
> Regards,
> Jay
>



Ok, but this is Solaris:

-bash-3.00# ./configure --with-pgconfigdir=/usr/postgres/8.3/bin -- 
with-pglibdir=/usr/postgres/8.3/lib/amd64 --with-perltools

....

checking for POSIX signal interface... yes
checking if you have requested slony1-engine building... yes
overriding pglibdir with /usr/postgres/8.3/lib/amd64
checking for pg_config... /usr/postgres/8.3/bin/pg_config
pg_config says pg_bindir is /usr/postgres/8.3/bin/
pg_config says pg_includedir is /usr/postgres/8.3/include/
pg_config says pg_pkglibdir is /usr/postgres/8.3/lib/
pg_config says pg_includeserverdir is /usr/postgres/8.3/include/server/
checking for correct version of PostgreSQL... 8.3
8.3
pg_config says pg_sharedir is /usr/postgres/8.3/share/
checking PostgreSQL for enable-thread-safety as required on  
solaris2.10... yes
checking for PQunescapeBytea in -lpq... no
configure: error: Your version of libpq doesn't have PQunescapeBytea
      which means that your version of PostgreSQL is lower than 7.3
      and thus not even remotely supported by Slony-I version 2
./configure: line 7489: exit: which: numeric argument required
./configure: line 7489: exit: which: numeric argument required
-bash-3.00#


And now?


Best Regards,
Rainer


From Jayadevan.Maymala at ibsplc.com  Fri May 29 00:24:40 2009
From: Jayadevan.Maymala at ibsplc.com (Jayadevan M)
Date: Fri May 29 00:26:03 2009
Subject: [Slony1-general] Problem running slonik
	on	Solaris:	slony1_funcs	not found
In-Reply-To: <84A72F3B-F834-4D82-BE4F-397A2414B37D@ultra-secure.de>
Message-ID: <OF0732A532.66134EFA-ON652575C5.0028950C-652575C5.0028B9C7@ibsplc.com>

Hi,
There is a mention of that error (configure: error: Your version of
libpq doesn't have PQunescapeBytea) here...
http://www.slony.info/documentation/faq.html
Regards,
Jay


                                                                      
             Rainer Duffner                                           
             <rainer@ultra-s                                          
             ecure.de>                                             To 
             Sent by:                Jayadevan M                      
             slony1-general-         <Jayadevan.Maymala@ibsplc.com>   
             bounces@lists.s                                       cc 
             lony.info               slony1-general@lists.slony.info, 
                                     slony1-general-bounces@lists.slo 
                                     ny.info                          
             05/29/2009                                       Subject 
             12:45 PM                Re: [Slony1-general] Problem     
                                     running slonik on  Solaris:      
                                     slony1_funcs       not found     
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      





Am 29.05.2009 um 09:06 schrieb Jayadevan M:

> If your .so is 32 bit, you need to get the right so (64 bit) and
have
> everything in 64 bit mode.
> Sometimes both sets are present in the system and if you point it to
> the right one, it will work. Please try a find command for that .so
> file and see if both are available (32 bit and 64 bit). If they are,
> you can use the 64 bit so path during configure/compile.
> There is a switch available to compile in 64 bit mode.  Please see
> this link
>
http://www.linuxquestions.org/questions/linux-software-2/compiling-php-on-rhel-5-64-bit-685606/

> Regards,
> Jay
>



Ok, but this is Solaris:

-bash-3.00# ./configure --with-pgconfigdir=/usr/postgres/8.3/bin --
with-pglibdir=/usr/postgres/8.3/lib/amd64 --with-perltools

....

checking for POSIX signal interface... yes
checking if you have requested slony1-engine building... yes
overriding pglibdir with /usr/postgres/8.3/lib/amd64
checking for pg_config... /usr/postgres/8.3/bin/pg_config
pg_config says pg_bindir is /usr/postgres/8.3/bin/
pg_config says pg_includedir is /usr/postgres/8.3/include/
pg_config says pg_pkglibdir is /usr/postgres/8.3/lib/
pg_config says pg_includeserverdir is
/usr/postgres/8.3/include/server/
checking for correct version of PostgreSQL... 8.3
8.3
pg_config says pg_sharedir is /usr/postgres/8.3/share/
checking PostgreSQL for enable-thread-safety as required on
solaris2.10... yes
checking for PQunescapeBytea in -lpq... no
configure: error: Your version of libpq doesn't have PQunescapeBytea
      which means that your version of PostgreSQL is lower than 7.3
      and thus not even remotely supported by Slony-I version 2
./configure: line 7489: exit: which: numeric argument required
./configure: line 7489: exit: which: numeric argument required
-bash-3.00#


And now?


Best Regards,
Rainer


_______________________________________________
Slony1-general mailing list
Slony1-general@lists.slony.info
http://lists.slony.info/mailman/listinfo/slony1-general


From Jayadevan.Maymala at ibsplc.com  Fri May 29 00:06:31 2009
From: Jayadevan.Maymala at ibsplc.com (Jayadevan M)
Date: Fri May 29 08:24:40 2009
Subject: [Slony1-general] Problem running slonik on
	Solaris:	slony1_funcs	not found
In-Reply-To: <4145F68F-E894-4AF2-983F-237CDABC0E57@ultra-secure.de>
Message-ID: <OF7B1E1AE3.FBB36E57-ON652575C5.00260BA5-652575C5.00271032@ibsplc.com>

If your .so is 32 bit, you need to get the right so (64 bit) and have
everything in 64 bit mode.
Sometimes both sets are present in the system and if you point it to
the right one, it will work. Please try a find command for that .so
file and see if both are available (32 bit and 64 bit). If they are,
you can use the 64 bit so path during configure/compile.
There is a switch available to compile in 64 bit mode.  Please see
this link
http://www.linuxquestions.org/questions/linux-software-2/compiling-php-on-rhel-5-64-bit-685606/
Regards,
Jay


                                                                      
             Rainer Duffner                                           
             <rainer@ultra-s                                          
             ecure.de>                                             To 
             Sent by:                Jayadevan M                      
             slony1-general-         <Jayadevan.Maymala@ibsplc.com>   
             bounces@lists.s                                       cc 
             lony.info               slony1-general@lists.slony.info  
                                                              Subject 
                                     Re: [Slony1-general] Problem     
             05/29/2009              running slonik on Solaris:       
             12:22 PM                slony1_funcs       not found     
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      





Am 29.05.2009 um 08:31 schrieb Jayadevan M:

> Hi,
> You could also try a 'file' command on that .so file to see if it is
a
> 32-bit 64-bit confusion. I have faced that issue with other
software.
> Regards,
> Jay




Aha.
It's 32bit.
Postgres is 64bit...
How do I compile it 64bit?



Best Regards,
Rainer
_______________________________________________
Slony1-general mailing list
Slony1-general@lists.slony.info
http://lists.slony.info/mailman/listinfo/slony1-general


From sean at ftdna.com  Fri May 29 13:53:15 2009
From: sean at ftdna.com (Sean Staats)
Date: Fri May 29 13:53:32 2009
Subject: [Slony1-general] Initial replication of sequences is failing
Message-ID: <4A204B3B.9040900@ftdna.com>

The initial replication of all 165 tables appears to succeed.  When 
slony tries to replicate the first sequence, the following error is 
reported:
log snippet...
2009-05-29 15:39:05 CDT DEBUG1 copy_set 1
2009-05-29 15:39:05 CDT DEBUG1 remoteWorkerThread_1: connected to 
provider DB
2009-05-29 15:39:05 CDT DEBUG2 remoteWorkerThread_1: prepare to copy 
table "finch"."fs_category"
2009-05-29 15:39:05 CDT DEBUG2 remoteWorkerThread_1: prepare to copy 
table "finch"."fs_setting"
2009-05-29 15:39:05 CDT DEBUG2 remoteWorkerThread_1: prepare to copy 
table "finch"."fs_value"
2009-05-29 15:39:05 CDT DEBUG2 remoteWorkerThread_1: prepare to copy 
table "finch"."finch_user"
2009-05-29 15:39:05 CDT DEBUG2 remoteWorkerThread_1: prepare to copy 
table "finch"."primer"
<snip>
2009-05-29 15:39:06 CDT DEBUG2 remoteWorkerThread_1: prepare to copy 
table "finch"."cim_order_registry"
2009-05-29 15:39:06 CDT DEBUG2 remoteWorkerThread_1: prepare to copy 
table "finch"."config_master_table"
2009-05-29 15:39:06 CDT DEBUG2 remoteWorkerThread_1: all tables for set 
1 found on subscriber
2009-05-29 15:39:06 CDT DEBUG2 remoteWorkerThread_1: copy sequence 
"finch"."contig_sequence_id_seq"
2009-05-29 15:39:06 CDT ERROR  remoteWorkerThread_1: "select 
"_finch_cluster_1".setAddSequence_int(1, 1, 
'"finch"."contig_sequence_id_seq"', '')" PGRES_FATAL_ERROR ERROR:  
Slony-I: setAddSequence_int(): sequence ID 1 has already been assigned
2009-05-29 15:39:06 CDT WARN   remoteWorkerThread_1: data copy for set 1 
failed - sleep 60 seconds
WARNING:  there is no transaction in progress


I've created a 2-node cluster using the following slonik scripts:
preamble.slonik:
cluster name=cluster_1;
NODE 1 ADMIN CONNINFO = 'dbname=mydb host=host1 user=xxxx password=yyyy 
port=5432';
NODE 2 ADMIN CONNINFO = 'dbname=mydb host=host2 user=xxxx password=yyyy 
port=5432';

01-create_nodes.slonik:
include </home/foo/slony-setup/preamble.slonik>;
init cluster (id=1, comment='cluster_1 master');
store node (id=2, comment='cluster_1 subscriber');

02-store_paths.slonik:
include </home/foo/slony-setup/preamble.slonik>;
STORE PATH (SERVER=1, CLIENT=2, CONNINFO='dbname=mydb host=host1 
user=xxxx password=yyyy port=5432');
STORE PATH (SERVER=2, CLIENT=1, CONNINFO='dbname=mydb host=host2 
user=xxxx password=yyyy port=5432');

03-create_set.slonik:
include </home/foo/slony-setup/preamble.slonik>;
create set (id=1, origin=1, comment='cluster_1 Tables and Sequences');
# TABLES
set add table (set id=1, origin=1, id=1, full qualified name = 
'mydb.fs_category', comment='Table dependency level 0');
set add table (set id=1, origin=1, id=2, full qualified name = 
'mydb.fs_setting', comment='Table dependency level 0');
set add table (set id=1, origin=1, id=3, full qualified name = 
'mydb.fs_value', comment='Table dependency level 0');
set add table (set id=1, origin=1, id=4, full qualified name = 
'mydb.finch_user', comment='Table dependency level 1');
set add table (set id=1, origin=1, id=5, full qualified name = 
'mydb.primer', comment='Table dependency level 2');
set add table (set id=1, origin=1, id=6, full qualified name = 
'mydb.adb_marker', comment='Table dependency level 2');
set add table (set id=1, origin=1, id=7, full qualified name = 
'mydb.adb_sample', comment='Table dependency level 2');
<snip>
# SEQUENCES
set add sequence (set id=1, origin=1, id=1, full qualified name = 
'mydb.contig_sequence_id_seq', comment='');
set add sequence (set id=1, origin=1, id=2, full qualified name = 
'mydb.control_sample_seq', comment='');
set add sequence (set id=1, origin=1, id=3, full qualified name = 
'mydb.dbk_seq', comment='');
set add sequence (set id=1, origin=1, id=4, full qualified name = 
'mydb.dref_seq', comment='');
set add sequence (set id=1, origin=1, id=5, full qualified name = 
'mydb.email_seq', comment='');
set add sequence (set id=1, origin=1, id=6, full qualified name = 
'mydb.faddress_seq', comment='');
<snip>

** Note that there are a total of 165 tables and 100 sequences added to 
the set.

04-subscribe_set.slonik:
include </home/foo/slony-setup/preamble.slonik>;
subscribe set (id=1, provider=1, receiver=2, forward=yes);

I also tried adding the sequences to the set by starting their id values 
with 1001, but that got me the same results. 

Thanks in advance for your time and help!

Sean



From melvin6925 at yahoo.com  Fri May 29 15:37:04 2009
From: melvin6925 at yahoo.com (Melvin Davidson)
Date: Fri May 29 15:37:20 2009
Subject: [Slony1-general] Initial replication of sequences is failing
Message-ID: <393288.40720.qm@web53004.mail.re2.yahoo.com>

>>=A0 sequence ID 1 has already been assigned

There's your big clue! You probably have two sequences somewhere in the con=
fig with the same sequence ID. If you cannot resolve this by reviewing, the=
n please attach your initialization script for another set of eyes to check.
FYI, even though it's permitted to have sequences with the same ID as a tab=
le, I always start my sequences with an offset of 1000 from table ID's just=
 to make tracking easier.

Melvin Davidson =

 Home 720-870-9595 =

 =A0=A0=A0 Cell 720-320-0155  =





--- On Fri, 5/29/09, Sean Staats <sean@ftdna.com> wrote:

From: Sean Staats <sean@ftdna.com>
Subject: [Slony1-general] Initial replication of sequences is failing
To: slony1-general@lists.slony.info
Date: Friday, May 29, 2009, 2:53 PM

The initial replication of all 165 tables appears to succeed.=A0 When slony=
 tries to replicate the first sequence, the following error is reported:
log snippet...
2009-05-29 15:39:05 CDT DEBUG1 copy_set 1
2009-05-29 15:39:05 CDT DEBUG1 remoteWorkerThread_1: connected to provider =
DB
2009-05-29 15:39:05 CDT DEBUG2 remoteWorkerThread_1: prepare to copy table =
"finch"."fs_category"
2009-05-29 15:39:05 CDT DEBUG2 remoteWorkerThread_1: prepare to copy table =
"finch"."fs_setting"
2009-05-29 15:39:05 CDT DEBUG2 remoteWorkerThread_1: prepare to copy table =
"finch"."fs_value"
2009-05-29 15:39:05 CDT DEBUG2 remoteWorkerThread_1: prepare to copy table =
"finch"."finch_user"
2009-05-29 15:39:05 CDT DEBUG2 remoteWorkerThread_1: prepare to copy table =
"finch"."primer"
<snip>
2009-05-29 15:39:06 CDT DEBUG2 remoteWorkerThread_1: prepare to copy table =
"finch"."cim_order_registry"
2009-05-29 15:39:06 CDT DEBUG2 remoteWorkerThread_1: prepare to copy table =
"finch"."config_master_table"
2009-05-29 15:39:06 CDT DEBUG2 remoteWorkerThread_1: all tables for set 1 f=
ound on subscriber
2009-05-29 15:39:06 CDT DEBUG2 remoteWorkerThread_1: copy sequence "finch".=
"contig_sequence_id_seq"
2009-05-29 15:39:06 CDT ERROR=A0 remoteWorkerThread_1: "select "_finch_clus=
ter_1".setAddSequence_int(1, 1, '"finch"."contig_sequence_id_seq"', '')" PG=
RES_FATAL_ERROR ERROR:=A0 Slony-I: setAddSequence_int(): sequence ID 1 has =
already been assigned
2009-05-29 15:39:06 CDT WARN=A0=A0=A0remoteWorkerThread_1: data copy for se=
t 1 failed - sleep 60 seconds
WARNING:=A0 there is no transaction in progress


I've created a 2-node cluster using the following slonik scripts:
preamble.slonik:
cluster name=3Dcluster_1;
NODE 1 ADMIN CONNINFO =3D 'dbname=3Dmydb host=3Dhost1 user=3Dxxxx password=
=3Dyyyy port=3D5432';
NODE 2 ADMIN CONNINFO =3D 'dbname=3Dmydb host=3Dhost2 user=3Dxxxx password=
=3Dyyyy port=3D5432';

01-create_nodes.slonik:
include </home/foo/slony-setup/preamble.slonik>;
init cluster (id=3D1, comment=3D'cluster_1 master');
store node (id=3D2, comment=3D'cluster_1 subscriber');

02-store_paths.slonik:
include </home/foo/slony-setup/preamble.slonik>;
STORE PATH (SERVER=3D1, CLIENT=3D2, CONNINFO=3D'dbname=3Dmydb host=3Dhost1 =
user=3Dxxxx password=3Dyyyy port=3D5432');
STORE PATH (SERVER=3D2, CLIENT=3D1, CONNINFO=3D'dbname=3Dmydb host=3Dhost2 =
user=3Dxxxx password=3Dyyyy port=3D5432');

03-create_set.slonik:
include </home/foo/slony-setup/preamble.slonik>;
create set (id=3D1, origin=3D1, comment=3D'cluster_1 Tables and Sequences');
# TABLES
set add table (set id=3D1, origin=3D1, id=3D1, full qualified name =3D 'myd=
b.fs_category', comment=3D'Table dependency level 0');
set add table (set id=3D1, origin=3D1, id=3D2, full qualified name =3D 'myd=
b.fs_setting', comment=3D'Table dependency level 0');
set add table (set id=3D1, origin=3D1, id=3D3, full qualified name =3D 'myd=
b.fs_value', comment=3D'Table dependency level 0');
set add table (set id=3D1, origin=3D1, id=3D4, full qualified name =3D 'myd=
b.finch_user', comment=3D'Table dependency level 1');
set add table (set id=3D1, origin=3D1, id=3D5, full qualified name =3D 'myd=
b.primer', comment=3D'Table dependency level 2');
set add table (set id=3D1, origin=3D1, id=3D6, full qualified name =3D 'myd=
b.adb_marker', comment=3D'Table dependency level 2');
set add table (set id=3D1, origin=3D1, id=3D7, full qualified name =3D 'myd=
b.adb_sample', comment=3D'Table dependency level 2');
<snip>
# SEQUENCES
set add sequence (set id=3D1, origin=3D1, id=3D1, full qualified name =3D '=
mydb.contig_sequence_id_seq', comment=3D'');
set add sequence (set id=3D1, origin=3D1, id=3D2, full qualified name =3D '=
mydb.control_sample_seq', comment=3D'');
set add sequence (set id=3D1, origin=3D1, id=3D3, full qualified name =3D '=
mydb.dbk_seq', comment=3D'');
set add sequence (set id=3D1, origin=3D1, id=3D4, full qualified name =3D '=
mydb.dref_seq', comment=3D'');
set add sequence (set id=3D1, origin=3D1, id=3D5, full qualified name =3D '=
mydb.email_seq', comment=3D'');
set add sequence (set id=3D1, origin=3D1, id=3D6, full qualified name =3D '=
mydb.faddress_seq', comment=3D'');
<snip>

** Note that there are a total of 165 tables and 100 sequences added to the=
 set.

04-subscribe_set.slonik:
include </home/foo/slony-setup/preamble.slonik>;
subscribe set (id=3D1, provider=3D1, receiver=3D2, forward=3Dyes);

I also tried adding the sequences to the set by starting their id values wi=
th 1001, but that got me the same results. =

Thanks in advance for your time and help!

Sean



_______________________________________________
Slony1-general mailing list
Slony1-general@lists.slony.info
http://lists.slony.info/mailman/listinfo/slony1-general



      =

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090529/=
f3d71642/attachment.htm
From ajs at crankycanuck.ca  Fri May 29 21:08:48 2009
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Fri May 29 21:09:13 2009
Subject: [Slony1-general] Initial replication of sequences is failing
In-Reply-To: <393288.40720.qm@web53004.mail.re2.yahoo.com>
References: <393288.40720.qm@web53004.mail.re2.yahoo.com>
Message-ID: <20090530040848.GF13757@shinkuro.com>

On Fri, May 29, 2009 at 03:37:04PM -0700, Melvin Davidson wrote:
> >>? sequence ID 1 has already been assigned
> 
> There's your big clue! You probably have two sequences somewhere in
> the config with the same sequence ID. 

I agree this has to be the problem.

> sequences with the same ID as a table, I always start my sequences
> with an offset of 1000 from table ID's just to make tracking easier.

Gee, and then what do you do when you end up with 1000 tables, because
you have to do with table rotation due to huge success of your
incredible application?  Integers in int32 space are pretty much
free.  If you're trying to save yourself trouble this way, offset by
more than 1000 -- 10 000 or even 100 000 isn't a bad idea.

Note I'm not objecting on principled grounds that "you might need 
10 000 tables" or anything.  This is just a prudential remark that an
offset of 1 000 is a little too close, in my experience.

A

-- 
Andrew Sullivan
ajs@crankycanuck.ca
From melvin6925 at yahoo.com  Fri May 29 21:17:42 2009
From: melvin6925 at yahoo.com (Melvin Davidson)
Date: Fri May 29 21:18:06 2009
Subject: [Slony1-general] Initial replication of sequences is failing
Message-ID: <873334.15299.qm@web53003.mail.re2.yahoo.com>

Andrew,

>Gee, and then what do you do when you end up with 1000 tables, =



It's simply a matter of individual requirements. In my situation, it is
relatively safe to safe that there will never be more than 1K of
tables. In other situations, the offset can be adjusted accordingly. I
do not know of any installations with over 100k tables. If there are, I
suspect someone has not designed it too well. :)



Melvin Davidson =

 Home 720-870-9595 =

 =A0=A0=A0 Cell 720-320-0155  =






      =

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20090529/=
16da3a08/attachment.htm
From stuart at stuartbishop.net  Sun May 31 06:59:42 2009
From: stuart at stuartbishop.net (Stuart Bishop)
Date: Sun May 31 06:59:47 2009
Subject: [Slony1-general] Initial replication of sequences is failing
In-Reply-To: <4A204B3B.9040900@ftdna.com>
References: <4A204B3B.9040900@ftdna.com>
Message-ID: <6bc73d4c0905310659g2484101cn56013b4cf825ca40@mail.gmail.com>

On Sat, May 30, 2009 at 3:53 AM, Sean Staats <sean@ftdna.com> wrote:
> The initial replication of all 165 tables appears to succeed. ?When slony
> tries to replicate the first sequence, the following error is reported:
> log snippet...

> 2009-05-29 15:39:06 CDT ERROR ?remoteWorkerThread_1: "select
> "_finch_cluster_1".setAddSequence_int(1, 1,
> '"finch"."contig_sequence_id_seq"', '')" PGRES_FATAL_ERROR ERROR: ?Slony-I:
> setAddSequence_int(): sequence ID 1 has already been assigned
> 2009-05-29 15:39:06 CDT WARN ? remoteWorkerThread_1: data copy for set 1
> failed - sleep 60 seconds
> WARNING: ?there is no transaction in progress

Does it keep looping?

You might be hitting Bug #62 (
http://www.slony.info/bugzilla/show_bug.cgi?id=62 ). Its repeatable if
you run out of disk space during replication, but there might be other
triggers too. If you search the archives, there is a thread about the
same error message roughly every month or two.

-- 
Stuart Bishop <stuart@stuartbishop.net>
http://www.stuartbishop.net/
