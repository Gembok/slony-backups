From decibel at decibel.org  Sat Sep  1 16:19:08 2007
From: decibel at decibel.org (Decibel!)
Date: Sat Sep  1 16:19:31 2007
Subject: Packaging for FreeBSD (was Re: [Slony1-general] Slony-I 1.2.11
	released)
In-Reply-To: <20070829164103.979f5358.wmoran@collaborativefusion.com>
References: <608x7vo2sn.fsf@dba2.int.libertyrms.com>
	<20070829164103.979f5358.wmoran@collaborativefusion.com>
Message-ID: <20070901231908.GW38801@decibel.org>

On Wed, Aug 29, 2007 at 04:41:03PM -0400, Bill Moran wrote:
> 
> Anyone started on updating the port for FreeBSD yet?
> 
> Can we have the rc script developed by my cohort, Brian Seklecki, be
> the default installed on FreeBSD.  It behaves exactly the same as
> the previous rc script, unless slon_profiles is enabled, in which
> case it allows the administrator to configure profiles that automatically
> start multiple slons with different configurations.

Who's MAINTAINER? Might be easier to just open a PR.
-- 
Decibel!, aka Jim C. Nasby, Database Architect  decibel@decibel.org 
Give your computer some brain candy! www.distributed.net Team #1828
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 187 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20070901/6559af37/attachment.pgp
From wmoran at collaborativefusion.com  Sat Sep  1 16:34:02 2007
From: wmoran at collaborativefusion.com (Bill Moran)
Date: Sat Sep  1 16:34:20 2007
Subject: Packaging for FreeBSD (was Re: [Slony1-general] Slony-I 1.2.11
	released)
In-Reply-To: <20070901231908.GW38801@decibel.org>
References: <608x7vo2sn.fsf@dba2.int.libertyrms.com>
	<20070829164103.979f5358.wmoran@collaborativefusion.com>
	<20070901231908.GW38801@decibel.org>
Message-ID: <20070901193402.997809bb.wmoran@collaborativefusion.com>

"Decibel!" <decibel@decibel.org> wrote:
>
> On Wed, Aug 29, 2007 at 04:41:03PM -0400, Bill Moran wrote:
> > 
> > Anyone started on updating the port for FreeBSD yet?
> > 
> > Can we have the rc script developed by my cohort, Brian Seklecki, be
> > the default installed on FreeBSD.  It behaves exactly the same as
> > the previous rc script, unless slon_profiles is enabled, in which
> > case it allows the administrator to configure profiles that automatically
> > start multiple slons with different configurations.
> 
> Who's MAINTAINER? Might be easier to just open a PR.

Vivek and I sorted it out, he had already opened a PR, and he's listed
as maintainer.

I just wanted to make sure I didn't put together a patch when someone
else was already on it.  It worked out well -- Vivek and I sorted it
all out.

-- 
Bill Moran
Collaborative Fusion Inc.

wmoran@collaborativefusion.com
Phone: 412-422-3463x4023
From cscetbon.ext at orange-ftgroup.com  Sun Sep  2 10:44:34 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Sun Sep  2 10:44:43 2007
Subject: [Slony1-general] Configuration on 2 sites
In-Reply-To: <46D84297.8010204@Yahoo.com>
References: <46D3EF28.40108@orange-ftgroup.com>	<20070828132235.GA461@phlogi		ston.dyndns.org>	<46D43DAF.5010604@orange-ftgroup.com>	<20070828152919.GB9	7	9@phlogiston.dyndns.org>	<46D539A4.9020601@orange-ftgroup.com>	<200708291	74	509.GR4183@phlogiston.dyndns.org>	<46D5B216.2010708@orange-ftgroup.com>		<20	070829180550.GT4183@phlogiston.dyndns.org>	<46D5BD84.8090302@orange-ftg	roup.com>
	<46D7D4AE.6000600@orange-ftgroup.com> <46D7FE31.3080308@Yahoo.com>
	<46D820F7.7070904@orange-ftgroup.com> <46D84297.8010204@Yahoo.com>
Message-ID: <46DAF682.5030902@orange-ftgroup.com>



Jan Wieck wrote:
> On 8/31/2007 10:08 AM, Cyril SCETBON wrote:
>>
>> Jan Wieck wrote:
>>> On 8/31/2007 4:43 AM, Cyril SCETBON wrote:
>>>>
>>>> Cyril SCETBON wrote:
>>>>>
>>>>>
>>>>> Andrew Sullivan wrote:
>>>>>> On Wed, Aug 29, 2007 at 07:51:18PM +0200, Cyril SCETBON wrote:
>>>>>>  
>>>>>>> So, How can I do if M2 is lost ? Cause I don't want S2 to resync 
>>>>>>> with M1 from scratch
>>>>>>>     
>>>>>>
>>>>>> You can't.  If you can't co-ordinate a switchover, then you lose the
>>>>>> node.  This is discussed at length in the manual.
>>>>>>   
>>>>> Really ????
>>>>> Are you really saying that losing M2 make me lose S2 ?????
>>>>> If it's true I'm really disappointed by slony :-(
>>>>>
>>>>> My config is as follows (just to remember) :
>>>>>
>>>>> psql db1 -c 'select * from "_CLUSTER1".sl_subscribe'
>>>>> sub_set | sub_provider | sub_receiver | sub_forward | sub_active
>>>>> ---------+--------------+--------------+-------------+------------
>>>>>      1 |            1 (M1)|            3 (M2)| t           | t
>>>>>      1 |            1 (M1)|            2 (S1) | t           | t
>>>>>      1 |            3 (M2)|            4 (S2) | t           | t
>>>
>>> Since all nodes in your scenario are forwarders, you won't lose 
>>> anything other than the failed node ever. In your configuration if 
>>> you lose node M2 (which is a subscriber), simply issuing a new 
>>> SUBSCRIBE SET for node S2 to use M1 or S1 as data provider will do. 
>>> It will catch up from there without the need to sync from scratch.
>> I tried reshaping subscription. The subscription works. But no more 
>> updates go to S2.
>
> Check the sl_path configuration. S2 might not have the necessary (or 
> correct) information to connect to its new data provider.
I don't think so, cause I wasn't able to reshape subscription to the new 
provider until I added store path between both nodes. I'll try to get 
log files to check and let you know what happens.

thanks.
>
>
> Jan
>

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From cscetbon.ext at orange-ftgroup.com  Sun Sep  2 10:47:33 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Sun Sep  2 10:47:41 2007
Subject: [Slony1-general] Configuration on 2 sites
In-Reply-To: <46DAF682.5030902@orange-ftgroup.com>
References: <46D3EF28.40108@orange-ftgroup.com>	<20070828132235.GA461@phlogi		ston.dyndns.org>	<46D43DAF.5010604@orange-ftgroup.com>	<20070828152919.GB9	7	9@phlogiston.dyndns.org>	<46D539A4.9020601@orange-ftgroup.com>	<200708291	74	509.GR4183@phlogiston.dyndns.org>	<46D5B216.2010708@orange-ftgroup.com>		<20	070829180550.GT4183@phlogiston.dyndns.org>	<46D5BD84.8090302@orange-ftg	roup.com>	<46D7D4AE.6000600@orange-ftgroup.com>
	<46D7FE31.3080308@Yahoo.com>	<46D820F7.7070904@orange-ftgroup.com>
	<46D84297.8010204@Yahoo.com> <46DAF682.5030902@orange-ftgroup.com>
Message-ID: <46DAF735.7010000@orange-ftgroup.com>



Cyril SCETBON wrote:
>
>
> Jan Wieck wrote:
>> On 8/31/2007 10:08 AM, Cyril SCETBON wrote:
>>>
>>> Jan Wieck wrote:
>>>> On 8/31/2007 4:43 AM, Cyril SCETBON wrote:
>>>>>
>>>>> Cyril SCETBON wrote:
>>>>>>
>>>>>>
>>>>>> Andrew Sullivan wrote:
>>>>>>> On Wed, Aug 29, 2007 at 07:51:18PM +0200, Cyril SCETBON wrote:
>>>>>>>  
>>>>>>>> So, How can I do if M2 is lost ? Cause I don't want S2 to 
>>>>>>>> resync with M1 from scratch
>>>>>>>>     
>>>>>>>
>>>>>>> You can't.  If you can't co-ordinate a switchover, then you lose 
>>>>>>> the
>>>>>>> node.  This is discussed at length in the manual.
>>>>>>>   
>>>>>> Really ????
>>>>>> Are you really saying that losing M2 make me lose S2 ?????
>>>>>> If it's true I'm really disappointed by slony :-(
>>>>>>
>>>>>> My config is as follows (just to remember) :
>>>>>>
>>>>>> psql db1 -c 'select * from "_CLUSTER1".sl_subscribe'
>>>>>> sub_set | sub_provider | sub_receiver | sub_forward | sub_active
>>>>>> ---------+--------------+--------------+-------------+------------
>>>>>>      1 |            1 (M1)|            3 (M2)| t           | t
>>>>>>      1 |            1 (M1)|            2 (S1) | t           | t
>>>>>>      1 |            3 (M2)|            4 (S2) | t           | t
>>>>
>>>> Since all nodes in your scenario are forwarders, you won't lose 
>>>> anything other than the failed node ever. In your configuration if 
>>>> you lose node M2 (which is a subscriber), simply issuing a new 
>>>> SUBSCRIBE SET for node S2 to use M1 or S1 as data provider will do. 
>>>> It will catch up from there without the need to sync from scratch.
>>> I tried reshaping subscription. The subscription works. But no more 
>>> updates go to S2.
>>
>> Check the sl_path configuration. S2 might not have the necessary (or 
>> correct) information to connect to its new data provider.
> I don't think so, cause I wasn't able to reshape subscription to the 
> new provider until I added store path between both nodes. I'll try to 
> get log files to check and let you know what happens.
Do you think I have to upgrade to last version before doing these tests 
again ?
>
> thanks.
>>
>>
>> Jan
>>
>

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From trinaths at intoto.com  Sun Sep  2 21:11:21 2007
From: trinaths at intoto.com (Trinath Somanchi)
Date: Sun Sep  2 21:11:59 2007
Subject: [Slony1-general] Which is Version of slony-I to use ??
In-Reply-To: <60bqcnztzi.fsf@dba2.int.libertyrms.com>
References: <46D7B436.90502@intoto.com>	<d7df81620708310008n399f44e6y637c92cd2f6cfa2b@mail.gmail.com>	<46D7CBE7.4030506@intoto.com>
	<46D7FBA6.6060108@Yahoo.com>	<46D8050C.80905@intoto.com>
	<60bqcnztzi.fsf@dba2.int.libertyrms.com>
Message-ID: <46DB8969.3060807@intoto.com>

An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070903/17d054fd/attachment.htm
-------------- next part --------------
A non-text attachment was scrubbed...
Name: trinaths.vcf
Type: text/x-vcard
Size: 316 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20070903/17d054fd/trinaths.vcf
From drees76 at gmail.com  Mon Sep  3 00:27:49 2007
From: drees76 at gmail.com (David Rees)
Date: Mon Sep  3 00:28:06 2007
Subject: [Slony1-general] Which is Version of slony-I to use ??
In-Reply-To: <46DB8969.3060807@intoto.com>
References: <46D7B436.90502@intoto.com>
	<d7df81620708310008n399f44e6y637c92cd2f6cfa2b@mail.gmail.com>
	<46D7CBE7.4030506@intoto.com> <46D7FBA6.6060108@Yahoo.com>
	<46D8050C.80905@intoto.com> <60bqcnztzi.fsf@dba2.int.libertyrms.com>
	<46DB8969.3060807@intoto.com>
Message-ID: <72dbd3150709030027h5ed8a61foa3d34ac44c8b291b@mail.gmail.com>

On 9/2/07, Trinath Somanchi <trinaths@intoto.com> wrote:
>  I will be more clear this time , I just wanted to know ,  " Which of
> version is more stable ( less prone to failures crashes etc. ) and is
> suitable for a production environment. "

The latest, 1.2.11.

-Dave
From trinaths at intoto.com  Mon Sep  3 00:30:27 2007
From: trinaths at intoto.com (Trinath Somanchi)
Date: Mon Sep  3 00:30:50 2007
Subject: [Slony1-general] Which is Version of slony-I to use ??
In-Reply-To: <72dbd3150709030027h5ed8a61foa3d34ac44c8b291b@mail.gmail.com>
References: <46D7B436.90502@intoto.com>	
	<d7df81620708310008n399f44e6y637c92cd2f6cfa2b@mail.gmail.com>	
	<46D7CBE7.4030506@intoto.com> <46D7FBA6.6060108@Yahoo.com>	
	<46D8050C.80905@intoto.com>
	<60bqcnztzi.fsf@dba2.int.libertyrms.com>	
	<46DB8969.3060807@intoto.com>
	<72dbd3150709030027h5ed8a61foa3d34ac44c8b291b@mail.gmail.com>
Message-ID: <46DBB813.70400@intoto.com>

Skipped content of type multipart/related-------------- next part --------------
A non-text attachment was scrubbed...
Name: trinaths.vcf
Type: text/x-vcard
Size: 316 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20070903/1c287bf2/trinaths-0001.vcf
From drees76 at gmail.com  Mon Sep  3 00:50:51 2007
From: drees76 at gmail.com (David Rees)
Date: Mon Sep  3 00:51:09 2007
Subject: [Slony1-general] Which is Version of slony-I to use ??
In-Reply-To: <46DBB813.70400@intoto.com>
References: <46D7B436.90502@intoto.com>
	<d7df81620708310008n399f44e6y637c92cd2f6cfa2b@mail.gmail.com>
	<46D7CBE7.4030506@intoto.com> <46D7FBA6.6060108@Yahoo.com>
	<46D8050C.80905@intoto.com> <60bqcnztzi.fsf@dba2.int.libertyrms.com>
	<46DB8969.3060807@intoto.com>
	<72dbd3150709030027h5ed8a61foa3d34ac44c8b291b@mail.gmail.com>
	<46DBB813.70400@intoto.com>
Message-ID: <72dbd3150709030050t2db55ecbt5f4e1e83279b0108@mail.gmail.com>

On 9/3/07, Trinath Somanchi <trinaths@intoto.com> wrote:
>  David Rees wrote:
>>  On 9/2/07, Trinath Somanchi <trinaths@intoto.com> wrote:
>>> I will be more clear this time , I just wanted to know ,  " Which of
>>> version is more stable ( less prone to failures crashes etc. ) and is
>>> suitable for a production environment. "
>>
>> The latest, 1.2.11.
>
>  I want want to know  " Which of version is more stable ( less prone to failures crashes
> etc. ) and is suitable for a production environment."  not the latest release version

The latest, 1.2.11.

-Dave
From cscetbon.ext at orange-ftgroup.com  Mon Sep  3 01:49:18 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Mon Sep  3 01:49:39 2007
Subject: [Slony1-general] Configuration on 2 sites
In-Reply-To: <46D84297.8010204@Yahoo.com>
References: <46D3EF28.40108@orange-ftgroup.com>	<20070828132235.GA461@phlogi		ston.dyndns.org>	<46D43DAF.5010604@orange-ftgroup.com>	<20070828152919.GB9	7	9@phlogiston.dyndns.org>	<46D539A4.9020601@orange-ftgroup.com>	<200708291	74	509.GR4183@phlogiston.dyndns.org>	<46D5B216.2010708@orange-ftgroup.com>		<20	070829180550.GT4183@phlogiston.dyndns.org>	<46D5BD84.8090302@orange-ftg	roup.com>
	<46D7D4AE.6000600@orange-ftgroup.com> <46D7FE31.3080308@Yahoo.com>
	<46D820F7.7070904@orange-ftgroup.com> <46D84297.8010204@Yahoo.com>
Message-ID: <46DBCA8E.2060507@orange-ftgroup.com>



Jan Wieck wrote:
> On 8/31/2007 10:08 AM, Cyril SCETBON wrote:
>>
>> Jan Wieck wrote:
>>> On 8/31/2007 4:43 AM, Cyril SCETBON wrote:
>>>>
>>>> Cyril SCETBON wrote:
>>>>>
>>>>>
>>>>> Andrew Sullivan wrote:
>>>>>> On Wed, Aug 29, 2007 at 07:51:18PM +0200, Cyril SCETBON wrote:
>>>>>>  
>>>>>>> So, How can I do if M2 is lost ? Cause I don't want S2 to resync 
>>>>>>> with M1 from scratch
>>>>>>>     
>>>>>>
>>>>>> You can't.  If you can't co-ordinate a switchover, then you lose the
>>>>>> node.  This is discussed at length in the manual.
>>>>>>   
>>>>> Really ????
>>>>> Are you really saying that losing M2 make me lose S2 ?????
>>>>> If it's true I'm really disappointed by slony :-(
>>>>>
>>>>> My config is as follows (just to remember) :
>>>>>
>>>>> psql db1 -c 'select * from "_CLUSTER1".sl_subscribe'
>>>>> sub_set | sub_provider | sub_receiver | sub_forward | sub_active
>>>>> ---------+--------------+--------------+-------------+------------
>>>>>      1 |            1 (M1)|            3 (M2)| t           | t
>>>>>      1 |            1 (M1)|            2 (S1) | t           | t
>>>>>      1 |            3 (M2)|            4 (S2) | t           | t
>>>
>>> Since all nodes in your scenario are forwarders, you won't lose 
>>> anything other than the failed node ever. In your configuration if 
>>> you lose node M2 (which is a subscriber), simply issuing a new 
>>> SUBSCRIBE SET for node S2 to use M1 or S1 as data provider will do. 
>>> It will catch up from there without the need to sync from scratch.
>> I tried reshaping subscription. The subscription works. But no more 
>> updates go to S2.
>
> Check the sl_path configuration. S2 might not have the necessary (or 
> correct) information to connect to its new data provider.
The problem is that S2 does not know that it must now connect to a new 
provider :

On node S2 I have the following subscribe information :

 sub_set | sub_provider | sub_receiver | sub_forward | sub_active
---------+--------------+--------------+-------------+------------
       1 |            1 |            2 | t           | t
       1 |            1 |            3 | t           | t
       1 |            3 |            4 | t           | t

But, on other nodes I have :

 sub_set | sub_provider | sub_receiver | sub_forward | sub_active
---------+--------------+--------------+-------------+------------
       1 |            1 |            2 | t           | t
       1 |            1 |            4 | t           | t

I've used SUBSCRIBE SET (ID=1,PROVIDER=1,RECEIVER=4,FORWARD=YES); to 
reshape subscription from node 4 to node 1.

Since node 3 was lost, node 4 does not know that it has to change 
subscription even if I instruct slonik to make this change and that the 
script has the correct node informations and path on node 4 :

         2 |         1 | dbname=db2 host=xx user=postgres port=5432 
|           10
         1 |         2 | dbname=db1 host=yy user=postgres port=5432 
|           10
         3 |         4 | dbname=db3 host=zz user=postgres port=5432 
|           10
         1 |         3 | dbname=db1 host=yy user=postgres port=5432 
|           10
         4 |         3 | dbname=db4 host=ww user=postgres port=5432 
|           10
         3 |         1 | dbname=db3 host=zz user=postgres port=5432 
|           10
         1 |         4 | dbname=db1 host=yy user=postgres port=5432 
|           10
         4 |         1 | dbname=db4 host=ww user=postgres port=5432 
|           10

This time, I've added path between node 4 and node 1 before dropping 
node 3, but node 4 continues to connect to node 3 and get the following 
error  slon_connectdb: PQconnectdb("dbname=db3 host=zz user=postgres 
port=5432") failed - FATAL:  database "db3" does not exist.

Why it did not delete entry for node 3 on node 4 ???

any idea ?

>
>
> Jan
>

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From cbbrowne at ca.afilias.info  Mon Sep  3 09:35:02 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Sep  3 09:35:10 2007
Subject: [Slony1-general] Which is Version of slony-I to use ??
In-Reply-To: <46DBB813.70400@intoto.com> (Trinath Somanchi's message of "Mon,
	03 Sep 2007 13:00:27 +0530")
References: <46D7B436.90502@intoto.com>
	<d7df81620708310008n399f44e6y637c92cd2f6cfa2b@mail.gmail.com>
	<46D7CBE7.4030506@intoto.com> <46D7FBA6.6060108@Yahoo.com>
	<46D8050C.80905@intoto.com> <60bqcnztzi.fsf@dba2.int.libertyrms.com>
	<46DB8969.3060807@intoto.com>
	<72dbd3150709030027h5ed8a61foa3d34ac44c8b291b@mail.gmail.com>
	<46DBB813.70400@intoto.com>
Message-ID: <60d4wzyafd.fsf@dba2.int.libertyrms.com>

Trinath Somanchi <trinaths@intoto.com> writes:
> I want want to know? " Which of version is more stable ( less prone
> to failures crashes etc. ) and is suitable for a production
> environment."? not the latest release version

The latest release *is* expected to be the most stable, and to be the
most suitable for a production environment.

To my mind, there are only two plausible choices to consider
"production releases," and they are:

a) Version 1.1.9, the most-fixed version in the 1.1 branch, and
b) Version 1.2.11, the most-fixed version in the 1.2 branch.

Those are the only logical possibilities, as if you review release
notes, you'll see that versions 1.1.0 thru 1.1.8 have problems
addressed in 1.1.9, and likewise, 1.2.0 thru 1.2.10 are less
satisfactory than 1.2.11.

Version 1.2 is the version currently being maintained; we stopped
fixing 1.1 a while ago.  THAT suggests that you should prefer
something in the 1.2 branch to something in the 1.1 branch.

And that, therefore points to David Rees being absolutely correct when
he pointed to 1.2.11 as being the recommended version.

If you won't listen, there seems little value in making suggestions.
-- 
let name="cbbrowne" and tld="acm.org" in String.concat "@" [name;tld];;
http://linuxfinances.info/info/
Faith  is the  quality that  enables you  to eat  blackberry jam  on a
picnic without looking to see whether the seeds move. -- DeMara Cabrera
From masonhale at gmail.com  Mon Sep  3 11:19:43 2007
From: masonhale at gmail.com (Mason Hale)
Date: Mon Sep  3 11:19:51 2007
Subject: [Slony1-general] Replication + partitioned table question
Message-ID: <8bca3aa10709031119j1d50722g87b34ef33f791b7a@mail.gmail.com>

Hello everyone --

I'm planning to use Slony divide work across two postgres servers.

Our environment is such that there are two mostly separate pieces,
each updated by a separate application. The data that is updated by
the first application is only read by the second application and data
updated by the second application is only read by the first
application.

Slony looks like a good solution to our needs, as we can replicate one
set of tables in each direction between a first and second database
server.

We're running 8.2.4 and our db is ~150GB in size (and growing fast).

We are using the table partitioning features of Postgres to break up
our larger tables and keep indexes in RAM.

My questions are:

- In slony, when replicating inherited/partitioned tables, do you
replicate each child table individually? Or can you add the slony
triggers to the parent table? (Because some of these tables are
partitioned based on a creation date, we end up adding new tables
frequently).

- Is it possible to replicate from a partitioned table to a
non-partitioned table?

- Is it possible to replicate from a partitioned table to table that
is partitioned differently?

The access patterns of our two applications are quite different. One
application would benefit partitioning based primary key, while the
other would be better off partitioning the same table based on
creation date of the row. Granted there is high correlation between
the primary key and creation date, but the actual queries use one or
the other.

So would it be possible to create a table in the first database
partitioned by serial primary key, and replicate that table (and its
child tables) to a second database where the same table is partitioned
based on creation date?

thanks in advance,
Mason
From cbbrowne at ca.afilias.info  Mon Sep  3 12:23:16 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Sep  3 12:23:32 2007
Subject: [Slony1-general] Replication + partitioned table question
In-Reply-To: <8bca3aa10709031119j1d50722g87b34ef33f791b7a@mail.gmail.com>
	(Mason Hale's message of "Mon, 3 Sep 2007 13:19:43 -0500")
References: <8bca3aa10709031119j1d50722g87b34ef33f791b7a@mail.gmail.com>
Message-ID: <608x7ny2mz.fsf@dba2.int.libertyrms.com>

"Mason Hale" <masonhale@gmail.com> writes:
> Hello everyone --
>
> I'm planning to use Slony divide work across two postgres servers.
>
> Our environment is such that there are two mostly separate pieces,
> each updated by a separate application. The data that is updated by
> the first application is only read by the second application and data
> updated by the second application is only read by the first
> application.
>
> Slony looks like a good solution to our needs, as we can replicate one
> set of tables in each direction between a first and second database
> server.
>
> We're running 8.2.4 and our db is ~150GB in size (and growing fast).
>
> We are using the table partitioning features of Postgres to break up
> our larger tables and keep indexes in RAM.
>
> My questions are:
>
> - In slony, when replicating inherited/partitioned tables, do you
> replicate each child table individually? Or can you add the slony
> triggers to the parent table? (Because some of these tables are
> partitioned based on a creation date, we end up adding new tables
> frequently).

You replicate each child table individually.

Note that there is an example in the tests under
slony1-engine/tests/testinherit.

> - Is it possible to replicate from a partitioned table to a
> non-partitioned table?

At present there is no ability to rename what table data goes into, so
I think the practical answer to that is "no."

Note that Slony-I isn't really aware of partitioning; it's just aware
of what tables you ask it to replicate.

> - Is it possible to replicate from a partitioned table to table that
> is partitioned differently?

Perhaps, but...

As mentioned above, Slony-I isn't really aware of partitioning, so you
could have a different partitioning scheme from origin to subscriber.
But Slony-I would copy data around based on the partitioning scheme on
the origin.  Data would not shift around based on the subscriber's
configuration.

> So would it be possible to create a table in the first database
> partitioned by serial primary key, and replicate that table (and its
> child tables) to a second database where the same table is partitioned
> based on creation date?

I don't think so, at this point in time.  Not beyond possibility; some
(not yet documented) log shipping work is oriented to something
somewhat like this...
-- 
"cbbrowne","@","acm.org"
http://linuxdatabases.info/info/advocacy.html
"When a float occurs  on the same page  as the start of a supertabular
you can expect unexpected results." -- Documentation of supertabular.sty
From cscetbon.ext at orange-ftgroup.com  Mon Sep  3 12:57:25 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Mon Sep  3 12:57:46 2007
Subject: [Slony1-general] Configuration on 2 sites
In-Reply-To: <46DBCA8E.2060507@orange-ftgroup.com>
References: <46D3EF28.40108@orange-ftgroup.com>	<20070828132235.GA461@phlogi		ston.dyndns.org>	<46D43DAF.5010604@orange-ftgroup.com>	<20070828152919.GB9	7	9@phlogiston.dyndns.org>	<46D539A4.9020601@orange-ftgroup.com>	<200708291	74	509.GR4183@phlogiston.dyndns.org>	<46D5B216.2010708@orange-ftgroup.com>		<20	070829180550.GT4183@phlogiston.dyndns.org>	<46D5BD84.8090302@orange-ftg	roup.com>	<46D7D4AE.6000600@orange-ftgroup.com>
	<46D7FE31.3080308@Yahoo.com>	<46D820F7.7070904@orange-ftgroup.com>
	<46D84297.8010204@Yahoo.com> <46DBCA8E.2060507@orange-ftgroup.com>
Message-ID: <46DC6725.20903@orange-ftgroup.com>



Cyril SCETBON wrote:
>
>
> Jan Wieck wrote:
>> On 8/31/2007 10:08 AM, Cyril SCETBON wrote:
>>>
>>> Jan Wieck wrote:
>>>> On 8/31/2007 4:43 AM, Cyril SCETBON wrote:
>>>>>
>>>>> Cyril SCETBON wrote:
>>>>>>
>>>>>>
>>>>>> Andrew Sullivan wrote:
>>>>>>> On Wed, Aug 29, 2007 at 07:51:18PM +0200, Cyril SCETBON wrote:
>>>>>>>  
>>>>>>>> So, How can I do if M2 is lost ? Cause I don't want S2 to 
>>>>>>>> resync with M1 from scratch
>>>>>>>>     
>>>>>>>
>>>>>>> You can't.  If you can't co-ordinate a switchover, then you lose 
>>>>>>> the
>>>>>>> node.  This is discussed at length in the manual.
>>>>>>>   
>>>>>> Really ????
>>>>>> Are you really saying that losing M2 make me lose S2 ?????
>>>>>> If it's true I'm really disappointed by slony :-(
>>>>>>
>>>>>> My config is as follows (just to remember) :
>>>>>>
>>>>>> psql db1 -c 'select * from "_CLUSTER1".sl_subscribe'
>>>>>> sub_set | sub_provider | sub_receiver | sub_forward | sub_active
>>>>>> ---------+--------------+--------------+-------------+------------
>>>>>>      1 |            1 (M1)|            3 (M2)| t           | t
>>>>>>      1 |            1 (M1)|            2 (S1) | t           | t
>>>>>>      1 |            3 (M2)|            4 (S2) | t           | t
>>>>
>>>> Since all nodes in your scenario are forwarders, you won't lose 
>>>> anything other than the failed node ever. In your configuration if 
>>>> you lose node M2 (which is a subscriber), simply issuing a new 
>>>> SUBSCRIBE SET for node S2 to use M1 or S1 as data provider will do. 
>>>> It will catch up from there without the need to sync from scratch.
>>> I tried reshaping subscription. The subscription works. But no more 
>>> updates go to S2.
>>
>> Check the sl_path configuration. S2 might not have the necessary (or 
>> correct) information to connect to its new data provider.
> The problem is that S2 does not know that it must now connect to a new 
> provider :
>
> On node S2 I have the following subscribe information :
>
> sub_set | sub_provider | sub_receiver | sub_forward | sub_active
> ---------+--------------+--------------+-------------+------------
>       1 |            1 |            2 | t           | t
>       1 |            1 |            3 | t           | t
>       1 |            3 |            4 | t           | t
why node 4 wasn't updated ? weird , no ?
>
> But, on other nodes I have :
>
> sub_set | sub_provider | sub_receiver | sub_forward | sub_active
> ---------+--------------+--------------+-------------+------------
>       1 |            1 |            2 | t           | t
>       1 |            1 |            4 | t           | t
>
> I've used SUBSCRIBE SET (ID=1,PROVIDER=1,RECEIVER=4,FORWARD=YES); to 
> reshape subscription from node 4 to node 1.
>
> Since node 3 was lost, node 4 does not know that it has to change 
> subscription even if I instruct slonik to make this change and that 
> the script has the correct node informations and path on node 4 :
>
>         2 |         1 | dbname=db2 host=xx user=postgres port=5432 
> |           10
>         1 |         2 | dbname=db1 host=yy user=postgres port=5432 
> |           10
>         3 |         4 | dbname=db3 host=zz user=postgres port=5432 
> |           10
>         1 |         3 | dbname=db1 host=yy user=postgres port=5432 
> |           10
>         4 |         3 | dbname=db4 host=ww user=postgres port=5432 
> |           10
>         3 |         1 | dbname=db3 host=zz user=postgres port=5432 
> |           10
>         1 |         4 | dbname=db1 host=yy user=postgres port=5432 
> |           10
>         4 |         1 | dbname=db4 host=ww user=postgres port=5432 
> |           10
>
> This time, I've added path between node 4 and node 1 before dropping 
> node 3, but node 4 continues to connect to node 3 and get the 
> following error  slon_connectdb: PQconnectdb("dbname=db3 host=zz 
> user=postgres port=5432") failed - FATAL:  database "db3" does not exist.
>
> Why it did not delete entry for node 3 on node 4 ???
>
> any idea ?
>
>>
>>
>> Jan
>>
>

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From JanWieck at Yahoo.com  Mon Sep  3 14:58:52 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Mon Sep  3 14:59:12 2007
Subject: [Slony1-general] Which is Version of slony-I to use ??
In-Reply-To: <46DBB813.70400@intoto.com>
References: <46D7B436.90502@intoto.com>		<d7df81620708310008n399f44e6y637c92cd2f6cfa2b@mail.gmail.com>		<46D7CBE7.4030506@intoto.com>
	<46D7FBA6.6060108@Yahoo.com>		<46D8050C.80905@intoto.com>	<60bqcnztzi.fsf@dba2.int.libertyrms.com>		<46DB8969.3060807@intoto.com>	<72dbd3150709030027h5ed8a61foa3d34ac44c8b291b@mail.gmail.com>
	<46DBB813.70400@intoto.com>
Message-ID: <46DC839C.4050601@Yahoo.com>

On 9/3/2007 3:30 AM, Trinath Somanchi wrote:
> I want want to know * " Which of version is more stable ( less prone to 
> failures crashes etc. ) and is suitable for a production environment."  
> not the latest release version*

Why do you repeat this question in enlarged, bold font, quoting the 
proper and absolutely fine answer to it?


Jan

> 
> David Rees wrote:
>> On 9/2/07, Trinath Somanchi <trinaths@intoto.com> wrote:
>>   
>>>  I will be more clear this time , I just wanted to know ,  " Which of
>>> version is more stable ( less prone to failures crashes etc. ) and is
>>> suitable for a production environment. "
>>>     
>>
>> The latest, 1.2.11.
>>
>> -Dave
>>
>>   
> 
> -- 
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From cscetbon.ext at orange-ftgroup.com  Tue Sep  4 01:58:43 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Tue Sep  4 01:59:07 2007
Subject: [Slony1-general] Configuration on 2 sites
In-Reply-To: <20070828161837.GA1194@phlogiston.dyndns.org>
References: <46D3EF28.40108@orange-ftgroup.com>
	<20070828132235.GA461@phlogiston.dyndns.org>
	<46D43DAF.5010604@orange-ftgroup.com>
	<20070828152919.GB979@phlogiston.dyndns.org>
	<46D4418C.6090802@orange-ftgroup.com>
	<20070828161837.GA1194@phlogiston.dyndns.org>
Message-ID: <46DD1E43.4020300@orange-ftgroup.com>



Andrew Sullivan wrote:
> On Tue, Aug 28, 2007 at 05:38:52PM +0200, Cyril SCETBON wrote:
>   
>>>  
>>>       
>> Do I have to add path between Origin M1 and S2 too ?
>>     
>
> I think so, but it may depend on what version you have.  I'd test it
> out.  These procedures are ones you want to have well-baked in case
> of disaster.
>
>   
I've read "Slony-I - A replication system for PostgreSQL" -  
http://developer.postgresql.org/~wieck/slony1/Slony-I-concept.pdf - 
written by Jan Wieck, and effectively, it says in section 2.1 that Node 
C must continues replicating Set 1 from Node A although it was 
replicating Set 1 from Node B which has been lost. That's exactly the 
disaster case I'm studying.

Regards
> A
>
>   

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From JanWieck at Yahoo.com  Tue Sep  4 05:38:47 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Tue Sep  4 05:39:01 2007
Subject: [Slony1-general] Replication + partitioned table question
In-Reply-To: <8bca3aa10709031119j1d50722g87b34ef33f791b7a@mail.gmail.com>
References: <8bca3aa10709031119j1d50722g87b34ef33f791b7a@mail.gmail.com>
Message-ID: <46DD51D7.1020207@Yahoo.com>

On 9/3/2007 2:19 PM, Mason Hale wrote:
> Hello everyone --
> 
> I'm planning to use Slony divide work across two postgres servers.
> 
> Our environment is such that there are two mostly separate pieces,
> each updated by a separate application. The data that is updated by
> the first application is only read by the second application and data
> updated by the second application is only read by the first
> application.
> 
> Slony looks like a good solution to our needs, as we can replicate one
> set of tables in each direction between a first and second database
> server.
> 
> We're running 8.2.4 and our db is ~150GB in size (and growing fast).
> 
> We are using the table partitioning features of Postgres to break up
> our larger tables and keep indexes in RAM.
> 
> My questions are:
> 
> - In slony, when replicating inherited/partitioned tables, do you
> replicate each child table individually? Or can you add the slony
> triggers to the parent table? (Because some of these tables are
> partitioned based on a creation date, we end up adding new tables
> frequently).

Which tuple or update hits which table is decided by Postgres in layers 
that are far above the trigger mechanism Slony uses to record the 
changes. And those triggers have absolutely no information about how 
that operation got there, so it is impossible to replay the entire 
decision process on the replica. For example, an insert into a child 
table could have been redirected to it because a trigger or rule on the 
parent table did so, or the application might have inserted directly 
into the child ... how to tell the difference from inside a trigger?

With that background information, you will have to replicate each child 
table and the parent too (in case you don't have a default rule and rows 
can possibly end up in it).

> 
> - Is it possible to replicate from a partitioned table to a
> non-partitioned table?

No. The table structure of a slony replica is 1:1 identical to that of 
the origin.

> 
> - Is it possible to replicate from a partitioned table to table that
> is partitioned differently?

Same as above.

> 
> The access patterns of our two applications are quite different. One
> application would benefit partitioning based primary key, while the
> other would be better off partitioning the same table based on
> creation date of the row. Granted there is high correlation between
> the primary key and creation date, but the actual queries use one or
> the other.
> 
> So would it be possible to create a table in the first database
> partitioned by serial primary key, and replicate that table (and its
> child tables) to a second database where the same table is partitioned
> based on creation date?

Same as third question.


Sorry
Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From andrew.george.hammond at gmail.com  Tue Sep  4 10:51:04 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Tue Sep  4 10:51:13 2007
Subject: [Slony1-general] Re: Bug in slonik SQL parser: comments are not
	removed properly
In-Reply-To: <46D7886F.5040902@Yahoo.com>
References: <d7df81620708290821p38284405uc095f811740132c8@mail.gmail.com>
	<d7df81620708291152s6d1ce8aaqe87c04be8a462af4@mail.gmail.com>
	<46D6E9D9.2040306@Yahoo.com> <46D6EDD0.5080305@ca.afilias.info>
	<d7df81620708301049h614000fau9b560595289074cf@mail.gmail.com>
	<20070830184639.GO7661@phlogiston.dyndns.org>
	<46D75CAD.9070502@Yahoo.com>
	<20070831023443.GA11181@phlogiston.dyndns.org>
	<46D7886F.5040902@Yahoo.com>
Message-ID: <5a0a9d6f0709041051u7a3ed392ia81be2ec00065b25@mail.gmail.com>

On 8/30/07, Jan Wieck <JanWieck@yahoo.com> wrote:
>
> On 8/30/2007 10:34 PM, Andrew Sullivan wrote:
> > On Thu, Aug 30, 2007 at 08:11:25PM -0400, Jan Wieck wrote:
> >> You forget that Slony is also supposed to replicate across different
> >> Postgres versions. So what are we going to do if DDL with multiple
> >> nesting layers of different comment styles is supported by one, but not
> >> all Postgres versions inside of a Slony cluster? Somehow convert it to
> >> something that is understood by all?
> >
> > No, we're supposed to support the least common denominator.  If there
> > isn't one, then I agree tha the user loses.  This is more or less the
> > pg_dump strategy: use the latest, or die.
>
> Which means we'd have to somehow extract the Postgres backend or psql
> parser in order to do so. Without that I don't know how to keep the two
> 100 percent in sync.
>

This seems to be the right direction to go in. An ideal solution would be a
generalized parser that worked for the backend, psql (including tab
completion), slony and other applications. I don't have any clever ideas on
how to do that though.

Andrew
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070904/=
ac054a0c/attachment-0001.htm
From andrew.george.hammond at gmail.com  Tue Sep  4 11:27:13 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Tue Sep  4 11:27:21 2007
Subject: [Slony1-general] Which is Version of slony-I to use ??
In-Reply-To: <46DC839C.4050601@Yahoo.com>
References: <46D7B436.90502@intoto.com>
	<d7df81620708310008n399f44e6y637c92cd2f6cfa2b@mail.gmail.com>
	<46D7CBE7.4030506@intoto.com> <46D7FBA6.6060108@Yahoo.com>
	<46D8050C.80905@intoto.com> <60bqcnztzi.fsf@dba2.int.libertyrms.com>
	<46DB8969.3060807@intoto.com>
	<72dbd3150709030027h5ed8a61foa3d34ac44c8b291b@mail.gmail.com>
	<46DBB813.70400@intoto.com> <46DC839C.4050601@Yahoo.com>
Message-ID: <5a0a9d6f0709041127n7912bacx453dfe07b8a3b4fa@mail.gmail.com>

On 9/3/07, Jan Wieck <JanWieck@yahoo.com> wrote:
>
> On 9/3/2007 3:30 AM, Trinath Somanchi wrote:
> > I want want to know * " Which of version is more stable ( less prone to
> > failures crashes etc. ) and is suitable for a production environment."
> > not the latest release version*
>
> Why do you repeat this question in enlarged, bold font, quoting the
> proper and absolutely fine answer to it?


On a related note, the tone of your emails is not appropriate to this
mailing list. If you want to demand answers from people, you need to hire
them and pay them well enough to put up with you. If you want to take
advantage of the community resource that is this mailing list, then you need
to at least be polite to the people you are asking for help.

Andrew


> David Rees wrote:
> >> On 9/2/07, Trinath Somanchi <trinaths@intoto.com> wrote:
> >>
> >>>  I will be more clear this time , I just wanted to know ,  " Which of
> >>> version is more stable ( less prone to failures crashes etc. ) and is
> >>> suitable for a production environment. "
> >>>
> >>
> >> The latest, 1.2.11.
> >>
> >> -Dave
> >>
> >>
> >
> > --
> >
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general@lists.slony.info
> > http://lists.slony.info/mailman/listinfo/slony1-general
>
>
> --
> #=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D#
> # It's easier to get forgiveness for being wrong than for being right. #
> # Let's break this rule - forgive me.                                  #
> #=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D JanWieck@Yahoo.com #
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070904/=
c22efd5c/attachment.htm
From jpfletch at ca.afilias.info  Tue Sep  4 13:34:20 2007
From: jpfletch at ca.afilias.info (JP Fletcher)
Date: Tue Sep  4 13:35:06 2007
Subject: [Slony1-general] missing sl_listen path following SUBSCRIBE SET
Message-ID: <46DDC14C.5030409@ca.afilias.info>

Hi,

I've encountered some unusual behavior in v 1.2.11 (pg819 on AIX),  
though I can't swear that it is unique to this release.

The scenario is as follows:

There are four nodes, 8143, 8142, 8194, and 8141.  Node 8143 is the 
origin for set1.  Node 8142 is directly subscribed to the origin, as is 
8194.  Node 8141 cascades from 8142.  The state of sl_listen, where 8141 
is a receiver, is as follows:


oxrsorg=# SELECT * from _oxrsorg.sl_listen where li_receiver = 8141 
order by li_origin;
 li_origin | li_provider | li_receiver
-----------+-------------+-------------
      8142 |        8143 |        8141
      8142 |        8194 |        8141
      8142 |        8142 |        8141
      8143 |        8142 |        8141
      8194 |        8142 |        8141
      8194 |        8194 |        8141
      8194 |        8143 |        8141
(7 rows)


If I add an additional set, with origin 8143, then subscribe 8141 
directly to it, the listen path between 8143 and 8141 goes away:

include <cluster.preamble>

SUBSCRIBE SET (ID = 2, PROVIDER = 8143, RECEIVER = 8141, FORWARD = YES);

oxrsorg=# SELECT * from _oxrsorg.sl_listen where li_receiver = 8141 
order by li_origin;
 li_origin | li_provider | li_receiver
-----------+-------------+-------------
      8142 |        8142 |        8141
      8142 |        8143 |        8141
      8142 |        8194 |        8141
      8194 |        8143 |        8141
      8194 |        8142 |        8141
      8194 |        8194 |        8141
(6 rows)


If I unsubscribe the set, the listen path returns...

It may or may not be significant that 8141 is also the origin for a 
third set.  Thought i'd mention it.



JP


-- 
JP Fletcher
Database Administrator
Afilias Canada
voice: 416.646.3304 ext. 4123
fax: 416.646.3305
mobile: 416.561.4763
jpfletch@ca.afilias.info


From lists_slony1-general at avsupport.com  Tue Sep  4 18:53:02 2007
From: lists_slony1-general at avsupport.com (Dan Falconer)
Date: Tue Sep  4 18:53:22 2007
Subject: [Slony1-general] SYNCs with no subscribers + log switching problems?
Message-ID: <200709042053.02879.lists_slony1-general@avsupport.com>

	I have a Master -> Slave setup for Slony-I replication.  For reasons I've 
been working out on another thread on this list, I have recently been plagued 
with problems from our slave server being constantly behind.  Every week for 
the past month, I've had to rebuild the cluster on monday or tuesday, after 
our main inventory processing is done, to get that slave server back up to 
speed.

	Today, instead of dropping the schema & going through the painful process of 
initializing the cluster, creating the main set (set #1), then subscribing 
the slave, I've decided just to drop the slave node.  After doing this, I was 
surprised to find that Slony didn't automatically truncate all the data in 
sl_log_1 and sl_log_2 (~30.6 million records)... I truncated the tables by 
hand (it only took about 1 second), and then started the slons back up.

	I was then struck by yet another surprise: Slony seems to like keeping all 
it's log data, even when it's the only running node.  I've noticed there have 
been some cleanup processes, but... well, it seems like part of the problem I 
was running into with the slave server being so desperately far behind has 
something to do with an inability to switch log tables:  Take a look at my 
logs (the "NOTICE" lines always seem to be dumped to the console when I 
restart slons, until I open another console)::::

************************* SNIP *************************

pl=# select NOW() AS timestamp, * from _pl_replication.sl_node; SELECT (select 
NOW()) AS time, (select count(*) FROM _pl_replication.sl_log_1) AS 
count_of_slony_log_1, (select count(*) FROM _pl_replication.sl_log_2) AS 
count_of_slony_log_2;
          timestamp           | no_id | no_active |        
no_comment         | no_spool
------------------------------+-------+-----------+---------------------------+----------
 2007-09-04 14:46:56.86454-05 |     2 | t         | Node 2 - 
pl@192.168.1.201 | f
(1 row)

             time              | count_of_slony_log_1 | count_of_slony_log_2
-------------------------------+----------------------+----------------------
 2007-09-04 14:46:56.865127-05 |                    0 |                25142
(1 row)

pl=# NOTICE:  Slony-I: cleanupEvent(): Single node - deleting events < 73770

pl=# select NOW() AS timestamp, * from _pl_replication.sl_node; SELECT (select 
NOW()) AS time, (select count(*) FROM _pl_replication.sl_log_1) AS 
count_of_slony_log_1, (select count(*) FROM _pl_replication.sl_log_2) AS 
count_of_slony_log_2;
          timestamp          | no_id | no_active |        no_comment         | 
no_spool
-----------------------------+-------+-----------+---------------------------+----------
 2007-09-04 14:52:27.9332-05 |     2 | t         | Node 2 - pl@192.168.1.201 | 
f
(1 row)

             time              | count_of_slony_log_1 | count_of_slony_log_2
-------------------------------+----------------------+----------------------
 2007-09-04 14:52:27.933927-05 |                    0 |                39972
(1 row)

pl=# NOTICE:  Slony-I: log switch to sl_log_2 complete - truncate sl_log_1

pl=# select NOW() AS timestamp, * from _pl_replication.sl_node; SELECT (select 
NOW()) AS time, (select count(*) FROM _pl_replication.sl_log_1) AS 
count_of_slony_log_1, (select count(*) FROM _pl_replication.sl_log_2) AS 
count_of_slony_log_2;
           timestamp           | no_id | no_active |        
no_comment         | no_spool
-------------------------------+-------+-----------+---------------------------+----------
 2007-09-04 14:52:51.148288-05 |     2 | t         | Node 2 - 
pl@192.168.1.201 | f
(1 row)

             time              | count_of_slony_log_1 | count_of_slony_log_2
-------------------------------+----------------------+----------------------
 2007-09-04 14:52:51.149097-05 |                    0 |                40182
(1 row)
************************ /SNIP *************************

-- 
Best Regards,


Dan Falconer
"Head Geek", Avsupport, Inc. / Partslogistics.com
http://www.partslogistics.com
From lists_slony1-general at avsupport.com  Wed Sep  5 08:33:03 2007
From: lists_slony1-general at avsupport.com (Dan Falconer)
Date: Wed Sep  5 08:33:21 2007
Subject: [Slony1-general] SYNCs with no subscribers + log switching
	problems?
In-Reply-To: <200709042053.02879.lists_slony1-general@avsupport.com>
References: <200709042053.02879.lists_slony1-general@avsupport.com>
Message-ID: <200709051033.03650.lists_slony1-general@avsupport.com>

Oh, I forgot to mention the required info:
	* SLONY-I:  1.2.10
	* POSTGRES: 8.0.13

On Tuesday 04 September 2007 20:53, Dan Falconer wrote:
> 	I have a Master -> Slave setup for Slony-I replication.  For reasons I've
> been working out on another thread on this list, I have recently been
> plagued with problems from our slave server being constantly behind.  Every
> week for the past month, I've had to rebuild the cluster on monday or
> tuesday, after our main inventory processing is done, to get that slave
> server back up to speed.
>
> 	Today, instead of dropping the schema & going through the painful process
> of initializing the cluster, creating the main set (set #1), then
> subscribing the slave, I've decided just to drop the slave node.  After
> doing this, I was surprised to find that Slony didn't automatically
> truncate all the data in sl_log_1 and sl_log_2 (~30.6 million records)... I
> truncated the tables by hand (it only took about 1 second), and then
> started the slons back up.
>
> 	I was then struck by yet another surprise: Slony seems to like keeping all
> it's log data, even when it's the only running node.  I've noticed there
> have been some cleanup processes, but... well, it seems like part of the
> problem I was running into with the slave server being so desperately far
> behind has something to do with an inability to switch log tables:  Take a
> look at my logs (the "NOTICE" lines always seem to be dumped to the console
> when I restart slons, until I open another console)::::
>
> ************************* SNIP *************************
>
> pl=# select NOW() AS timestamp, * from _pl_replication.sl_node; SELECT
> (select NOW()) AS time, (select count(*) FROM _pl_replication.sl_log_1) AS
> count_of_slony_log_1, (select count(*) FROM _pl_replication.sl_log_2) AS
> count_of_slony_log_2;
>           timestamp           | no_id | no_active |
> no_comment         | no_spool
> ------------------------------+-------+-----------+------------------------
>---+---------- 2007-09-04 14:46:56.86454-05 |     2 | t         | Node 2 -
> pl@192.168.1.201 | f
> (1 row)
>
>              time              | count_of_slony_log_1 |
> count_of_slony_log_2
> -------------------------------+----------------------+--------------------
>-- 2007-09-04 14:46:56.865127-05 |                    0 |               
> 25142 (1 row)
>
> pl=# NOTICE:  Slony-I: cleanupEvent(): Single node - deleting events <
> 73770
>
> pl=# select NOW() AS timestamp, * from _pl_replication.sl_node; SELECT
> (select NOW()) AS time, (select count(*) FROM _pl_replication.sl_log_1) AS
> count_of_slony_log_1, (select count(*) FROM _pl_replication.sl_log_2) AS
> count_of_slony_log_2;
>           timestamp          | no_id | no_active |        no_comment       
>  | no_spool
> -----------------------------+-------+-----------+-------------------------
>--+---------- 2007-09-04 14:52:27.9332-05 |     2 | t         | Node 2 -
> pl@192.168.1.201 | f
> (1 row)
>
>              time              | count_of_slony_log_1 |
> count_of_slony_log_2
> -------------------------------+----------------------+--------------------
>-- 2007-09-04 14:52:27.933927-05 |                    0 |               
> 39972 (1 row)
>
> pl=# NOTICE:  Slony-I: log switch to sl_log_2 complete - truncate sl_log_1
>
> pl=# select NOW() AS timestamp, * from _pl_replication.sl_node; SELECT
> (select NOW()) AS time, (select count(*) FROM _pl_replication.sl_log_1) AS
> count_of_slony_log_1, (select count(*) FROM _pl_replication.sl_log_2) AS
> count_of_slony_log_2;
>            timestamp           | no_id | no_active |
> no_comment         | no_spool
> -------------------------------+-------+-----------+-----------------------
>----+---------- 2007-09-04 14:52:51.148288-05 |     2 | t         | Node 2 -
> pl@192.168.1.201 | f
> (1 row)
>
>              time              | count_of_slony_log_1 |
> count_of_slony_log_2
> -------------------------------+----------------------+--------------------
>-- 2007-09-04 14:52:51.149097-05 |                    0 |               
> 40182 (1 row)
> ************************ /SNIP *************************

-- 
Best Regards,


Dan Falconer
"Head Geek", Avsupport, Inc. / Partslogistics.com
http://www.partslogistics.com
From cscetbon.ext at orange-ftgroup.com  Wed Sep  5 10:32:30 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Wed Sep  5 10:32:59 2007
Subject: [Slony1-general] Configuration on 2 sites
In-Reply-To: <46DC6725.20903@orange-ftgroup.com>
References: <46D3EF28.40108@orange-ftgroup.com>	<20070828132235.GA461@phlogi		ston.dyndns.org>	<46D43DAF.5010604@orange-ftgroup.com>	<20070828152919.GB9	7	9@phlogiston.dyndns.org>	<46D539A4.9020601@orange-ftgroup.com>	<200708291	74	509.GR4183@phlogiston.dyndns.org>	<46D5B216.2010708@orange-ftgroup.com>		<20	070829180550.GT4183@phlogiston.dyndns.org>	<46D5BD84.8090302@orange-ftg	roup.com>	<46D7D4AE.6000600@orange-ftgroup.com>	<46D7FE31.3080308@Yahoo.com>	<46D820F7.7070904@orange-ftgroup.com>	<46D84297.8010204@Yahoo.com>
	<46DBCA8E.2060507@orange-ftgroup.com>
	<46DC6725.20903@orange-ftgroup.com>
Message-ID: <46DEE82E.60909@orange-ftgroup.com>

Sorry to reply one more time, but I need help :-(
A little precision, these tests have been done on the same host, maybe 
the problem is known ...

Any idea to fix the issue ?

thanks.

Cyril SCETBON wrote:
>
>
> Cyril SCETBON wrote:
>>
>>
>> Jan Wieck wrote:
>>> On 8/31/2007 10:08 AM, Cyril SCETBON wrote:
>>>>
>>>> Jan Wieck wrote:
>>>>> On 8/31/2007 4:43 AM, Cyril SCETBON wrote:
>>>>>>
>>>>>> Cyril SCETBON wrote:
>>>>>>>
>>>>>>>
>>>>>>> Andrew Sullivan wrote:
>>>>>>>> On Wed, Aug 29, 2007 at 07:51:18PM +0200, Cyril SCETBON wrote:
>>>>>>>>  
>>>>>>>>> So, How can I do if M2 is lost ? Cause I don't want S2 to 
>>>>>>>>> resync with M1 from scratch
>>>>>>>>>     
>>>>>>>>
>>>>>>>> You can't.  If you can't co-ordinate a switchover, then you 
>>>>>>>> lose the
>>>>>>>> node.  This is discussed at length in the manual.
>>>>>>>>   
>>>>>>> Really ????
>>>>>>> Are you really saying that losing M2 make me lose S2 ?????
>>>>>>> If it's true I'm really disappointed by slony :-(
>>>>>>>
>>>>>>> My config is as follows (just to remember) :
>>>>>>>
>>>>>>> psql db1 -c 'select * from "_CLUSTER1".sl_subscribe'
>>>>>>> sub_set | sub_provider | sub_receiver | sub_forward | sub_active
>>>>>>> ---------+--------------+--------------+-------------+------------
>>>>>>>      1 |            1 (M1)|            3 (M2)| t           | t
>>>>>>>      1 |            1 (M1)|            2 (S1) | t           | t
>>>>>>>      1 |            3 (M2)|            4 (S2) | t           | t
>>>>>
>>>>> Since all nodes in your scenario are forwarders, you won't lose 
>>>>> anything other than the failed node ever. In your configuration if 
>>>>> you lose node M2 (which is a subscriber), simply issuing a new 
>>>>> SUBSCRIBE SET for node S2 to use M1 or S1 as data provider will 
>>>>> do. It will catch up from there without the need to sync from 
>>>>> scratch.
>>>> I tried reshaping subscription. The subscription works. But no more 
>>>> updates go to S2.
>>>
>>> Check the sl_path configuration. S2 might not have the necessary (or 
>>> correct) information to connect to its new data provider.
>> The problem is that S2 does not know that it must now connect to a 
>> new provider :
>>
>> On node S2 I have the following subscribe information :
>>
>> sub_set | sub_provider | sub_receiver | sub_forward | sub_active
>> ---------+--------------+--------------+-------------+------------
>>       1 |            1 |            2 | t           | t
>>       1 |            1 |            3 | t           | t
>>       1 |            3 |            4 | t           | t
> why node 4 wasn't updated ? weird , no ?
>>
>> But, on other nodes I have :
>>
>> sub_set | sub_provider | sub_receiver | sub_forward | sub_active
>> ---------+--------------+--------------+-------------+------------
>>       1 |            1 |            2 | t           | t
>>       1 |            1 |            4 | t           | t
>>
>> I've used SUBSCRIBE SET (ID=1,PROVIDER=1,RECEIVER=4,FORWARD=YES); to 
>> reshape subscription from node 4 to node 1.
>>
>> Since node 3 was lost, node 4 does not know that it has to change 
>> subscription even if I instruct slonik to make this change and that 
>> the script has the correct node informations and path on node 4 :
>>
>>         2 |         1 | dbname=db2 host=xx user=postgres port=5432 
>> |           10
>>         1 |         2 | dbname=db1 host=yy user=postgres port=5432 
>> |           10
>>         3 |         4 | dbname=db3 host=zz user=postgres port=5432 
>> |           10
>>         1 |         3 | dbname=db1 host=yy user=postgres port=5432 
>> |           10
>>         4 |         3 | dbname=db4 host=ww user=postgres port=5432 
>> |           10
>>         3 |         1 | dbname=db3 host=zz user=postgres port=5432 
>> |           10
>>         1 |         4 | dbname=db1 host=yy user=postgres port=5432 
>> |           10
>>         4 |         1 | dbname=db4 host=ww user=postgres port=5432 
>> |           10
>>
>> This time, I've added path between node 4 and node 1 before dropping 
>> node 3, but node 4 continues to connect to node 3 and get the 
>> following error  slon_connectdb: PQconnectdb("dbname=db3 host=zz 
>> user=postgres port=5432") failed - FATAL:  database "db3" does not 
>> exist.
>>
>> Why it did not delete entry for node 3 on node 4 ???
>>
>> any idea ?
>>
>>>
>>>
>>> Jan
>>>
>>
>

-- 
Cyril SCETBON

From JanWieck at Yahoo.com  Wed Sep  5 19:39:42 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Wed Sep  5 19:40:36 2007
Subject: [Slony1-general] SYNCs with no subscribers + log switching
	problems?
In-Reply-To: <200709042053.02879.lists_slony1-general@avsupport.com>
References: <200709042053.02879.lists_slony1-general@avsupport.com>
Message-ID: <46DF686E.6000106@Yahoo.com>

On 9/4/2007 9:53 PM, Dan Falconer wrote:
> 	I was then struck by yet another surprise: Slony seems to like keeping all 
> it's log data, even when it's the only running node.  I've noticed there have 

The case of having a replication set but no subscribers at all is a 
little pathologic and not optimized for especially.

Slony indeed likes to keep logs. It never vacuumes the sl_log_* tables. 
Instead it periodically switches them and truncates the old when all 
tuples have been deleted out of it. This could even be optimized by not 
even deleting them in the first place but deciding that none of them is 
needed any more. This switching is a process that can take a while if 
you for example have long running transactions. The log trigger only 
decides which log table to write to once per transaction. After the log 
switch is initiated, the system basically waits until all transactions 
that have been in progress during that log switch start have ended and 
then it waits until the log later on is completely empty because all 
known subscribers have replicated everything. There might be a bug in 
that code that actually prevents the delete of old log rows if you don't 
have any subscribers at all.

As said, it is a pathological case that should not happen in a normal 
setup where you have at least one single subscriber.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From vivek at khera.org  Thu Sep  6 08:07:02 2007
From: vivek at khera.org (Vivek Khera)
Date: Thu Sep  6 08:07:11 2007
Subject: [Slony1-general] SYNCs with no subscribers + log switching
	problems?
In-Reply-To: <46DF686E.6000106@Yahoo.com>
References: <200709042053.02879.lists_slony1-general@avsupport.com>
	<46DF686E.6000106@Yahoo.com>
Message-ID: <471E0231-AA46-4FBD-AFCA-BF717B368299@khera.org>


On Sep 5, 2007, at 10:39 PM, Jan Wieck wrote:

> On 9/4/2007 9:53 PM, Dan Falconer wrote:
>> 	I was then struck by yet another surprise: Slony seems to like  
>> keeping all it's log data, even when it's the only running node.   
>> I've noticed there have
>
> The case of having a replication set but no subscribers at all is a  
> little pathologic and not optimized for especially.

I ran into this in a 2-node setup when the replica failed and had to  
have hardware replaced. The only way out was to uninstall slony from  
the origin server, and then re-configure everything from scratch.

I recall either Chris or Jan saying roughly the same thing about it  
not being a tested normal operation case at that time, too :-)

From cbbrowne at ca.afilias.info  Thu Sep  6 08:41:12 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Sep  6 08:41:26 2007
Subject: [Slony1-general] SYNCs with no subscribers + log switching
	problems?
In-Reply-To: <471E0231-AA46-4FBD-AFCA-BF717B368299@khera.org> (Vivek Khera's
	message of "Thu, 6 Sep 2007 11:07:02 -0400")
References: <200709042053.02879.lists_slony1-general@avsupport.com>
	<46DF686E.6000106@Yahoo.com>
	<471E0231-AA46-4FBD-AFCA-BF717B368299@khera.org>
Message-ID: <601wdbx0mf.fsf@dba2.int.libertyrms.com>

Vivek Khera <vivek@khera.org> writes:
> On Sep 5, 2007, at 10:39 PM, Jan Wieck wrote:
>
>> On 9/4/2007 9:53 PM, Dan Falconer wrote:
>>> 	I was then struck by yet another surprise: Slony seems to like
>>> keeping all it's log data, even when it's the only running node.
>>> I've noticed there have
>>
>> The case of having a replication set but no subscribers at all is a
>> little pathologic and not optimized for especially.
>
> I ran into this in a 2-node setup when the replica failed and had to
> have hardware replaced. The only way out was to uninstall slony from
> the origin server, and then re-configure everything from scratch.
>
> I recall either Chris or Jan saying roughly the same thing about it
> not being a tested normal operation case at that time, too :-)

There was code changed for this a while back, so I think this is
likely a version-dependent issue.

This went into src/base/slony1_funcs.sql, in version 1.82, which was
committed 2006-03-28, in HEAD.  This should therefore be in the 1.2
branch.

It won't be in the 1.1 branch...
-- 
let name="cbbrowne" and tld="linuxfinances.info" in name ^ "@" ^ tld;;
http://linuxdatabases.info/info/sap.html
Signs of a Klingon Programmer - 12. "You question the worthiness of my
code? I should kill you where you stand!"
From dba at richyen.com  Thu Sep  6 08:51:36 2007
From: dba at richyen.com (Richard Yen)
Date: Thu Sep  6 08:51:49 2007
Subject: [Slony1-general] failover doesn't remove triggers
Message-ID: <EFF62083-4F1E-450C-A7E9-CF65A840D525@richyen.com>

Hi all,

I had to execute a FAIL OVER command last night, and I looks like the  
command might be buggy?

After executing the command, the subscribe table on the new master  
(node 2) had two rows, one signifying that it was the provider for  
node 3, the other had a blank provider column and had node 2 in the  
subscriber column.  I'm supposing this is expected behavior?

What really concerned me was that on the new master, the denyaccess  
triggers were still there, so my entire cluster was essentially read- 
only.  Is there a way to remedy this?  Or is there an explanation?

--Richard
From dmitry at koterov.ru  Thu Sep  6 13:19:09 2007
From: dmitry at koterov.ru (Dmitry Koterov)
Date: Thu Sep  6 13:19:33 2007
Subject: [Slony1-general] failover doesn't remove triggers
In-Reply-To: <EFF62083-4F1E-450C-A7E9-CF65A840D525@richyen.com>
References: <EFF62083-4F1E-450C-A7E9-CF65A840D525@richyen.com>
Message-ID: <d7df81620709061319r6f199c1cj32f8c0727a9264df@mail.gmail.com>

Which Slony version do you use?

On 9/6/07, Richard Yen <dba@richyen.com> wrote:
>
> Hi all,
>
> I had to execute a FAIL OVER command last night, and I looks like the
> command might be buggy?
>
> After executing the command, the subscribe table on the new master
> (node 2) had two rows, one signifying that it was the provider for
> node 3, the other had a blank provider column and had node 2 in the
> subscriber column.  I'm supposing this is expected behavior?
>
> What really concerned me was that on the new master, the denyaccess
> triggers were still there, so my entire cluster was essentially read-
> only.  Is there a way to remedy this?  Or is there an explanation?
>
> --Richard
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070907/=
d2434df6/attachment.htm
From dba at richyen.com  Thu Sep  6 14:46:33 2007
From: dba at richyen.com (Richard Yen)
Date: Thu Sep  6 14:46:59 2007
Subject: [Slony1-general] failover doesn't remove triggers
In-Reply-To: <d7df81620709061319r6f199c1cj32f8c0727a9264df@mail.gmail.com>
References: <EFF62083-4F1E-450C-A7E9-CF65A840D525@richyen.com>
	<d7df81620709061319r6f199c1cj32f8c0727a9264df@mail.gmail.com>
Message-ID: <48644493-83F2-40F9-AD1A-2C2A969B5A64@richyen.com>

sorry...1.2.9

--Richard



On Sep 6, 2007, at 1:19 PM, Dmitry Koterov wrote:

> Which Slony version do you use?
>
> On 9/6/07, Richard Yen <dba@richyen.com> wrote: Hi all,
>
> I had to execute a FAIL OVER command last night, and I looks like the
> command might be buggy?
>
> After executing the command, the subscribe table on the new master
> (node 2) had two rows, one signifying that it was the provider for
> node 3, the other had a blank provider column and had node 2 in the
> subscriber column.  I'm supposing this is expected behavior?
>
> What really concerned me was that on the new master, the denyaccess
> triggers were still there, so my entire cluster was essentially read-
> only.  Is there a way to remedy this?  Or is there an explanation?
>
> --Richard
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>

From andrew.george.hammond at gmail.com  Thu Sep  6 16:00:13 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Thu Sep  6 16:00:44 2007
Subject: [Slony1-general] failover doesn't remove triggers
In-Reply-To: <48644493-83F2-40F9-AD1A-2C2A969B5A64@richyen.com>
References: <EFF62083-4F1E-450C-A7E9-CF65A840D525@richyen.com>
	<d7df81620709061319r6f199c1cj32f8c0727a9264df@mail.gmail.com>
	<48644493-83F2-40F9-AD1A-2C2A969B5A64@richyen.com>
Message-ID: <5a0a9d6f0709061600g5004212du3e761aa8162d6240@mail.gmail.com>

What slonik script did you run. How did you run it. What was the output of
slonik.

On 9/6/07, Richard Yen <dba@richyen.com> wrote:
>
> sorry...1.2.9
>
> --Richard
>
>
>
> On Sep 6, 2007, at 1:19 PM, Dmitry Koterov wrote:
>
> > Which Slony version do you use?
> >
> > On 9/6/07, Richard Yen <dba@richyen.com> wrote: Hi all,
> >
> > I had to execute a FAIL OVER command last night, and I looks like the
> > command might be buggy?
> >
> > After executing the command, the subscribe table on the new master
> > (node 2) had two rows, one signifying that it was the provider for
> > node 3, the other had a blank provider column and had node 2 in the
> > subscriber column.  I'm supposing this is expected behavior?
> >
> > What really concerned me was that on the new master, the denyaccess
> > triggers were still there, so my entire cluster was essentially read-
> > only.  Is there a way to remedy this?  Or is there an explanation?
> >
> > --Richard
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general@lists.slony.info
> > http://lists.slony.info/mailman/listinfo/slony1-general
> >
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070906/=
7bcc9692/attachment.htm
From dba at richyen.com  Thu Sep  6 20:17:43 2007
From: dba at richyen.com (Richard Yen)
Date: Thu Sep  6 20:18:27 2007
Subject: [Slony1-general] failover doesn't remove triggers
In-Reply-To: <5a0a9d6f0709061600g5004212du3e761aa8162d6240@mail.gmail.com>
References: <EFF62083-4F1E-450C-A7E9-CF65A840D525@richyen.com>
	<d7df81620709061319r6f199c1cj32f8c0727a9264df@mail.gmail.com>
	<48644493-83F2-40F9-AD1A-2C2A969B5A64@richyen.com>
	<5a0a9d6f0709061600g5004212du3e761aa8162d6240@mail.gmail.com>
Message-ID: <D70792C7-7275-4A94-B78F-7B6655B0A14B@richyen.com>

On Sep 6, 2007, at 4:00 PM, Andrew Hammond wrote:

> What slonik script did you run. How did you run it. What was the  
> output of slonik.
>

I ran a shell script (from command line) that passes conninfo and  
such to slonik:

> #!/bin/sh
>
> ${SLONIK} <<EOF
>
> # ----
> # This defines which namespace the replication system uses
> # ----
> cluster name = $CLUSTER_NAME;
>
> # ----
> # Admin conninfo's are used by the slonik program to connect
> # to the node databases.  So therse are the PQconnectdb arguments
> # that connect from the administrators workstation (where
> # slonik is executed).
> # ----
> node $MASTER_NODE_ID admin conninfo = '$MASTER_CONNINFO';
> node $SLAVE1_NODE_ID admin conninfo = '$SLAVE1_CONNINFO';
> node $SLAVE2_NODE_ID admin conninfo = '$SLAVE2_CONNINFO';
>
> # ----
> # Switch provider from db3 to db1
> # ----
>
> failover( id=$MASTER_NODE_ID, backup node = $SLAVE1_NODE_ID);
> EOF
>
> echo "slonik is done"

The output was the following:
NOTICE:  failedNode: set 1 has other direct receivers - change  
providers only
NOTICE:  failedNode: set 1 has other direct receivers - change  
providers only
slonik is done

The logs on the new master (tii-db2) show the following (tii-db1g is  
the failed node):
Sep  5 19:17:23 tii-db2.local.myip.com postgres[3012]: [3-1]  
2007-09-05 19:17:23.178 PDT [user=slony,db=tii 192.168.1.42(33459)  
PID:3012 XID:210896798]NOTICE:  failedNode: set 1 has other
Sep  5 19:17:23 tii-db2.local.myip.com postgres[3012]: [3-2]  direct  
receivers - change providers only
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6100-1]  
2007-09-05 19:17:23 PDT INFO   localListenThread: got restart  
notification
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6101-1]  
2007-09-05 19:17:23 PDT DEBUG2 slon_restart() from pid=31603
Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [5-1] 2007-09-05  
19:17:23 PDT DEBUG1 slon: restart requested
Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [6-1] 2007-09-05  
19:17:23 PDT DEBUG2 slon: notify worker process to shutdown
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6102-1]  
2007-09-05 19:17:23 PDT DEBUG1 remoteListenThread_1: thread done
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6103-1]  
2007-09-05 19:17:23 PDT DEBUG1 cleanupThread: thread done
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6104-1]  
2007-09-05 19:17:23 PDT DEBUG1 syncThread: thread done
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6105-1]  
2007-09-05 19:17:23 PDT INFO   remoteListenThread_3: disconnecting  
from 'dbname=tii host=tii-db3g.local.myip.com
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6105-2]   
user=slony password=3l3phant'
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6106-1]  
2007-09-05 19:17:23 PDT DEBUG1 remoteListenThread_3: thread done
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6107-1]  
2007-09-05 19:17:23 PDT DEBUG1 main: scheduler mainloop returned
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6108-1]  
2007-09-05 19:17:23 PDT DEBUG2 main: wait for remote threads
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6109-1]  
2007-09-05 19:17:23 PDT DEBUG2 sched_wakeup_node(): no_id=1 (0  
threads + worker signaled)
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6110-1]  
2007-09-05 19:17:23 PDT DEBUG4 remoteWorkerThread_1: update provider  
configuration
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6111-1]  
2007-09-05 19:17:23 PDT DEBUG1 remoteWorkerThread_1: helper thread  
for provider 1 terminated
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6112-1]  
2007-09-05 19:17:23 PDT DEBUG1 remoteWorkerThread_1: thread done
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6113-1]  
2007-09-05 19:17:23 PDT DEBUG2 sched_wakeup_node(): no_id=3 (0  
threads + worker signaled)
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6114-1]  
2007-09-05 19:17:23 PDT DEBUG4 remoteWorkerThread_3: update provider  
configuration
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6115-1]  
2007-09-05 19:17:23 PDT DEBUG1 remoteWorkerThread_3: thread done
Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6116-1]  
2007-09-05 19:17:23 PDT DEBUG1 main: done
Sep  5 19:17:23 tii-db2.local.myip.com postgres[31607]: [5-1]  
2007-09-05 19:17:23.319 PDT [user=slony,db=tii 192.168.3.42(51836)  
PID:31607 XID:210896805]LOG:  unexpected EOF on client
Sep  5 19:17:23 tii-db2.local.myip.com postgres[31607]: [5-2]   
connection
Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [7-1] 2007-09-05  
19:17:23 PDT DEBUG2 slon: child terminated status: 0; pid: 31603,  
current worker pid: 31603
Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [1-1] 2007-09-05  
19:17:23 PDT CONFIG main: slon version 1.2.9 starting up
Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [2-1] 2007-09-05  
19:17:23 PDT DEBUG2 slon: watchdog process started
Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [3-1] 2007-09-05  
19:17:23 PDT DEBUG2 slon: watchdog ready - pid = 31602
Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [4-1] 2007-09-05  
19:17:23 PDT DEBUG2 slon: worker process created - pid = 3013
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [4-1] 2007-09-05  
19:17:23 PDT CONFIG main: local node id = 2
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [5-1] 2007-09-05  
19:17:23 PDT DEBUG2 main: main process started
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [6-1] 2007-09-05  
19:17:23 PDT CONFIG main: launching sched_start_mainloop
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [7-1] 2007-09-05  
19:17:23 PDT CONFIG main: loading current cluster configuration
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [8-1] 2007-09-05  
19:17:23 PDT CONFIG storeNode: no_id=1 no_comment='Master node'
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [9-1] 2007-09-05  
19:17:23 PDT DEBUG2 setNodeLastEvent: no_id=1 event_seq=5748563
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [10-1] 2007-09-05  
19:17:23 PDT CONFIG storeNode: no_id=3 no_comment='second slave node'
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [11-1] 2007-09-05  
19:17:23 PDT DEBUG2 setNodeLastEvent: no_id=3 event_seq=1319203
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [12-1] 2007-09-05  
19:17:23 PDT CONFIG storePath: pa_server=1 pa_client=2  
pa_conninfo="dbname=tii host=tii-db1g.local.myip.com
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [12-2]  user=slony  
password=3l3phant" pa_connretry=10
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [13-1] 2007-09-05  
19:17:23 PDT CONFIG storePath: pa_server=3 pa_client=2  
pa_conninfo="dbname=tii host=tii-db3g.local.myip.com
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [13-2]  user=slony  
password=3l3phant" pa_connretry=10
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [14-1] 2007-09-05  
19:17:23 PDT CONFIG storeListen: li_origin=1 li_receiver=2 li_provider=1
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [15-1] 2007-09-05  
19:17:23 PDT CONFIG storeListen: li_origin=3 li_receiver=2 li_provider=1
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [16-1] 2007-09-05  
19:17:23 PDT CONFIG storeListen: li_origin=3 li_receiver=2 li_provider=3
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [17-1] 2007-09-05  
19:17:23 PDT CONFIG storeListen: li_origin=1 li_receiver=2 li_provider=3
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [18-1] 2007-09-05  
19:17:23 PDT CONFIG storeSet: set_id=1 set_origin=1 set_comment='all  
tables'
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [19-1] 2007-09-05  
19:17:23 PDT WARN   remoteWorker_wakeup: node 1 - no worker thread
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [20-1] 2007-09-05  
19:17:23 PDT DEBUG2 sched_wakeup_node(): no_id=1 (0 threads + worker  
signaled)
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [21-1] 2007-09-05  
19:17:23 PDT CONFIG storeSubscribe: sub_set=1 sub_provider=0  
sub_forward='t'
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [22-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteWorker_wakeup: unknown node 0
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [23-1] 2007-09-05  
19:17:23 PDT DEBUG2 sched_wakeup_node(): no_id=0 (0 threads + worker  
signaled)
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [24-1] 2007-09-05  
19:17:23 PDT CONFIG enableSubscription: sub_set=1
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [25-1] 2007-09-05  
19:17:23 PDT DEBUG2 main: last local event sequence = 1312811
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [26-1] 2007-09-05  
19:17:23 PDT CONFIG main: configuration complete - starting threads
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [27-1] 2007-09-05  
19:17:23 PDT DEBUG1 localListenThread: thread starts
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [28-1] 2007-09-05  
19:17:23 PDT DEBUG4 version for "dbname=tii host=tii- 
db2g.local.myip.com user=slony password=3l3phant" is
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [28-2]  80204
Sep  5 19:17:23 tii-db2.local.myip.com postgres[3018]: [3-1]  
2007-09-05 19:17:23.390 PDT [user=slony,db=tii 192.168.3.42(50883)  
PID:3018 XID:210896821]NOTICE:  Slony-I: cleanup stale
Sep  5 19:17:23 tii-db2.local.myip.com postgres[3018]: [3-2]   
sl_nodelock entry for pid=31582
Sep  5 19:17:23 tii-db2.local.myip.com postgres[3018]: [4-1]  
2007-09-05 19:17:23.392 PDT [user=slony,db=tii 192.168.3.42(50883)  
PID:3018 XID:210896821]NOTICE:  Slony-I: cleanup stale
Sep  5 19:17:23 tii-db2.local.myip.com postgres[3018]: [4-2]   
sl_nodelock entry for pid=31607
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [29-1] 2007-09-05  
19:17:23 PDT CONFIG enableNode: no_id=1
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [30-1] 2007-09-05  
19:17:23 PDT CONFIG enableNode: no_id=3
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [31-1] 2007-09-05  
19:17:23 PDT DEBUG1 remoteWorkerThread_1: thread starts
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [32-1] 2007-09-05  
19:17:23 PDT DEBUG1 remoteListenThread_1: thread starts
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [33-1] 2007-09-05  
19:17:23 PDT DEBUG1 remoteWorkerThread_3: thread starts
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [34-1] 2007-09-05  
19:17:23 PDT DEBUG1 remoteListenThread_3: thread starts
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [35-1] 2007-09-05  
19:17:23 PDT DEBUG1 main: running scheduler mainloop
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [36-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_1: start listening for event  
origin 1
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [37-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_1: start listening for event  
origin 3
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [38-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: start listening for event  
origin 3
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [39-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: start listening for event  
origin 1
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [40-1] 2007-09-05  
19:17:23 PDT DEBUG1 cleanupThread: thread starts
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [41-1] 2007-09-05  
19:17:23 PDT DEBUG4 cleanupThread: bias = 35383
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [42-1] 2007-09-05  
19:17:23 PDT DEBUG1 syncThread: thread starts
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [43-1] 2007-09-05  
19:17:23 PDT ERROR  slon_connectdb: PQconnectdb("dbname=tii host=tii- 
db1g.local.myip.com user=slony
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [43-2]   
password=3l3phant") failed - could not connect to server: Connection  
refused
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [43-3]       Is  
the server running on host "tii-db1g.local.myip.com" and accepting
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [43-4]       TCP/ 
IP connections on port 5432?
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [44-1] 2007-09-05  
19:17:23 PDT WARN   remoteListenThread_1: DB connection failed -  
sleep 10 seconds
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [45-1] 2007-09-05  
19:17:23 PDT DEBUG4 version for "dbname=tii host=tii- 
db3g.local.myip.com user=slony password=3l3phant" is
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [45-2]  80204
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [46-1] 2007-09-05  
19:17:23 PDT DEBUG4 version for "dbname=tii host=tii- 
db2g.local.myip.com user=slony password=3l3phant" is
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [46-2]  80204
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [47-1] 2007-09-05  
19:17:23 PDT DEBUG1 remoteListenThread_3: connected to 'dbname=tii  
host=tii-db3g.local.myip.com user=slony
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [47-2]   
password=3l3phant'
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [48-1] 2007-09-05  
19:17:23 PDT DEBUG4 version for "dbname=tii host=tii- 
db2g.local.myip.com user=slony password=3l3phant" is
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [48-2]  80204
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [49-1] 2007-09-05  
19:17:23 PDT DEBUG4 remoteWorkerThread_3: update provider configuration
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [50-1] 2007-09-05  
19:17:23 PDT DEBUG4 version for "dbname=tii host=tii- 
db2g.local.myip.com user=slony password=3l3phant" is
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [50-2]  80204
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [51-1] 2007-09-05  
19:17:23 PDT DEBUG4 remoteWorkerThread_1: update provider configuration
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [52-1] 2007-09-05  
19:17:23 PDT DEBUG1 remoteWorkerThread_1: helper thread for provider  
0 created
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [53-1] 2007-09-05  
19:17:23 PDT DEBUG4 remoteWorkerThread_1: added active set 1 to  
provider 0
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [54-1] 2007-09-05  
19:17:23 PDT DEBUG4 remoteHelperThread_1_0: waiting for work
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [55-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748564 SYNC
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [56-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748565 SYNC
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [57-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteWorkerThread_1: Received event 1,5748564 SYNC
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [58-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748566 SYNC
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [59-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748567 SYNC
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [60-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteWorkerThread_1: SYNC 5748564 processing
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [61-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748568 SYNC
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [62-1] 2007-09-05  
19:17:23 PDT ERROR  remoteWorkerThread_1: No pa_conninfo for data  
provider 0
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [63-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748569 SYNC
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [64-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748570 SYNC
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [65-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748571 SYNC
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [66-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748572 SYNC
[...]
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [726-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5749231 SYNC
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [727-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5749232 SYNC
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [728-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5749233 SYNC
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [729-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteWorkerThread_3: forward confirm 1,5749233  
received by 3
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [730-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteWorkerThread_3: forward confirm 2,1312302  
received by 1
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [731-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteWorkerThread_3: forward confirm 3,1318662  
received by 1
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [732-1] 2007-09-05  
19:17:23 PDT DEBUG2 remoteWorkerThread_3: forward confirm 2,1312811  
received by 3
Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [733-1] 2007-09-05  
19:17:23 PDT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 1312812
Sep  5 19:17:24 tii-db2.local.myip.com slon[3013]: [734-1] 2007-09-05  
19:17:24 PDT DEBUG2 localListenThread: Received event 2,1312812 SYNC
Sep  5 19:17:25 tii-db2.local.myip.com slon[3013]: [735-1] 2007-09-05  
19:17:25 PDT DEBUG2 remoteListenThread_3: queue event 1,5749234  
FAILOVER_SET
Sep  5 19:17:25 tii-db2.local.myip.com slon[3013]: [736-1] 2007-09-05  
19:17:25 PDT DEBUG2 remoteWorkerThread_3: forward confirm 1,5749234  
received by 3
Sep  5 19:17:26 tii-db2.local.myip.com slon[3013]: [737-1] 2007-09-05  
19:17:26 PDT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 1312813
Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [738-1] 2007-09-05  
19:17:27 PDT DEBUG2 remoteListenThread_3: queue event 3,1319204 SYNC
Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [739-1] 2007-09-05  
19:17:27 PDT DEBUG2 remoteWorkerThread_3: Received event 3,1319204 SYNC
Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [740-1] 2007-09-05  
19:17:27 PDT DEBUG3 calc sync size - last time: 1 last length: 4113  
ideal: 100 proposed size: 3
Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [741-1] 2007-09-05  
19:17:27 PDT DEBUG2 remoteWorkerThread_3: SYNC 1319204 processing
Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [742-1] 2007-09-05  
19:17:27 PDT DEBUG2 remoteWorkerThread_3: no sets need syncing for  
this event
Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [743-1] 2007-09-05  
19:17:27 PDT DEBUG2 remoteWorkerThread_3: forward confirm 2,1312813  
received by 3
Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [744-1] 2007-09-05  
19:17:27 PDT DEBUG2 localListenThread: Received event 2,1312813 SYNC
Sep  5 19:17:29 tii-db2.local.myip.com slon[3013]: [745-1] 2007-09-05  
19:17:29 PDT DEBUG2 remoteListenThread_3: LISTEN
Sep  5 19:17:29 tii-db2.local.myip.com slon[3013]: [746-1] 2007-09-05  
19:17:29 PDT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 1312814
Sep  5 19:17:29 tii-db2.local.myip.com slon[3013]: [747-1] 2007-09-05  
19:17:29 PDT DEBUG2 remoteWorkerThread_3: forward confirm 2,1312814  
received by 3
Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [748-1] 2007-09-05  
19:17:30 PDT DEBUG2 remoteListenThread_3: queue event 3,1319205 SYNC
Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [749-1] 2007-09-05  
19:17:30 PDT DEBUG2 remoteListenThread_3: UNLISTEN
Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [750-1] 2007-09-05  
19:17:30 PDT DEBUG2 remoteWorkerThread_3: Received event 3,1319205 SYNC
Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [751-1] 2007-09-05  
19:17:30 PDT DEBUG3 calc sync size - last time: 1 last length: 2518  
ideal: 100 proposed size: 3
Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [752-1] 2007-09-05  
19:17:30 PDT DEBUG2 remoteWorkerThread_3: SYNC 1319205 processing
Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [753-1] 2007-09-05  
19:17:30 PDT DEBUG2 remoteWorkerThread_3: no sets need syncing for  
this event
Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [754-1] 2007-09-05  
19:17:30 PDT DEBUG2 localListenThread: Received event 2,1312814 SYNC
Sep  5 19:17:32 tii-db2.local.myip.com slon[3013]: [755-1] 2007-09-05  
19:17:32 PDT DEBUG2 remoteListenThread_3: LISTEN
Sep  5 19:17:32 tii-db2.local.myip.com slon[3013]: [756-1] 2007-09-05  
19:17:32 PDT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 1312815
Sep  5 19:17:32 tii-db2.local.myip.com slon[3013]: [757-1] 2007-09-05  
19:17:32 PDT DEBUG2 remoteWorkerThread_3: forward confirm 2,1312815  
received by 3
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [758-1] 2007-09-05  
19:17:33 PDT DEBUG2 remoteListenThread_3: queue event 3,1319206 SYNC
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [759-1] 2007-09-05  
19:17:33 PDT DEBUG2 remoteListenThread_3: UNLISTEN
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [760-1] 2007-09-05  
19:17:33 PDT DEBUG2 remoteWorkerThread_3: Received event 3,1319206 SYNC
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [761-1] 2007-09-05  
19:17:33 PDT DEBUG3 calc sync size - last time: 1 last length: 3002  
ideal: 100 proposed size: 3
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [762-1] 2007-09-05  
19:17:33 PDT DEBUG2 remoteWorkerThread_3: SYNC 1319206 processing
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [763-1] 2007-09-05  
19:17:33 PDT DEBUG2 remoteWorkerThread_3: no sets need syncing for  
this event
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [764-1] 2007-09-05  
19:17:33 PDT ERROR  slon_connectdb: PQconnectdb("dbname=tii host=tii- 
db1g.local.myip.com user=slony
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [764-2]   
password=3l3phant") failed - could not connect to server: Connection  
refused
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [764-3]      Is  
the server running on host "tii-db1g.local.myip.com" and accepting
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [764-4]      TCP/ 
IP connections on port 5432?
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [765-1] 2007-09-05  
19:17:33 PDT WARN   remoteListenThread_1: DB connection failed -  
sleep 10 seconds
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [766-1] 2007-09-05  
19:17:33 PDT DEBUG2 remoteWorkerThread_1: SYNC 5748564 processing
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [767-1] 2007-09-05  
19:17:33 PDT ERROR  remoteWorkerThread_1: No pa_conninfo for data  
provider 0
Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [768-1] 2007-09-05  
19:17:33 PDT DEBUG2 localListenThread: Received event 2,1312815 SYNC
Sep  5 19:17:35 tii-db2.local.myip.com slon[3013]: [769-1] 2007-09-05  
19:17:35 PDT DEBUG2 remoteListenThread_3: LISTEN
Sep  5 19:17:35 tii-db2.local.myip.com slon[3013]: [770-1] 2007-09-05  
19:17:35 PDT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 1312816
Sep  5 19:17:35 tii-db2.local.myip.com slon[3013]: [771-1] 2007-09-05  
19:17:35 PDT DEBUG2 remoteWorkerThread_3: forward confirm 2,1312816  
received by 3
Sep  5 19:17:36 tii-db2.local.myip.com slon[3013]: [772-1] 2007-09-05  
19:17:36 PDT DEBUG2 remoteListenThread_3: queue event 3,1319207 SYNC
Sep  5 19:17:36 tii-db2.local.myip.com slon[3013]: [773-1] 2007-09-05  
19:17:36 PDT DEBUG2 remoteListenThread_3: UNLISTEN
Sep  5 19:17:36 tii-db2.local.myip.com slon[3013]: [774-1] 2007-09-05  
19:17:36 PDT DEBUG2 remoteWorkerThread_3: Received event 3,1319207 SYNC
Sep  5 19:17:36 tii-db2.local.myip.com slon[3013]: [775-1] 2007-09-05  
19:17:36 PDT DEBUG3 calc sync size - last time: 1 last length: 3009  
ideal: 100 proposed size: 3

Thanks for the help!
--Richard


From cscetbon.ext at orange-ftgroup.com  Fri Sep  7 06:36:17 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Fri Sep  7 06:36:25 2007
Subject: [Slony1-general] Processing of SYNC from origin node
Message-ID: <46E153D1.4060903@orange-ftgroup.com>

Hi,

I got this configuration                Node1 --> Node2 (5 seconds late)
                                                          |
                                                          --> Node3 (2 
hours late)

Node2 is processing each SYNC from Node3 and Node2, but Node3 is 
processing each SYNC from Node2 but not from Node1 which is the origin 
of the sets :

On Node3 we see  `grep processing 
/var/log/slony1/node3-pns_profiles_preprod.log|awk '{print 
$5}'|sort|uniq -c`
     19 remoteWorkerThread_1:
    963 remoteWorkerThread_2:

On Node2 we see `grep processing 
/var/log/slony1/node2-pns_profiles_preprod.log |awk '{print 
$5}'|sort|uniq -c`
   1570 remoteWorkerThread_1:
    865 remoteWorkerThread_3:

Why is there so many SYNC not processed on Node3 ???

Node3 got 22440 queue event and 25 Received event from 
remoteWorkerThread_1, while Node2 got 4467 queue event and 1578 Received 
event from the same worker.

Is there something to do ?

Regards

-- 
Cyril SCETBON - Ing?nieur bases de donn?es

From lists_slony1-general at avsupport.com  Fri Sep  7 06:47:02 2007
From: lists_slony1-general at avsupport.com (Dan Falconer)
Date: Fri Sep  7 06:47:26 2007
Subject: [Slony1-general] "wait for event" invalidly requires node 1?
Message-ID: <200709070847.02545.lists_slony1-general@avsupport.com>

	Running Postgres v8.0.13, Slony 1.2.11.   In our development replication 
environment (thank God we finally got it setup), we've got the following 
setup (both running the same version of Slony + Postgres):

	Node 10 ("Cartman")
	Debian 4.0

	Node 20 ("Belial")
	SLES 10.0 (x86_64)

	I had setup Belial to be the temporary master, then attempted to move the 
origin to Cartman.  I used the "slonik_move_set" script, provided with the 
altperl tools, but decided to update it to contain the "wait for event" 
commands, as described on http://slony.info/documentation/failover.html.   
The following transcript of the session shows the problem with the 
mysterious "node 1" error (with some added linebreaks to accentuate each 
run/output):

--------------------------------- SNIP ---------------------------------
postgres@belial:~/slony> vi bin/slonik_move_set

postgres@belial:~/slony> ./bin/slonik_move_set --config 
conf/slon_tools-pl.conf 1 20 10
cluster name = dev_pl_replication;
 node 10 admin conninfo='host=192.168.10.226 dbname=pl user=postgres 
port=5432';
 node 20 admin conninfo='host=192.168.10.101 dbname=pl user=postgres 
port=5432';
  echo 'Locking down set 1 on node 20';
  lock set (id = 1, origin = 20);
  echo 'Locked down - moving it';
  wait for event (origin = 20, confirmed = 10);
  move set (id = 1, old origin = 20, new origin = 10);
  wait for event (origin = 20, confirmed = 10);
  echo 'Replication set 1 moved from node 20 to 10.  Remember to';
  echo 'update your configuration file, if necessary, to note the new 
location';
  echo 'for the set.';


postgres@belial:~/slony> ./bin/slonik_move_set --config 
conf/slon_tools-pl.conf 1 20 10 | slonik
<stdin>:7: Error: No admin conninfo provided for node 1
<stdin>:9: Error: No admin conninfo provided for node 1



postgres@belial:~/slony> ./bin/slonik_move_set --config 
conf/slon_tools-pl.conf 1 20 10 | grep "node 1"
 node 10 admin conninfo='host=192.168.10.226 dbname=pl user=postgres 
port=5432';


postgres@belial:~/slony> svn revert bin/slonik_move_set
Reverted 'bin/slonik_move_set'


postgres@belial:~/slony> ./bin/slonik_move_set --config 
conf/slon_tools-pl.conf 1 20 10
cluster name = dev_pl_replication;
 node 10 admin conninfo='host=192.168.10.226 dbname=pl user=postgres 
port=5432';
 node 20 admin conninfo='host=192.168.10.101 dbname=pl user=postgres 
port=5432';
  echo 'Locking down set 1 on node 20';
  lock set (id = 1, origin = 20);
  echo 'Locked down - moving it';
  move set (id = 1, old origin = 20, new origin = 10);
  echo 'Replication set 1 moved from node 20 to 10.  Remember to';
  echo 'update your configuration file, if necessary, to note the new 
location';
  echo 'for the set.';


postgres@belial:~/slony> ./bin/slonik_move_set --config 
conf/slon_tools-pl.conf 1 20 10 | slonik
<stdin>:4: Locking down set 1 on node 20
<stdin>:6: Locked down - moving it
<stdin>:8: Replication set 1 moved from node 20 to 10.  Remember to
<stdin>:9: update your configuration file, if necessary, to note the new 
location
<stdin>:10: for the set.
-------------------------------- /SNIP ---------------------------------
-- 
Best Regards,


Dan Falconer
"Head Geek", Avsupport, Inc. / Partslogistics.com
http://www.partslogistics.com
From stephen.hindmarch at bt.com  Fri Sep  7 07:15:47 2007
From: stephen.hindmarch at bt.com (stephen.hindmarch@bt.com)
Date: Fri Sep  7 07:16:00 2007
Subject: [Slony1-general] "wait for event" invalidly requires node 1?
In-Reply-To: <200709070847.02545.lists_slony1-general@avsupport.com>
Message-ID: <614CEAAF10695543B87ED664C03A5DB203F2D047@E03MVX1-UKDY.domain1.systemhost.net>


Dan,

I was caught by this recently. There is a third parameter for "wait for
event" which is the id of the node you are confirming has received the
event. This defaults to 1 so you need to explicitly set it to the new
origin node.

You should also consider setting the 4th parameter which is a timeout.

http://slony.info/documentation/stmtwaitevent.html

Steve Hindmarch

One IT - iBridge Development

> -----Original Message-----
> From: slony1-general-bounces@lists.slony.info 
> [mailto:slony1-general-bounces@lists.slony.info] On Behalf Of 
> Dan Falconer
> Sent: 07 September 2007 14:47
> To: slony1-general@lists.slony.info
> Subject: [Slony1-general] "wait for event" invalidly requires node 1?
> 
> 	Running Postgres v8.0.13, Slony 1.2.11.   In our 
> development replication 
> environment (thank God we finally got it setup), we've got 
> the following 
> setup (both running the same version of Slony + Postgres):
> 
> 	Node 10 ("Cartman")
> 	Debian 4.0
> 
> 	Node 20 ("Belial")
> 	SLES 10.0 (x86_64)
> 
> 	I had setup Belial to be the temporary master, then 
> attempted to move the 
> origin to Cartman.  I used the "slonik_move_set" script, 
> provided with the 
> altperl tools, but decided to update it to contain the "wait 
> for event" 
> commands, as described on 
> http://slony.info/documentation/failover.html.   
> The following transcript of the session shows the problem with the 
> mysterious "node 1" error (with some added linebreaks to 
> accentuate each 
> run/output):
> 
> --------------------------------- SNIP 
> ---------------------------------
> postgres@belial:~/slony> vi bin/slonik_move_set
> 
> postgres@belial:~/slony> ./bin/slonik_move_set --config 
> conf/slon_tools-pl.conf 1 20 10
> cluster name = dev_pl_replication;
>  node 10 admin conninfo='host=192.168.10.226 dbname=pl user=postgres 
> port=5432';
>  node 20 admin conninfo='host=192.168.10.101 dbname=pl user=postgres 
> port=5432';
>   echo 'Locking down set 1 on node 20';
>   lock set (id = 1, origin = 20);
>   echo 'Locked down - moving it';
>   wait for event (origin = 20, confirmed = 10);
>   move set (id = 1, old origin = 20, new origin = 10);
>   wait for event (origin = 20, confirmed = 10);
>   echo 'Replication set 1 moved from node 20 to 10.  Remember to';
>   echo 'update your configuration file, if necessary, to note the new 
> location';
>   echo 'for the set.';
> 
> 
> postgres@belial:~/slony> ./bin/slonik_move_set --config 
> conf/slon_tools-pl.conf 1 20 10 | slonik
> <stdin>:7: Error: No admin conninfo provided for node 1
> <stdin>:9: Error: No admin conninfo provided for node 1
> 
> 
> 
> postgres@belial:~/slony> ./bin/slonik_move_set --config 
> conf/slon_tools-pl.conf 1 20 10 | grep "node 1"
>  node 10 admin conninfo='host=192.168.10.226 dbname=pl user=postgres 
> port=5432';
> 
> 
> postgres@belial:~/slony> svn revert bin/slonik_move_set
> Reverted 'bin/slonik_move_set'
> 
> 
> postgres@belial:~/slony> ./bin/slonik_move_set --config 
> conf/slon_tools-pl.conf 1 20 10
> cluster name = dev_pl_replication;
>  node 10 admin conninfo='host=192.168.10.226 dbname=pl user=postgres 
> port=5432';
>  node 20 admin conninfo='host=192.168.10.101 dbname=pl user=postgres 
> port=5432';
>   echo 'Locking down set 1 on node 20';
>   lock set (id = 1, origin = 20);
>   echo 'Locked down - moving it';
>   move set (id = 1, old origin = 20, new origin = 10);
>   echo 'Replication set 1 moved from node 20 to 10.  Remember to';
>   echo 'update your configuration file, if necessary, to note the new 
> location';
>   echo 'for the set.';
> 
> 
> postgres@belial:~/slony> ./bin/slonik_move_set --config 
> conf/slon_tools-pl.conf 1 20 10 | slonik
> <stdin>:4: Locking down set 1 on node 20
> <stdin>:6: Locked down - moving it
> <stdin>:8: Replication set 1 moved from node 20 to 10.  Remember to
> <stdin>:9: update your configuration file, if necessary, to 
> note the new 
> location
> <stdin>:10: for the set.
> -------------------------------- /SNIP 
> ---------------------------------
> -- 
> Best Regards,
> 
> 
> Dan Falconer
> "Head Geek", Avsupport, Inc. / Partslogistics.com
> http://www.partslogistics.com
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
> 
From cscetbon.ext at orange-ftgroup.com  Fri Sep  7 07:23:32 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Fri Sep  7 07:23:42 2007
Subject: [Slony1-general] Configuration on 2 sites / RESOLVED
In-Reply-To: <46DEE82E.60909@orange-ftgroup.com>
References: <46D3EF28.40108@orange-ftgroup.com>	<20070828132235.GA461@phlogi		ston.dyndns.org>	<46D43DAF.5010604@orange-ftgroup.com>	<20070828152919.GB9	7	9@phlogiston.dyndns.org>	<46D539A4.9020601@orange-ftgroup.com>	<200708291	74	509.GR4183@phlogiston.dyndns.org>	<46D5B216.2010708@orange-ftgroup.com>		<20	070829180550.GT4183@phlogiston.dyndns.org>	<46D5BD84.8090302@orange-ftg	roup.com>	<46D7D4AE.6000600@orange-ftgroup.com>	<46D7FE31.3080308@Yahoo.com>	<46D820F7.7070904@orange-ftgroup.com>	<46D84297.8010204@Yahoo.com>	<46DBCA8E.2060507@orange-ftgroup.com>	<46DC6725.20903@orange-ftgroup.com>
	<46DEE82E.60909@orange-ftgroup.com>
Message-ID: <46E15EE4.6060806@orange-ftgroup.com>

Problem solved with the following procedure : (slony 1.2.10)

when node M2 is lost :

- reshape subscription from S2 to M1 -> all the nodes except S2 is updated
- update manually sl_subscribe on S2 : update "_CLUSTER1".sl_subscribe 
set sub_provider=1 where sub_receiver=4;
- reshape subscription from S2 to M1 (in case of much more need to be 
done on S2 ?) + drop node M1

and everything works :-)

So, when S2 is receiveing events (done on M1) from M2, it's not updated 
if M2 is lost although paths between M1 and S2 exist.

Regards

Cyril SCETBON wrote:
> Sorry to reply one more time, but I need help :-(
> A little precision, these tests have been done on the same host, maybe 
> the problem is known ...
>
> Any idea to fix the issue ?
>
> thanks.
>
> Cyril SCETBON wrote:
>>
>>
>> Cyril SCETBON wrote:
>>>
>>>
>>> Jan Wieck wrote:
>>>> On 8/31/2007 10:08 AM, Cyril SCETBON wrote:
>>>>>
>>>>> Jan Wieck wrote:
>>>>>> On 8/31/2007 4:43 AM, Cyril SCETBON wrote:
>>>>>>>
>>>>>>> Cyril SCETBON wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>> Andrew Sullivan wrote:
>>>>>>>>> On Wed, Aug 29, 2007 at 07:51:18PM +0200, Cyril SCETBON wrote:
>>>>>>>>>  
>>>>>>>>>> So, How can I do if M2 is lost ? Cause I don't want S2 to 
>>>>>>>>>> resync with M1 from scratch
>>>>>>>>>>     
>>>>>>>>>
>>>>>>>>> You can't.  If you can't co-ordinate a switchover, then you 
>>>>>>>>> lose the
>>>>>>>>> node.  This is discussed at length in the manual.
>>>>>>>>>   
>>>>>>>> Really ????
>>>>>>>> Are you really saying that losing M2 make me lose S2 ?????
>>>>>>>> If it's true I'm really disappointed by slony :-(
>>>>>>>>
>>>>>>>> My config is as follows (just to remember) :
>>>>>>>>
>>>>>>>> psql db1 -c 'select * from "_CLUSTER1".sl_subscribe'
>>>>>>>> sub_set | sub_provider | sub_receiver | sub_forward | sub_active
>>>>>>>> ---------+--------------+--------------+-------------+------------
>>>>>>>>      1 |            1 (M1)|            3 (M2)| t           | t
>>>>>>>>      1 |            1 (M1)|            2 (S1) | t           | t
>>>>>>>>      1 |            3 (M2)|            4 (S2) | t           | t
>>>>>>
>>>>>> Since all nodes in your scenario are forwarders, you won't lose 
>>>>>> anything other than the failed node ever. In your configuration 
>>>>>> if you lose node M2 (which is a subscriber), simply issuing a new 
>>>>>> SUBSCRIBE SET for node S2 to use M1 or S1 as data provider will 
>>>>>> do. It will catch up from there without the need to sync from 
>>>>>> scratch.
>>>>> I tried reshaping subscription. The subscription works. But no 
>>>>> more updates go to S2.
>>>>
>>>> Check the sl_path configuration. S2 might not have the necessary 
>>>> (or correct) information to connect to its new data provider.
>>> The problem is that S2 does not know that it must now connect to a 
>>> new provider :
>>>
>>> On node S2 I have the following subscribe information :
>>>
>>> sub_set | sub_provider | sub_receiver | sub_forward | sub_active
>>> ---------+--------------+--------------+-------------+------------
>>>       1 |            1 |            2 | t           | t
>>>       1 |            1 |            3 | t           | t
>>>       1 |            3 |            4 | t           | t
>> why node 4 wasn't updated ? weird , no ?
>>>
>>> But, on other nodes I have :
>>>
>>> sub_set | sub_provider | sub_receiver | sub_forward | sub_active
>>> ---------+--------------+--------------+-------------+------------
>>>       1 |            1 |            2 | t           | t
>>>       1 |            1 |            4 | t           | t
>>>
>>> I've used SUBSCRIBE SET (ID=1,PROVIDER=1,RECEIVER=4,FORWARD=YES); to 
>>> reshape subscription from node 4 to node 1.
>>>
>>> Since node 3 was lost, node 4 does not know that it has to change 
>>> subscription even if I instruct slonik to make this change and that 
>>> the script has the correct node informations and path on node 4 :
>>>
>>>         2 |         1 | dbname=db2 host=xx user=postgres port=5432 
>>> |           10
>>>         1 |         2 | dbname=db1 host=yy user=postgres port=5432 
>>> |           10
>>>         3 |         4 | dbname=db3 host=zz user=postgres port=5432 
>>> |           10
>>>         1 |         3 | dbname=db1 host=yy user=postgres port=5432 
>>> |           10
>>>         4 |         3 | dbname=db4 host=ww user=postgres port=5432 
>>> |           10
>>>         3 |         1 | dbname=db3 host=zz user=postgres port=5432 
>>> |           10
>>>         1 |         4 | dbname=db1 host=yy user=postgres port=5432 
>>> |           10
>>>         4 |         1 | dbname=db4 host=ww user=postgres port=5432 
>>> |           10
>>>
>>> This time, I've added path between node 4 and node 1 before dropping 
>>> node 3, but node 4 continues to connect to node 3 and get the 
>>> following error  slon_connectdb: PQconnectdb("dbname=db3 host=zz 
>>> user=postgres port=5432") failed - FATAL:  database "db3" does not 
>>> exist.
>>>
>>> Why it did not delete entry for node 3 on node 4 ???
>>>
>>> any idea ?
>>>
>>>>
>>>>
>>>> Jan
>>>>
>>>
>>
>

-- 
Cyril SCETBON


From JanWieck at Yahoo.com  Fri Sep  7 12:00:19 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Fri Sep  7 12:00:59 2007
Subject: [Slony1-general] failover doesn't remove triggers
In-Reply-To: <D70792C7-7275-4A94-B78F-7B6655B0A14B@richyen.com>
References: <EFF62083-4F1E-450C-A7E9-CF65A840D525@richyen.com>	<d7df81620709061319r6f199c1cj32f8c0727a9264df@mail.gmail.com>	<48644493-83F2-40F9-AD1A-2C2A969B5A64@richyen.com>	<5a0a9d6f0709061600g5004212du3e761aa8162d6240@mail.gmail.com>
	<D70792C7-7275-4A94-B78F-7B6655B0A14B@richyen.com>
Message-ID: <46E19FC3.6040508@Yahoo.com>

On 9/6/2007 11:17 PM, Richard Yen wrote:
> On Sep 6, 2007, at 4:00 PM, Andrew Hammond wrote:
> 
>> What slonik script did you run. How did you run it. What was the  
>> output of slonik.
>>
> 
> I ran a shell script (from command line) that passes conninfo and  
> such to slonik:
> 
>> #!/bin/sh
>>
>> ${SLONIK} <<EOF
>>
>> # ----
>> # This defines which namespace the replication system uses
>> # ----
>> cluster name = $CLUSTER_NAME;
>>
>> # ----
>> # Admin conninfo's are used by the slonik program to connect
>> # to the node databases.  So therse are the PQconnectdb arguments
>> # that connect from the administrators workstation (where
>> # slonik is executed).
>> # ----
>> node $MASTER_NODE_ID admin conninfo = '$MASTER_CONNINFO';
>> node $SLAVE1_NODE_ID admin conninfo = '$SLAVE1_CONNINFO';
>> node $SLAVE2_NODE_ID admin conninfo = '$SLAVE2_CONNINFO';
>>
>> # ----
>> # Switch provider from db3 to db1
>> # ----
>>
>> failover( id=$MASTER_NODE_ID, backup node = $SLAVE1_NODE_ID);
>> EOF
>>
>> echo "slonik is done"
> 
> The output was the following:
> NOTICE:  failedNode: set 1 has other direct receivers - change  
> providers only
> NOTICE:  failedNode: set 1 has other direct receivers - change  
> providers only
> slonik is done
> 
> The logs on the new master (tii-db2) show the following (tii-db1g is  
> the failed node):
> Sep  5 19:17:23 tii-db2.local.myip.com postgres[3012]: [3-1]  
> 2007-09-05 19:17:23.178 PDT [user=slony,db=tii 192.168.1.42(33459)  
> PID:3012 XID:210896798]NOTICE:  failedNode: set 1 has other
> Sep  5 19:17:23 tii-db2.local.myip.com postgres[3012]: [3-2]  direct  
> receivers - change providers only
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6100-1]  
> 2007-09-05 19:17:23 PDT INFO   localListenThread: got restart  
> notification
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6101-1]  
> 2007-09-05 19:17:23 PDT DEBUG2 slon_restart() from pid=31603
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [5-1] 2007-09-05  
> 19:17:23 PDT DEBUG1 slon: restart requested
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [6-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 slon: notify worker process to shutdown
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6102-1]  
> 2007-09-05 19:17:23 PDT DEBUG1 remoteListenThread_1: thread done
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6103-1]  
> 2007-09-05 19:17:23 PDT DEBUG1 cleanupThread: thread done
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6104-1]  
> 2007-09-05 19:17:23 PDT DEBUG1 syncThread: thread done
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6105-1]  
> 2007-09-05 19:17:23 PDT INFO   remoteListenThread_3: disconnecting  
> from 'dbname=tii host=tii-db3g.local.myip.com
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6105-2]   
> user=slony password=3l3phant'
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6106-1]  
> 2007-09-05 19:17:23 PDT DEBUG1 remoteListenThread_3: thread done
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6107-1]  
> 2007-09-05 19:17:23 PDT DEBUG1 main: scheduler mainloop returned
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6108-1]  
> 2007-09-05 19:17:23 PDT DEBUG2 main: wait for remote threads
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6109-1]  
> 2007-09-05 19:17:23 PDT DEBUG2 sched_wakeup_node(): no_id=1 (0  
> threads + worker signaled)
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6110-1]  
> 2007-09-05 19:17:23 PDT DEBUG4 remoteWorkerThread_1: update provider  
> configuration
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6111-1]  
> 2007-09-05 19:17:23 PDT DEBUG1 remoteWorkerThread_1: helper thread  
> for provider 1 terminated
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6112-1]  
> 2007-09-05 19:17:23 PDT DEBUG1 remoteWorkerThread_1: thread done
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6113-1]  
> 2007-09-05 19:17:23 PDT DEBUG2 sched_wakeup_node(): no_id=3 (0  
> threads + worker signaled)
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6114-1]  
> 2007-09-05 19:17:23 PDT DEBUG4 remoteWorkerThread_3: update provider  
> configuration
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6115-1]  
> 2007-09-05 19:17:23 PDT DEBUG1 remoteWorkerThread_3: thread done
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31603]: [6116-1]  
> 2007-09-05 19:17:23 PDT DEBUG1 main: done
> Sep  5 19:17:23 tii-db2.local.myip.com postgres[31607]: [5-1]  
> 2007-09-05 19:17:23.319 PDT [user=slony,db=tii 192.168.3.42(51836)  
> PID:31607 XID:210896805]LOG:  unexpected EOF on client
> Sep  5 19:17:23 tii-db2.local.myip.com postgres[31607]: [5-2]   
> connection
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [7-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 slon: child terminated status: 0; pid: 31603,  
> current worker pid: 31603
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [1-1] 2007-09-05  
> 19:17:23 PDT CONFIG main: slon version 1.2.9 starting up
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [2-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 slon: watchdog process started
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [3-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 slon: watchdog ready - pid = 31602
> Sep  5 19:17:23 tii-db2.local.myip.com slon[31602]: [4-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 slon: worker process created - pid = 3013
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [4-1] 2007-09-05  
> 19:17:23 PDT CONFIG main: local node id = 2
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [5-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 main: main process started
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [6-1] 2007-09-05  
> 19:17:23 PDT CONFIG main: launching sched_start_mainloop
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [7-1] 2007-09-05  
> 19:17:23 PDT CONFIG main: loading current cluster configuration
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [8-1] 2007-09-05  
> 19:17:23 PDT CONFIG storeNode: no_id=1 no_comment='Master node'
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [9-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 setNodeLastEvent: no_id=1 event_seq=5748563
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [10-1] 2007-09-05  
> 19:17:23 PDT CONFIG storeNode: no_id=3 no_comment='second slave node'
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [11-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 setNodeLastEvent: no_id=3 event_seq=1319203
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [12-1] 2007-09-05  
> 19:17:23 PDT CONFIG storePath: pa_server=1 pa_client=2  
> pa_conninfo="dbname=tii host=tii-db1g.local.myip.com
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [12-2]  user=slony  
> password=3l3phant" pa_connretry=10
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [13-1] 2007-09-05  
> 19:17:23 PDT CONFIG storePath: pa_server=3 pa_client=2  
> pa_conninfo="dbname=tii host=tii-db3g.local.myip.com
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [13-2]  user=slony  
> password=3l3phant" pa_connretry=10
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [14-1] 2007-09-05  
> 19:17:23 PDT CONFIG storeListen: li_origin=1 li_receiver=2 li_provider=1
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [15-1] 2007-09-05  
> 19:17:23 PDT CONFIG storeListen: li_origin=3 li_receiver=2 li_provider=1
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [16-1] 2007-09-05  
> 19:17:23 PDT CONFIG storeListen: li_origin=3 li_receiver=2 li_provider=3
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [17-1] 2007-09-05  
> 19:17:23 PDT CONFIG storeListen: li_origin=1 li_receiver=2 li_provider=3
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [18-1] 2007-09-05  
> 19:17:23 PDT CONFIG storeSet: set_id=1 set_origin=1 set_comment='all  
> tables'
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [19-1] 2007-09-05  
> 19:17:23 PDT WARN   remoteWorker_wakeup: node 1 - no worker thread
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [20-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 sched_wakeup_node(): no_id=1 (0 threads + worker  
> signaled)
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [21-1] 2007-09-05  
> 19:17:23 PDT CONFIG storeSubscribe: sub_set=1 sub_provider=0  
> sub_forward='t'
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [22-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteWorker_wakeup: unknown node 0
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [23-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 sched_wakeup_node(): no_id=0 (0 threads + worker  
> signaled)
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [24-1] 2007-09-05  
> 19:17:23 PDT CONFIG enableSubscription: sub_set=1
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [25-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 main: last local event sequence = 1312811
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [26-1] 2007-09-05  
> 19:17:23 PDT CONFIG main: configuration complete - starting threads
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [27-1] 2007-09-05  
> 19:17:23 PDT DEBUG1 localListenThread: thread starts
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [28-1] 2007-09-05  
> 19:17:23 PDT DEBUG4 version for "dbname=tii host=tii- 
> db2g.local.myip.com user=slony password=3l3phant" is
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [28-2]  80204
> Sep  5 19:17:23 tii-db2.local.myip.com postgres[3018]: [3-1]  
> 2007-09-05 19:17:23.390 PDT [user=slony,db=tii 192.168.3.42(50883)  
> PID:3018 XID:210896821]NOTICE:  Slony-I: cleanup stale
> Sep  5 19:17:23 tii-db2.local.myip.com postgres[3018]: [3-2]   
> sl_nodelock entry for pid=31582
> Sep  5 19:17:23 tii-db2.local.myip.com postgres[3018]: [4-1]  
> 2007-09-05 19:17:23.392 PDT [user=slony,db=tii 192.168.3.42(50883)  
> PID:3018 XID:210896821]NOTICE:  Slony-I: cleanup stale
> Sep  5 19:17:23 tii-db2.local.myip.com postgres[3018]: [4-2]   
> sl_nodelock entry for pid=31607
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [29-1] 2007-09-05  
> 19:17:23 PDT CONFIG enableNode: no_id=1
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [30-1] 2007-09-05  
> 19:17:23 PDT CONFIG enableNode: no_id=3
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [31-1] 2007-09-05  
> 19:17:23 PDT DEBUG1 remoteWorkerThread_1: thread starts
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [32-1] 2007-09-05  
> 19:17:23 PDT DEBUG1 remoteListenThread_1: thread starts
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [33-1] 2007-09-05  
> 19:17:23 PDT DEBUG1 remoteWorkerThread_3: thread starts
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [34-1] 2007-09-05  
> 19:17:23 PDT DEBUG1 remoteListenThread_3: thread starts
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [35-1] 2007-09-05  
> 19:17:23 PDT DEBUG1 main: running scheduler mainloop
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [36-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_1: start listening for event  
> origin 1
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [37-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_1: start listening for event  
> origin 3
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [38-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: start listening for event  
> origin 3
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [39-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: start listening for event  
> origin 1
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [40-1] 2007-09-05  
> 19:17:23 PDT DEBUG1 cleanupThread: thread starts
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [41-1] 2007-09-05  
> 19:17:23 PDT DEBUG4 cleanupThread: bias = 35383
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [42-1] 2007-09-05  
> 19:17:23 PDT DEBUG1 syncThread: thread starts
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [43-1] 2007-09-05  
> 19:17:23 PDT ERROR  slon_connectdb: PQconnectdb("dbname=tii host=tii- 
> db1g.local.myip.com user=slony
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [43-2]   
> password=3l3phant") failed - could not connect to server: Connection  
> refused
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [43-3]       Is  
> the server running on host "tii-db1g.local.myip.com" and accepting
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [43-4]       TCP/ 
> IP connections on port 5432?
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [44-1] 2007-09-05  
> 19:17:23 PDT WARN   remoteListenThread_1: DB connection failed -  
> sleep 10 seconds
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [45-1] 2007-09-05  
> 19:17:23 PDT DEBUG4 version for "dbname=tii host=tii- 
> db3g.local.myip.com user=slony password=3l3phant" is
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [45-2]  80204
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [46-1] 2007-09-05  
> 19:17:23 PDT DEBUG4 version for "dbname=tii host=tii- 
> db2g.local.myip.com user=slony password=3l3phant" is
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [46-2]  80204
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [47-1] 2007-09-05  
> 19:17:23 PDT DEBUG1 remoteListenThread_3: connected to 'dbname=tii  
> host=tii-db3g.local.myip.com user=slony
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [47-2]   
> password=3l3phant'
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [48-1] 2007-09-05  
> 19:17:23 PDT DEBUG4 version for "dbname=tii host=tii- 
> db2g.local.myip.com user=slony password=3l3phant" is
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [48-2]  80204
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [49-1] 2007-09-05  
> 19:17:23 PDT DEBUG4 remoteWorkerThread_3: update provider configuration
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [50-1] 2007-09-05  
> 19:17:23 PDT DEBUG4 version for "dbname=tii host=tii- 
> db2g.local.myip.com user=slony password=3l3phant" is
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [50-2]  80204
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [51-1] 2007-09-05  
> 19:17:23 PDT DEBUG4 remoteWorkerThread_1: update provider configuration
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [52-1] 2007-09-05  
> 19:17:23 PDT DEBUG1 remoteWorkerThread_1: helper thread for provider  
> 0 created
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [53-1] 2007-09-05  
> 19:17:23 PDT DEBUG4 remoteWorkerThread_1: added active set 1 to  
> provider 0
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [54-1] 2007-09-05  
> 19:17:23 PDT DEBUG4 remoteHelperThread_1_0: waiting for work
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [55-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748564 SYNC
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [56-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748565 SYNC
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [57-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteWorkerThread_1: Received event 1,5748564 SYNC
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [58-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748566 SYNC
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [59-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748567 SYNC
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [60-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteWorkerThread_1: SYNC 5748564 processing
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [61-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748568 SYNC
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [62-1] 2007-09-05  
> 19:17:23 PDT ERROR  remoteWorkerThread_1: No pa_conninfo for data  
> provider 0
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [63-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748569 SYNC
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [64-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748570 SYNC
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [65-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748571 SYNC
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [66-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5748572 SYNC
> [...]
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [726-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5749231 SYNC
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [727-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5749232 SYNC
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [728-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteListenThread_3: queue event 1,5749233 SYNC
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [729-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteWorkerThread_3: forward confirm 1,5749233  
> received by 3
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [730-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteWorkerThread_3: forward confirm 2,1312302  
> received by 1
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [731-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteWorkerThread_3: forward confirm 3,1318662  
> received by 1
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [732-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 remoteWorkerThread_3: forward confirm 2,1312811  
> received by 3
> Sep  5 19:17:23 tii-db2.local.myip.com slon[3013]: [733-1] 2007-09-05  
> 19:17:23 PDT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 1312812
> Sep  5 19:17:24 tii-db2.local.myip.com slon[3013]: [734-1] 2007-09-05  
> 19:17:24 PDT DEBUG2 localListenThread: Received event 2,1312812 SYNC
> Sep  5 19:17:25 tii-db2.local.myip.com slon[3013]: [735-1] 2007-09-05  
> 19:17:25 PDT DEBUG2 remoteListenThread_3: queue event 1,5749234  
> FAILOVER_SET
> Sep  5 19:17:25 tii-db2.local.myip.com slon[3013]: [736-1] 2007-09-05  
> 19:17:25 PDT DEBUG2 remoteWorkerThread_3: forward confirm 1,5749234  
> received by 3
> Sep  5 19:17:26 tii-db2.local.myip.com slon[3013]: [737-1] 2007-09-05  
> 19:17:26 PDT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 1312813
> Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [738-1] 2007-09-05  
> 19:17:27 PDT DEBUG2 remoteListenThread_3: queue event 3,1319204 SYNC
> Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [739-1] 2007-09-05  
> 19:17:27 PDT DEBUG2 remoteWorkerThread_3: Received event 3,1319204 SYNC
> Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [740-1] 2007-09-05  
> 19:17:27 PDT DEBUG3 calc sync size - last time: 1 last length: 4113  
> ideal: 100 proposed size: 3
> Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [741-1] 2007-09-05  
> 19:17:27 PDT DEBUG2 remoteWorkerThread_3: SYNC 1319204 processing
> Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [742-1] 2007-09-05  
> 19:17:27 PDT DEBUG2 remoteWorkerThread_3: no sets need syncing for  
> this event
> Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [743-1] 2007-09-05  
> 19:17:27 PDT DEBUG2 remoteWorkerThread_3: forward confirm 2,1312813  
> received by 3
> Sep  5 19:17:27 tii-db2.local.myip.com slon[3013]: [744-1] 2007-09-05  
> 19:17:27 PDT DEBUG2 localListenThread: Received event 2,1312813 SYNC
> Sep  5 19:17:29 tii-db2.local.myip.com slon[3013]: [745-1] 2007-09-05  
> 19:17:29 PDT DEBUG2 remoteListenThread_3: LISTEN
> Sep  5 19:17:29 tii-db2.local.myip.com slon[3013]: [746-1] 2007-09-05  
> 19:17:29 PDT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 1312814
> Sep  5 19:17:29 tii-db2.local.myip.com slon[3013]: [747-1] 2007-09-05  
> 19:17:29 PDT DEBUG2 remoteWorkerThread_3: forward confirm 2,1312814  
> received by 3
> Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [748-1] 2007-09-05  
> 19:17:30 PDT DEBUG2 remoteListenThread_3: queue event 3,1319205 SYNC
> Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [749-1] 2007-09-05  
> 19:17:30 PDT DEBUG2 remoteListenThread_3: UNLISTEN
> Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [750-1] 2007-09-05  
> 19:17:30 PDT DEBUG2 remoteWorkerThread_3: Received event 3,1319205 SYNC
> Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [751-1] 2007-09-05  
> 19:17:30 PDT DEBUG3 calc sync size - last time: 1 last length: 2518  
> ideal: 100 proposed size: 3
> Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [752-1] 2007-09-05  
> 19:17:30 PDT DEBUG2 remoteWorkerThread_3: SYNC 1319205 processing
> Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [753-1] 2007-09-05  
> 19:17:30 PDT DEBUG2 remoteWorkerThread_3: no sets need syncing for  
> this event
> Sep  5 19:17:30 tii-db2.local.myip.com slon[3013]: [754-1] 2007-09-05  
> 19:17:30 PDT DEBUG2 localListenThread: Received event 2,1312814 SYNC
> Sep  5 19:17:32 tii-db2.local.myip.com slon[3013]: [755-1] 2007-09-05  
> 19:17:32 PDT DEBUG2 remoteListenThread_3: LISTEN
> Sep  5 19:17:32 tii-db2.local.myip.com slon[3013]: [756-1] 2007-09-05  
> 19:17:32 PDT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 1312815
> Sep  5 19:17:32 tii-db2.local.myip.com slon[3013]: [757-1] 2007-09-05  
> 19:17:32 PDT DEBUG2 remoteWorkerThread_3: forward confirm 2,1312815  
> received by 3
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [758-1] 2007-09-05  
> 19:17:33 PDT DEBUG2 remoteListenThread_3: queue event 3,1319206 SYNC
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [759-1] 2007-09-05  
> 19:17:33 PDT DEBUG2 remoteListenThread_3: UNLISTEN
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [760-1] 2007-09-05  
> 19:17:33 PDT DEBUG2 remoteWorkerThread_3: Received event 3,1319206 SYNC
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [761-1] 2007-09-05  
> 19:17:33 PDT DEBUG3 calc sync size - last time: 1 last length: 3002  
> ideal: 100 proposed size: 3
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [762-1] 2007-09-05  
> 19:17:33 PDT DEBUG2 remoteWorkerThread_3: SYNC 1319206 processing
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [763-1] 2007-09-05  
> 19:17:33 PDT DEBUG2 remoteWorkerThread_3: no sets need syncing for  
> this event
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [764-1] 2007-09-05  
> 19:17:33 PDT ERROR  slon_connectdb: PQconnectdb("dbname=tii host=tii- 
> db1g.local.myip.com user=slony
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [764-2]   
> password=3l3phant") failed - could not connect to server: Connection  
> refused
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [764-3]      Is  
> the server running on host "tii-db1g.local.myip.com" and accepting
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [764-4]      TCP/ 
> IP connections on port 5432?
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [765-1] 2007-09-05  
> 19:17:33 PDT WARN   remoteListenThread_1: DB connection failed -  
> sleep 10 seconds
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [766-1] 2007-09-05  
> 19:17:33 PDT DEBUG2 remoteWorkerThread_1: SYNC 5748564 processing
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [767-1] 2007-09-05  
> 19:17:33 PDT ERROR  remoteWorkerThread_1: No pa_conninfo for data  
> provider 0
> Sep  5 19:17:33 tii-db2.local.myip.com slon[3013]: [768-1] 2007-09-05  
> 19:17:33 PDT DEBUG2 localListenThread: Received event 2,1312815 SYNC
> Sep  5 19:17:35 tii-db2.local.myip.com slon[3013]: [769-1] 2007-09-05  
> 19:17:35 PDT DEBUG2 remoteListenThread_3: LISTEN
> Sep  5 19:17:35 tii-db2.local.myip.com slon[3013]: [770-1] 2007-09-05  
> 19:17:35 PDT DEBUG2 syncThread: new sl_action_seq 1 - SYNC 1312816
> Sep  5 19:17:35 tii-db2.local.myip.com slon[3013]: [771-1] 2007-09-05  
> 19:17:35 PDT DEBUG2 remoteWorkerThread_3: forward confirm 2,1312816  
> received by 3
> Sep  5 19:17:36 tii-db2.local.myip.com slon[3013]: [772-1] 2007-09-05  
> 19:17:36 PDT DEBUG2 remoteListenThread_3: queue event 3,1319207 SYNC
> Sep  5 19:17:36 tii-db2.local.myip.com slon[3013]: [773-1] 2007-09-05  
> 19:17:36 PDT DEBUG2 remoteListenThread_3: UNLISTEN
> Sep  5 19:17:36 tii-db2.local.myip.com slon[3013]: [774-1] 2007-09-05  
> 19:17:36 PDT DEBUG2 remoteWorkerThread_3: Received event 3,1319207 SYNC
> Sep  5 19:17:36 tii-db2.local.myip.com slon[3013]: [775-1] 2007-09-05  
> 19:17:36 PDT DEBUG3 calc sync size - last time: 1 last length: 3009  
> ideal: 100 proposed size: 3

Are you sure that those environment variables were set when you ran that 
script? Because the script doesn't set them and for some reason, the 
subscription points to a node 0 as data provider. There are also error 
messages that there is no conninfo for node 0 and that one DB server is 
refusing connections.

It would help to see the content of the sl_node, sl_path, sl_subscribe 
tables of all nodes.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From JanWieck at Yahoo.com  Fri Sep  7 12:33:52 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Fri Sep  7 12:34:29 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <46E153D1.4060903@orange-ftgroup.com>
References: <46E153D1.4060903@orange-ftgroup.com>
Message-ID: <46E1A7A0.30401@Yahoo.com>

On 9/7/2007 9:36 AM, Cyril SCETBON wrote:
> Hi,
> 
> I got this configuration                Node1 --> Node2 (5 seconds late)
>                                                           |
>                                                           --> Node3 (2 
> hours late)
> 
> Node2 is processing each SYNC from Node3 and Node2, but Node3 is 
> processing each SYNC from Node2 but not from Node1 which is the origin 
> of the sets :
> 
> On Node3 we see  `grep processing 
> /var/log/slony1/node3-pns_profiles_preprod.log|awk '{print 
> $5}'|sort|uniq -c`
>      19 remoteWorkerThread_1:
>     963 remoteWorkerThread_2:
> 
> On Node2 we see `grep processing 
> /var/log/slony1/node2-pns_profiles_preprod.log |awk '{print 
> $5}'|sort|uniq -c`
>    1570 remoteWorkerThread_1:
>     865 remoteWorkerThread_3:
> 
> Why is there so many SYNC not processed on Node3 ???
> 
> Node3 got 22440 queue event and 25 Received event from 
> remoteWorkerThread_1, while Node2 got 4467 queue event and 1578 Received 
> event from the same worker.
> 
> Is there something to do ?

How about looking for some error messages?

What comes to mind would be that sl_event is grossly out of shape and 
that the event selection times out.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From dba at richyen.com  Fri Sep  7 16:24:32 2007
From: dba at richyen.com (Richard Yen)
Date: Fri Sep  7 16:25:18 2007
Subject: [Slony1-general] failover doesn't remove triggers
In-Reply-To: <5a0a9d6f0709071523q685c7a8y5e28af04ed965d8f@mail.gmail.com>
References: <EFF62083-4F1E-450C-A7E9-CF65A840D525@richyen.com>
	<d7df81620709061319r6f199c1cj32f8c0727a9264df@mail.gmail.com>
	<48644493-83F2-40F9-AD1A-2C2A969B5A64@richyen.com>
	<5a0a9d6f0709061600g5004212du3e761aa8162d6240@mail.gmail.com>
	<D70792C7-7275-4A94-B78F-7B6655B0A14B@richyen.com>
	<46E19FC3.6040508@Yahoo.com>
	<5a0a9d6f0709071523q685c7a8y5e28af04ed965d8f@mail.gmail.com>
Message-ID: <8C549CA2-309B-44EB-85EC-1D4498693B20@richyen.com>

> Are you sure that those environment variables were set when you ran  
> that
> script? Because the script doesn't set them and for some reason, the
> subscription points to a node 0 as data provider. There are also error
> messages that there is no conninfo for node 0 and that one DB  
> server is
> refusing connections.
>
> It would help to see the content of the sl_node, sl_path, sl_subscribe
> tables of all nodes.
>
> Shell variables turned out not to be a very good idea. We really  
> should re-write the "replicating my first database" and other  
> sections of the docs to move away from them. At the very least they  
> ought to be defined at the head of any script that uses them.
>
What would be the preferred method of executing the FAIL OVER command?

--Richard


From cscetbon.ext at orange-ftgroup.com  Sat Sep  8 13:28:08 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Sat Sep  8 13:28:44 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <46E1A7A0.30401@Yahoo.com>
References: <46E153D1.4060903@orange-ftgroup.com> <46E1A7A0.30401@Yahoo.com>
Message-ID: <46E305D8.3090502@orange-ftgroup.com>



Jan Wieck wrote:
> On 9/7/2007 9:36 AM, Cyril SCETBON wrote:
>> Hi,
>>
>> I got this configuration                Node1 --> Node2 (5 seconds late)
>>                                                           |
>>                                                           --> Node3 
>> (2 hours late)
>>
>> Node2 is processing each SYNC from Node3 and Node2, but Node3 is 
>> processing each SYNC from Node2 but not from Node1 which is the 
>> origin of the sets :
>>
>> On Node3 we see  `grep processing 
>> /var/log/slony1/node3-pns_profiles_preprod.log|awk '{print 
>> $5}'|sort|uniq -c`
>>      19 remoteWorkerThread_1:
>>     963 remoteWorkerThread_2:
>>
>> On Node2 we see `grep processing 
>> /var/log/slony1/node2-pns_profiles_preprod.log |awk '{print 
>> $5}'|sort|uniq -c`
>>    1570 remoteWorkerThread_1:
>>     865 remoteWorkerThread_3:
>>
>> Why is there so many SYNC not processed on Node3 ???
>>
>> Node3 got 22440 queue event and 25 Received event from 
>> remoteWorkerThread_1, while Node2 got 4467 queue event and 1578 
>> Received event from the same worker.
>>
>> Is there something to do ?
>
> How about looking for some error messages?
None.
>
> What comes to mind would be that sl_event is grossly out of shape and 
> that the event selection times out.
Seems vacuuming sl_log_1 takes too much time cause of vacuum_cost_delay 
and that selecting from this table use a seq scan. I'm investiguating.

Regards.
>
>
> Jan
>

-- 
Cyril SCETBON
From tim.bowden at westnet.com.au  Sat Sep  8 18:07:04 2007
From: tim.bowden at westnet.com.au (Tim Bowden)
Date: Sat Sep  8 18:08:16 2007
Subject: [Slony1-general] different masters for different tables
Message-ID: <1189300024.5736.21.camel@edoras>

Hi,

I'm looking at using slony for the first time.  I'd like to know if it's
possible to have different tables in a slave db replicated from
different master db's.

Just to outline the setup I'm looking at, I have (proposed) master db's
that are distributed in various geographical areas for performance
reasons that need to be replicated back to a central slave.  The
critical table in each master db (the only table needing to be
replicated) would have an identical data structure and RI model (except
for a constraint limiting the pk to that properly belonging to that
particular master db).

If possible the slave tables would actually be partitions of a "whole of
system" slave db (ie, children in a table inheritance relationship) in
order to provide a view of all the data in one slave table, though from
a first reading of the docs I suspect this is not possible as the table
schemas would be different from master to slave.

Regards,
Tim Bowden

From JanWieck at Yahoo.com  Sat Sep  8 19:47:47 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sat Sep  8 19:48:34 2007
Subject: [Slony1-general] slony_logshipper
Message-ID: <46E35ED3.3020606@Yahoo.com>

There is a (utterly undocumented) new utility that I just added to 
REL_1_2_STABLE and HEAD. It is called slony_logshipper and will be 
released with 1.2.12 as soon as somebody fixes the documentation problem 
of it.

As the name suggests, it is a utility that can be used (eventually by 
using slon's option -x) to pick up slony log archives (caused by option 
-a). It can currently do limited archive file processing, like filtering 
out a table, or an entire namespace, or renaming a table or an entire 
namespace. It can write the result into another file, or it can open a 
database connection and apply all resulting queries.

It can also issue pre- and post-processing commands like compressing or 
removing the archive file (or just throw it over the fence via scp).

So if anyone was thinking about developing some crude shell scripts that 
do anything with the log archives ... maybe you don't any more.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From plk.zuber at gmail.com  Sun Sep  9 03:49:26 2007
From: plk.zuber at gmail.com (=?UTF-8?Q?Filip_Rembia=C5=82kowski?=)
Date: Sun Sep  9 03:50:24 2007
Subject: [Slony1-general] different masters for different tables
In-Reply-To: <1189300024.5736.21.camel@edoras>
References: <1189300024.5736.21.camel@edoras>
Message-ID: <92869e660709090349v6ad365f0j21daa29910fb4dbb@mail.gmail.com>

2007/9/9, Tim Bowden <tim.bowden@westnet.com.au>:
> I'm looking at using slony for the first time.  I'd like to know if it's
> possible to have different tables in a slave db replicated from
> different master db's.
Yes.

> Just to outline the setup I'm looking at, I have (proposed) master db's
> that are distributed in various geographical areas for performance
> reasons that need to be replicated back to a central slave.  The
> critical table in each master db (the only table needing to be
> replicated) would have an identical data structure and RI model (except
> for a constraint limiting the pk to that properly belonging to that
> particular master db).
>
> If possible the slave tables would actually be partitions of a "whole of
> system" slave db (ie, children in a table inheritance relationship) in
> order to provide a view of all the data in one slave table,
Yes :) That's a neat idea and should be doable.
Slony has a concept of replication sets, and you can have different
set for each partition, as long as they have same structure.
Try to get more familiar with slony1 and it will be clear to you.

I recommend http://slony.info/documentation/, begin from
http://slony.info/documentation/concepts.html

>  though from
> a first reading of the docs I suspect this is not possible as the table
> schemas would be different from master to slave.

i don't get it, first you said that tables have identical structure,
and now you say table schemas are different.

For the setup you described  to work, it's enough that they have same
columns and that you have PK unique across whole set of partitions,
but this should be easy.



-- 
Filip Rembia?kowski
From tim.bowden at westnet.com.au  Sun Sep  9 07:56:08 2007
From: tim.bowden at westnet.com.au (Tim Bowden)
Date: Sun Sep  9 07:56:28 2007
Subject: [Slony1-general] different masters for different tables
In-Reply-To: <92869e660709090349v6ad365f0j21daa29910fb4dbb@mail.gmail.com>
References: <1189300024.5736.21.camel@edoras>
	<92869e660709090349v6ad365f0j21daa29910fb4dbb@mail.gmail.com>
Message-ID: <1189349768.5736.41.camel@edoras>

On Sun, 2007-09-09 at 11:49 +0100, Filip Rembia?kowski wrote:
> 2007/9/9, Tim Bowden <tim.bowden@westnet.com.au>:
> > I'm looking at using slony for the first time.  I'd like to know if it's
> > possible to have different tables in a slave db replicated from
> > different master db's.
> Yes.
> 

Great.  That's confirmed my understanding.

> > Just to outline the setup I'm looking at, I have (proposed) master db's
> > that are distributed in various geographical areas for performance
> > reasons that need to be replicated back to a central slave.  The
> > critical table in each master db (the only table needing to be
> > replicated) would have an identical data structure and RI model (except
> > for a constraint limiting the pk to that properly belonging to that
> > particular master db).
> >
> > If possible the slave tables would actually be partitions of a "whole of
> > system" slave db (ie, children in a table inheritance relationship) in
> > order to provide a view of all the data in one slave table,
> Yes :) That's a neat idea and should be doable.

Oh good, things are looking up.  Hopefully that will scale well as I've
got 100+ master db's.  Hmmm, I'm going to have to be careful with time
syncing all hosts and db/system management is going to be a job and a
half...

> Slony has a concept of replication sets, and you can have different
> set for each partition, as long as they have same structure.
> Try to get more familiar with slony1 and it will be clear to you.
> 
> I recommend http://slony.info/documentation/, begin from
> http://slony.info/documentation/concepts.html
> 

Ok, back to reading for me, and time to build up a test scenario to help
develop my understanding.

> >  though from
> > a first reading of the docs I suspect this is not possible as the table
> > schemas would be different from master to slave.
> 
> i don't get it, first you said that tables have identical structure,
> and now you say table schemas are different.
> 

*sigh*  That's just me being clear as mud as usual.  _I_ knew what I
meant, even if no one else did!  What I meant was the slave tables are
defined as inherited tables, while the masters are not, though they
share the same field structures.  It seems from what you are saying that
this is ok, and not a problem as I suspected.

> For the setup you described  to work, it's enough that they have same
> columns and that you have PK unique across whole set of partitions,
> but this should be easy.

Easy?  That's what I like to hear!

Thanks,
Tim Bowden

From plk.zuber at gmail.com  Sun Sep  9 10:58:53 2007
From: plk.zuber at gmail.com (=?UTF-8?Q?Filip_Rembia=C5=82kowski?=)
Date: Sun Sep  9 10:59:14 2007
Subject: [Slony1-general] different masters for different tables
In-Reply-To: <1189349768.5736.41.camel@edoras>
References: <1189300024.5736.21.camel@edoras>
	<92869e660709090349v6ad365f0j21daa29910fb4dbb@mail.gmail.com>
	<1189349768.5736.41.camel@edoras>
Message-ID: <92869e660709091058p4d23c096w82c5ac388ea8fa9b@mail.gmail.com>

2007/9/9, Tim Bowden <tim.bowden@westnet.com.au>:

>  Hopefully that will scale well as I've
> got 100+ master db's.

over 100 partitions? you should be careful as slony1 has some
communication overhead  which grows quadratically with the number of
nodes in a cluster.

google for "slony communication costs"

I'm not sure if it applies to your situation though... I've never
tested such setup, maybe we should wait untill someone more
experienced gives a word about it

maybe I should not say this here ... but at worst, you will have to
drop slony in favour of other (simpler) solution - like home-made
trigger-based tool or other replication engine (londiste?)
From JanWieck at Yahoo.com  Sun Sep  9 14:27:23 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sun Sep  9 14:28:05 2007
Subject: [Slony1-general] different masters for different tables
In-Reply-To: <1189300024.5736.21.camel@edoras>
References: <1189300024.5736.21.camel@edoras>
Message-ID: <46E4653B.2090402@Yahoo.com>

On 9/8/2007 9:07 PM, Tim Bowden wrote:
> Hi,
> 
> I'm looking at using slony for the first time.  I'd like to know if it's
> possible to have different tables in a slave db replicated from
> different master db's.

It was part of the initial concept and the initial implementation. If it 
doesn't work now, that'd be a bug.

> Just to outline the setup I'm looking at, I have (proposed) master db's
> that are distributed in various geographical areas for performance
> reasons that need to be replicated back to a central slave.  The
> critical table in each master db (the only table needing to be
> replicated) would have an identical data structure and RI model (except
> for a constraint limiting the pk to that properly belonging to that
> particular master db).
> 
> If possible the slave tables would actually be partitions of a "whole of
> system" slave db (ie, children in a table inheritance relationship) in
> order to provide a view of all the data in one slave table, though from
> a first reading of the docs I suspect this is not possible as the table
> schemas would be different from master to slave.

As of right now, slon itself cannot change the table or namespace on the 
fly during replication. So every table that is actually replicated 
inside of your cluster must have a unique fully qualified name. This 
could in your case be achieved by creating a partition structure where 
even on the different origin servers, the table in question has an 
(always empty) master and just the one, location specific child 
partition. The central slave then would have all those partitions and 
replicate into them. That way, the application would see the same table 
name everywhere, containing the site specific data.

As another idea, if any site only ever updates its own key range, 
nothing would prevent you from having all partitions everywhere. Each 
location would be origin of one partition while every other location 
would subscribe to it. That way, the "local" data is read/write and all 
remote data is available readonly. Slony doesn't distinguish between 
master and slave nodes. Since every table can have a different "origin", 
each node can actually be master and slave at the same time, with 
respect to different tables, that is.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From JanWieck at Yahoo.com  Sun Sep  9 17:46:54 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sun Sep  9 17:47:41 2007
Subject: [Slony1-general] different masters for different tables
In-Reply-To: <92869e660709091058p4d23c096w82c5ac388ea8fa9b@mail.gmail.com>
References: <1189300024.5736.21.camel@edoras>	<92869e660709090349v6ad365f0j21daa29910fb4dbb@mail.gmail.com>	<1189349768.5736.41.camel@edoras>
	<92869e660709091058p4d23c096w82c5ac388ea8fa9b@mail.gmail.com>
Message-ID: <46E493FE.6080101@Yahoo.com>

On 9/9/2007 1:58 PM, Filip Rembia?kowski wrote:
> 2007/9/9, Tim Bowden <tim.bowden@westnet.com.au>:
> 
>>  Hopefully that will scale well as I've
>> got 100+ master db's.
> 
> over 100 partitions? you should be careful as slony1 has some
> communication overhead  which grows quadratically with the number of
> nodes in a cluster.
> 
> google for "slony communication costs"
> 
> I'm not sure if it applies to your situation though... I've never
> tested such setup, maybe we should wait untill someone more
> experienced gives a word about it
> 
> maybe I should not say this here ... but at worst, you will have to
> drop slony in favour of other (simpler) solution - like home-made
> trigger-based tool or other replication engine (londiste?)

No problem with saying that here. It is a valid concern and points to a 
known weakness in Slony, so Tim knows right away what to test first (now 
having a 100+ node test cluster is of cause a different story).

The new logshipper tool I just added to the CVS tree (not released yet) 
might be of help here. It would certainly be possible to divide the 
whole bunch of locations into several regions and replicate each of them 
into a region specific central slave. All those would use slony archives 
and the logshipper to consolidate into one central database.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From tim.bowden at westnet.com.au  Sun Sep  9 18:11:26 2007
From: tim.bowden at westnet.com.au (Tim Bowden)
Date: Sun Sep  9 18:12:13 2007
Subject: [Slony1-general] different masters for different tables
In-Reply-To: <46E4653B.2090402@Yahoo.com>
References: <1189300024.5736.21.camel@edoras>  <46E4653B.2090402@Yahoo.com>
Message-ID: <1189386686.5736.58.camel@edoras>

On Sun, 2007-09-09 at 17:27 -0400, Jan Wieck wrote:
> On 9/8/2007 9:07 PM, Tim Bowden wrote:
> > Hi,
> > 
> > I'm looking at using slony for the first time.  I'd like to know if it's
> > possible to have different tables in a slave db replicated from
> > different master db's.
> 
> It was part of the initial concept and the initial implementation. If it 
> doesn't work now, that'd be a bug.
> 
> > Just to outline the setup I'm looking at, I have (proposed) master db's
> > that are distributed in various geographical areas for performance
> > reasons that need to be replicated back to a central slave.  The
> > critical table in each master db (the only table needing to be
> > replicated) would have an identical data structure and RI model (except
> > for a constraint limiting the pk to that properly belonging to that
> > particular master db).
> > 
> > If possible the slave tables would actually be partitions of a "whole of
> > system" slave db (ie, children in a table inheritance relationship) in
> > order to provide a view of all the data in one slave table, though from
> > a first reading of the docs I suspect this is not possible as the table
> > schemas would be different from master to slave.
> 
> As of right now, slon itself cannot change the table or namespace on the 
> fly during replication. So every table that is actually replicated 
> inside of your cluster must have a unique fully qualified name. This 
> could in your case be achieved by creating a partition structure where 
> even on the different origin servers, the table in question has an 
> (always empty) master and just the one, location specific child 
> partition. The central slave then would have all those partitions and 
> replicate into them. That way, the application would see the same table 
> name everywhere, containing the site specific data.
> 

Ah yes, this would simplify things.  Thanks.

> As another idea, if any site only ever updates its own key range, 
> nothing would prevent you from having all partitions everywhere. Each 
> location would be origin of one partition while every other location 
> would subscribe to it. That way, the "local" data is read/write and all 
> remote data is available readonly. Slony doesn't distinguish between 
> master and slave nodes. Since every table can have a different "origin", 
> each node can actually be master and slave at the same time, with 
> respect to different tables, that is.
> 
> 

I want to avoid communications between outlying nodes.  If my
understanding is correct, this is what would lead to the exponential
growth in comms that has been flagged as a problem with so many nodes.
Each outlying node also has no need of data collected at any other node.
In this case, it's very much location specific (geometries and
associated attribute data in a postgis database).  If each outlying node
replicates only with the central node, does this problem become
manageable?  Is it possible (or needed) to "hide" the existence of
multiple outlying "master" nodes from each other?

> Jan
> 
Regards,
Tim Bowden

From tim.bowden at westnet.com.au  Sun Sep  9 18:23:33 2007
From: tim.bowden at westnet.com.au (Tim Bowden)
Date: Sun Sep  9 18:24:18 2007
Subject: [Slony1-general] different masters for different tables
In-Reply-To: <46E493FE.6080101@Yahoo.com>
References: <1189300024.5736.21.camel@edoras>
	<92869e660709090349v6ad365f0j21daa29910fb4dbb@mail.gmail.com>
	<1189349768.5736.41.camel@edoras>
	<92869e660709091058p4d23c096w82c5ac388ea8fa9b@mail.gmail.com>
	<46E493FE.6080101@Yahoo.com>
Message-ID: <1189387413.5736.63.camel@edoras>

On Sun, 2007-09-09 at 20:46 -0400, Jan Wieck wrote:
> On 9/9/2007 1:58 PM, Filip Rembia?kowski wrote:
> > 2007/9/9, Tim Bowden <tim.bowden@westnet.com.au>:
> > 
> >>  Hopefully that will scale well as I've
> >> got 100+ master db's.
> > 
> > over 100 partitions? you should be careful as slony1 has some
> > communication overhead  which grows quadratically with the number of
> > nodes in a cluster.
> > 
> > google for "slony communication costs"
> > 
> > I'm not sure if it applies to your situation though... I've never
> > tested such setup, maybe we should wait untill someone more
> > experienced gives a word about it
> > 
> > maybe I should not say this here ... but at worst, you will have to
> > drop slony in favour of other (simpler) solution - like home-made
> > trigger-based tool or other replication engine (londiste?)
> 
> No problem with saying that here. It is a valid concern and points to a 
> known weakness in Slony, so Tim knows right away what to test first (now 
> having a 100+ node test cluster is of cause a different story).
> 
Don't I know it.  Still haven't worked out how I'm going to build a test
system with each node carrying a reasonable load.

> The new logshipper tool I just added to the CVS tree (not released yet) 
> might be of help here. It would certainly be possible to divide the 
> whole bunch of locations into several regions and replicate each of them 
> into a region specific central slave. All those would use slony archives 
> and the logshipper to consolidate into one central database.
> 
> 

Ah, now there's a good idea.  Worst case I was going to revert to
logshipping for as many nodes as required to get it going so anything
better is sweet candy.

> Jan
> 

Thanks,
Tim Bowden

From tim.bowden at westnet.com.au  Sun Sep  9 19:54:13 2007
From: tim.bowden at westnet.com.au (Tim Bowden)
Date: Sun Sep  9 19:55:19 2007
Subject: [Slony1-general] Flakey network links
Message-ID: <1189392853.5736.69.camel@edoras>

>From the docs: 
cases where Slony-I probably won't work out well would include:

      * Sites where connectivity is really "flakey"
        
      * Replication to nodes that are unpredictably connected.

How flakey/unpredictably connected can nodes be before it all goes
haywire?  Is it time critical, or load critical?  If an origin node goes
offline for a day, but there are only a couple of transactions, will
that be a problem?  If an origin node goes offline for a few minutes but
there are hundreds of transactions, what's the recovery scenario look
like?

Thanks,
Tim Bowden

From tim.bowden at westnet.com.au  Sun Sep  9 20:06:06 2007
From: tim.bowden at westnet.com.au (Tim Bowden)
Date: Sun Sep  9 20:06:57 2007
Subject: [Slony1-general] Flakey network links
In-Reply-To: <1189392853.5736.69.camel@edoras>
References: <1189392853.5736.69.camel@edoras>
Message-ID: <1189393566.5736.79.camel@edoras>

On Mon, 2007-09-10 at 10:54 +0800, Tim Bowden wrote:
> >From the docs: 
> cases where Slony-I probably won't work out well would include:
> 
>       * Sites where connectivity is really "flakey"
>         
>       * Replication to nodes that are unpredictably connected.
> 
> How flakey/unpredictably connected can nodes be before it all goes
> haywire?  Is it time critical, or load critical?  If an origin node goes
> offline for a day, but there are only a couple of transactions, will
> that be a problem?  If an origin node goes offline for a few minutes but
> there are hundreds of transactions, what's the recovery scenario look
> like?
> 

As a follow up, I noticed a post a week ago or thereabouts I think it
was that mentioned bouncing nodes between standard replication and
updating by log shipping, but it wasn't currently a viable solution.  Is
this likely to ever become a viable solution, as it would solve the
problem of unpredictable network links (at least for some use cases)?

Regards,
Tim Bowden

From cscetbon.ext at orange-ftgroup.com  Mon Sep 10 07:07:09 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Mon Sep 10 07:07:19 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
Message-ID: <46E54F8D.5010500@orange-ftgroup.com>

Hi,

We're hitting 400 requests per second and noticed that sl_log_? are 
growing a lot. This is also due to the fact that our tables have a lot 
of columns (more that 100). We noticed that slony stores each column and 
its value for each request in sl_log_x. Would it not be more optimized 
to store just the user request ? Actually, a user is just updating a few 
column, or inserting a tuple by giving some attributes but not all, 
however as slony stores every column with its value it sl_log_x, these 
tables are growing very fast :-(

Another question :

How logswitch is used in slony ? I try a logswitch.start() and I had to 
move date between sl_log_1 and sl_log_2 to finish it. How does it work ? 
which thread is using this function ?

Regards.

-- 
Cyril SCETBON
From JanWieck at Yahoo.com  Mon Sep 10 07:51:31 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Mon Sep 10 07:51:50 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E54F8D.5010500@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com>
Message-ID: <46E559F3.60602@Yahoo.com>

On 9/10/2007 10:07 AM, Cyril SCETBON wrote:
> Hi,
> 
> We're hitting 400 requests per second and noticed that sl_log_? are 
> growing a lot. This is also due to the fact that our tables have a lot 
> of columns (more that 100). We noticed that slony stores each column and 
> its value for each request in sl_log_x. Would it not be more optimized 
> to store just the user request ? Actually, a user is just updating a few 
> column, or inserting a tuple by giving some attributes but not all, 
> however as slony stores every column with its value it sl_log_x, these 
> tables are growing very fast :-(

Slony only logs columns where the value actually has changed. Please 
explain in detail how you propose that the log table would contain which 
columns have changed without naming them.

> How logswitch is used in slony ? I try a logswitch.start() and I had to 
> move date between sl_log_1 and sl_log_2 to finish it. How does it work ? 
> which thread is using this function ?

Slony does this by itself. Once a logswitch is initiated, slony waits 
until the regular cleanup procedure has removed all log tuples from the 
old log table. At that point, it will truncate the table (instead of 
vacuuming it) and finish the logswitch.

Moving log tuples between the tables manually is a good way to screw up 
replication. Are you actually 100% sure that slony before, during and 
right after that operation was in union select mode scanning both logs 
together?


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From cscetbon.ext at orange-ftgroup.com  Mon Sep 10 08:06:51 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Mon Sep 10 08:07:01 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E559F3.60602@Yahoo.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>
Message-ID: <46E55D8B.3050003@orange-ftgroup.com>



Jan Wieck wrote:
> On 9/10/2007 10:07 AM, Cyril SCETBON wrote:
>> Hi,
>>
>> We're hitting 400 requests per second and noticed that sl_log_? are 
>> growing a lot. This is also due to the fact that our tables have a 
>> lot of columns (more that 100). We noticed that slony stores each 
>> column and its value for each request in sl_log_x. Would it not be 
>> more optimized to store just the user request ? Actually, a user is 
>> just updating a few column, or inserting a tuple by giving some 
>> attributes but not all, however as slony stores every column with its 
>> value it sl_log_x, these tables are growing very fast :-(
>
> Slony only logs columns where the value actually has changed. Please 
> explain in detail how you propose that the log table would contain 
> which columns have changed without naming them.
when I execute this command on the master :

 insert into t1(ise) values('cyril100001');

I can see in sl_log_1 :

psql>select log_cmddata from sl_log_1;
 (ise,id,id2) values ('cyril100001','24161',NULL)

dbtest=# \d t1;
                                Table "public.t1"
 Column |         Type          |                    
Modifiers                   
--------+-----------------------+-------------------------------------------------
 ise    | character varying(54) | not null
 id     | integer               | not null default 
nextval('t1_id_seq'::regclass)
 id2    | integer               |
Indexes:
    "t1_pkey" PRIMARY KEY, btree (ise)
Triggers:
    "_CLUSTER1_logtrigger_1" AFTER INSERT OR DELETE OR UPDATE ON t1 FOR 
EACH ROW EXECUTE PROCEDURE "_CLUSTER1".logtrigger('_CLUSTER1', '1', 'kvv')

I agree for id which is an auto_increment but not for id2 :-(

In another plateform my table has more than  100 columns as said earlier 
and that's really matter :-(






>
>> How logswitch is used in slony ? I try a logswitch.start() and I had 
>> to move date between sl_log_1 and sl_log_2 to finish it. How does it 
>> work ? which thread is using this function ?
>
> Slony does this by itself. Once a logswitch is initiated, slony waits 
> until the regular cleanup procedure has removed all log tuples from 
> the old log table. At that point, it will truncate the table (instead 
> of vacuuming it) and finish the logswitch.
>
> Moving log tuples between the tables manually is a good way to screw 
> up replication. Are you actually 100% sure that slony before, during 
> and right after that operation was in union select mode scanning both 
> logs together?
>
Slony on slave was stopped, and no DML have been done during this operation.
>
> Jan
>

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From cbbrowne at ca.afilias.info  Mon Sep 10 09:40:50 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Sep 10 09:41:10 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E55D8B.3050003@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>
	<46E55D8B.3050003@orange-ftgroup.com>
Message-ID: <46E57392.4000706@ca.afilias.info>

Cyril SCETBON wrote:
>
>
> Jan Wieck wrote:
>> On 9/10/2007 10:07 AM, Cyril SCETBON wrote:
>>> Hi,
>>>
>>> We're hitting 400 requests per second and noticed that sl_log_? are 
>>> growing a lot. This is also due to the fact that our tables have a 
>>> lot of columns (more that 100). We noticed that slony stores each 
>>> column and its value for each request in sl_log_x. Would it not be 
>>> more optimized to store just the user request ? Actually, a user is 
>>> just updating a few column, or inserting a tuple by giving some 
>>> attributes but not all, however as slony stores every column with 
>>> its value it sl_log_x, these tables are growing very fast :-(
>>
>> Slony only logs columns where the value actually has changed. Please 
>> explain in detail how you propose that the log table would contain 
>> which columns have changed without naming them.
> when I execute this command on the master :
>
> insert into t1(ise) values('cyril100001');
>
> I can see in sl_log_1 :
>
> psql>select log_cmddata from sl_log_1;
> (ise,id,id2) values ('cyril100001','24161',NULL)
>
> dbtest=# \d t1;
>                                Table "public.t1"
> Column |         Type          |                    
> Modifiers                   
> --------+-----------------------+------------------------------------------------- 
>
> ise    | character varying(54) | not null
> id     | integer               | not null default 
> nextval('t1_id_seq'::regclass)
> id2    | integer               |
> Indexes:
>    "t1_pkey" PRIMARY KEY, btree (ise)
> Triggers:
>    "_CLUSTER1_logtrigger_1" AFTER INSERT OR DELETE OR UPDATE ON t1 FOR 
> EACH ROW EXECUTE PROCEDURE "_CLUSTER1".logtrigger('_CLUSTER1', '1', 
> 'kvv')
>
> I agree for id which is an auto_increment but not for id2 :-(
>
> In another plateform my table has more than  100 columns as said 
> earlier and that's really matter :-(
Jan's request seems to remain perfectly good...

"Please explain in detail how you propose that the log table would 
contain which columns have changed without naming them."

It is *not* obvious how to avoid naming all of the columns.  It is not 
safe to simply assume "that column was null so we may omit it" - 
different nodes may be configured differently, and it may well be 
important to actually have that NULL value.



From cscetbon.ext at orange-ftgroup.com  Mon Sep 10 09:49:31 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Mon Sep 10 09:49:44 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E57392.4000706@ca.afilias.info>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>	
	<46E55D8B.3050003@orange-ftgroup.com>
	<46E57392.4000706@ca.afilias.info>
Message-ID: <46E5759B.5090709@orange-ftgroup.com>



Christopher Browne wrote:
> Cyril SCETBON wrote:
>>
>>
>> Jan Wieck wrote:
>>> On 9/10/2007 10:07 AM, Cyril SCETBON wrote:
>>>> Hi,
>>>>
>>>> We're hitting 400 requests per second and noticed that sl_log_? are 
>>>> growing a lot. This is also due to the fact that our tables have a 
>>>> lot of columns (more that 100). We noticed that slony stores each 
>>>> column and its value for each request in sl_log_x. Would it not be 
>>>> more optimized to store just the user request ? Actually, a user is 
>>>> just updating a few column, or inserting a tuple by giving some 
>>>> attributes but not all, however as slony stores every column with 
>>>> its value it sl_log_x, these tables are growing very fast :-(
>>>
>>> Slony only logs columns where the value actually has changed. Please 
>>> explain in detail how you propose that the log table would contain 
>>> which columns have changed without naming them.
>> when I execute this command on the master :
>>
>> insert into t1(ise) values('cyril100001');
>>
>> I can see in sl_log_1 :
>>
>> psql>select log_cmddata from sl_log_1;
>> (ise,id,id2) values ('cyril100001','24161',NULL)
>>
>> dbtest=# \d t1;
>>                                Table "public.t1"
>> Column |         Type          |                    
>> Modifiers                   
>> --------+-----------------------+------------------------------------------------- 
>>
>> ise    | character varying(54) | not null
>> id     | integer               | not null default 
>> nextval('t1_id_seq'::regclass)
>> id2    | integer               |
>> Indexes:
>>    "t1_pkey" PRIMARY KEY, btree (ise)
>> Triggers:
>>    "_CLUSTER1_logtrigger_1" AFTER INSERT OR DELETE OR UPDATE ON t1 
>> FOR EACH ROW EXECUTE PROCEDURE "_CLUSTER1".logtrigger('_CLUSTER1', 
>> '1', 'kvv')
>>
>> I agree for id which is an auto_increment but not for id2 :-(
>>
>> In another plateform my table has more than  100 columns as said 
>> earlier and that's really matter :-(
> Jan's request seems to remain perfectly good...
>
> "Please explain in detail how you propose that the log table would 
> contain which columns have changed without naming them."
>
> It is *not* obvious how to avoid naming all of the columns.  It is not 
> safe to simply assume "that column was null so we may omit it" - 
> different nodes may be configured differently, and it may well be 
> important to actually have that NULL value.
I was just thinking of using the same way as other statement based 
replication way like does mysql, that is to say just log the request 
that user did. However, I forgot that slony uses triggers to log 
requests :-( Maybe finding a way to know which current request is done 
on the table for which the trigger has been called would be possible ?
>
>
>

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From JanWieck at Yahoo.com  Mon Sep 10 10:14:00 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Mon Sep 10 10:14:24 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E55D8B.3050003@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>
	<46E55D8B.3050003@orange-ftgroup.com>
Message-ID: <46E57B58.4060007@Yahoo.com>

On 9/10/2007 11:06 AM, Cyril SCETBON wrote:
> 
> Jan Wieck wrote:
>> On 9/10/2007 10:07 AM, Cyril SCETBON wrote:
>>> Hi,
>>>
>>> We're hitting 400 requests per second and noticed that sl_log_? are 
>>> growing a lot. This is also due to the fact that our tables have a 
>>> lot of columns (more that 100). We noticed that slony stores each 
>>> column and its value for each request in sl_log_x. Would it not be 
>>> more optimized to store just the user request ? Actually, a user is 
>>> just updating a few column, or inserting a tuple by giving some 
>>> attributes but not all, however as slony stores every column with its 
>>> value it sl_log_x, these tables are growing very fast :-(
>>
>> Slony only logs columns where the value actually has changed. Please 
>> explain in detail how you propose that the log table would contain 
>> which columns have changed without naming them.
> when I execute this command on the master :
> 
>  insert into t1(ise) values('cyril100001');
> 
> I can see in sl_log_1 :
> 
> psql>select log_cmddata from sl_log_1;
>  (ise,id,id2) values ('cyril100001','24161',NULL)

How can Slony know that none of those column might have a default value 
different from the value explicitly given *on any subscriber out there*?

> 
> dbtest=# \d t1;
>                                 Table "public.t1"
>  Column |         Type          |                    
> Modifiers                   
> --------+-----------------------+-------------------------------------------------
>  ise    | character varying(54) | not null
>  id     | integer               | not null default 
> nextval('t1_id_seq'::regclass)
>  id2    | integer               |
> Indexes:
>     "t1_pkey" PRIMARY KEY, btree (ise)
> Triggers:
>     "_CLUSTER1_logtrigger_1" AFTER INSERT OR DELETE OR UPDATE ON t1 FOR 
> EACH ROW EXECUTE PROCEDURE "_CLUSTER1".logtrigger('_CLUSTER1', '1', 'kvv')
> 
> I agree for id which is an auto_increment but not for id2 :-(
> 
> In another plateform my table has more than  100 columns as said earlier 
> and that's really matter :-(

Feel free to provide a patch that implements an optional, runtime 
configurable optimization to suppress columns that are NULL on INSERT.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From JanWieck at Yahoo.com  Mon Sep 10 10:15:49 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Mon Sep 10 10:16:16 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E57392.4000706@ca.afilias.info>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>
	<46E55D8B.3050003@orange-ftgroup.com>
	<46E57392.4000706@ca.afilias.info>
Message-ID: <46E57BC5.20804@Yahoo.com>

On 9/10/2007 12:40 PM, Christopher Browne wrote:
> Cyril SCETBON wrote:
>>
>>
>> Jan Wieck wrote:
>>> On 9/10/2007 10:07 AM, Cyril SCETBON wrote:
>>>> Hi,
>>>>
>>>> We're hitting 400 requests per second and noticed that sl_log_? are 
>>>> growing a lot. This is also due to the fact that our tables have a 
>>>> lot of columns (more that 100). We noticed that slony stores each 
>>>> column and its value for each request in sl_log_x. Would it not be 
>>>> more optimized to store just the user request ? Actually, a user is 
>>>> just updating a few column, or inserting a tuple by giving some 
>>>> attributes but not all, however as slony stores every column with 
>>>> its value it sl_log_x, these tables are growing very fast :-(
>>>
>>> Slony only logs columns where the value actually has changed. Please 
>>> explain in detail how you propose that the log table would contain 
>>> which columns have changed without naming them.
>> when I execute this command on the master :
>>
>> insert into t1(ise) values('cyril100001');
>>
>> I can see in sl_log_1 :
>>
>> psql>select log_cmddata from sl_log_1;
>> (ise,id,id2) values ('cyril100001','24161',NULL)
>>
>> dbtest=# \d t1;
>>                                Table "public.t1"
>> Column |         Type          |                    
>> Modifiers                   
>> --------+-----------------------+------------------------------------------------- 
>>
>> ise    | character varying(54) | not null
>> id     | integer               | not null default 
>> nextval('t1_id_seq'::regclass)
>> id2    | integer               |
>> Indexes:
>>    "t1_pkey" PRIMARY KEY, btree (ise)
>> Triggers:
>>    "_CLUSTER1_logtrigger_1" AFTER INSERT OR DELETE OR UPDATE ON t1 FOR 
>> EACH ROW EXECUTE PROCEDURE "_CLUSTER1".logtrigger('_CLUSTER1', '1', 
>> 'kvv')
>>
>> I agree for id which is an auto_increment but not for id2 :-(
>>
>> In another plateform my table has more than  100 columns as said 
>> earlier and that's really matter :-(
> Jan's request seems to remain perfectly good...
> 
> "Please explain in detail how you propose that the log table would 
> contain which columns have changed without naming them."
> 
> It is *not* obvious how to avoid naming all of the columns.  It is not 
> safe to simply assume "that column was null so we may omit it" - 
> different nodes may be configured differently, and it may well be 
> important to actually have that NULL value.

Neither would it be safe to assume all subscribers actually have all 
tables with the exact identical column order. One might have been 
created with a newer version of the schema, while another one was 
upgraded with ALTER TABLE ADD COLUMN.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From JanWieck at Yahoo.com  Mon Sep 10 10:26:38 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Mon Sep 10 10:27:06 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E5759B.5090709@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>	
	<46E55D8B.3050003@orange-ftgroup.com>
	<46E57392.4000706@ca.afilias.info>
	<46E5759B.5090709@orange-ftgroup.com>
Message-ID: <46E57E4E.2090807@Yahoo.com>

On 9/10/2007 12:49 PM, Cyril SCETBON wrote:
> 
> Christopher Browne wrote:
>> Cyril SCETBON wrote:
>>>
>>>
>>> Jan Wieck wrote:
>>>> On 9/10/2007 10:07 AM, Cyril SCETBON wrote:
>>>>> Hi,
>>>>>
>>>>> We're hitting 400 requests per second and noticed that sl_log_? are 
>>>>> growing a lot. This is also due to the fact that our tables have a 
>>>>> lot of columns (more that 100). We noticed that slony stores each 
>>>>> column and its value for each request in sl_log_x. Would it not be 
>>>>> more optimized to store just the user request ? Actually, a user is 
>>>>> just updating a few column, or inserting a tuple by giving some 
>>>>> attributes but not all, however as slony stores every column with 
>>>>> its value it sl_log_x, these tables are growing very fast :-(
>>>>
>>>> Slony only logs columns where the value actually has changed. Please 
>>>> explain in detail how you propose that the log table would contain 
>>>> which columns have changed without naming them.
>>> when I execute this command on the master :
>>>
>>> insert into t1(ise) values('cyril100001');
>>>
>>> I can see in sl_log_1 :
>>>
>>> psql>select log_cmddata from sl_log_1;
>>> (ise,id,id2) values ('cyril100001','24161',NULL)
>>>
>>> dbtest=# \d t1;
>>>                                Table "public.t1"
>>> Column |         Type          |                    
>>> Modifiers                   
>>> --------+-----------------------+------------------------------------------------- 
>>>
>>> ise    | character varying(54) | not null
>>> id     | integer               | not null default 
>>> nextval('t1_id_seq'::regclass)
>>> id2    | integer               |
>>> Indexes:
>>>    "t1_pkey" PRIMARY KEY, btree (ise)
>>> Triggers:
>>>    "_CLUSTER1_logtrigger_1" AFTER INSERT OR DELETE OR UPDATE ON t1 
>>> FOR EACH ROW EXECUTE PROCEDURE "_CLUSTER1".logtrigger('_CLUSTER1', 
>>> '1', 'kvv')
>>>
>>> I agree for id which is an auto_increment but not for id2 :-(
>>>
>>> In another plateform my table has more than  100 columns as said 
>>> earlier and that's really matter :-(
>> Jan's request seems to remain perfectly good...
>>
>> "Please explain in detail how you propose that the log table would 
>> contain which columns have changed without naming them."
>>
>> It is *not* obvious how to avoid naming all of the columns.  It is not 
>> safe to simply assume "that column was null so we may omit it" - 
>> different nodes may be configured differently, and it may well be 
>> important to actually have that NULL value.
> I was just thinking of using the same way as other statement based 
> replication way like does mysql, that is to say just log the request 
> that user did. However, I forgot that slony uses triggers to log 
> requests :-( Maybe finding a way to know which current request is done 
> on the table for which the trigger has been called would be possible ?

Turning Slony into a statement based replication system would make it 
far worse. Queries depend on the exact transaction commit order with 
respect to the exact rows that are visible to them. That in addition to 
the non-deterministic behavior of sequential scans and a myriad of 
functions ... how do you expect some query like

     update mytable set foo = nextval('someseq') where foo is null;

to lead to exactly the same result on two different databases? Not even 
the order in which the rows are processed is defined.

Compared to Postgres, MySQL is a fairly limited system feature wise. Yet 
with their limited functionality the MySQL user manual already states 
that several features are not supported by their statement based 
replication. What do you think the corresponding documentation for Slony 
would look like?


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From andrew.george.hammond at gmail.com  Mon Sep 10 10:34:21 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Mon Sep 10 10:34:38 2007
Subject: [Slony1-general] Flakey network links
In-Reply-To: <1189393566.5736.79.camel@edoras>
References: <1189392853.5736.69.camel@edoras> <1189393566.5736.79.camel@edoras>
Message-ID: <5a0a9d6f0709101034kc33b99xa2d4fa77fd0c83d0@mail.gmail.com>

On 9/9/07, Tim Bowden <tim.bowden@westnet.com.au> wrote:
>
> On Mon, 2007-09-10 at 10:54 +0800, Tim Bowden wrote:
> > >From the docs:
> > cases where Slony-I probably won't work out well would include:
> >
> >       * Sites where connectivity is really "flakey"
> >
> >       * Replication to nodes that are unpredictably connected.
> >
> > How flakey/unpredictably connected can nodes be before it all goes
> > haywire?  Is it time critical, or load critical?


Yes, and yes.

> If an origin node goes
> > offline for a day, but there are only a couple of transactions, will
> > that be a problem?  If an origin node goes offline for a few minutes but
> > there are hundreds of transactions, what's the recovery scenario look
> > like?
>

Assuming your run each slon either on the same box as the database it's
supporting or in the same LAN, this is probably survivable. You will need to
restart your slons every time the network status for _any_ of your databases
changes. And yes, detecting and handling this correctly is likely to get
complicated.

Your slons will generate transactions regularly on all nodes in the form of
SYNCs. These need to be propagated between all nodes and then applied. Once
SYNCs (and other events) have been applied, confirmation messages are
propagated between all nodes. Once all nodes have applied events, then the
cleanup thread on each node can remove the information necessary for
confirmed events.

For the cases you mention above, the obvious failure scenarios are as
follows.
1) Network failures at a rate where a slon can not process all the items in
some event before getting reset.
2) Any one node being down long enough to grow sl_log_n to the point that it
enters the "death spiral" (becomes so large that maintenance costs cause it
to grow faster than it can be consumed).

To quote Jan's concept paper (which you really ought to read before going
further in this discussion:
http://developer.postgresql.org/~wieck/slony1/Slony-I-concept.pdf), "Neither
offline nodes that only become available for sporadic synchronization (the
salesman on the road) nor ... will be supported..."

As a follow up, I noticed a post a week ago or thereabouts I think it
> was that mentioned bouncing nodes between standard replication and
> updating by log shipping, but it wasn't currently a viable solution.  Is
> this likely to ever become a viable solution, as it would solve the
> problem of unpredictable network links (at least for some use cases)?
>

That sounds kinda complicated. Has anyone written a proposal for how to do
it yet? It's taken us almost 2 years to get log-shipping to the point where
it seems seriously viable. The project has existed for something approaching
4 years...

Andrew
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070910/=
45f96493/attachment.htm
From cscetbon.ext at orange-ftgroup.com  Mon Sep 10 13:01:27 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Mon Sep 10 13:01:54 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E57E4E.2090807@Yahoo.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>	
	<46E55D8B.3050003@orange-ftgroup.com>
	<46E57392.4000706@ca.afilias.info>
	<46E5759B.5090709@orange-ftgroup.com> <46E57E4E.2090807@Yahoo.com>
Message-ID: <46E5A297.3090309@orange-ftgroup.com>



Jan Wieck wrote:
> On 9/10/2007 12:49 PM, Cyril SCETBON wrote:
>>
>> Christopher Browne wrote:
>>> Cyril SCETBON wrote:
>>>>
>>>>
>>>> Jan Wieck wrote:
>>>>> On 9/10/2007 10:07 AM, Cyril SCETBON wrote:
>>>>>> Hi,
>>>>>>
>>>>>> We're hitting 400 requests per second and noticed that sl_log_? 
>>>>>> are growing a lot. This is also due to the fact that our tables 
>>>>>> have a lot of columns (more that 100). We noticed that slony 
>>>>>> stores each column and its value for each request in sl_log_x. 
>>>>>> Would it not be more optimized to store just the user request ? 
>>>>>> Actually, a user is just updating a few column, or inserting a 
>>>>>> tuple by giving some attributes but not all, however as slony 
>>>>>> stores every column with its value it sl_log_x, these tables are 
>>>>>> growing very fast :-(
>>>>>
>>>>> Slony only logs columns where the value actually has changed. 
>>>>> Please explain in detail how you propose that the log table would 
>>>>> contain which columns have changed without naming them.
>>>> when I execute this command on the master :
>>>>
>>>> insert into t1(ise) values('cyril100001');
>>>>
>>>> I can see in sl_log_1 :
>>>>
>>>> psql>select log_cmddata from sl_log_1;
>>>> (ise,id,id2) values ('cyril100001','24161',NULL)
>>>>
>>>> dbtest=# \d t1;
>>>>                                Table "public.t1"
>>>> Column |         Type          |                    
>>>> Modifiers                   
>>>> --------+-----------------------+------------------------------------------------- 
>>>>
>>>> ise    | character varying(54) | not null
>>>> id     | integer               | not null default 
>>>> nextval('t1_id_seq'::regclass)
>>>> id2    | integer               |
>>>> Indexes:
>>>>    "t1_pkey" PRIMARY KEY, btree (ise)
>>>> Triggers:
>>>>    "_CLUSTER1_logtrigger_1" AFTER INSERT OR DELETE OR UPDATE ON t1 
>>>> FOR EACH ROW EXECUTE PROCEDURE "_CLUSTER1".logtrigger('_CLUSTER1', 
>>>> '1', 'kvv')
>>>>
>>>> I agree for id which is an auto_increment but not for id2 :-(
>>>>
>>>> In another plateform my table has more than  100 columns as said 
>>>> earlier and that's really matter :-(
>>> Jan's request seems to remain perfectly good...
>>>
>>> "Please explain in detail how you propose that the log table would 
>>> contain which columns have changed without naming them."
>>>
>>> It is *not* obvious how to avoid naming all of the columns.  It is 
>>> not safe to simply assume "that column was null so we may omit it" - 
>>> different nodes may be configured differently, and it may well be 
>>> important to actually have that NULL value.
>> I was just thinking of using the same way as other statement based 
>> replication way like does mysql, that is to say just log the request 
>> that user did. However, I forgot that slony uses triggers to log 
>> requests :-( Maybe finding a way to know which current request is 
>> done on the table for which the trigger has been called would be 
>> possible ?
>
> Turning Slony into a statement based replication system would make it 
> far worse. 
You may be right. It was just a suggestion to do something to replace 
the long SQL string by a shorter one to gain space, and so performance 
when getting blocks from disks with more rows :-)
> Queries depend on the exact transaction commit order with respect to 
> the exact rows that are visible to them. That in addition to the 
> non-deterministic behavior of sequential scans and a myriad of 
> functions ... how do you expect some query like
>
>     update mytable set foo = nextval('someseq') where foo is null;
>
> to lead to exactly the same result on two different databases? Not 
> even the order in which the rows are processed is defined.
If MySQL support it , why slony would not ? 
(http://dev.mysql.com/doc/refman/5.1/en/replication-features-autoincid.html), 
but you right for deterministic functions it's hard if value is added in 
the statement. But it's not what I've suggested.
>
> Compared to Postgres, MySQL is a fairly limited system feature wise. 
> Yet with their limited functionality the MySQL user manual already 
> states that several features are not supported by their statement 
> based replication. What do you think the corresponding documentation 
> for Slony would look like?
Sorry, but you can compare it to the log shipping feature of slon with 
less lag time.
>
>
> Jan
>

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From cscetbon.ext at orange-ftgroup.com  Mon Sep 10 13:33:17 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Mon Sep 10 13:33:42 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <46E305D8.3090502@orange-ftgroup.com>
References: <46E153D1.4060903@orange-ftgroup.com> <46E1A7A0.30401@Yahoo.com>
	<46E305D8.3090502@orange-ftgroup.com>
Message-ID: <46E5AA0D.1060708@orange-ftgroup.com>



Cyril SCETBON wrote:
>
>
> Jan Wieck wrote:
>> On 9/7/2007 9:36 AM, Cyril SCETBON wrote:
>>> Hi,
>>>
>>> I got this configuration                Node1 --> Node2 (5 seconds 
>>> late)
>>>                                                           |
>>>                                                           --> Node3 
>>> (2 hours late)
>>>
>>> Node2 is processing each SYNC from Node3 and Node2, but Node3 is 
>>> processing each SYNC from Node2 but not from Node1 which is the 
>>> origin of the sets :
>>>
>>> On Node3 we see  `grep processing 
>>> /var/log/slony1/node3-pns_profiles_preprod.log|awk '{print 
>>> $5}'|sort|uniq -c`
>>>      19 remoteWorkerThread_1:
>>>     963 remoteWorkerThread_2:
>>>
>>> On Node2 we see `grep processing 
>>> /var/log/slony1/node2-pns_profiles_preprod.log |awk '{print 
>>> $5}'|sort|uniq -c`
>>>    1570 remoteWorkerThread_1:
>>>     865 remoteWorkerThread_3:
>>>
>>> Why is there so many SYNC not processed on Node3 ???
>>>
>>> Node3 got 22440 queue event and 25 Received event from 
>>> remoteWorkerThread_1, while Node2 got 4467 queue event and 1578 
>>> Received event from the same worker.
>>>
>>> Is there something to do ?
>>
>> How about looking for some error messages?
> None.
I've put slon in debug level 2
>>
>> What comes to mind would be that sl_event is grossly out of shape and 
>> that the event selection times out.
> Seems vacuuming sl_log_1 takes too much time cause of 
> vacuum_cost_delay and that selecting from this table use a seq scan. 
> I'm investiguating.
I forced vacuum to go faster and checked slon logs of subscribers. They 
got similar disks capabilities which seems to be the bottleneck on all 
node (wait io ~=50% in vmstat).

I found replication tasks time are different :

On node 3 :
                     delay in seconds = 585.974ms
                     cleanupEvent in seconds = 9.25167s

On node 2 :
                     delay in seconds = 37.6463ms
                     cleanupEvent in seconds = 0.203265s

May these times explain why node 3 is late compared to node 2 ? What do 
you think I have to investiguate now ?

PS: hosts consume the same processor load but node 2 is a biprocessor 
2.6Ghz and node 3 is a biprocessor dual core 1.8Ghz (4 processors seen 
by Linux kernel SMP)
>
> Regards.
>>
>>
>> Jan
>>
>

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From cbbrowne at ca.afilias.info  Mon Sep 10 13:54:59 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Sep 10 13:55:24 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E5A297.3090309@orange-ftgroup.com> (Cyril SCETBON's message of
	"Mon, 10 Sep 2007 22:01:27 +0200")
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>
	<46E55D8B.3050003@orange-ftgroup.com>
	<46E57392.4000706@ca.afilias.info>
	<46E5759B.5090709@orange-ftgroup.com> <46E57E4E.2090807@Yahoo.com>
	<46E5A297.3090309@orange-ftgroup.com>
Message-ID: <60hcm2b5r0.fsf@dba2.int.libertyrms.com>

Cyril SCETBON <cscetbon.ext@orange-ftgroup.com> writes:
> Jan Wieck wrote:
>> On 9/10/2007 12:49 PM, Cyril SCETBON wrote:
>>>
>>> Christopher Browne wrote:
>> Turning Slony into a statement based replication system would make
>> it far worse.
> You may be right. It was just a suggestion to do something to replace
> the long SQL string by a shorter one to gain space, and so performance
> when getting blocks from disks with more rows :-)
>> Queries depend on the exact transaction commit order with respect to
>> the exact rows that are visible to them. That in addition to the
>> non-deterministic behavior of sequential scans and a myriad of
>> functions ... how do you expect some query like
>>
>>     update mytable set foo = nextval('someseq') where foo is null;
>>
>> to lead to exactly the same result on two different databases? Not
>> even the order in which the rows are processed is defined.

> If MySQL support it , why slony would not ? 
> (http://dev.mysql.com/doc/refman/5.1/en/replication-features-autoincid.html),
> but you right for deterministic functions it's hard if value is added
> in the statement. But it's not what I've suggested.

Just because they choose to jump off a cliff, that doesn't make it
make sense for us to do so.

Your suggestion does indeed amount to asking for Slony-I to behave in
the same sort of nondeterministic mode that the MySQL replication
system sometimes suffers from.

>> Compared to Postgres, MySQL is a fairly limited system feature
>> wise. Yet with their limited functionality the MySQL user manual
>> already states that several features are not supported by their
>> statement based replication. What do you think the corresponding
>> documentation for Slony would look like?

> Sorry, but you can compare it to the log shipping feature of slon
> with less lag time.

You can only do that if you also commit to wishful thinking:

 "If I choose not to care about data integrity, we can make the system
  somewhat more efficient."

That is decidedly NOT one of the design considerations for Slony-I.
One of the express goals is to provide confidence of data integrity.

If we drop that goal, we will lose the existing user base, so that is
a totally unacceptable approach.
-- 
output = ("cbbrowne" "@" "acm.org")
http://www3.sympatico.ca/cbbrowne/wp.html
The statistics on  sanity are that one out of  every four Americans is
suffering from some  form of mental illness. Think  of your three best
friends. If they're okay, then it's you. -- Rita Mae Brown
From andrew.george.hammond at gmail.com  Mon Sep 10 15:02:20 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Mon Sep 10 15:02:48 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E5A297.3090309@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>
	<46E55D8B.3050003@orange-ftgroup.com>
	<46E57392.4000706@ca.afilias.info>
	<46E5759B.5090709@orange-ftgroup.com> <46E57E4E.2090807@Yahoo.com>
	<46E5A297.3090309@orange-ftgroup.com>
Message-ID: <5a0a9d6f0709101502v277c5dectac299f4c39e5e957@mail.gmail.com>

On 9/10/07, Cyril SCETBON <cscetbon.ext@orange-ftgroup.com> wrote:
>
>
> Jan Wieck wrote:
> > On 9/10/2007 12:49 PM, Cyril SCETBON wrote:
> >>
> >> Christopher Browne wrote:
> >>> Cyril SCETBON wrote:
> >>>>
> >>>>
> >>>> Jan Wieck wrote:
> >>>>> On 9/10/2007 10:07 AM, Cyril SCETBON wrote:
> >>>>>> Hi,
> >>>>>>
> >>>>>> We're hitting 400 requests per second and noticed that sl_log_?
> >>>>>> are growing a lot. This is also due to the fact that our tables
> >>>>>> have a lot of columns (more that 100). We noticed that slony
> >>>>>> stores each column and its value for each request in sl_log_x.
> >>>>>> Would it not be more optimized to store just the user request ?
> >>>>>> Actually, a user is just updating a few column, or inserting a
> >>>>>> tuple by giving some attributes but not all, however as slony
> >>>>>> stores every column with its value it sl_log_x, these tables are
> >>>>>> growing very fast :-(
> >>>>>
> >>>>> Slony only logs columns where the value actually has changed.
> >>>>> Please explain in detail how you propose that the log table would
> >>>>> contain which columns have changed without naming them.
> >>>> when I execute this command on the master :
> >>>>
> >>>> insert into t1(ise) values('cyril100001');
> >>>>
> >>>> I can see in sl_log_1 :
> >>>>
> >>>> psql>select log_cmddata from sl_log_1;
> >>>> (ise,id,id2) values ('cyril100001','24161',NULL)
> >>>>
> >>>> dbtest=3D# \d t1;
> >>>>                                Table "public.t1"
> >>>> Column |         Type          |
> >>>> Modifiers
> >>>>
> --------+-----------------------+----------------------------------------=
---------
> >>>>
> >>>> ise    | character varying(54) | not null
> >>>> id     | integer               | not null default
> >>>> nextval('t1_id_seq'::regclass)
> >>>> id2    | integer               |
> >>>> Indexes:
> >>>>    "t1_pkey" PRIMARY KEY, btree (ise)
> >>>> Triggers:
> >>>>    "_CLUSTER1_logtrigger_1" AFTER INSERT OR DELETE OR UPDATE ON t1
> >>>> FOR EACH ROW EXECUTE PROCEDURE "_CLUSTER1".logtrigger('_CLUSTER1',
> >>>> '1', 'kvv')
> >>>>
> >>>> I agree for id which is an auto_increment but not for id2 :-(
> >>>>
> >>>> In another plateform my table has more than  100 columns as said
> >>>> earlier and that's really matter :-(
> >>> Jan's request seems to remain perfectly good...
> >>>
> >>> "Please explain in detail how you propose that the log table would
> >>> contain which columns have changed without naming them."
> >>>
> >>> It is *not* obvious how to avoid naming all of the columns.  It is
> >>> not safe to simply assume "that column was null so we may omit it" -
> >>> different nodes may be configured differently, and it may well be
> >>> important to actually have that NULL value.
> >> I was just thinking of using the same way as other statement based
> >> replication way like does mysql, that is to say just log the request
> >> that user did. However, I forgot that slony uses triggers to log
> >> requests :-( Maybe finding a way to know which current request is
> >> done on the table for which the trigger has been called would be
> >> possible ?
> >
> > Turning Slony into a statement based replication system would make it
> > far worse.
> You may be right. It was just a suggestion to do something to replace
> the long SQL string by a shorter one to gain space, and so performance
> when getting blocks from disks with more rows :-)
> > Queries depend on the exact transaction commit order with respect to
> > the exact rows that are visible to them. That in addition to the
> > non-deterministic behavior of sequential scans and a myriad of
> > functions ... how do you expect some query like
> >
> >     update mytable set foo =3D nextval('someseq') where foo is null;
> >
> > to lead to exactly the same result on two different databases? Not
> > even the order in which the rows are processed is defined.
> If MySQL support it , why slony would not ?
> (
> http://dev.mysql.com/doc/refman/5.1/en/replication-features-autoincid.html
> ),
> but you right for deterministic functions it's hard if value is added in
> the statement. But it's not what I've suggested.


Well, unlike MySQL our top priority is that it be correct. That's why. If
you want fast, and don't mind sloppy, then perhaps you should investigate
MySQL and their replication solution.

> Compared to Postgres, MySQL is a fairly limited system feature wise.
> > Yet with their limited functionality the MySQL user manual already
> > states that several features are not supported by their statement
> > based replication. What do you think the corresponding documentation
> > for Slony would look like?
> Sorry, but you can compare it to the log shipping feature of slon with
> less lag time.


Slony log shipping is extremely different from MySQL's approach. Slony log
shipping is _NOT_ statement based replication. Like all the rest of slony,
it is data driven. The fact that the data is represented as SQL statements
does not alter the fundamental design. If you would like a clear example of
this, consider a table with 10 entries. On the origin UPDATE foo SET bar =
=3D
1;. With an SBR solution, that command will be transmitted verbatim or very
close to verbatim. With slony log shipping you will see 10 commands that
look like UPDATE foo SET bar =3D 1 WHERE foo_id =3D ?.

I'm not exactly clear what you're suggesting, but perhaps this will clarify
things enough that you can express your idea.

Andrew
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070910/=
8bc456c0/attachment-0001.htm
From JanWieck at Yahoo.com  Mon Sep 10 15:29:52 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Mon Sep 10 15:30:37 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E5A297.3090309@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>	
	<46E55D8B.3050003@orange-ftgroup.com>
	<46E57392.4000706@ca.afilias.info>
	<46E5759B.5090709@orange-ftgroup.com> <46E57E4E.2090807@Yahoo.com>
	<46E5A297.3090309@orange-ftgroup.com>
Message-ID: <46E5C560.8090102@Yahoo.com>

On 9/10/2007 4:01 PM, Cyril SCETBON wrote:
> 
> Jan Wieck wrote:
>> On 9/10/2007 12:49 PM, Cyril SCETBON wrote:
>>>
>>> Christopher Browne wrote:
>>>> Cyril SCETBON wrote:
>>>>>
>>>>>
>>>>> Jan Wieck wrote:
>>>>>> On 9/10/2007 10:07 AM, Cyril SCETBON wrote:
>>>>>>> Hi,
>>>>>>>
>>>>>>> We're hitting 400 requests per second and noticed that sl_log_? 
>>>>>>> are growing a lot. This is also due to the fact that our tables 
>>>>>>> have a lot of columns (more that 100). We noticed that slony 
>>>>>>> stores each column and its value for each request in sl_log_x. 
>>>>>>> Would it not be more optimized to store just the user request ? 
>>>>>>> Actually, a user is just updating a few column, or inserting a 
>>>>>>> tuple by giving some attributes but not all, however as slony 
>>>>>>> stores every column with its value it sl_log_x, these tables are 
>>>>>>> growing very fast :-(
>>>>>>
>>>>>> Slony only logs columns where the value actually has changed. 
>>>>>> Please explain in detail how you propose that the log table would 
>>>>>> contain which columns have changed without naming them.
>>>>> when I execute this command on the master :
>>>>>
>>>>> insert into t1(ise) values('cyril100001');
>>>>>
>>>>> I can see in sl_log_1 :
>>>>>
>>>>> psql>select log_cmddata from sl_log_1;
>>>>> (ise,id,id2) values ('cyril100001','24161',NULL)
>>>>>
>>>>> dbtest=# \d t1;
>>>>>                                Table "public.t1"
>>>>> Column |         Type          |                    
>>>>> Modifiers                   
>>>>> --------+-----------------------+------------------------------------------------- 
>>>>>
>>>>> ise    | character varying(54) | not null
>>>>> id     | integer               | not null default 
>>>>> nextval('t1_id_seq'::regclass)
>>>>> id2    | integer               |
>>>>> Indexes:
>>>>>    "t1_pkey" PRIMARY KEY, btree (ise)
>>>>> Triggers:
>>>>>    "_CLUSTER1_logtrigger_1" AFTER INSERT OR DELETE OR UPDATE ON t1 
>>>>> FOR EACH ROW EXECUTE PROCEDURE "_CLUSTER1".logtrigger('_CLUSTER1', 
>>>>> '1', 'kvv')
>>>>>
>>>>> I agree for id which is an auto_increment but not for id2 :-(
>>>>>
>>>>> In another plateform my table has more than  100 columns as said 
>>>>> earlier and that's really matter :-(
>>>> Jan's request seems to remain perfectly good...
>>>>
>>>> "Please explain in detail how you propose that the log table would 
>>>> contain which columns have changed without naming them."
>>>>
>>>> It is *not* obvious how to avoid naming all of the columns.  It is 
>>>> not safe to simply assume "that column was null so we may omit it" - 
>>>> different nodes may be configured differently, and it may well be 
>>>> important to actually have that NULL value.
>>> I was just thinking of using the same way as other statement based 
>>> replication way like does mysql, that is to say just log the request 
>>> that user did. However, I forgot that slony uses triggers to log 
>>> requests :-( Maybe finding a way to know which current request is 
>>> done on the table for which the trigger has been called would be 
>>> possible ?
>>
>> Turning Slony into a statement based replication system would make it 
>> far worse. 
> You may be right. It was just a suggestion to do something to replace 
> the long SQL string by a shorter one to gain space, and so performance 
> when getting blocks from disks with more rows :-)
>> Queries depend on the exact transaction commit order with respect to 
>> the exact rows that are visible to them. That in addition to the 
>> non-deterministic behavior of sequential scans and a myriad of 
>> functions ... how do you expect some query like
>>
>>     update mytable set foo = nextval('someseq') where foo is null;
>>
>> to lead to exactly the same result on two different databases? Not 
>> even the order in which the rows are processed is defined.
> If MySQL support it , why slony would not ? 
> (http://dev.mysql.com/doc/refman/5.1/en/replication-features-autoincid.html), 
> but you right for deterministic functions it's hard if value is added in 
> the statement. But it's not what I've suggested.

What does MySQL's autoincrement feature have to do with the above UPDATE 
query?

>> Compared to Postgres, MySQL is a fairly limited system feature wise. 
>> Yet with their limited functionality the MySQL user manual already 
>> states that several features are not supported by their statement 
>> based replication. What do you think the corresponding documentation 
>> for Slony would look like?
> Sorry, but you can compare it to the log shipping feature of slon with 
> less lag time.

In what way are these two even remotely similar?


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From andrew.george.hammond at gmail.com  Mon Sep 10 15:44:20 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Mon Sep 10 15:44:50 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <46E5AA0D.1060708@orange-ftgroup.com>
References: <46E153D1.4060903@orange-ftgroup.com> <46E1A7A0.30401@Yahoo.com>
	<46E305D8.3090502@orange-ftgroup.com>
	<46E5AA0D.1060708@orange-ftgroup.com>
Message-ID: <5a0a9d6f0709101544h41da1a6pa7375579aab463ff@mail.gmail.com>

On 9/10/07, Cyril SCETBON <cscetbon.ext@orange-ftgroup.com> wrote:
>
>
> Cyril SCETBON wrote:
> >
> >
> > Jan Wieck wrote:
> >> On 9/7/2007 9:36 AM, Cyril SCETBON wrote:
> >>> Hi,
> >>>
> >>> I got this configuration                Node1 --> Node2 (5 seconds
> >>> late)
> >>>                                                           |
> >>>                                                           --> Node3
> >>> (2 hours late)
> >>>
> >>> Node2 is processing each SYNC from Node3 and Node2, but Node3 is
> >>> processing each SYNC from Node2 but not from Node1 which is the
> >>> origin of the sets :
> >>>
> >>> On Node3 we see  `grep processing
> >>> /var/log/slony1/node3-pns_profiles_preprod.log|awk '{print
> >>> $5}'|sort|uniq -c`
> >>>      19 remoteWorkerThread_1:
> >>>     963 remoteWorkerThread_2:
> >>>
> >>> On Node2 we see `grep processing
> >>> /var/log/slony1/node2-pns_profiles_preprod.log |awk '{print
> >>> $5}'|sort|uniq -c`
> >>>    1570 remoteWorkerThread_1:
> >>>     865 remoteWorkerThread_3:
> >>>
> >>> Why is there so many SYNC not processed on Node3 ???
> >>>
> >>> Node3 got 22440 queue event and 25 Received event from
> >>> remoteWorkerThread_1, while Node2 got 4467 queue event and 1578
> >>> Received event from the same worker.
> >>>
> >>> Is there something to do ?
> >>
> >> How about looking for some error messages?
> > None.
> I've put slon in debug level 2
> >>
> >> What comes to mind would be that sl_event is grossly out of shape and
> >> that the event selection times out.
> > Seems vacuuming sl_log_1 takes too much time cause of
> > vacuum_cost_delay and that selecting from this table use a seq scan.
> > I'm investiguating.
> I forced vacuum to go faster and checked slon logs of subscribers. They
> got similar disks capabilities which seems to be the bottleneck on all
> node (wait io ~=3D50% in vmstat).
>
> I found replication tasks time are different :
>
> On node 3 :
>                      delay in seconds =3D 585.974ms
>                      cleanupEvent in seconds =3D 9.25167s
>
> On node 2 :
>                      delay in seconds =3D 37.6463ms
>                      cleanupEvent in seconds =3D 0.203265s
>
> May these times explain why node 3 is late compared to node 2 ? What do
> you think I have to investiguate now ?
>
> PS: hosts consume the same processor load but node 2 is a biprocessor
> 2.6Ghz and node 3 is a biprocessor dual core 1.8Ghz (4 processors seen
> by Linux kernel SMP)
>

So... the computer with the slower processor is slower?
What delay are you referring too? If it's from _foo.sl_status.st_lag_time
then you should be aware that it's actual precision is about +/-5 seconds.
While the cleanup is disk intensive, it also does a good chunk of number
crunching. I'm surprised to see an order of magnitude in difference, but...
not shocked.

Andrew
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070910/=
b7f9e201/attachment.htm
From JanWieck at Yahoo.com  Mon Sep 10 15:46:47 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Mon Sep 10 15:47:25 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <46E5AA0D.1060708@orange-ftgroup.com>
References: <46E153D1.4060903@orange-ftgroup.com>
	<46E1A7A0.30401@Yahoo.com>	<46E305D8.3090502@orange-ftgroup.com>
	<46E5AA0D.1060708@orange-ftgroup.com>
Message-ID: <46E5C957.7020003@Yahoo.com>

On 9/10/2007 4:33 PM, Cyril SCETBON wrote:
> 
> Cyril SCETBON wrote:
>>
>>
>> Jan Wieck wrote:
>>> On 9/7/2007 9:36 AM, Cyril SCETBON wrote:
>>>> Hi,
>>>>
>>>> I got this configuration                Node1 --> Node2 (5 seconds 
>>>> late)
>>>>                                                           |
>>>>                                                           --> Node3 
>>>> (2 hours late)
>>>>
>>>> Node2 is processing each SYNC from Node3 and Node2, but Node3 is 
>>>> processing each SYNC from Node2 but not from Node1 which is the 
>>>> origin of the sets :
>>>>
>>>> On Node3 we see  `grep processing 
>>>> /var/log/slony1/node3-pns_profiles_preprod.log|awk '{print 
>>>> $5}'|sort|uniq -c`
>>>>      19 remoteWorkerThread_1:
>>>>     963 remoteWorkerThread_2:
>>>>
>>>> On Node2 we see `grep processing 
>>>> /var/log/slony1/node2-pns_profiles_preprod.log |awk '{print 
>>>> $5}'|sort|uniq -c`
>>>>    1570 remoteWorkerThread_1:
>>>>     865 remoteWorkerThread_3:
>>>>
>>>> Why is there so many SYNC not processed on Node3 ???
>>>>
>>>> Node3 got 22440 queue event and 25 Received event from 
>>>> remoteWorkerThread_1, while Node2 got 4467 queue event and 1578 
>>>> Received event from the same worker.
>>>>
>>>> Is there something to do ?
>>>
>>> How about looking for some error messages?
>> None.
> I've put slon in debug level 2
>>>
>>> What comes to mind would be that sl_event is grossly out of shape and 
>>> that the event selection times out.
>> Seems vacuuming sl_log_1 takes too much time cause of 
>> vacuum_cost_delay and that selecting from this table use a seq scan. 
>> I'm investiguating.
> I forced vacuum to go faster and checked slon logs of subscribers. They 
> got similar disks capabilities which seems to be the bottleneck on all 
> node (wait io ~=50% in vmstat).
> 
> I found replication tasks time are different :
> 
> On node 3 :
>                      delay in seconds = 585.974ms
>                      cleanupEvent in seconds = 9.25167s
> 
> On node 2 :
>                      delay in seconds = 37.6463ms
>                      cleanupEvent in seconds = 0.203265s
> 
> May these times explain why node 3 is late compared to node 2 ? What do 
> you think I have to investiguate now ?

Considering that node 2 can pretty well keep up but node 3 is falling 
way behind, the problem cannot be caused by node 1. Neither can it be 
caused by the event selection of node 3, so that leaves us with either 
the log selection done by node 3 against the data provider node 2, or 
the actual speed of node 3 itself.

In debug level 2, what does node 3's slon usually report as "delay for 
first row" when processing SYNC events?


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From tim.bowden at westnet.com.au  Mon Sep 10 18:57:08 2007
From: tim.bowden at westnet.com.au (Tim Bowden)
Date: Mon Sep 10 18:57:58 2007
Subject: [Slony1-general] Flakey network links
In-Reply-To: <5a0a9d6f0709101034kc33b99xa2d4fa77fd0c83d0@mail.gmail.com>
References: <1189392853.5736.69.camel@edoras> <1189393566.5736.79.camel@edoras>
	<5a0a9d6f0709101034kc33b99xa2d4fa77fd0c83d0@mail.gmail.com>
Message-ID: <1189475828.4048.17.camel@edoras>


On Mon, 2007-09-10 at 10:34 -0700, Andrew Hammond wrote:
> On 9/9/07, Tim Bowden <tim.bowden@westnet.com.au> wrote:
>         On Mon, 2007-09-10 at 10:54 +0800, Tim Bowden wrote:
>         > >From the docs:
>         > cases where Slony-I probably won't work out well would
>         include:
>         >
>         >       * Sites where connectivity is really "flakey" 
>         >
>         >       * Replication to nodes that are unpredictably
>         connected.
>         >
>         > How flakey/unpredictably connected can nodes be before it
>         all goes
>         > haywire?  Is it time critical, or load critical?
> 
> Yes, and yes.
> 
> 
>         > If an origin node goes 
>         > offline for a day, but there are only a couple of
>         transactions, will
>         > that be a problem?  If an origin node goes offline for a few
>         minutes but
>         > there are hundreds of transactions, what's the recovery
>         scenario look 
>         > like?
> 
> Assuming your run each slon either on the same box as the database
> it's supporting or in the same LAN, this is probably survivable. You
> will need to restart your slons every time the network status for
> _any_ of your databases changes. And yes, detecting and handling this
> correctly is likely to get complicated. 

Way too complicated for the environment I'm looking at.

> 
> 
> Your slons will generate transactions regularly on all nodes in the
> form of SYNCs. These need to be propagated between all nodes and then
> applied. Once SYNCs (and other events) have been applied, confirmation
> messages are propagated between all nodes. Once all nodes have applied
> events, then the cleanup thread on each node can remove the
> information necessary for confirmed events. 
> 
> For the cases you mention above, the obvious failure scenarios are as
> follows.
> 1) Network failures at a rate where a slon can not process all the
> items in some event before getting reset. 
> 2) Any one node being down long enough to grow sl_log_n to the point
> that it enters the "death spiral" (becomes so large that maintenance
> costs cause it to grow faster than it can be consumed). 
> 

Given 100+ nodes each on a different LAN, I think it's safe to assume we
will have significant network issues.  In this case we need to do log
shipping by default and std replication only within a well connected
core group of nodes.

Given the need for each node to do std replication to at least one other
node, I'll set up each remote node to replicate to itself (I believe
this is possible) so it can then log ship to central slave.


> To quote Jan's concept paper (which you really ought to read before
> going further in this discussion:
> http://developer.postgresql.org/~wieck/slony1/Slony-I-concept.pdf),
> "Neither offline nodes that only become available for sporadic
> synchronization (the salesman on the road) nor ... will be
> supported..."
> 

Thanks, the more reading I do the better at this stage.

> 
>         As a follow up, I noticed a post a week ago or thereabouts I
>         think it
>         was that mentioned bouncing nodes between standard replication
>         and
>         updating by log shipping, but it wasn't currently a viable
>         solution.  Is
>         this likely to ever become a viable solution, as it would
>         solve the
>         problem of unpredictable network links (at least for some use
>         cases)?
> 
> That sounds kinda complicated. Has anyone written a proposal for how
> to do it yet? It's taken us almost 2 years to get log-shipping to the
> point where it seems seriously viable. The project has existed for
> something approaching 4 years... 

The more I learn the more I see why this is so complicated.  I won't
count on this feature.

> 
> Andrew
> 
Thanks,
Tim Bowden

From mboehm at voilaip.com  Mon Sep 10 21:09:42 2007
From: mboehm at voilaip.com (Matthew Boehm)
Date: Mon Sep 10 21:10:43 2007
Subject: [Slony1-general] Replicating 1 DB
Message-ID: <46E61506.3010709@voilaip.com>

Hey gang,
  Newbie Slony1 user here. Is it possible to replicate just 1 particular 
database or a select number of schemas? We have no need to replicate the 
entire server.  pgcluster doesn't have this ability so I'm searching 
here now.

Thanks,
Matthew
From honza at jyxo.com  Mon Sep 10 23:25:31 2007
From: honza at jyxo.com (Jan Matousek)
Date: Mon Sep 10 23:26:19 2007
Subject: [Slony1-general] Replicating 1 DB
In-Reply-To: <46E61506.3010709@voilaip.com>
References: <46E61506.3010709@voilaip.com>
Message-ID: <c14eaebb0709102325t799eec76t6e7a3fe965370d36@mail.gmail.com>

SGksCgppbiBTbG9ueTEsIHRoZSAidW5pdCBvZiByZXBsaWNhdGlvbiIgaXMgc2V0LCB3aGljaCBj
b25zaXN0IG9mIGV4cGxpY2l0bHkKc2VsZWN0ZWQgdGFibGVzIGZyb20gc29tZSBwYXJ0aWN1bGFy
IGRhdGFiYXNlLiBTbyB0aGUgYW5zd2VyIGlzIHllcywgdG8KcmVwbGljYXRlIHNvbWUgc2NoZW1h
cyBqdXN0IGNyZWF0ZSBzZXQgKG9yIHNldHMpIHRoYXQgY29uc2lzdHMgb2YgYWxsIHRhYmxlcwpp
biB0aGF0IHNjaGVtYXMuCgpqLgoKT24gOS8xMS8wNywgTWF0dGhldyBCb2VobSA8bWJvZWhtQHZv
aWxhaXAuY29tPiB3cm90ZToKPgo+IEhleSBnYW5nLAo+ICAgTmV3YmllIFNsb255MSB1c2VyIGhl
cmUuIElzIGl0IHBvc3NpYmxlIHRvIHJlcGxpY2F0ZSBqdXN0IDEgcGFydGljdWxhcgo+IGRhdGFi
YXNlIG9yIGEgc2VsZWN0IG51bWJlciBvZiBzY2hlbWFzPyBXZSBoYXZlIG5vIG5lZWQgdG8gcmVw
bGljYXRlIHRoZQo+IGVudGlyZSBzZXJ2ZXIuICBwZ2NsdXN0ZXIgZG9lc24ndCBoYXZlIHRoaXMg
YWJpbGl0eSBzbyBJJ20gc2VhcmNoaW5nCj4gaGVyZSBub3cuCj4KPiBUaGFua3MsCj4gTWF0dGhl
dwo+IF9fX19fX19fX19fX19fX19fX19fX19fX19fX19fX19fX19fX19fX19fX19fX19fCj4gU2xv
bnkxLWdlbmVyYWwgbWFpbGluZyBsaXN0Cj4gU2xvbnkxLWdlbmVyYWxAbGlzdHMuc2xvbnkuaW5m
bwo+IGh0dHA6Ly9saXN0cy5zbG9ueS5pbmZvL21haWxtYW4vbGlzdGluZm8vc2xvbnkxLWdlbmVy
YWwKPgotLS0tLS0tLS0tLS0tLSBuZXh0IHBhcnQgLS0tLS0tLS0tLS0tLS0KQW4gSFRNTCBhdHRh
Y2htZW50IHdhcyBzY3J1YmJlZC4uLgpVUkw6IGh0dHA6Ly9saXN0cy5zbG9ueS5pbmZvL3BpcGVy
bWFpbC9zbG9ueTEtZ2VuZXJhbC9hdHRhY2htZW50cy8yMDA3MDkxMS9mNDNiNTk5NC9hdHRhY2ht
ZW50Lmh0bQo=
From cscetbon.ext at orange-ftgroup.com  Mon Sep 10 23:46:52 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Mon Sep 10 23:47:48 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <5a0a9d6f0709101544h41da1a6pa7375579aab463ff@mail.gmail.com>
References: <46E153D1.4060903@orange-ftgroup.com> <46E1A7A0.30401@Yahoo.com>	
	<46E305D8.3090502@orange-ftgroup.com>
	<46E5AA0D.1060708@orange-ftgroup.com>
	<5a0a9d6f0709101544h41da1a6pa7375579aab463ff@mail.gmail.com>
Message-ID: <46E639DC.2020506@orange-ftgroup.com>



Andrew Hammond wrote:
> On 9/10/07, *Cyril SCETBON* <cscetbon.ext@orange-ftgroup.com 
> <mailto:cscetbon.ext@orange-ftgroup.com>> wrote:
>
>
>     Cyril SCETBON wrote:
>     >
>     >
>     > Jan Wieck wrote:
>     >> On 9/7/2007 9:36 AM, Cyril SCETBON wrote:
>     >>> Hi,
>     >>>
>     >>> I got this configuration                Node1 --> Node2 (5
>     seconds
>     >>> late)
>     >>>                                                           |
>     >>>                                                           -->
>     Node3
>     >>> (2 hours late)
>     >>>
>     >>> Node2 is processing each SYNC from Node3 and Node2, but Node3 is
>     >>> processing each SYNC from Node2 but not from Node1 which is the
>     >>> origin of the sets :
>     >>>
>     >>> On Node3 we see  `grep processing
>     >>> /var/log/slony1/node3-pns_profiles_preprod.log|awk '{print
>     >>> $5}'|sort|uniq -c`
>     >>>      19 remoteWorkerThread_1:
>     >>>     963 remoteWorkerThread_2:
>     >>>
>     >>> On Node2 we see `grep processing
>     >>> /var/log/slony1/node2-pns_profiles_preprod.log |awk '{print
>     >>> $5}'|sort|uniq -c`
>     >>>    1570 remoteWorkerThread_1:
>     >>>     865 remoteWorkerThread_3:
>     >>>
>     >>> Why is there so many SYNC not processed on Node3 ???
>     >>>
>     >>> Node3 got 22440 queue event and 25 Received event from
>     >>> remoteWorkerThread_1, while Node2 got 4467 queue event and 1578
>     >>> Received event from the same worker.
>     >>>
>     >>> Is there something to do ?
>     >>
>     >> How about looking for some error messages?
>     > None.
>     I've put slon in debug level 2
>     >>
>     >> What comes to mind would be that sl_event is grossly out of
>     shape and
>     >> that the event selection times out.
>     > Seems vacuuming sl_log_1 takes too much time cause of
>     > vacuum_cost_delay and that selecting from this table use a seq
>     scan.
>     > I'm investiguating.
>     I forced vacuum to go faster and checked slon logs of subscribers.
>     They
>     got similar disks capabilities which seems to be the bottleneck on all
>     node (wait io ~=50% in vmstat).
>
>     I found replication tasks time are different :
>
>     On node 3 :
>                          delay in seconds = 585.974ms
>                          cleanupEvent in seconds = 9.25167s
>
>     On node 2 :
>                          delay in seconds = 37.6463ms
>                          cleanupEvent in seconds = 0.203265s
>
>     May these times explain why node 3 is late compared to node 2 ?
>     What do
>     you think I have to investiguate now ?
>
>     PS: hosts consume the same processor load but node 2 is a biprocessor
>     2.6Ghz and node 3 is a biprocessor dual core 1.8Ghz (4 processors seen
>     by Linux kernel SMP)
>
>
> So... the computer with the slower processor is slower?
> What delay are you referring too? If it's from 
> _foo.sl_status.st_lag_time then you should be aware that it's actual 
> precision is about +/-5 seconds.
yes
> While the cleanup is disk intensive, it also does a good chunk of 
> number crunching. I'm surprised to see an order of magnitude in 
> difference, but... not shocked.
>
> Andrew

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From cscetbon.ext at orange-ftgroup.com  Mon Sep 10 23:49:49 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Mon Sep 10 23:50:37 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <46E5C957.7020003@Yahoo.com>
References: <46E153D1.4060903@orange-ftgroup.com>
	<46E1A7A0.30401@Yahoo.com>	<46E305D8.3090502@orange-ftgroup.com>
	<46E5AA0D.1060708@orange-ftgroup.com> <46E5C957.7020003@Yahoo.com>
Message-ID: <46E63A8D.3020607@orange-ftgroup.com>



Jan Wieck wrote:
> On 9/10/2007 4:33 PM, Cyril SCETBON wrote:
>>
>> Cyril SCETBON wrote:
>>>
>>>
>>> Jan Wieck wrote:
>>>> On 9/7/2007 9:36 AM, Cyril SCETBON wrote:
>>>>> Hi,
>>>>>
>>>>> I got this configuration                Node1 --> Node2 (5 seconds 
>>>>> late)
>>>>>                                                           |
>>>>>                                                           --> 
>>>>> Node3 (2 hours late)
>>>>>
>>>>> Node2 is processing each SYNC from Node3 and Node2, but Node3 is 
>>>>> processing each SYNC from Node2 but not from Node1 which is the 
>>>>> origin of the sets :
>>>>>
>>>>> On Node3 we see  `grep processing 
>>>>> /var/log/slony1/node3-pns_profiles_preprod.log|awk '{print 
>>>>> $5}'|sort|uniq -c`
>>>>>      19 remoteWorkerThread_1:
>>>>>     963 remoteWorkerThread_2:
>>>>>
>>>>> On Node2 we see `grep processing 
>>>>> /var/log/slony1/node2-pns_profiles_preprod.log |awk '{print 
>>>>> $5}'|sort|uniq -c`
>>>>>    1570 remoteWorkerThread_1:
>>>>>     865 remoteWorkerThread_3:
>>>>>
>>>>> Why is there so many SYNC not processed on Node3 ???
>>>>>
>>>>> Node3 got 22440 queue event and 25 Received event from 
>>>>> remoteWorkerThread_1, while Node2 got 4467 queue event and 1578 
>>>>> Received event from the same worker.
>>>>>
>>>>> Is there something to do ?
>>>>
>>>> How about looking for some error messages?
>>> None.
>> I've put slon in debug level 2
>>>>
>>>> What comes to mind would be that sl_event is grossly out of shape 
>>>> and that the event selection times out.
>>> Seems vacuuming sl_log_1 takes too much time cause of 
>>> vacuum_cost_delay and that selecting from this table use a seq scan. 
>>> I'm investiguating.
>> I forced vacuum to go faster and checked slon logs of subscribers. 
>> They got similar disks capabilities which seems to be the bottleneck 
>> on all node (wait io ~=50% in vmstat).
>>
>> I found replication tasks time are different :
>>
>> On node 3 :
>>                      delay in seconds = 585.974ms
>>                      cleanupEvent in seconds = 9.25167s
>>
>> On node 2 :
>>                      delay in seconds = 37.6463ms
>>                      cleanupEvent in seconds = 0.203265s
>>
>> May these times explain why node 3 is late compared to node 2 ? What 
>> do you think I have to investiguate now ?
>
> Considering that node 2 can pretty well keep up but node 3 is falling 
> way behind, the problem cannot be caused by node 1. Neither can it be 
> caused by the event selection of node 3, so that leaves us with either 
> the log selection done by node 3 against the data provider node 2, or 
> the actual speed of node 3 itself.
>
> In debug level 2, what does node 3's slon usually report as "delay for 
> first row" when processing SYNC events?
that's what I gave as 'delay in seconds' above
>
>
> Jan
>

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From cscetbon.ext at orange-ftgroup.com  Tue Sep 11 01:13:42 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Tue Sep 11 01:14:39 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <5a0a9d6f0709101502v277c5dectac299f4c39e5e957@mail.gmail.com>
References: <46E54F8D.5010500@orange-ftgroup.com>
	<46E559F3.60602@Yahoo.com>	<46E55D8B.3050003@orange-ftgroup.com>	<46E57392.4000706@ca.afilias.info>	<46E5759B.5090709@orange-ftgroup.com>
	<46E57E4E.2090807@Yahoo.com>	<46E5A297.3090309@orange-ftgroup.com>
	<5a0a9d6f0709101502v277c5dectac299f4c39e5e957@mail.gmail.com>
Message-ID: <46E64E36.2070400@orange-ftgroup.com>



Andrew Hammond wrote:
> On 9/10/07, *Cyril SCETBON* <cscetbon.ext@orange-ftgroup.com 
> <mailto:cscetbon.ext@orange-ftgroup.com>> wrote:
>
>
>     Jan Wieck wrote:
>     > On 9/10/2007 12:49 PM, Cyril SCETBON wrote:
>     >>
>     >> Christopher Browne wrote:
>     >>> Cyril SCETBON wrote:
>     >>>>
>     >>>>
>     >>>> Jan Wieck wrote:
>     >>>>> On 9/10/2007 10:07 AM, Cyril SCETBON wrote:
>     >>>>>> Hi,
>     >>>>>>
>     >>>>>> We're hitting 400 requests per second and noticed that
>     sl_log_?
>     >>>>>> are growing a lot. This is also due to the fact that our tables
>     >>>>>> have a lot of columns (more that 100). We noticed that slony
>     >>>>>> stores each column and its value for each request in sl_log_x.
>     >>>>>> Would it not be more optimized to store just the user request ?
>     >>>>>> Actually, a user is just updating a few column, or inserting a
>     >>>>>> tuple by giving some attributes but not all, however as slony
>     >>>>>> stores every column with its value it sl_log_x, these
>     tables are
>     >>>>>> growing very fast :-(
>     >>>>>
>     >>>>> Slony only logs columns where the value actually has changed.
>     >>>>> Please explain in detail how you propose that the log table
>     would
>     >>>>> contain which columns have changed without naming them.
>     >>>> when I execute this command on the master :
>     >>>>
>     >>>> insert into t1(ise) values('cyril100001');
>     >>>>
>     >>>> I can see in sl_log_1 :
>     >>>>
>     >>>> psql>select log_cmddata from sl_log_1;
>     >>>> (ise,id,id2) values ('cyril100001','24161',NULL)
>     >>>>
>     >>>> dbtest=# \d t1;
>     >>>>                                Table "public.t1"
>     >>>> Column |         Type          |
>     >>>> Modifiers
>     >>>>
>     --------+-----------------------+-------------------------------------------------
>     >>>>
>     >>>> ise    | character varying(54) | not null
>     >>>> id     | integer               | not null default
>     >>>> nextval('t1_id_seq'::regclass)
>     >>>> id2    | integer               |
>     >>>> Indexes:
>     >>>>    "t1_pkey" PRIMARY KEY, btree (ise)
>     >>>> Triggers:
>     >>>>    "_CLUSTER1_logtrigger_1" AFTER INSERT OR DELETE OR UPDATE
>     ON t1
>     >>>> FOR EACH ROW EXECUTE PROCEDURE
>     "_CLUSTER1".logtrigger('_CLUSTER1',
>     >>>> '1', 'kvv')
>     >>>>
>     >>>> I agree for id which is an auto_increment but not for id2 :-(
>     >>>>
>     >>>> In another plateform my table has more than  100 columns as said
>     >>>> earlier and that's really matter :-(
>     >>> Jan's request seems to remain perfectly good...
>     >>>
>     >>> "Please explain in detail how you propose that the log table
>     would
>     >>> contain which columns have changed without naming them."
>     >>>
>     >>> It is *not* obvious how to avoid naming all of the columns.  It is
>     >>> not safe to simply assume "that column was null so we may omit
>     it" -
>     >>> different nodes may be configured differently, and it may well be
>     >>> important to actually have that NULL value.
>     >> I was just thinking of using the same way as other statement based
>     >> replication way like does mysql, that is to say just log the
>     request
>     >> that user did. However, I forgot that slony uses triggers to log
>     >> requests :-( Maybe finding a way to know which current request is
>     >> done on the table for which the trigger has been called would be
>     >> possible ?
>     >
>     > Turning Slony into a statement based replication system would
>     make it
>     > far worse.
>     You may be right. It was just a suggestion to do something to replace
>     the long SQL string by a shorter one to gain space, and so performance
>     when getting blocks from disks with more rows :-)
>     > Queries depend on the exact transaction commit order with respect to
>     > the exact rows that are visible to them. That in addition to the
>     > non-deterministic behavior of sequential scans and a myriad of
>     > functions ... how do you expect some query like
>     >
>     >     update mytable set foo = nextval('someseq') where foo is null;
>     >
>     > to lead to exactly the same result on two different databases? Not
>     > even the order in which the rows are processed is defined.
>     If MySQL support it , why slony would not ?
>     (
>     http://dev.mysql.com/doc/refman/5.1/en/replication-features-autoincid.html),
>     but you right for deterministic functions it's hard if value is
>     added in
>     the statement. But it's not what I've suggested.
>
>
> Well, unlike MySQL our top priority is that it be correct. That's why. 
> If you want fast, and don't mind sloppy, then perhaps you should 
> investigate MySQL and their replication solution.
>
>     > Compared to Postgres, MySQL is a fairly limited system feature wise.
>     > Yet with their limited functionality the MySQL user manual already
>     > states that several features are not supported by their statement
>     > based replication. What do you think the corresponding documentation
>     > for Slony would look like?
>     Sorry, but you can compare it to the log shipping feature of slon with
>     less lag time.
>
>
> Slony log shipping is extremely different from MySQL's approach. Slony 
> log shipping is _NOT_ statement based replication. Like all the rest 
> of slony, it is data driven. The fact that the data is represented as 
> SQL statements does not alter the fundamental design. If you would 
> like a clear example of this, consider a table with 10 entries. On the 
> origin UPDATE foo SET bar = 1;. With an SBR solution, that command 
> will be transmitted verbatim or very close to verbatim. With slony log 
> shipping you will see 10 commands that look like UPDATE foo SET bar = 
> 1 WHERE foo_id = ?.
OK.
You don't think that it alter the performance doing 100 updates for a 
table with 100 atributes versus one update on 2 columns ? We certainly 
have to accept poor performance when applying log if we use log shipping 
in this case ?
>
> I'm not exactly clear what you're suggesting, but perhaps this will 
> clarify things enough that you can express your idea.
>
> Andrew
>
> ------------------------------------------------------------------------
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>   

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From cscetbon.ext at orange-ftgroup.com  Tue Sep 11 02:46:56 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Tue Sep 11 02:47:55 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <5a0a9d6f0709101544h41da1a6pa7375579aab463ff@mail.gmail.com>
References: <46E153D1.4060903@orange-ftgroup.com> <46E1A7A0.30401@Yahoo.com>	
	<46E305D8.3090502@orange-ftgroup.com>
	<46E5AA0D.1060708@orange-ftgroup.com>
	<5a0a9d6f0709101544h41da1a6pa7375579aab463ff@mail.gmail.com>
Message-ID: <46E66410.9010702@orange-ftgroup.com>



Andrew Hammond wrote:
> On 9/10/07, *Cyril SCETBON* <cscetbon.ext@orange-ftgroup.com 
> <mailto:cscetbon.ext@orange-ftgroup.com>> wrote:
>
>
>     Cyril SCETBON wrote:
>     >
>     >
>     > Jan Wieck wrote:
>     >> On 9/7/2007 9:36 AM, Cyril SCETBON wrote:
>     >>> Hi,
>     >>>
>     >>> I got this configuration                Node1 --> Node2 (5
>     seconds
>     >>> late)
>     >>>                                                           |
>     >>>                                                           -->
>     Node3
>     >>> (2 hours late)
>     >>>
>     >>> Node2 is processing each SYNC from Node3 and Node2, but Node3 is
>     >>> processing each SYNC from Node2 but not from Node1 which is the
>     >>> origin of the sets :
>     >>>
>     >>> On Node3 we see  `grep processing
>     >>> /var/log/slony1/node3-pns_profiles_preprod.log|awk '{print
>     >>> $5}'|sort|uniq -c`
>     >>>      19 remoteWorkerThread_1:
>     >>>     963 remoteWorkerThread_2:
>     >>>
>     >>> On Node2 we see `grep processing
>     >>> /var/log/slony1/node2-pns_profiles_preprod.log |awk '{print
>     >>> $5}'|sort|uniq -c`
>     >>>    1570 remoteWorkerThread_1:
>     >>>     865 remoteWorkerThread_3:
>     >>>
>     >>> Why is there so many SYNC not processed on Node3 ???
>     >>>
>     >>> Node3 got 22440 queue event and 25 Received event from
>     >>> remoteWorkerThread_1, while Node2 got 4467 queue event and 1578
>     >>> Received event from the same worker.
>     >>>
>     >>> Is there something to do ?
>     >>
>     >> How about looking for some error messages?
>     > None.
>     I've put slon in debug level 2
>     >>
>     >> What comes to mind would be that sl_event is grossly out of
>     shape and
>     >> that the event selection times out.
>     > Seems vacuuming sl_log_1 takes too much time cause of
>     > vacuum_cost_delay and that selecting from this table use a seq
>     scan.
>     > I'm investiguating.
>     I forced vacuum to go faster and checked slon logs of subscribers.
>     They
>     got similar disks capabilities which seems to be the bottleneck on all
>     node (wait io ~=50% in vmstat).
>
>     I found replication tasks time are different :
>
>     On node 3 :
>                          delay in seconds = 585.974ms
>                          cleanupEvent in seconds = 9.25167s
>
>     On node 2 :
>                          delay in seconds = 37.6463ms
>                          cleanupEvent in seconds = 0.203265s
>
>     May these times explain why node 3 is late compared to node 2 ?
>     What do
>     you think I have to investiguate now ?
>
>     PS: hosts consume the same processor load but node 2 is a biprocessor
>     2.6Ghz and node 3 is a biprocessor dual core 1.8Ghz (4 processors seen
>     by Linux kernel SMP)
>
>
> So... the computer with the slower processor is slower?
> What delay are you referring too? If it's from 
> _foo.sl_status.st_lag_time then you should be aware that it's actual 
> precision is about +/-5 seconds.
thanks. I didn't know this precision. Is there a better way to know the 
delay (with a better precision) between subscribers and origin ?
> While the cleanup is disk intensive, it also does a good chunk of 
> number crunching. I'm surprised to see an order of magnitude in 
> difference, but... not shocked.
Yeah, but the time difference gets up to 2 hours !!!
>
> Andrew

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From andrew.george.hammond at gmail.com  Tue Sep 11 10:26:45 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Tue Sep 11 10:27:03 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E64E36.2070400@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>
	<46E55D8B.3050003@orange-ftgroup.com>
	<46E57392.4000706@ca.afilias.info>
	<46E5759B.5090709@orange-ftgroup.com> <46E57E4E.2090807@Yahoo.com>
	<46E5A297.3090309@orange-ftgroup.com>
	<5a0a9d6f0709101502v277c5dectac299f4c39e5e957@mail.gmail.com>
	<46E64E36.2070400@orange-ftgroup.com>
Message-ID: <5a0a9d6f0709111026i52769ccbnf54da17397a061ae@mail.gmail.com>

On 9/11/07, Cyril SCETBON <cscetbon.ext@orange-ftgroup.com> wrote:

> OK.
> You don't think that it alter the performance doing 100 updates for a
> table with 100 atributes versus one update on 2 columns ? We certainly
> have to accept poor performance when applying log if we use log shipping
> in this case ?
>

Sure. How do you figure out what that statement ought to be?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070911/=
ceaf98f1/attachment.htm
From cscetbon.ext at orange-ftgroup.com  Tue Sep 11 13:51:14 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Tue Sep 11 13:51:43 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <46E5C957.7020003@Yahoo.com>
References: <46E153D1.4060903@orange-ftgroup.com>
	<46E1A7A0.30401@Yahoo.com>	<46E305D8.3090502@orange-ftgroup.com>
	<46E5AA0D.1060708@orange-ftgroup.com> <46E5C957.7020003@Yahoo.com>
Message-ID: <46E6FFC2.7080307@orange-ftgroup.com>

Here 
http://dl.free.fr/cfmKo4lkP/slony_tests_60sets_sophia_bagnollet_11092007.xls 
there are the different times of sync processing, delay for first row,
until close cursor, lag time (sl_status) and numbers of inserts (we're 
not doing other DML for the moment).

After 12h30 I changed the group parameter of slon from 12 to 6. As you
can see, slave01 is processing insert better by grouping less inserts.
But Masterb01 continues  doing lot of inserts (greater than 20000) even
if I configured the same  value for the group parameter of slon, and
nothing better, if change it from 6 to 2 :-(

Any idea ?

Jan Wieck wrote:
> On 9/10/2007 4:33 PM, Cyril SCETBON wrote:
>>
>> Cyril SCETBON wrote:
>>>
>>>
>>> Jan Wieck wrote:
>>>> On 9/7/2007 9:36 AM, Cyril SCETBON wrote:
>>>>> Hi,
>>>>>
>>>>> I got this configuration                Node1 --> Node2 (5 seconds 
>>>>> late)
>>>>>                                                           |
>>>>>                                                           --> 
>>>>> Node3 (2 hours late)
>>>>>
>>>>> Node2 is processing each SYNC from Node3 and Node2, but Node3 is 
>>>>> processing each SYNC from Node2 but not from Node1 which is the 
>>>>> origin of the sets :
>>>>>
>>>>> On Node3 we see  `grep processing 
>>>>> /var/log/slony1/node3-pns_profiles_preprod.log|awk '{print 
>>>>> $5}'|sort|uniq -c`
>>>>>      19 remoteWorkerThread_1:
>>>>>     963 remoteWorkerThread_2:
>>>>>
>>>>> On Node2 we see `grep processing 
>>>>> /var/log/slony1/node2-pns_profiles_preprod.log |awk '{print 
>>>>> $5}'|sort|uniq -c`
>>>>>    1570 remoteWorkerThread_1:
>>>>>     865 remoteWorkerThread_3:
>>>>>
>>>>> Why is there so many SYNC not processed on Node3 ???
>>>>>
>>>>> Node3 got 22440 queue event and 25 Received event from 
>>>>> remoteWorkerThread_1, while Node2 got 4467 queue event and 1578 
>>>>> Received event from the same worker.
>>>>>
>>>>> Is there something to do ?
>>>>
>>>> How about looking for some error messages?
>>> None.
>> I've put slon in debug level 2
>>>>
>>>> What comes to mind would be that sl_event is grossly out of shape 
>>>> and that the event selection times out.
>>> Seems vacuuming sl_log_1 takes too much time cause of 
>>> vacuum_cost_delay and that selecting from this table use a seq scan. 
>>> I'm investiguating.
>> I forced vacuum to go faster and checked slon logs of subscribers. 
>> They got similar disks capabilities which seems to be the bottleneck 
>> on all node (wait io ~=50% in vmstat).
>>
>> I found replication tasks time are different :
>>
>> On node 3 :
>>                      delay in seconds = 585.974ms
>>                      cleanupEvent in seconds = 9.25167s
>>
>> On node 2 :
>>                      delay in seconds = 37.6463ms
>>                      cleanupEvent in seconds = 0.203265s
>>
>> May these times explain why node 3 is late compared to node 2 ? What 
>> do you think I have to investiguate now ?
>
> Considering that node 2 can pretty well keep up but node 3 is falling 
> way behind, the problem cannot be caused by node 1. Neither can it be 
> caused by the event selection of node 3, so that leaves us with either 
> the log selection done by node 3 against the data provider node 2, or 
> the actual speed of node 3 itself.
>
> In debug level 2, what does node 3's slon usually report as "delay for 
> first row" when processing SYNC events?
>
>
> Jan
>

-- 
Cyril SCETBON

From JanWieck at Yahoo.com  Tue Sep 11 14:58:16 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Tue Sep 11 14:58:54 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <46E63A8D.3020607@orange-ftgroup.com>
References: <46E153D1.4060903@orange-ftgroup.com>	<46E1A7A0.30401@Yahoo.com>	<46E305D8.3090502@orange-ftgroup.com>	<46E5AA0D.1060708@orange-ftgroup.com>
	<46E5C957.7020003@Yahoo.com> <46E63A8D.3020607@orange-ftgroup.com>
Message-ID: <46E70F78.8060603@Yahoo.com>

On 9/11/2007 2:49 AM, Cyril SCETBON wrote:
> 
> Jan Wieck wrote:
>> On 9/10/2007 4:33 PM, Cyril SCETBON wrote:
>>>
>>> Cyril SCETBON wrote:
>>>>
>>>>
>>>> Jan Wieck wrote:
>>>>> On 9/7/2007 9:36 AM, Cyril SCETBON wrote:
>>>>>> Hi,
>>>>>>
>>>>>> I got this configuration                Node1 --> Node2 (5 seconds 
>>>>>> late)
>>>>>>                                                           |
>>>>>>                                                           --> 
>>>>>> Node3 (2 hours late)
>>>>>>
>>>>>> Node2 is processing each SYNC from Node3 and Node2, but Node3 is 
>>>>>> processing each SYNC from Node2 but not from Node1 which is the 
>>>>>> origin of the sets :
>>>>>>
>>>>>> On Node3 we see  `grep processing 
>>>>>> /var/log/slony1/node3-pns_profiles_preprod.log|awk '{print 
>>>>>> $5}'|sort|uniq -c`
>>>>>>      19 remoteWorkerThread_1:
>>>>>>     963 remoteWorkerThread_2:
>>>>>>
>>>>>> On Node2 we see `grep processing 
>>>>>> /var/log/slony1/node2-pns_profiles_preprod.log |awk '{print 
>>>>>> $5}'|sort|uniq -c`
>>>>>>    1570 remoteWorkerThread_1:
>>>>>>     865 remoteWorkerThread_3:
>>>>>>
>>>>>> Why is there so many SYNC not processed on Node3 ???
>>>>>>
>>>>>> Node3 got 22440 queue event and 25 Received event from 
>>>>>> remoteWorkerThread_1, while Node2 got 4467 queue event and 1578 
>>>>>> Received event from the same worker.
>>>>>>
>>>>>> Is there something to do ?
>>>>>
>>>>> How about looking for some error messages?
>>>> None.
>>> I've put slon in debug level 2
>>>>>
>>>>> What comes to mind would be that sl_event is grossly out of shape 
>>>>> and that the event selection times out.
>>>> Seems vacuuming sl_log_1 takes too much time cause of 
>>>> vacuum_cost_delay and that selecting from this table use a seq scan. 
>>>> I'm investiguating.
>>> I forced vacuum to go faster and checked slon logs of subscribers. 
>>> They got similar disks capabilities which seems to be the bottleneck 
>>> on all node (wait io ~=50% in vmstat).
>>>
>>> I found replication tasks time are different :
>>>
>>> On node 3 :
>>>                      delay in seconds = 585.974ms
>>>                      cleanupEvent in seconds = 9.25167s
>>>
>>> On node 2 :
>>>                      delay in seconds = 37.6463ms
>>>                      cleanupEvent in seconds = 0.203265s
>>>
>>> May these times explain why node 3 is late compared to node 2 ? What 
>>> do you think I have to investiguate now ?
>>
>> Considering that node 2 can pretty well keep up but node 3 is falling 
>> way behind, the problem cannot be caused by node 1. Neither can it be 
>> caused by the event selection of node 3, so that leaves us with either 
>> the log selection done by node 3 against the data provider node 2, or 
>> the actual speed of node 3 itself.
>>
>> In debug level 2, what does node 3's slon usually report as "delay for 
>> first row" when processing SYNC events?
> that's what I gave as 'delay in seconds' above

OK, so the origin can provide log rows almost instantaneously, while 
node 2 has apparently some issues with the same. Although half a second 
isn't a catastrophe, it indicates that there are some performance issues 
handling the overall workload already on that system.

Now when in comes to node 3, this means that it is not doing any actual 
replication work for 500ms per sync group. Which should not pose a real 
problem. So my guess is that node 3 is simply too slow to keep up with 
the write load of the origin, or that the network connection is too slow 
to actually deliver the log data fast enough. If this is a WAN 
connection (which by itself can explain 500ms for the first FETCH of 100 
log rows), you might want to try using an ssh tunnel with compression.

The other thing to check is to make sure all databases are tuned.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From JanWieck at Yahoo.com  Tue Sep 11 15:41:29 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Tue Sep 11 15:42:14 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E64E36.2070400@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com>	<46E559F3.60602@Yahoo.com>	<46E55D8B.3050003@orange-ftgroup.com>	<46E57392.4000706@ca.afilias.info>	<46E5759B.5090709@orange-ftgroup.com>	<46E57E4E.2090807@Yahoo.com>	<46E5A297.3090309@orange-ftgroup.com>	<5a0a9d6f0709101502v277c5dectac299f4c39e5e957@mail.gmail.com>
	<46E64E36.2070400@orange-ftgroup.com>
Message-ID: <46E71999.6090600@Yahoo.com>

On 9/11/2007 4:13 AM, Cyril SCETBON wrote:

> OK.
> You don't think that it alter the performance doing 100 updates for a 
> table with 100 atributes versus one update on 2 columns ? We certainly 
> have to accept poor performance when applying log if we use log shipping 
> in this case ?

Certainly does statement based replication offer better performance when 
used for mass-updates or mass-deletes. But how on earth do you replicate 
something like

     UPDATE foo SET bar = random();

with a statement based replication system. And under MVCC, how do you 
ensure that the order and logical content of all transaction visibility 
snapshots is consistent while replicating the data? Please note that 
something as simple as

     DELETE FROM foo WHERE bar < 20;

executed by a session in READ COMMITTED transaction isolation level will 
delete different sets of rows if a concurrent transaction, setting a 
rows bar from 30 to 10 committed before or after it. This MVCC 
visibility crap will also be in the way if your answer to the above 
random() problem was "setting the random seed ...".

And finally, consider 20 concurrent sessions, each doing all sorts of 
things using temp tables, then doing

     INSERT INTO real_table SELECT nextval('some_seq'), a, b, c
         FROM temp_table;

Lets ignore for a moment the fact that actually using those 20 temp 
tables would require to replay the updates on the replica in 20 separate 
and concurrent sessions, which ultimately will lead to a replication 
design that requires each and every single master session to be 
replicated in its own slave session (if your master has 200 clients, 
your slave will eventually have 200 replication DB connections to serve).

All those 20 sessions have concurrent access to real_table. They will 
run in parallel. It is totally impossible to foresee which session will 
allocate which sequence numbers. So what's your idea to coordinate that 
mess within a statement based replication system? And don't tell me you 
want to serialize those transactions, because the point of doing 
something like that in the first place is probably performance problems, 
so serializing all application access isn't going to be the answer.

Does anyone know what MySQL using InnoDB tables would do in this case?


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From JanWieck at Yahoo.com  Tue Sep 11 15:47:49 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Tue Sep 11 15:48:30 2007
Subject: [Slony1-general] Replicating 1 DB
In-Reply-To: <c14eaebb0709102325t799eec76t6e7a3fe965370d36@mail.gmail.com>
References: <46E61506.3010709@voilaip.com>
	<c14eaebb0709102325t799eec76t6e7a3fe965370d36@mail.gmail.com>
Message-ID: <46E71B15.8060502@Yahoo.com>

On 9/11/2007 2:25 AM, Jan Matousek wrote:
> Hi,
> 
> in Slony1, the "unit of replication" is set, which consist of explicitly 
> selected tables from some particular database. So the answer is yes, to 
> replicate some schemas just create set (or sets) that consists of all 
> tables in that schemas.

However, be warned that you will have to specify each and every single 
table and sequence you want to be replicated. There is no "automagic" 
replication of "entire schema" including DDL statements or the like.


Jan



> 
> j.
> 
> On 9/11/07, *Matthew Boehm* <mboehm@voilaip.com 
> <mailto:mboehm@voilaip.com>> wrote:
> 
>     Hey gang,
>       Newbie Slony1 user here. Is it possible to replicate just 1 particular
>     database or a select number of schemas? We have no need to replicate the
>     entire server.  pgcluster doesn't have this ability so I'm searching
>     here now.
> 
>     Thanks,
>     Matthew
>     _______________________________________________
>     Slony1-general mailing list
>     Slony1-general@lists.slony.info <mailto:Slony1-general@lists.slony.info>
>     http://lists.slony.info/mailman/listinfo/slony1-general
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From jpfletch at ca.afilias.info  Wed Sep 12 09:12:37 2007
From: jpfletch at ca.afilias.info (JP Fletcher)
Date: Wed Sep 12 09:13:41 2007
Subject: [Slony1-general] init cluster won't work when node id out of range.
Message-ID: <46E80FF5.6060202@ca.afilias.info>

Hi,

I'm trying to create a  test cluster in the image of one that already 
exists.  The script I'm using  connects to the existing cluster, then 
builds an INIT CLUSTER command based on the current origin node.  The id 
of the node in question is 40003.  The INIT CLUSTER fails with the 
following:

/opt/scripts/slonik/cluster/cluster_init.slonik:2: PGRES_FATAL_ERROR 
select "_cluster".initializeLocalNode(40003, 'Node 40003'); select 
"_cluster".enableNode(40003);  - ERROR:  bigint out of range
CONTEXT:  SQL statement "SELECT  setval('"_cluster".sl_rowid_seq',  $1 
::int8 * '1000000000000000'::int8)"
PL/pgSQL function "initializelocalnode" line 26 at perform


The node in question was added via STORE NODE, and a MOVE SET was done 
at some time.  If a node id is acceptable to STORE NODE should it not 
also be acceptable to INIT CLUSTER?  I happened to notice this on a 
1.1.5 cluster, but it looks to me that initializeLocalNode() is 
identical in v 1.2.

JP

-- 
JP Fletcher
Database Administrator
Afilias Canada
voice: 416.646.3304 ext. 4123
fax: 416.646.3305
mobile: 416.561.4763
jpfletch@ca.afilias.info


From jpfletch at ca.afilias.info  Wed Sep 12 12:40:09 2007
From: jpfletch at ca.afilias.info (JP Fletcher)
Date: Wed Sep 12 12:41:26 2007
Subject: [Slony1-general] init cluster won't work when node id out of
	range.
In-Reply-To: <46E80FF5.6060202@ca.afilias.info>
References: <46E80FF5.6060202@ca.afilias.info>
Message-ID: <46E84099.3070100@ca.afilias.info>

I just noticed when doing a different cluster, that the same thing seems 
to happen with STORE NODE

/opt/scripts/slonik/cluster/cluster_init.slonik:5: PGRES_FATAL_ERROR 
select "_cluster".initializeLocalNode(650901, 'Node 650901'); select 
"_cluster".enableNode_int(650901);  - ERROR:  bigint out of range
CONTEXT:  SQL statement "SELECT  setval('"_cluster".sl_rowid_seq',  $1 
::int8 * '1000000000000000'::int8)"
PL/pgSQL function "initializelocalnode" line 26 at perform

The slonik command was

STORE NODE (ID = 650901, EVENT NODE = 22, COMMENT = 'Node 650901');

These node ids may have been created initially on 1.0.5, many months ago...

JP Fletcher wrote:
> Hi,
>
> I'm trying to create a  test cluster in the image of one that already 
> exists.  The script I'm using  connects to the existing cluster, then 
> builds an INIT CLUSTER command based on the current origin node.  The 
> id of the node in question is 40003.  The INIT CLUSTER fails with the 
> following:
>
> /opt/scripts/slonik/cluster/cluster_init.slonik:2: PGRES_FATAL_ERROR 
> select "_cluster".initializeLocalNode(40003, 'Node 40003'); select 
> "_cluster".enableNode(40003);  - ERROR:  bigint out of range
> CONTEXT:  SQL statement "SELECT  setval('"_cluster".sl_rowid_seq',  $1 
> ::int8 * '1000000000000000'::int8)"
> PL/pgSQL function "initializelocalnode" line 26 at perform
>
>
> The node in question was added via STORE NODE, and a MOVE SET was done 
> at some time.  If a node id is acceptable to STORE NODE should it not 
> also be acceptable to INIT CLUSTER?  I happened to notice this on a 
> 1.1.5 cluster, but it looks to me that initializeLocalNode() is 
> identical in v 1.2.
>
> JP
>


-- 
JP Fletcher
Database Administrator
Afilias Canada
voice: 416.646.3304 ext. 4123
fax: 416.646.3305
mobile: 416.561.4763
jpfletch@ca.afilias.info


From JanWieck at Yahoo.com  Wed Sep 12 13:30:52 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Wed Sep 12 13:31:36 2007
Subject: [Slony1-general] init cluster won't work when node id out of
	range.
In-Reply-To: <46E84099.3070100@ca.afilias.info>
References: <46E80FF5.6060202@ca.afilias.info>
	<46E84099.3070100@ca.afilias.info>
Message-ID: <46E84C7C.3000504@Yahoo.com>

On 9/12/2007 3:40 PM, JP Fletcher wrote:
> I just noticed when doing a different cluster, that the same thing seems 
> to happen with STORE NODE

It is a side effect of that TABLE ADD KEY misfeature. It requires a 
cluster wide uniquely maintained sequence, and the way slony does that 
is by setting that sequence to the nodeID * 1000000000000000.

I didn't plan for someone using birth dates or lottery ticket numbers as 
nodeID's ;-) Sorry, for the time being you have to stay below something 
around 9220 ... the problem will be gone in 2.0.


Jan

> 
> /opt/scripts/slonik/cluster/cluster_init.slonik:5: PGRES_FATAL_ERROR 
> select "_cluster".initializeLocalNode(650901, 'Node 650901'); select 
> "_cluster".enableNode_int(650901);  - ERROR:  bigint out of range
> CONTEXT:  SQL statement "SELECT  setval('"_cluster".sl_rowid_seq',  $1 
> ::int8 * '1000000000000000'::int8)"
> PL/pgSQL function "initializelocalnode" line 26 at perform
> 
> The slonik command was
> 
> STORE NODE (ID = 650901, EVENT NODE = 22, COMMENT = 'Node 650901');
> 
> These node ids may have been created initially on 1.0.5, many months ago...
> 
> JP Fletcher wrote:
>> Hi,
>>
>> I'm trying to create a  test cluster in the image of one that already 
>> exists.  The script I'm using  connects to the existing cluster, then 
>> builds an INIT CLUSTER command based on the current origin node.  The 
>> id of the node in question is 40003.  The INIT CLUSTER fails with the 
>> following:
>>
>> /opt/scripts/slonik/cluster/cluster_init.slonik:2: PGRES_FATAL_ERROR 
>> select "_cluster".initializeLocalNode(40003, 'Node 40003'); select 
>> "_cluster".enableNode(40003);  - ERROR:  bigint out of range
>> CONTEXT:  SQL statement "SELECT  setval('"_cluster".sl_rowid_seq',  $1 
>> ::int8 * '1000000000000000'::int8)"
>> PL/pgSQL function "initializelocalnode" line 26 at perform
>>
>>
>> The node in question was added via STORE NODE, and a MOVE SET was done 
>> at some time.  If a node id is acceptable to STORE NODE should it not 
>> also be acceptable to INIT CLUSTER?  I happened to notice this on a 
>> 1.1.5 cluster, but it looks to me that initializeLocalNode() is 
>> identical in v 1.2.
>>
>> JP
>>
> 
> 


-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From jpfletch at ca.afilias.info  Thu Sep 13 13:46:10 2007
From: jpfletch at ca.afilias.info (JP Fletcher)
Date: Thu Sep 13 13:47:34 2007
Subject: [Slony1-general] cluster broken
Message-ID: <46E9A192.2010906@ca.afilias.info>

Hi,

My 1.2.11 cluster abruptly stopped working, with the following error 
message present in the pg logs of the origin:

2007-09-13 20:29:06.358 UTC [1679750] cluster slony 10.1.2.133 ERROR:  
syntax error at or near "order" at character 283
2007-09-13 20:29:06.358 UTC [1679750] cluster slony 10.1.2.133 
STATEMENT:  declare LOG cursor for select     log_origin, log_xid, 
log_tableid,     log_actionseq, log_cmdtype,     
octet_length(log_cmddata),     case when octet_length(log_cmddata) <= 
8192         then log_cmddata         else null end from 
"_cluster".sl_log_1 where log_origin = 8143 and (  order by log_actionseq;


I had been changing some subscriptions around,  with no evidence of 
failure.  Apart from that, the cluster wasn't doing anything...

-- 
JP Fletcher
Database Administrator
Afilias Canada
voice: 416.646.3304 ext. 4123
fax: 416.646.3305
mobile: 416.561.4763
jpfletch@ca.afilias.info


From cbbrowne at ca.afilias.info  Thu Sep 13 14:42:41 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Thu Sep 13 14:43:18 2007
Subject: [Slony1-general] cluster broken
In-Reply-To: <46E9A192.2010906@ca.afilias.info> (JP Fletcher's message of "Thu,
	13 Sep 2007 16:46:10 -0400")
References: <46E9A192.2010906@ca.afilias.info>
Message-ID: <60y7fa2qem.fsf@dba2.int.libertyrms.com>

JP Fletcher <jpfletch@ca.afilias.info> writes:

> Hi,
>
> My 1.2.11 cluster abruptly stopped working, with the following error
> message present in the pg logs of the origin:
>
> 2007-09-13 20:29:06.358 UTC [1679750] cluster slony 10.1.2.133 ERROR:
> syntax error at or near "order" at character 283
> 2007-09-13 20:29:06.358 UTC [1679750] cluster slony 10.1.2.133
> STATEMENT:  declare LOG cursor for select     log_origin, log_xid,
> log_tableid,     log_actionseq, log_cmdtype,
> octet_length(log_cmddata),     case when octet_length(log_cmddata) <=
> 8192         then log_cmddata         else null end from
> "_cluster".sl_log_1 where log_origin = 8143 and (  order by
> log_actionseq;
>
>
> I had been changing some subscriptions around,  with no evidence of
> failure.  Apart from that, the cluster wasn't doing anything...

Hmm.  This sounds a whole lot like:

<http://gborg.postgresql.org/project/slony1/bugs/bugupdate.php?1226>

That was supposedly fixed about two years ago.
-- 
(reverse (concatenate 'string "ofni.secnanifxunil" "@" "enworbbc"))
http://www3.sympatico.ca/cbbrowne/linuxxian.html
There are  three kinds of people:  those who can count,  and those who
can't.
From Slawek.Jarosz at advantechamt.com  Fri Sep 14 03:23:52 2007
From: Slawek.Jarosz at advantechamt.com (Slawek Jarosz)
Date: Fri Sep 14 03:25:10 2007
Subject: [Slony1-general] Replication stopping
Message-ID: <8B3930FEA8618C44B48EB06B5D33A06EA4EBE3@satmail.Advantech.ca>

Hello, I am having problems with the stability of Slony-I (version
1.2.6).  I have a simple set up with 1 master and 1 slave database.
Both are running on 2 GHz, SuSE 9.2 Linux servers connect directly via
an ethernet cable.  I'm also running High-Availability Linux which I'm
using to manage the virtual database IP addresses and handle
network/machine failure events.
 
The test I'm doing is writing a UNIX timestamp the prime database and
checking if both databases are updated with the timestamp.  This runs
fine for a number of hours then a number of problems occur (sometimes
independantly):
1) the slave database is no longer updated with the timestamp (the
master is updated)
2) database primeship changes (master becomes slave) but according to HA
Linux no failure has occured.
 
>From the Slony log file I can see some errors which occur every 30
seconds or so:
 
2007-09-12 13:39:15 GMT ERROR  remoteWorkerThread_1: "begin transaction;
set transaction isolation level serializable; lock table
"_t1".sl_config_lock; select "_t1".failoverSet_int(1, 2, 1, 10787);
notify "_t1_Event"; notify "_t1_Confirm"; insert into "_t1".sl_event
(ev_origin, ev_seqno, ev_timestamp,      ev_minxid, ev_maxxid, ev_xip,
ev_type , ev_data1, ev_data2, ev_data3    ) values ('1', '10787',
'2007-09-12 07:34:50.791482', '9692768', '9692769', '', 'FAILOVER_SET',
'1', '2', '1'); insert into "_t1".sl_confirm      (con_origin,
con_received, con_seqno, con_timestamp)    values (1, 2, '10787',
now()); commit transaction;" PGRES_FATAL_ERROR ERROR:  duplicate key
violates unique constraint "pg_trigger_tgrelid_tgname_index"
 
>From log file slon-smsdb-node2.err (where smsdb is the name of my
database)
 
WATCHDOG: No Slon is running for node node2!
WATCHDOG: You ought to check the postmaster and slon for evidence of a
crash!
WATCHDOG: I'm going to restart slon for node2...
WATCHDOG: Restarted slon for the t1 cluster, PID 3240
 
>From PostgreSQL log file
 
2007-09-13 04:16:53 LOG:  SSL SYSCALL error: EOF detected
2007-09-13 04:16:53 LOG:  could not receive data from client: Connection
reset by peer
2007-09-13 04:16:53 LOG:  unexpected EOF on client connection

 
 
So the questions I have:
1) Where (i.e. log files) can I find out more information about what's
happening?
2) If Slony-I fails and looks like watchdog cannot recover from it, how
can I restart it?
3) And of course, any ideas why is Slony failing?
 
 
Thank you for your help,
Slawek
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070914/93fce2d8/attachment.htm
From cbbrowne at ca.afilias.info  Fri Sep 14 07:03:50 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri Sep 14 07:04:01 2007
Subject: [Slony1-general] Replication stopping
In-Reply-To: <8B3930FEA8618C44B48EB06B5D33A06EA4EBE3@satmail.Advantech.ca>
	(Slawek Jarosz's message of "Fri, 14 Sep 2007 06:23:52 -0400")
References: <8B3930FEA8618C44B48EB06B5D33A06EA4EBE3@satmail.Advantech.ca>
Message-ID: <60tzpx2vjt.fsf@dba2.int.libertyrms.com>

"Slawek Jarosz" <Slawek.Jarosz@advantechamt.com> writes:
> From the?Slony log file I can see some errors which occur every 30 seconds or so:
>
> 2007-09-12 13:39:15 GMT ERROR? remoteWorkerThread_1: "begin transaction; set transaction isolation level serializable; lock table "_t1".sl_config_lock; select
> "_t1".failoverSet_int(1, 2, 1, 10787); notify "_t1_Event"; notify "_t1_Confirm"; insert into "_t1".sl_event???? (ev_origin, ev_seqno, ev_timestamp,????? ev_minxid,
> ev_maxxid, ev_xip, ev_type , ev_data1, ev_data2, ev_data3??? ) values ('1', '10787', '2007-09-12 07:34:50.791482', '9692768', '9692769', '', 'FAILOVER_SET', '1', '2',
> '1'); insert into "_t1".sl_confirm????? (con_origin, con_received, con_seqno, con_timestamp)??? values (1, 2, '10787', now()); commit transaction;" PGRES_FATAL_ERROR
> ERROR:? duplicate key violates unique constraint "pg_trigger_tgrelid_tgname_index"

The error suggests that someone has been hacking on indexes by hand.  

Probably one of the tables has a trigger on it, which gets hidden, via
catalog trickery, on the subscribers.

Then someone added the "apparently missing" trigger by hand, rather
than via the slonik STORE TRIGGER command, and so there are now two
triggers, one "hidden by trickery," the other visible.

The FAILOVER attempts to restore the "hidden-by-trickery" triggers,
and fails, because you hacked the same trigger back into place.

And thus the problem every 30s...

Use DROP TRIGGER on the node to drop the visible version of the
trigger, and that should resolve that issue.  With some luck, that is
the only thing you need to do...

> From log file slon-smsdb-node2.err (where smsdb is the name of my database)
>
> ?
>
> WATCHDOG: No Slon is running for node node2!
> WATCHDOG: You ought to check the postmaster and slon for evidence of a crash!
> WATCHDOG: I'm going to restart slon for node2...
> WATCHDOG: Restarted slon for the t1 cluster, PID 3240

This is probably just falling out of the other issues - the slon hits
a fatal problem, and dies, so the watchdog finds it gone...
-- 
let name="cbbrowne" and tld="linuxfinances.info" in String.concat "@" [name;tld];;
http://linuxfinances.info/info/nonrdbms.html
Rules  of the  Evil  Overlord #39.  "If  I absolutely  must ride  into
battle, I  will certainly not ride  at the forefront of  my Legions of
Terror, nor will I seek out my opposite number among his army."
<http://www.eviloverlord.com/>
From Slawek.Jarosz at advantechamt.com  Fri Sep 14 08:27:54 2007
From: Slawek.Jarosz at advantechamt.com (Slawek Jarosz)
Date: Fri Sep 14 08:28:02 2007
Subject: [Slony1-general] Replication stopping
In-Reply-To: <60k5qt2spl.fsf@dba2.int.libertyrms.com>
Message-ID: <8B3930FEA8618C44B48EB06B5D33A06EA4EBE6@satmail.Advantech.ca>

I put the SQL statement that you supplied and it returned no results.
That means no duplicate triggers?

BTW, I also let Slony replicate the data across to the slave db after a
10 second delay because I found anything else was not sufficient for the
replication to occur reliably.  Is that normal?

The slonik script I'm running to set up the replication is below (I
removed a bunch of tables and sequences to make this shorter):

======================== START ======================

#! /bin/bash

host=`hostname`
if [ $host = "CM" ]
then
   HOST_PRIME=${CM_eth2_CM2}
   HOST_BACKUP=${CM2_eth2_CM}
else
   HOST_PRIME=${CM2_eth2_CM}
   HOST_BACKUP=${CM_eth2_CM2}
fi
DB_PORT=5432

rm -f /root/slony_setup.log

echo "Starting Slony setup" `date` > /root/slony_setup.log

if [ x$1 = "xuninstall" ]
then
slonik <<_EOF_ 2>> /root/slony_setup.log 1>> /root/slony_setup.log
    cluster name = t1;
    node 1 admin conninfo = 'dbname=smsdb host=$HOST_PRIME port=$DB_PORT
user=slonysu password=pass';
    node 2 admin conninfo = 'dbname=smsdb host=$HOST_BACKUP
port=$DB_PORT user=slonysu password=pass';
    try {
        uninstall node (id = 1);
    }
    on error {
        echo 'Could not uninstall Slony-I on node 1';
        exit -1;
    }
	try {
        uninstall node (id = 2);
    }
    on error {
        echo 'Could not uninstall Slony-I on node 2';
        exit -1;
    }
    echo 'Slony-I successfully uninstalled on database smsdb';
_EOF_

if [ $? -ne 0 ]
then
    echo Errors were detected.  Please review /root/slony_setup.log.
Uninstall halted.
    exit -1
fi

exit 0
fi

rm -f ~/.pgpass

echo $HOST_PRIME":5432:*:slonysu:pass" >> ~/.pgpass
echo $HOST_BACKUP":5432:*:slonysu:pass" >> ~/.pgpass

chmod 600 ~/.pgpass

slonik <<_EOF_ 2>> /root/slony_setup.log 1>> /root/slony_setup.log
    cluster name = t1;
    node 1 admin conninfo = 'dbname=smsdb host=$HOST_PRIME port=$DB_PORT
user=slonysu password=pass';
    node 2 admin conninfo = 'dbname=smsdb host=$HOST_BACKUP
port=$DB_PORT user=slonysu password=pass';
    try {
        echo 'Initializing the cluster';
        init cluster (id = 1, comment = 'Node 1');
    }
    on error {
        echo 'Could not initialize the cluster!';
        exit -1;
    }
    echo 'Database cluster initialized as Node 1';
    try {
        create set (id = 1, origin = 1, comment = 'smsdb tables');
    }
    on error {
        echo 'Could not create subscription set!';
        exit -1;
    }
    echo 'Subscription set created';
    try {
        echo 'Adding tables to the subscription set';

        echo '  Adding table public.t_fl_beam...';
        set add table (set id = 1, origin = 1, id = 1, full qualified
name = 'public.t_fl_beam', comment = 'Table public.t_fl_beam');
        echo '    done';

<---- + A WHOLE OF BUNCH OF OTHER TABLES and SEQUENCES ---->

        echo '  Adding sequence public.t_sla_condition_set_id_seq...';
        set add sequence (set id = 1, origin = 1, id = 108, full
qualified name = 'public.t_sla_condition_set_id_seq', comment =
'Sequence public.t_sla_condition_set_id_seq');
        echo '    done';

    }
    on error {
        echo 'Could not add tables and sequences!';
        exit -1;
    }
    echo 'All tables added';
_EOF_

if [ $? -ne 0 ]
then
    echo Errors were detected.  Please review /root/slony_setup.log and
fix the errors.
    exit -1
fi

sleep 10

slonik <<_EOF_ 2>> /root/slony_setup.log 1>> /root/slony_setup.log
    cluster name = t1;
    node 1 admin conninfo = 'dbname=smsdb host=$HOST_PRIME port=$DB_PORT
user=slonysu password=pass';
    node 2 admin conninfo = 'dbname=smsdb host=$HOST_BACKUP
port=$DB_PORT user=slonysu password=pass';
    try {
        echo 'Storing node 2 - try 1';
        store node (id = 2, comment = 'Node 2');
    }
    on error {
        echo 'Could not create Node 2!';
        exit -1;
    }
_EOF_

slonik <<_EOF_ 2>> /root/slony_setup.log 1>> /root/slony_setup.log
    cluster name = t1;
    node 1 admin conninfo = 'dbname=smsdb host=$HOST_PRIME port=$DB_PORT
user=slonysu password=pass';
    node 2 admin conninfo = 'dbname=smsdb host=$HOST_BACKUP
port=$DB_PORT user=slonysu password=pass';
    
    try {
        drop node ( id = 2 );
        uninstall node ( id = 2 );
        echo 'Recreating node 2 - try 2';
        store node (id = 2, comment = 'Node 2');
    }
    on error {
        echo 'Could not create Node 2!';
    }    
    
    try {
        echo 'Creating store paths';
        store path (server = 1, client = 2, conninfo = 'dbname=smsdb
host=$HOST_PRIME port=$DB_PORT user=slonysu password=pass');
        store path (server = 2, client = 1, conninfo = 'dbname=smsdb
host=$HOST_BACKUP port=$DB_PORT user=slonysu password=pass');
    }
    on error {
        echo 'Could not create store paths!';
        exit -1;
    }
    echo 'Store paths created';
    try {
        echo 'Storing listen network';
        store listen (origin = 1, provider = 1, receiver = 2);
        store listen (origin = 2, provider = 2, receiver = 1);
    }
    on error {
        echo 'Could not store listen network!';
        exit -1;
    }
    echo 'listen network stored';
_EOF_

if [ $? -ne 0 ]
then
    echo Errors were detected.  Please review /root/slony_setup.log and
fix the errors.
    exit -1
fi

/usr/local/bin/slon_start 1 2>> /root/slony_setup.log 1>>
/root/slony_setup.log
/usr/local/bin/slon_start 2 2>> /root/slony_setup.log 1>>
/root/slony_setup.log

if [ $? -ne 0 ]
then
    echo Errors were detected.  Please review /root/slony_setup.log and
fix the errors.
    exit -1
else
#     /usr/local/bin/slon_start 1 2>/root/redundancy/slon-smsdb.err
>/root/redundancy/slon-smsdb.out
#     /usr/local/bin/slon_start 2 2>>/root/redundancy/slon-smsdb.err
>>/root/redundancy/slon-smsdb.out

#    slon t1 "user=slonysu host=$HOST_PRIME dbname=smsdb"
2>/root/slon-smsdb.err >/root/slon-smsdb.out &
    echo slon has been started on the master and slave and placed into
the background.
    echo It is logging STDOUT to /root/slon-smsdb.out and STDERR to
/root/slon-smsdb.err.
    echo
fi


slonik <<_EOF_ 2>> /root/slony_setup.log 1>> /root/slony_setup.log
    cluster name = t1;
    node 1 admin conninfo = 'dbname=smsdb host=$HOST_PRIME port=$DB_PORT
user=slonysu password=pass';
    node 2 admin conninfo = 'dbname=smsdb host=$HOST_BACKUP
port=$DB_PORT user=slonysu password=pass';

    try {
        subscribe set (id = 1, provider = 1, receiver = 2, forward =
no);
    }
    on error {
        echo 'Could not subscribe the set to the slaves';
        echo '-> Try again';
        try {
            echo 'Recreating node 2 - after subscribtion failure';
            store node (id = 2, comment = 'Node 2');
        }
        on error {
            echo 'Could not create Node 2!';
            exit -1;
        }
        try {
            subscribe set (id = 1, provider = 1, receiver = 2, forward =
no);
        }
        on error {
            exit -1;
        }
    }
    echo 'Database smsdb subscribed to slaves';
_EOF_

if [ $? -ne 0 ]
then
    echo Errors were detected.  Please review /root/slony_setup.log and
fix the errors.
    exit -1
fi

echo The installation has succeeded.  At this time the slaves should be
receiving the data
echo from the master.

======================== END ======================

 

-----Original Message-----
From: Christopher Browne [mailto:cbbrowne@ca.afilias.info] 
Sent: Friday, September 14, 2007 11:05 AM
To: Slawek Jarosz
Subject: Re: [Slony1-general] Replication stopping

"Slawek Jarosz" <Slawek.Jarosz@advantechamt.com> writes:

> Hello, first of all thanks for the quick response.
>
> I am pretty sure no one has added a trigger by hand.  The servers are 
> only controlled by me and I haven't done anything.  However the main 
> database that I'm working with has triggers on half of the tables.  
> These are BEFORE or AFTER triggers and these triggers cause another 
> table to be updated automatically (a log of all database actions 
> performed).

Well, that suggests that there shouldn't be lavish quantities of
hand-hacked stuff, at least :-).

> What puzzles me is that fact that replication is running great of a 
> long period of time (hours) before these issues can be seen.  When 
> they occur, I have to recreate the master and slave databases (BTW, 
> I'm using PostgreSQL 7.4.2), running the slonik scripts to create the 
> nodes, subscription sets and everything else before the replication 
> starts again.  slon_kill & slon_start does not fix the issue.  Is 
> there any other way to restart Slony?

It is likely that there was some more or less subtle thing broken in the
configuration that you didn't find.

slon_kill / slon_start will fix things like:
 - DB connections that have gotten mussed up due to network events
 - A slon that has gotten confused ABOUT ITS STATE (OOPS - KEYBOARD
WEIRDNESS JUST NOW...)

> When you mentioned that one of the tables has duplicate triggers on 
> it, how can I check which one?

select a.* from pg_trigger a, pg_trigger b where a.tgrelid = b.tgrelid
and a.tgname = b.tgname and a.oid <> b.oid;
--
output = ("cbbrowne" "@" "acm.org")
http://www3.sympatico.ca/cbbrowne/linux.html
                              MULTICS MAN!!!!
With his power ring PL-1, backed by the mighty resources of the powerful
H-6880, his faithful sidekick, the Fso Eagle, and his trusted gang: "The
System Daemons", he fights a never-ending battle for truth, security,
and the Honeywell Way!
-- T. Kenney
From dba at richyen.com  Fri Sep 14 11:50:57 2007
From: dba at richyen.com (Richard Yen)
Date: Fri Sep 14 11:51:15 2007
Subject: [Slony1-general] EXECUTE SCRIPT error causes subscribers not to get
	DDL commands
Message-ID: <1F6A6204-C556-424E-A6F3-9B31A506F8B9@richyen.com>

Hi All,

Ran an EXECUTE SCRIPT command, but somewhere, the script failed.  The  
DDL statements were successfully executed on the provider, but for  
the two subscribers, naturally, nothing happened.

Now, I'm wondering what I need to do?  Manually add the columns in on  
the subscribers?  Attempt to drop the columns from the provider?  Do  
something else?

Here is the output of my slonik command:
> perform a single schema change
> DDL script consisting of 4 SQL statements
> DDL Statement 0: (0,6) [BEGIN;]
> <stdin>:6: WARNING:  there is already a transaction in progress
> DDL Statement 1: (6,57) [
> ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;]
> DDL Statement 2: (57,109) [
> ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;]
> DDL Statement 3: (109,117) [
> COMMIT;]
> Complete DDL Event...
> Event submission for DDL failed - PGRES_FATAL_ERROR
> <stdin>:6: WARNING:  there is no transaction in progress

Not sure if it helps much.  I'm still scouring around my logs for the  
statement that failed, but I don't think I can uncover it...

Any suggestions/little known facts about what I can do?

Thanks!
--Richard
From dba at richyen.com  Fri Sep 14 11:54:29 2007
From: dba at richyen.com (Richard Yen)
Date: Fri Sep 14 11:54:46 2007
Subject: [Slony1-general] EXECUTE SCRIPT error causes subscribers not to
	get DDL commands
In-Reply-To: <1F6A6204-C556-424E-A6F3-9B31A506F8B9@richyen.com>
References: <1F6A6204-C556-424E-A6F3-9B31A506F8B9@richyen.com>
Message-ID: <A4B67153-62D7-44A0-AED2-244A4BE1AC07@richyen.com>

btw, replication is still happily proceeding...

--Richard


On Sep 14, 2007, at 11:50 AM, Richard Yen wrote:

> Hi All,
>
> Ran an EXECUTE SCRIPT command, but somewhere, the script failed.   
> The DDL statements were successfully executed on the provider, but  
> for the two subscribers, naturally, nothing happened.
>
> Now, I'm wondering what I need to do?  Manually add the columns in  
> on the subscribers?  Attempt to drop the columns from the  
> provider?  Do something else?
>
> Here is the output of my slonik command:
>> perform a single schema change
>> DDL script consisting of 4 SQL statements
>> DDL Statement 0: (0,6) [BEGIN;]
>> <stdin>:6: WARNING:  there is already a transaction in progress
>> DDL Statement 1: (6,57) [
>> ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;]
>> DDL Statement 2: (57,109) [
>> ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;]
>> DDL Statement 3: (109,117) [
>> COMMIT;]
>> Complete DDL Event...
>> Event submission for DDL failed - PGRES_FATAL_ERROR
>> <stdin>:6: WARNING:  there is no transaction in progress
>
> Not sure if it helps much.  I'm still scouring around my logs for  
> the statement that failed, but I don't think I can uncover it...
>
> Any suggestions/little known facts about what I can do?
>
> Thanks!
> --Richard
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general

From dmitry at koterov.ru  Fri Sep 14 12:05:09 2007
From: dmitry at koterov.ru (Dmitry Koterov)
Date: Fri Sep 14 12:05:30 2007
Subject: [Slony1-general] EXECUTE SCRIPT error causes subscribers not to
	get DDL commands
In-Reply-To: <A4B67153-62D7-44A0-AED2-244A4BE1AC07@richyen.com>
References: <1F6A6204-C556-424E-A6F3-9B31A506F8B9@richyen.com>
	<A4B67153-62D7-44A0-AED2-244A4BE1AC07@richyen.com>
Message-ID: <d7df81620709141205l73340d40le150cbec0abc620d@mail.gmail.com>

Possibly it is because you have used BEGIN/COMMIT statements inside the
slonik script?
(I'm not sure that exactly this caused your problem, but you surely MUST
avoid using a BEGIN statement.)

On 9/14/07, Richard Yen <dba@richyen.com> wrote:
>
> btw, replication is still happily proceeding...
>
> --Richard
>
>
> On Sep 14, 2007, at 11:50 AM, Richard Yen wrote:
>
> > Hi All,
> >
> > Ran an EXECUTE SCRIPT command, but somewhere, the script failed.
> > The DDL statements were successfully executed on the provider, but
> > for the two subscribers, naturally, nothing happened.
> >
> > Now, I'm wondering what I need to do?  Manually add the columns in
> > on the subscribers?  Attempt to drop the columns from the
> > provider?  Do something else?
> >
> > Here is the output of my slonik command:
> >> perform a single schema change
> >> DDL script consisting of 4 SQL statements
> >> DDL Statement 0: (0,6) [BEGIN;]
> >> <stdin>:6: WARNING:  there is already a transaction in progress
> >> DDL Statement 1: (6,57) [
> >> ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;]
> >> DDL Statement 2: (57,109) [
> >> ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;]
> >> DDL Statement 3: (109,117) [
> >> COMMIT;]
> >> Complete DDL Event...
> >> Event submission for DDL failed - PGRES_FATAL_ERROR
> >> <stdin>:6: WARNING:  there is no transaction in progress
> >
> > Not sure if it helps much.  I'm still scouring around my logs for
> > the statement that failed, but I don't think I can uncover it...
> >
> > Any suggestions/little known facts about what I can do?
> >
> > Thanks!
> > --Richard
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general@lists.slony.info
> > http://lists.slony.info/mailman/listinfo/slony1-general
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070914/=
effe6746/attachment.htm
From dmitry at koterov.ru  Fri Sep 14 12:10:51 2007
From: dmitry at koterov.ru (Dmitry Koterov)
Date: Fri Sep 14 12:11:13 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E71999.6090600@Yahoo.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>
	<46E55D8B.3050003@orange-ftgroup.com>
	<46E57392.4000706@ca.afilias.info>
	<46E5759B.5090709@orange-ftgroup.com> <46E57E4E.2090807@Yahoo.com>
	<46E5A297.3090309@orange-ftgroup.com>
	<5a0a9d6f0709101502v277c5dectac299f4c39e5e957@mail.gmail.com>
	<46E64E36.2070400@orange-ftgroup.com> <46E71999.6090600@Yahoo.com>
Message-ID: <d7df81620709141210j6785fdb2v4fb29cbb14098e2c@mail.gmail.com>

MySQL has the "binary log" to which all data is appended before it is
committed to the real table. All MySQL replicas are simply replaying this
binary log from a specified position, so it is quite close to what Slony
does (but Slony uses its own event log, not built-in as in MySQL). Seems an
asynchronous statement-based replication does not exists in the world at
all.

On 9/12/07, Jan Wieck <JanWieck@yahoo.com> wrote:
>
> On 9/11/2007 4:13 AM, Cyril SCETBON wrote:
>
> > OK.
> > You don't think that it alter the performance doing 100 updates for a
> > table with 100 atributes versus one update on 2 columns ? We certainly
> > have to accept poor performance when applying log if we use log shipping
> > in this case ?
>
> Certainly does statement based replication offer better performance when
> used for mass-updates or mass-deletes. But how on earth do you replicate
> something like
>
>      UPDATE foo SET bar =3D random();
>
> with a statement based replication system. And under MVCC, how do you
> ensure that the order and logical content of all transaction visibility
> snapshots is consistent while replicating the data? Please note that
> something as simple as
>
>      DELETE FROM foo WHERE bar < 20;
>
> executed by a session in READ COMMITTED transaction isolation level will
> delete different sets of rows if a concurrent transaction, setting a
> rows bar from 30 to 10 committed before or after it. This MVCC
> visibility crap will also be in the way if your answer to the above
> random() problem was "setting the random seed ...".
>
> And finally, consider 20 concurrent sessions, each doing all sorts of
> things using temp tables, then doing
>
>      INSERT INTO real_table SELECT nextval('some_seq'), a, b, c
>          FROM temp_table;
>
> Lets ignore for a moment the fact that actually using those 20 temp
> tables would require to replay the updates on the replica in 20 separate
> and concurrent sessions, which ultimately will lead to a replication
> design that requires each and every single master session to be
> replicated in its own slave session (if your master has 200 clients,
> your slave will eventually have 200 replication DB connections to serve).
>
> All those 20 sessions have concurrent access to real_table. They will
> run in parallel. It is totally impossible to foresee which session will
> allocate which sequence numbers. So what's your idea to coordinate that
> mess within a statement based replication system? And don't tell me you
> want to serialize those transactions, because the point of doing
> something like that in the first place is probably performance problems,
> so serializing all application access isn't going to be the answer.
>
> Does anyone know what MySQL using InnoDB tables would do in this case?
>
>
> Jan
>
> --
> #=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D#
> # It's easier to get forgiveness for being wrong than for being right. #
> # Let's break this rule - forgive me.                                  #
> #=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D JanWieck@Yahoo.com #
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070914/=
408d53c7/attachment.htm
From ajs at crankycanuck.ca  Fri Sep 14 12:19:54 2007
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Fri Sep 14 12:20:24 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <d7df81620709141210j6785fdb2v4fb29cbb14098e2c@mail.gmail.com>
References: <46E559F3.60602@Yahoo.com> <46E55D8B.3050003@orange-ftgroup.com>
	<46E57392.4000706@ca.afilias.info>
	<46E5759B.5090709@orange-ftgroup.com> <46E57E4E.2090807@Yahoo.com>
	<46E5A297.3090309@orange-ftgroup.com>
	<5a0a9d6f0709101502v277c5dectac299f4c39e5e957@mail.gmail.com>
	<46E64E36.2070400@orange-ftgroup.com> <46E71999.6090600@Yahoo.com>
	<d7df81620709141210j6785fdb2v4fb29cbb14098e2c@mail.gmail.com>
Message-ID: <20070914191954.GG25868@crankycanuck.ca>

On Fri, Sep 14, 2007 at 11:10:51PM +0400, Dmitry Koterov wrote:
> binary log from a specified position, so it is quite close to what Slony
> does (but Slony uses its own event log, not built-in as in MySQL). Seems an

No, that's more like what PITR does.  

A

-- 
Andrew Sullivan  | ajs@crankycanuck.ca
The whole tendency of modern prose is away from concreteness.
		--George Orwell
From cbbrowne at ca.afilias.info  Fri Sep 14 13:15:18 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri Sep 14 13:15:40 2007
Subject: [Slony1-general] EXECUTE SCRIPT error causes subscribers not to
	get DDL commands
In-Reply-To: <1F6A6204-C556-424E-A6F3-9B31A506F8B9@richyen.com> (Richard Yen's
	message of "Fri, 14 Sep 2007 11:50:57 -0700")
References: <1F6A6204-C556-424E-A6F3-9B31A506F8B9@richyen.com>
Message-ID: <60k5qt9f6x.fsf@dba2.int.libertyrms.com>

Richard Yen <dba@richyen.com> writes:
> Hi All,
>
> Ran an EXECUTE SCRIPT command, but somewhere, the script failed.  The
> DDL statements were successfully executed on the provider, but for
> the two subscribers, naturally, nothing happened.
>
> Now, I'm wondering what I need to do?  Manually add the columns in on
> the subscribers?  Attempt to drop the columns from the provider?  Do
> something else?
>
> Here is the output of my slonik command:
>> perform a single schema change
>> DDL script consisting of 4 SQL statements
>> DDL Statement 0: (0,6) [BEGIN;]
>> <stdin>:6: WARNING:  there is already a transaction in progress
>> DDL Statement 1: (6,57) [
>> ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;]
>> DDL Statement 2: (57,109) [
>> ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;]
>> DDL Statement 3: (109,117) [
>> COMMIT;]
>> Complete DDL Event...
>> Event submission for DDL failed - PGRES_FATAL_ERROR
>> <stdin>:6: WARNING:  there is no transaction in progress
>
> Not sure if it helps much.  I'm still scouring around my logs for the
> statement that failed, but I don't think I can uncover it...
>
> Any suggestions/little known facts about what I can do?

<http://slony.info/documentation/ddlchanges.html>

I can point to where the problem lies:

   "The script must not contain transaction BEGIN or END statements,
    as the script is already executed inside a transaction."

I see a BEGIN and a COMMIT, which *guarantees* that the submission
works wrongly.

If you submit a DDL script consisting of:

BEGIN;
ALTER TABLE DROP COLUMN CRAWL_HOST;
ALTER TABLE DROP COLUMN CRAWL_PORT;
COMMIT;

(which re-commits, in the opposite fashion, the same sin that the first script did)

That should put the "master" back into the appropriate form.

You could then resubmit a slonik DDL script consisting of 
 ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;
 ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;
WITH NEITHER A BEGIN NOR A COMMIT IN IT...

If you're lucky, then you have not submitted any updates that would
have tried to add new tuples to table m_nodes, and this DDL script
should be able to propagate.

If there are tuples queued up with
m_nodes.crawl_port/m_nodes.crawl_host, sitting in sl_log_1, then I'm
not quite sure offhand what to suggest.
-- 
output = reverse("ofni.sesabatadxunil" "@" "enworbbc")
http://cbbrowne.com/info/unix.html
Rules of the Evil Overlord  #162. "If I steal something very important
to the hero, I will not put it on public display.
<http://www.eviloverlord.com/>
From andrew.george.hammond at gmail.com  Fri Sep 14 14:53:58 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Fri Sep 14 14:54:26 2007
Subject: [Slony1-general] EXECUTE SCRIPT error causes subscribers not to
	get DDL commands
In-Reply-To: <60k5qt9f6x.fsf@dba2.int.libertyrms.com>
References: <1F6A6204-C556-424E-A6F3-9B31A506F8B9@richyen.com>
	<60k5qt9f6x.fsf@dba2.int.libertyrms.com>
Message-ID: <5a0a9d6f0709141453t1618fc09tf0e26f272ec7b97d@mail.gmail.com>

On 9/14/07, Christopher Browne <cbbrowne@ca.afilias.info> wrote:
>
> Richard Yen <dba@richyen.com> writes:
> > Hi All,
> >
> > Ran an EXECUTE SCRIPT command, but somewhere, the script failed.  The
> > DDL statements were successfully executed on the provider, but for
> > the two subscribers, naturally, nothing happened.
> >
> > Now, I'm wondering what I need to do?  Manually add the columns in on
> > the subscribers?  Attempt to drop the columns from the provider?  Do
> > something else?
> >
> > Here is the output of my slonik command:
> >> perform a single schema change
> >> DDL script consisting of 4 SQL statements
> >> DDL Statement 0: (0,6) [BEGIN;]
> >> <stdin>:6: WARNING:  there is already a transaction in progress
> >> DDL Statement 1: (6,57) [
> >> ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;]
> >> DDL Statement 2: (57,109) [
> >> ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;]
> >> DDL Statement 3: (109,117) [
> >> COMMIT;]
> >> Complete DDL Event...
> >> Event submission for DDL failed - PGRES_FATAL_ERROR
> >> <stdin>:6: WARNING:  there is no transaction in progress
> >
> > Not sure if it helps much.  I'm still scouring around my logs for the
> > statement that failed, but I don't think I can uncover it...
> >
> > Any suggestions/little known facts about what I can do?
>
> <http://slony.info/documentation/ddlchanges.html>
>
> I can point to where the problem lies:
>
>    "The script must not contain transaction BEGIN or END statements,
>     as the script is already executed inside a transaction."
>
> I see a BEGIN and a COMMIT, which *guarantees* that the submission
> works wrongly.
>
> If you submit a DDL script consisting of:
>
> BEGIN;
> ALTER TABLE DROP COLUMN CRAWL_HOST;
> ALTER TABLE DROP COLUMN CRAWL_PORT;
> COMMIT;
>
> (which re-commits, in the opposite fashion, the same sin that the first
> script did)
>
> That should put the "master" back into the appropriate form.
>
> You could then resubmit a slonik DDL script consisting of
> ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;
> ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;
> WITH NEITHER A BEGIN NOR A COMMIT IN IT...
>
> If you're lucky, then you have not submitted any updates that would
> have tried to add new tuples to table m_nodes, and this DDL script
> should be able to propagate.
>
> If there are tuples queued up with
> m_nodes.crawl_port/m_nodes.crawl_host, sitting in sl_log_1, then I'm
> not quite sure offhand what to suggest.
>
>
You mean aside from reading the manual before using an admittedly bare-metal
tool? :)

Actually, I think this points out a potential new feature in slonik: detect
and refuse to run EXECUTE DDL commands which include transaction management
statements (BEGIN, COMMIT, ROLLBACK, SAVEPOINT and RELEASE).

Oh, and we probably need to update the documentation to talk about
savepoints too. I can't think of any legitimate way to use them, but then
again, it is a Friday afternoon so maybe I'm just being dense.

Andrew
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070914/=
fdccaa4b/attachment-0001.htm
From cbbrowne at ca.afilias.info  Fri Sep 14 15:11:45 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri Sep 14 15:12:13 2007
Subject: [Slony1-general] Problem with log shipping...
Message-ID: <60sl5g99su.fsf@dba2.int.libertyrms.com>

I'm discovering some problems with the new log shipping handling; note
in the following that there are sequence numbers duplicated.  Notably,
consider:

slony1_log_2_00000000000000000005.sql
slony1_log_2_00000000000000000008.sql
slony1_log_2_00000000000000000016.sql
slony1_log_2_00000000000000000018.sql
slony1_log_2_00000000000000000020.sql
slony1_log_2_00000000000000000027.sql
slony1_log_2_00000000000000000032.sql
slony1_log_2_00000000000000000041.sql
slony1_log_2_00000000000000000043.sql
slony1_log_2_00000000000000000047.sql
slony1_log_2_00000000000000000055.sql
slony1_log_2_00000000000000000062.sql
slony1_log_2_00000000000000000064.sql
slony1_log_2_00000000000000000067.sql
slony1_log_2_00000000000000000069.sql
slony1_log_2_00000000000000000071.sql

For each of these, there is a corresponding slony1_log_1_.......sql file.

The whole list:

slony1_log_1_00000000000000000001.sql
slony1_log_1_00000000000000000002.sql
slony1_log_1_00000000000000000003.sql
slony1_log_1_00000000000000000004.sql
slony1_log_1_00000000000000000005.sql
slony1_log_1_00000000000000000006.sql
slony1_log_1_00000000000000000007.sql
slony1_log_1_00000000000000000008.sql
slony1_log_1_00000000000000000010.sql
slony1_log_1_00000000000000000011.sql
slony1_log_1_00000000000000000012.sql
slony1_log_1_00000000000000000013.sql
slony1_log_1_00000000000000000014.sql
slony1_log_1_00000000000000000015.sql
slony1_log_1_00000000000000000016.sql
slony1_log_1_00000000000000000017.sql
slony1_log_1_00000000000000000018.sql
slony1_log_1_00000000000000000019.sql
slony1_log_1_00000000000000000020.sql
slony1_log_1_00000000000000000021.sql
slony1_log_1_00000000000000000022.sql
slony1_log_1_00000000000000000024.sql
slony1_log_1_00000000000000000026.sql
slony1_log_1_00000000000000000027.sql
slony1_log_1_00000000000000000028.sql
slony1_log_1_00000000000000000029.sql
slony1_log_1_00000000000000000031.sql
slony1_log_1_00000000000000000032.sql
slony1_log_1_00000000000000000033.sql
slony1_log_1_00000000000000000034.sql
slony1_log_1_00000000000000000035.sql
slony1_log_1_00000000000000000036.sql
slony1_log_1_00000000000000000037.sql
slony1_log_1_00000000000000000038.sql
slony1_log_1_00000000000000000039.sql
slony1_log_1_00000000000000000040.sql
slony1_log_1_00000000000000000041.sql
slony1_log_1_00000000000000000042.sql
slony1_log_1_00000000000000000043.sql
slony1_log_1_00000000000000000044.sql
slony1_log_1_00000000000000000045.sql
slony1_log_1_00000000000000000046.sql
slony1_log_1_00000000000000000047.sql
slony1_log_1_00000000000000000048.sql
slony1_log_1_00000000000000000049.sql
slony1_log_1_00000000000000000051.sql
slony1_log_1_00000000000000000053.sql
slony1_log_1_00000000000000000054.sql
slony1_log_1_00000000000000000055.sql
slony1_log_1_00000000000000000056.sql
slony1_log_1_00000000000000000057.sql
slony1_log_1_00000000000000000059.sql
slony1_log_1_00000000000000000060.sql
slony1_log_1_00000000000000000061.sql
slony1_log_1_00000000000000000062.sql
slony1_log_1_00000000000000000063.sql
slony1_log_1_00000000000000000064.sql
slony1_log_1_00000000000000000065.sql
slony1_log_1_00000000000000000066.sql
slony1_log_1_00000000000000000067.sql
slony1_log_1_00000000000000000068.sql
slony1_log_1_00000000000000000069.sql
slony1_log_1_00000000000000000070.sql
slony1_log_1_00000000000000000071.sql
slony1_log_2_00000000000000000005.sql
slony1_log_2_00000000000000000008.sql
slony1_log_2_00000000000000000009.sql
slony1_log_2_00000000000000000016.sql
slony1_log_2_00000000000000000018.sql
slony1_log_2_00000000000000000020.sql
slony1_log_2_00000000000000000023.sql
slony1_log_2_00000000000000000025.sql
slony1_log_2_00000000000000000027.sql
slony1_log_2_00000000000000000030.sql
slony1_log_2_00000000000000000032.sql
slony1_log_2_00000000000000000041.sql
slony1_log_2_00000000000000000043.sql
slony1_log_2_00000000000000000047.sql
slony1_log_2_00000000000000000050.sql
slony1_log_2_00000000000000000052.sql
slony1_log_2_00000000000000000055.sql
slony1_log_2_00000000000000000058.sql
slony1_log_2_00000000000000000062.sql
slony1_log_2_00000000000000000064.sql
slony1_log_2_00000000000000000067.sql
slony1_log_2_00000000000000000069.sql
slony1_log_2_00000000000000000071.sql
slony1_log_3_00000000000000000009.sql
slony1_log_3_00000000000000000010.sql
slony1_log_3_00000000000000000011.sql
slony1_log_3_00000000000000000017.sql
slony1_log_3_00000000000000000019.sql
slony1_log_3_00000000000000000021.sql
slony1_log_3_00000000000000000023.sql
slony1_log_3_00000000000000000025.sql
slony1_log_3_00000000000000000026.sql
slony1_log_3_00000000000000000029.sql
slony1_log_3_00000000000000000030.sql
slony1_log_3_00000000000000000033.sql
slony1_log_3_00000000000000000034.sql
slony1_log_3_00000000000000000036.sql
slony1_log_3_00000000000000000037.sql
slony1_log_3_00000000000000000040.sql
slony1_log_3_00000000000000000042.sql
slony1_log_3_00000000000000000046.sql
slony1_log_3_00000000000000000048.sql
slony1_log_3_00000000000000000049.sql
slony1_log_3_00000000000000000050.sql
slony1_log_3_00000000000000000051.sql
slony1_log_3_00000000000000000052.sql
slony1_log_3_00000000000000000053.sql
slony1_log_3_00000000000000000057.sql
slony1_log_3_00000000000000000058.sql
slony1_log_3_00000000000000000059.sql
slony1_log_3_00000000000000000063.sql
slony1_log_3_00000000000000000066.sql
slony1_log_3_00000000000000000068.sql
slony1_log_3_00000000000000000070.sql
-- 
(reverse (concatenate 'string "gro.mca" "@" "enworbbc"))
http://cbbrowne.com/info/sap.html
Rules of  the Evil Overlord #134. "If  I am escaping in  a large truck
and the hero is pursuing me in  a small Italian sports car, I will not
wait for the hero to pull up along side of me and try to force him off
the road  as he attempts to climb  aboard. Instead I will  slam on the
brakes  when he's  directly behind  me.  (A  rudimentary  knowledge of
physics can prove quite useful.)" <http://www.eviloverlord.com/>
From jason at buberel.org  Fri Sep 14 16:23:03 2007
From: jason at buberel.org (Jason L. Buberel)
Date: Fri Sep 14 16:23:27 2007
Subject: [Slony1-general] logswtich.weekly causing postmaster to crash?
Message-ID: <46EB17D7.4050701@buberel.org>

This configuration is running latest 1.2.11 slon on 8.2.4. After running =

a pg_bulkload command and starting slony back up, something that slony =

tried to do triggered the postmaster to restart suddenly. The listener =

for node 2 of a 3-node cluster starting up following the use of =

pg_bulkload to import 600k records:

Sep 14 09:26:40 srv2 postgres-8.2[13372]: [3-2] STATEMENT:  SELECT =

pg_bulkload($1)
Sep 14 09:26:57 srv2 sshd(pam_unix)[13389]: session opened for user =

jason by (uid=3D0)
Sep 14 09:27:07 srv2 sshd(pam_unix)[13389]: session closed for user jason
Sep 14 09:27:18 srv2 postgres-8.2[13490]: [2-1] NOTICE:  BULK LOAD START
Sep 14 09:40:37 srv2 postgres-8.2[13490]: [3-1] NOTICE:  BULK LOAD END  =

(632832 records)
Sep 14 09:40:37 srv2 postgres-8.2[13490]: [4-1] LOG:  duration: =

799245.160 ms  execute <unnamed>: SELECT pg_bulkload($1)
Sep 14 09:40:37 srv2 postgres-8.2[13490]: [4-2] DETAIL:  parameters: $1 =

=3D '/pgdata/8.2/sample_csv.ctl'

then:

Sep 14 10:48:18 srv2 slon[13841]: [27-1] 2007-09-14 10:48:18 CDT CONFIG =

main: configuration complete - starting threads
Sep 14 10:48:18 srv2 postgres-8.2[13852]: [2-1] NOTICE:  Slony-I: =

cleanup stale sl_nodelock entry for pid=3D23070
Sep 14 10:48:18 srv2 postgres-8.2[13852]: [3-1] NOTICE:  Slony-I: =

cleanup stale sl_nodelock entry for pid=3D1288
Sep 14 10:48:18 srv2 postgres-8.2[13852]: [4-1] NOTICE:  Slony-I: =

cleanup stale sl_nodelock entry for pid=3D1292
Sep 14 10:48:18 srv2 slon[13841]: [29-1] 2007-09-14 10:48:18 CDT CONFIG =

enableNode: no_id=3D1
Sep 14 10:48:18 srv2 slon[13841]: [30-1] 2007-09-14 10:48:18 CDT CONFIG =

enableNode: no_id=3D3

followed by:

Sep 14 10:59:26 srv2 slon[13841]: [45-1] 2007-09-14 10:59:26 CDT WARN   =

cleanupThread: "select "_ar_primary".logswitch_weekly(); " - server =

closed the connection
Sep 14 10:59:26 srv2 slon[13841]: [45-2]  unexpectedly
Sep 14 10:59:26 srv2 slon[13841]: [45-3]        This probably means the =

server terminated abnormally
Sep 14 10:59:26 srv2 slon[13841]: [45-4]        before or while =

processing the request.
Sep 14 10:59:26 srv2 slon[13841]: [46-1] 2007-09-14 10:59:26 CDT FATAL  =

cleanupThread: "delete from "_ar_primary".sl_log_1 where log_origin =3D =

'2' and log_xid <
Sep 14 10:59:26 srv2 slon[13841]: [46-2]  '151706861'; delete from =

"_ar_primary".sl_log_2 where log_origin =3D '2' and log_xid < '151706861'; =

delete from
Sep 14 10:59:26 srv2 slon[13841]: [46-3]  "_ar_primary".sl_seqlog where =

seql_origin =3D '2' and seql_ev_seqno < '1686420'; select =

"_ar_primary".logswitch_finish(); " -
Sep 14 10:59:26 srv2 postgres-8.2[25487]: [2-1] LOG:  server process =

(PID 13861) was terminated by signal 11
Sep 14 10:59:26 srv2 postgres-8.2[25487]: [3-1] LOG:  terminating any =

other active server processes
Sep 14 10:59:26 srv2 postgres-8.2[14136]: [5-1] WARNING:  terminating =

connection because of crash of another server process

The postmaster is now running again, but I am afraid to restart slony =

again. Anything I can do to verify the integrity of the slon =

configuration that will not crash the postmaster?

Thanks,
jason
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070914/=
8aa2face/attachment.htm
From cbbrowne at ca.afilias.info  Fri Sep 14 18:20:55 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri Sep 14 18:21:29 2007
Subject: [Slony1-general] Problem with log shipping...
In-Reply-To: <60sl5g99su.fsf@dba2.int.libertyrms.com> (Christopher Browne's
	message of "Fri, 14 Sep 2007 18:11:45 -0400")
References: <60sl5g99su.fsf@dba2.int.libertyrms.com>
Message-ID: <60odg4911k.fsf@dba2.int.libertyrms.com>

Christopher Browne <cbbrowne@ca.afilias.info> writes:
> I'm discovering some problems with the new log shipping handling; note
> in the following that there are sequence numbers duplicated.  

It strikes me that perhaps there's a race condition here...  My first
thought is "perhaps a lock should be taken out on sl_archive_counter
at the start of each archive log..."

That seems like not a bad idea, but it doesn't seem to be the key...
-- 
(reverse (concatenate 'string "gro.mca" "@" "enworbbc"))
http://cbbrowne.com/info/spreadsheets.html
Stop the world! I want to get off!! 
From cbbrowne at ca.afilias.info  Fri Sep 14 18:35:00 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri Sep 14 18:35:37 2007
Subject: [Slony1-general] logswtich.weekly causing postmaster to crash?
In-Reply-To: <46EB17D7.4050701@buberel.org> (Jason L. Buberel's message of
	"Fri, 14 Sep 2007 16:23:03 -0700")
References: <46EB17D7.4050701@buberel.org>
Message-ID: <60k5qs90e3.fsf@dba2.int.libertyrms.com>

"Jason L. Buberel" <jason@buberel.org> writes:
> This configuration is running latest 1.2.11 slon on 8.2.4. After running a pg_bulkload command and starting slony back up, something that slony tried to do triggered
> the postmaster to restart suddenly. The listener for node 2 of a 3-node cluster starting up following the use of pg_bulkload to import 600k records:
> Sep 14 09:26:40 srv2 postgres-8.2[13372]: [3-2] STATEMENT:? SELECT pg_bulkload($1)
> Sep 14 09:26:57 srv2 sshd(pam_unix)[13389]: session opened for user jason by (uid=0)
> Sep 14 09:27:07 srv2 sshd(pam_unix)[13389]: session closed for user jason
> Sep 14 09:27:18 srv2 postgres-8.2[13490]: [2-1] NOTICE:? BULK LOAD START
> Sep 14 09:40:37 srv2 postgres-8.2[13490]: [3-1] NOTICE:? BULK LOAD END? (632832 records)
> Sep 14 09:40:37 srv2 postgres-8.2[13490]: [4-1] LOG:? duration: 799245.160 ms? execute <unnamed>: SELECT pg_bulkload($1)
> Sep 14 09:40:37 srv2 postgres-8.2[13490]: [4-2] DETAIL:? parameters: $1 = '/pgdata/8.2/sample_csv.ctl'
> then:
> Sep 14 10:48:18 srv2 slon[13841]: [27-1] 2007-09-14 10:48:18 CDT CONFIG main: configuration complete - starting threads
> Sep 14 10:48:18 srv2 postgres-8.2[13852]: [2-1] NOTICE:? Slony-I: cleanup stale sl_nodelock entry for pid=23070
> Sep 14 10:48:18 srv2 postgres-8.2[13852]: [3-1] NOTICE:? Slony-I: cleanup stale sl_nodelock entry for pid=1288
> Sep 14 10:48:18 srv2 postgres-8.2[13852]: [4-1] NOTICE:? Slony-I: cleanup stale sl_nodelock entry for pid=1292
> Sep 14 10:48:18 srv2 slon[13841]: [29-1] 2007-09-14 10:48:18 CDT CONFIG enableNode: no_id=1
> Sep 14 10:48:18 srv2 slon[13841]: [30-1] 2007-09-14 10:48:18 CDT CONFIG enableNode: no_id=3
> followed by:
> Sep 14 10:59:26 srv2 slon[13841]: [45-1] 2007-09-14 10:59:26 CDT WARN?? cleanupThread: "select "_ar_primary".logswitch_weekly(); " - server closed the connection
> Sep 14 10:59:26 srv2 slon[13841]: [45-2]? unexpectedly
> Sep 14 10:59:26 srv2 slon[13841]: [45-3]??????? This probably means the server terminated abnormally
> Sep 14 10:59:26 srv2 slon[13841]: [45-4]??????? before or while processing the request.
> Sep 14 10:59:26 srv2 slon[13841]: [46-1] 2007-09-14 10:59:26 CDT FATAL? cleanupThread: "delete from "_ar_primary".sl_log_1 where log_origin = '2' and log_xid <
> Sep 14 10:59:26 srv2 slon[13841]: [46-2]? '151706861'; delete from "_ar_primary".sl_log_2 where log_origin = '2' and log_xid < '151706861'; delete from
> Sep 14 10:59:26 srv2 slon[13841]: [46-3]? "_ar_primary".sl_seqlog where seql_origin = '2' and seql_ev_seqno < '1686420'; select "_ar_primary".logswitch_finish(); " -
> Sep 14 10:59:26 srv2 postgres-8.2[25487]: [2-1] LOG:? server process (PID 13861) was terminated by signal 11
> Sep 14 10:59:26 srv2 postgres-8.2[25487]: [3-1] LOG:? terminating any other active server processes
> Sep 14 10:59:26 srv2 postgres-8.2[14136]: [5-1] WARNING:? terminating connection because of crash of another server process
> The postmaster is now running again, but I am afraid to restart slony again. Anything I can do to verify the integrity of the slon configuration that will not crash
> the postmaster?

logswitch_weekly() doesn't invoke any "wacky C stuff" that I'd expect
to be at all sensitive that way.  Indeed, it doesn't do much.

- It checks what the date is, to see if it's time to switch logs yet.

- It saves that time.

- It fiddles with the value of the sequence sl_log_status.

- And... nothing else.

This doesn't smell at all like a plausible cause for a sig11.

And the log doesn't tell us that it caused the problem - rather it
tells us that the problem terminated it.  The cleanup thread work was
being done on process 13841, terminated due to what was up with 13861.

I think you need to look, if you can, at what backend process 13861
was doing.  That, I believe, is the thing that's responsible for the
problem.
-- 
select 'cbbrowne' || '@' || 'linuxfinances.info';
http://www3.sympatico.ca/cbbrowne/finances.html
"I would rather spend 10 hours reading someone else's source code than
10  minutes listening  to Musak  waiting for  technical  support which
isn't." -- Dr. Greg Wettstein, Roger Maris Cancer Center
From JanWieck at Yahoo.com  Fri Sep 14 18:55:42 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Fri Sep 14 18:56:33 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <d7df81620709141210j6785fdb2v4fb29cbb14098e2c@mail.gmail.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>	
	<46E55D8B.3050003@orange-ftgroup.com>	
	<46E57392.4000706@ca.afilias.info>	
	<46E5759B.5090709@orange-ftgroup.com> <46E57E4E.2090807@Yahoo.com>	
	<46E5A297.3090309@orange-ftgroup.com>	
	<5a0a9d6f0709101502v277c5dectac299f4c39e5e957@mail.gmail.com>	
	<46E64E36.2070400@orange-ftgroup.com> <46E71999.6090600@Yahoo.com>
	<d7df81620709141210j6785fdb2v4fb29cbb14098e2c@mail.gmail.com>
Message-ID: <46EB3B9E.7090509@Yahoo.com>

On 9/14/2007 3:10 PM, Dmitry Koterov wrote:
> MySQL has the "binary log" to which all data is appended before it is 
> committed to the real table. All MySQL replicas are simply replaying 
> this binary log from a specified position, so it is quite close to what 
> Slony does (but Slony uses its own event log, not built-in as in MySQL). 
> Seems an asynchronous statement-based replication does not exists in the 
> world at all.

According to the MySQL 5.1 manual

     http://dev.mysql.com/doc/refman/5.1/en/binary-log.html

it contains statements. Seems people aren't exactly sure what a 
statement is in MySQL land.

Then again:

"The format of the events recorded in the binary log is dependent on the 
binary logging format. Three format types are supported, row-based 
logging, statement-based logging and mixed-base logging. The binry 
logging format used deoends on the MySQL version. For more information 
on logging formats, see Section 5.11.4.1, ?Binary Logging Formats?."

Which is as best confusing. So different versions support different 
logging formats, and they are not all available at the same time? And 
what the heck is mixed-based? Have MySQL (which is known to make pretty 
bad judgments when it comes the integrity and consistency of YOUR data) 
chose when to aim for row based and when statement based might be "faster"?

Further down it explains that writes to the log are handled like MyISAM 
writes. Which doesn't really mean much to me, but maybe someone can tell 
if that means that a transaction, done and committed against InnoDB 
tables, could be recovered in a server crash situation but lost from the 
"binary log"? Or is that something 100% guaranteed impossible? The 
manual isn't quite clear about that.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From cscetbon.ext at orange-ftgroup.com  Sat Sep 15 13:19:52 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Sat Sep 15 13:20:06 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46EB3B9E.7090509@Yahoo.com>
References: <46E54F8D.5010500@orange-ftgroup.com>
	<46E559F3.60602@Yahoo.com>		<46E55D8B.3050003@orange-ftgroup.com>		<46E57392.4000706@ca.afilias.info>		<46E5759B.5090709@orange-ftgroup.com>
	<46E57E4E.2090807@Yahoo.com>		<46E5A297.3090309@orange-ftgroup.com>		<5a0a9d6f0709101502v277c5dectac299f4c39e5e957@mail.gmail.com>		<46E64E36.2070400@orange-ftgroup.com>
	<46E71999.6090600@Yahoo.com>	<d7df81620709141210j6785fdb2v4fb29cbb14098e2c@mail.gmail.com>
	<46EB3B9E.7090509@Yahoo.com>
Message-ID: <46EC3E68.5070506@orange-ftgroup.com>



Jan Wieck wrote:
> On 9/14/2007 3:10 PM, Dmitry Koterov wrote:
>> MySQL has the "binary log" to which all data is appended before it is 
>> committed to the real table. All MySQL replicas are simply replaying 
>> this binary log from a specified position, so it is quite close to 
>> what Slony does (but Slony uses its own event log, not built-in as in 
>> MySQL). Seems an asynchronous statement-based replication does not 
>> exists in the world at all.
>
> According to the MySQL 5.1 manual
>
>     http://dev.mysql.com/doc/refman/5.1/en/binary-log.html
>
> it contains statements. Seems people aren't exactly sure what a 
> statement is in MySQL land.
>
> Then again:
>
> "The format of the events recorded in the binary log is dependent on 
> the binary logging format. Three format types are supported, row-based 
> logging, statement-based logging and mixed-base logging. The binry 
> logging format used deoends on the MySQL version. For more information 
> on logging formats, see Section 5.11.4.1, ?Binary Logging Formats?."
>
> Which is as best confusing. So different versions support different 
> logging formats, and they are not all available at the same time? And 
> what the heck is mixed-based? 
If you use for example the NDB engine, which is used in MySQL Cluster, 
MySQL chooses to switch to ROW based statement to provide replication 
between 2 different clusters.
> Have MySQL (which is known to make pretty bad judgments when it comes 
> the integrity and consistency of YOUR data) chose when to aim for row 
> based and when statement based might be "faster"?
>
> Further down it explains that writes to the log are handled like 
> MyISAM writes. Which doesn't really mean much to me, but maybe someone 
> can tell if that means that a transaction, done and committed against 
> InnoDB tables, could be recovered in a server crash situation but lost 
> from the "binary log"? Or is that something 100% guaranteed 
> impossible? The manual isn't quite clear about that.
Binary Log is not guaranteed to be written on disk cause it uses the 
filesystem cache as MyISAM does. So the situation you described can happen
>
>
> Jan
>

-- 
Cyril SCETBON
From JanWieck at Yahoo.com  Sat Sep 15 20:59:23 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sat Sep 15 20:59:45 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46EC3E68.5070506@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com>	<46E559F3.60602@Yahoo.com>		<46E55D8B.3050003@orange-ftgroup.com>		<46E57392.4000706@ca.afilias.info>		<46E5759B.5090709@orange-ftgroup.com>	<46E57E4E.2090807@Yahoo.com>		<46E5A297.3090309@orange-ftgroup.com>		<5a0a9d6f0709101502v277c5dectac299f4c39e5e957@mail.gmail.com>		<46E64E36.2070400@orange-ftgroup.com>	<46E71999.6090600@Yahoo.com>	<d7df81620709141210j6785fdb2v4fb29cbb14098e2c@mail.gmail.com>	<46EB3B9E.7090509@Yahoo.com>
	<46EC3E68.5070506@orange-ftgroup.com>
Message-ID: <46ECAA1B.6030909@Yahoo.com>

On 9/15/2007 4:19 PM, Cyril SCETBON wrote:
> 
> Jan Wieck wrote:
>> On 9/14/2007 3:10 PM, Dmitry Koterov wrote:
>>> MySQL has the "binary log" to which all data is appended before it is 
>>> committed to the real table. All MySQL replicas are simply replaying 
>>> this binary log from a specified position, so it is quite close to 
>>> what Slony does (but Slony uses its own event log, not built-in as in 
>>> MySQL). Seems an asynchronous statement-based replication does not 
>>> exists in the world at all.
>>
>> According to the MySQL 5.1 manual
>>
>>     http://dev.mysql.com/doc/refman/5.1/en/binary-log.html
>>
>> it contains statements. Seems people aren't exactly sure what a 
>> statement is in MySQL land.
>>
>> Then again:
>>
>> "The format of the events recorded in the binary log is dependent on 
>> the binary logging format. Three format types are supported, row-based 
>> logging, statement-based logging and mixed-base logging. The binry 
>> logging format used deoends on the MySQL version. For more information 
>> on logging formats, see Section 5.11.4.1, ?Binary Logging Formats?."
>>
>> Which is as best confusing. So different versions support different 
>> logging formats, and they are not all available at the same time? And 
>> what the heck is mixed-based? 
> If you use for example the NDB engine, which is used in MySQL Cluster, 
> MySQL chooses to switch to ROW based statement to provide replication 
> between 2 different clusters.

NDB ... that was the in-memory shared nothing table handler that asked 
for a little more physical RAM than your entire DB is in size, wasn't it?

>> Have MySQL (which is known to make pretty bad judgments when it comes 
>> the integrity and consistency of YOUR data) chose when to aim for row 
>> based and when statement based might be "faster"?
>>
>> Further down it explains that writes to the log are handled like 
>> MyISAM writes. Which doesn't really mean much to me, but maybe someone 
>> can tell if that means that a transaction, done and committed against 
>> InnoDB tables, could be recovered in a server crash situation but lost 
>> from the "binary log"? Or is that something 100% guaranteed 
>> impossible? The manual isn't quite clear about that.
> Binary Log is not guaranteed to be written on disk cause it uses the 
> filesystem cache as MyISAM does. So the situation you described can happen

So that means what? A server crash of the master, although it recovered 
just fine and all InnoDB tables are consistent, forces me to rebuild all 
slaves from scratch because I don't know if I lost any replication log? 
Why doesn't that sound right to me?


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From plk.zuber at gmail.com  Sun Sep 16 01:19:20 2007
From: plk.zuber at gmail.com (=?UTF-8?Q?Filip_Rembia=C5=82kowski?=)
Date: Sun Sep 16 01:19:38 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46E55D8B.3050003@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>
	<46E55D8B.3050003@orange-ftgroup.com>
Message-ID: <92869e660709160119h413e7a5exc901e1f66189e9eb@mail.gmail.com>

Guys, this discussion went quite offtopic, but maybe you missed one
fact that Cyril may no know about.

In postgres, setting N columns to NULL is just N bits of physical writes.

So the overhead of

INSERT INTO t1 ( id, data1, data2, data3, ..., data100 )
VALUES( 12345, 'the only non-null data', NULL,NULL, ..., NULL )

is not so terrible.

In regard to UPDATEs, we _have_to_ specify all columns anyway;
and DELETEs are handled by PK value.

So there's not much to optimize / without making a revolutionary changes /


-- 
Filip Rembia?kowski
From cscetbon.ext at orange-ftgroup.com  Sun Sep 16 01:23:02 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Sun Sep 16 01:23:25 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46ECAA1B.6030909@Yahoo.com>
References: <46E54F8D.5010500@orange-ftgroup.com>	<46E559F3.60602@Yahoo.com>			<46E55D8B.3050003@orange-ftgroup.com>		<46E57392.4000706@ca.afilias.info>			<46E5759B.5090709@orange-ftgroup.com>	<46E57E4E.2090807@Yahoo.com>		<46E5	A297.3090309@orange-ftgroup.com>		<5a0a9d6f0709101502v277c5dectac299f4c39e5	e957@mail.gmail.com>		<46E64E36.2070400@orange-ftgroup.com>	<46E71999.60906	00@Yahoo.com>	<d7df81620709141210j6785fdb2v4fb29cbb14098e2c@mail.gmail.com>		<46EB3B9E.7090509@Yahoo.com>
	<46EC3E68.5070506@orange-ftgroup.com> <46ECAA1B.6030909@Yahoo.com>
Message-ID: <46ECE7E6.3000305@orange-ftgroup.com>



Jan Wieck wrote:
> On 9/15/2007 4:19 PM, Cyril SCETBON wrote:
>>
>> Jan Wieck wrote:
>>> On 9/14/2007 3:10 PM, Dmitry Koterov wrote:
>>>> MySQL has the "binary log" to which all data is appended before it 
>>>> is committed to the real table. All MySQL replicas are simply 
>>>> replaying this binary log from a specified position, so it is quite 
>>>> close to what Slony does (but Slony uses its own event log, not 
>>>> built-in as in MySQL). Seems an asynchronous statement-based 
>>>> replication does not exists in the world at all.
>>>
>>> According to the MySQL 5.1 manual
>>>
>>>     http://dev.mysql.com/doc/refman/5.1/en/binary-log.html
>>>
>>> it contains statements. Seems people aren't exactly sure what a 
>>> statement is in MySQL land.
>>>
>>> Then again:
>>>
>>> "The format of the events recorded in the binary log is dependent on 
>>> the binary logging format. Three format types are supported, 
>>> row-based logging, statement-based logging and mixed-base logging. 
>>> The binry logging format used deoends on the MySQL version. For more 
>>> information on logging formats, see Section 5.11.4.1, ?Binary 
>>> Logging Formats?."
>>>
>>> Which is as best confusing. So different versions support different 
>>> logging formats, and they are not all available at the same time? 
>>> And what the heck is mixed-based? 
>> If you use for example the NDB engine, which is used in MySQL 
>> Cluster, MySQL chooses to switch to ROW based statement to provide 
>> replication between 2 different clusters.
>
> NDB ... that was the in-memory shared nothing table handler that asked 
> for a little more physical RAM than your entire DB is in size, wasn't it?
it's the engine used in MySQL Cluster which is a shared nothing cluster 
which can used memory and disks for storing data (since 5.1).
>
>>> Have MySQL (which is known to make pretty bad judgments when it 
>>> comes the integrity and consistency of YOUR data) chose when to aim 
>>> for row based and when statement based might be "faster"?
>>>
>>> Further down it explains that writes to the log are handled like 
>>> MyISAM writes. Which doesn't really mean much to me, but maybe 
>>> someone can tell if that means that a transaction, done and 
>>> committed against InnoDB tables, could be recovered in a server 
>>> crash situation but lost from the "binary log"? Or is that something 
>>> 100% guaranteed impossible? The manual isn't quite clear about that.
>> Binary Log is not guaranteed to be written on disk cause it uses the 
>> filesystem cache as MyISAM does. So the situation you described can 
>> happen
>
> So that means what? A server crash of the master, although it 
> recovered just fine and all InnoDB tables are consistent, forces me to 
> rebuild all slaves from scratch because I don't know if I lost any 
> replication log? Why doesn't that sound right to me?
I think that it can happen, but I didn't encounter this situation and I 
don't know if there's a link between InnoDB recovery and binary logging 
to resolve this issue. Whenever this happen you can promote a slave to 
be the new master as when you started using MySQL replication you've 
accepted to lose information in case of a master crash. MySQL 
replication is asynchronous and there is no guarantee to not lose data.
>
>
> Jan
>

From cscetbon.ext at orange-ftgroup.com  Sun Sep 16 01:27:49 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Sun Sep 16 01:28:11 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <92869e660709160119h413e7a5exc901e1f66189e9eb@mail.gmail.com>
References: <46E54F8D.5010500@orange-ftgroup.com>
	<46E559F3.60602@Yahoo.com>	<46E55D8B.3050003@orange-ftgroup.com>
	<92869e660709160119h413e7a5exc901e1f66189e9eb@mail.gmail.com>
Message-ID: <46ECE905.80506@orange-ftgroup.com>



Filip Rembia?kowski wrote:
> Guys, this discussion went quite offtopic, but maybe you missed one
> fact that Cyril may no know about.
>
> In postgres, setting N columns to NULL is just N bits of physical writes.
>
> So the overhead of
>
> INSERT INTO t1 ( id, data1, data2, data3, ..., data100 )
> VALUES( 12345, 'the only non-null data', NULL,NULL, ..., NULL )
>
> is not so terrible.
>   
Thanks filip, but I didn't talk about the performance when applying this 
request, but the fact that storing a longer request than a simple insert 
into t1(col1,col2) values(valcol1,valcol2) causes slony tables to grow 
faster, and needs more network bandwidth, that's all :-)
> In regard to UPDATEs, we _have_to_ specify all columns anyway;
> and DELETEs are handled by PK value.
>
> So there's not much to optimize / without making a revolutionary changes /
>
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>   

From dmitry at koterov.ru  Sun Sep 16 02:19:23 2007
From: dmitry at koterov.ru (Dmitry Koterov)
Date: Sun Sep 16 02:19:45 2007
Subject: [Slony1-general] EXECUTE SCRIPT error causes subscribers not to
	get DDL commands
In-Reply-To: <5a0a9d6f0709141453t1618fc09tf0e26f272ec7b97d@mail.gmail.com>
References: <1F6A6204-C556-424E-A6F3-9B31A506F8B9@richyen.com>
	<60k5qt9f6x.fsf@dba2.int.libertyrms.com>
	<5a0a9d6f0709141453t1618fc09tf0e26f272ec7b97d@mail.gmail.com>
Message-ID: <d7df81620709160219w138ef543wb8a2786262b71731@mail.gmail.com>

Could you please add a protection of submitting these commands in slonik in
future Slony versions?
I suppose ideally there should be no DDL script which causes the replication
to be broken via slonik...

On 9/15/07, Andrew Hammond <andrew.george.hammond@gmail.com> wrote:
>
> On 9/14/07, Christopher Browne <cbbrowne@ca.afilias.info> wrote:
> >
> > Richard Yen <dba@richyen.com> writes:
> > > Hi All,
> > >
> > > Ran an EXECUTE SCRIPT command, but somewhere, the script failed.  The
> > > DDL statements were successfully executed on the provider, but for
> > > the two subscribers, naturally, nothing happened.
> > >
> > > Now, I'm wondering what I need to do?  Manually add the columns in on
> > > the subscribers?  Attempt to drop the columns from the provider?  Do
> > > something else?
> > >
> > > Here is the output of my slonik command:
> > >> perform a single schema change
> > >> DDL script consisting of 4 SQL statements
> > >> DDL Statement 0: (0,6) [BEGIN;]
> > >> <stdin>:6: WARNING:  there is already a transaction in progress
> > >> DDL Statement 1: (6,57) [
> > >> ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;]
> > >> DDL Statement 2: (57,109) [
> > >> ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;]
> > >> DDL Statement 3: (109,117) [
> > >> COMMIT;]
> > >> Complete DDL Event...
> > >> Event submission for DDL failed - PGRES_FATAL_ERROR
> > >> <stdin>:6: WARNING:  there is no transaction in progress
> > >
> > > Not sure if it helps much.  I'm still scouring around my logs for the
> > > statement that failed, but I don't think I can uncover it...
> > >
> > > Any suggestions/little known facts about what I can do?
> >
> > <http://slony.info/documentation/ddlchanges.html >
> >
> > I can point to where the problem lies:
> >
> >    "The script must not contain transaction BEGIN or END statements,
> >     as the script is already executed inside a transaction."
> >
> > I see a BEGIN and a COMMIT, which *guarantees* that the submission
> > works wrongly.
> >
> > If you submit a DDL script consisting of:
> >
> > BEGIN;
> > ALTER TABLE DROP COLUMN CRAWL_HOST;
> > ALTER TABLE DROP COLUMN CRAWL_PORT;
> > COMMIT;
> >
> > (which re-commits, in the opposite fashion, the same sin that the first
> > script did)
> >
> > That should put the "master" back into the appropriate form.
> >
> > You could then resubmit a slonik DDL script consisting of
> > ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;
> > ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;
> > WITH NEITHER A BEGIN NOR A COMMIT IN IT...
> >
> > If you're lucky, then you have not submitted any updates that would
> > have tried to add new tuples to table m_nodes, and this DDL script
> > should be able to propagate.
> >
> > If there are tuples queued up with
> > m_nodes.crawl_port/m_nodes.crawl_host, sitting in sl_log_1, then I'm
> > not quite sure offhand what to suggest.
> >
> >
> You mean aside from reading the manual before using an admittedly
> bare-metal tool? :)
>
> Actually, I think this points out a potential new feature in slonik:
> detect and refuse to run EXECUTE DDL commands which include transaction
> management statements (BEGIN, COMMIT, ROLLBACK, SAVEPOINT and RELEASE).
>
> Oh, and we probably need to update the documentation to talk about
> savepoints too. I can't think of any legitimate way to use them, but then
> again, it is a Friday afternoon so maybe I'm just being dense.
>
> Andrew
>
>
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070916/=
e18fa1ef/attachment-0001.htm
From JanWieck at Yahoo.com  Sun Sep 16 04:55:34 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sun Sep 16 04:56:12 2007
Subject: [Slony1-general] EXECUTE SCRIPT error causes subscribers not
	to	get DDL commands
In-Reply-To: <d7df81620709160219w138ef543wb8a2786262b71731@mail.gmail.com>
References: <1F6A6204-C556-424E-A6F3-9B31A506F8B9@richyen.com>	<60k5qt9f6x.fsf@dba2.int.libertyrms.com>	<5a0a9d6f0709141453t1618fc09tf0e26f272ec7b97d@mail.gmail.com>
	<d7df81620709160219w138ef543wb8a2786262b71731@mail.gmail.com>
Message-ID: <46ED19B6.6080405@Yahoo.com>

On 9/16/2007 5:19 AM, Dmitry Koterov wrote:
> Could you please add a protection of submitting these commands in slonik 
> in future Slony versions?
> I suppose ideally there should be no DDL script which causes the 
> replication to be broken via slonik...

In an ideal world, one would have a chance to create foolproof software. 
Then again, would it be an ideal world if there still would be fools?

I agree that we should reject those scripts that we can easily detect as 
broken. However, with the evolving grammar of Postgres' SQL dialect and 
the explicit requirement of Slony to support cross DB version 
replication, I don't see how that could ever become foolproof.


Jan


> 
> On 9/15/07, *Andrew Hammond* <andrew.george.hammond@gmail.com 
> <mailto:andrew.george.hammond@gmail.com>> wrote:
> 
>     On 9/14/07, *Christopher Browne* < cbbrowne@ca.afilias.info
>     <mailto:cbbrowne@ca.afilias.info>> wrote:
> 
>         Richard Yen <dba@richyen.com <mailto:dba@richyen.com>> writes:
>         >  Hi All,
>         >
>         >  Ran an EXECUTE SCRIPT command, but somewhere, the script
>         failed.  The
>         >  DDL statements were successfully executed on the provider, but
>         for
>         >  the two subscribers, naturally, nothing happened.
>         >
>         >  Now, I'm wondering what I need to do?  Manually add the
>         columns in on
>         >  the subscribers?  Attempt to drop the columns from the
>         provider?  Do
>         >  something else?
>         >
>         >  Here is the output of my slonik command:
>         > > perform a single schema change
>         > > DDL script consisting of 4 SQL statements
>         > > DDL Statement 0: (0,6) [BEGIN;]
>         > > <stdin>:6: WARNING:  there is already a transaction in progress
>         > > DDL Statement 1: (6,57) [
>         > > ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;]
>         > > DDL Statement 2: (57,109) [
>         > > ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;]
>         > > DDL Statement 3: (109,117) [
>         > > COMMIT;]
>         > > Complete DDL Event...
>         > > Event submission for DDL failed - PGRES_FATAL_ERROR
>         > > <stdin>:6: WARNING:  there is no transaction in progress
>         >
>         >  Not sure if it helps much.  I'm still scouring around my logs
>         for the
>         >  statement that failed, but I don't think I can uncover it...
>         >
>         >  Any suggestions/little known facts about what I can do?
> 
>         <http://slony.info/documentation/ddlchanges.html
>         <http://slony.info/documentation/ddlchanges.html>>
> 
>         I can point to where the problem lies:
> 
>            "The script must not contain transaction BEGIN or END statements,
>             as the script is already executed inside a transaction."
> 
>         I see a BEGIN and a COMMIT, which *guarantees* that the submission
>         works wrongly.
> 
>         If you submit a DDL script consisting of:
> 
>         BEGIN;
>         ALTER TABLE DROP COLUMN CRAWL_HOST;
>         ALTER TABLE DROP COLUMN CRAWL_PORT;
>         COMMIT;
> 
>         (which re-commits, in the opposite fashion, the same sin that
>         the first script did)
> 
>         That should put the "master" back into the appropriate form.
> 
>         You could then resubmit a slonik DDL script consisting of
>         ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;
>         ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;
>         WITH NEITHER A BEGIN NOR A COMMIT IN IT...
> 
>         If you're lucky, then you have not submitted any updates that would
>         have tried to add new tuples to table m_nodes, and this DDL script
>         should be able to propagate.
> 
>         If there are tuples queued up with
>         m_nodes.crawl_port/m_nodes.crawl_host, sitting in sl_log_1, then I'm
>         not quite sure offhand what to suggest.
> 
> 
>     You mean aside from reading the manual before using an admittedly
>     bare-metal tool? :)
> 
>     Actually, I think this points out a potential new feature in slonik:
>     detect and refuse to run EXECUTE DDL commands which include
>     transaction management statements (BEGIN, COMMIT, ROLLBACK,
>     SAVEPOINT and RELEASE).
> 
>     Oh, and we probably need to update the documentation to talk about
>     savepoints too. I can't think of any legitimate way to use them, but
>     then again, it is a Friday afternoon so maybe I'm just being dense.
> 
>     Andrew
> 
> 
>     _______________________________________________
>     Slony1-general mailing list
>     Slony1-general@lists.slony.info <mailto:Slony1-general@lists.slony.info>
>     http://lists.slony.info/mailman/listinfo/slony1-general
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From JanWieck at Yahoo.com  Sun Sep 16 05:16:59 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sun Sep 16 05:17:11 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46ECE905.80506@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com>	<46E559F3.60602@Yahoo.com>	<46E55D8B.3050003@orange-ftgroup.com>	<92869e660709160119h413e7a5exc901e1f66189e9eb@mail.gmail.com>
	<46ECE905.80506@orange-ftgroup.com>
Message-ID: <46ED1EBB.706@Yahoo.com>

On 9/16/2007 4:27 AM, Cyril SCETBON wrote:
> 
> Filip Rembia?kowski wrote:
>> Guys, this discussion went quite offtopic, but maybe you missed one
>> fact that Cyril may no know about.
>>
>> In postgres, setting N columns to NULL is just N bits of physical writes.
>>
>> So the overhead of
>>
>> INSERT INTO t1 ( id, data1, data2, data3, ..., data100 )
>> VALUES( 12345, 'the only non-null data', NULL,NULL, ..., NULL )
>>
>> is not so terrible.
>>   
> Thanks filip, but I didn't talk about the performance when applying this 
> request, but the fact that storing a longer request than a simple insert 
> into t1(col1,col2) values(valcol1,valcol2) causes slony tables to grow 
> faster, and needs more network bandwidth, that's all :-)

And we can't do that because imagine you have a schema

     create table t1 (
         a int primary key,
         b text default 'foo'
     );

and then do

     insert into t1 (a, b) values (1, NULL);

the resulting row, that make it into the masters table, will be

     (1, NULL)

Yeah, another one of those little things where MySQL behaves different 
and where Postgres is right according to ANSI. If we omit that NULL 
column now from the INSERT on the subscriber, the default will be used 
there, resulting in

     (1, 'foo')

and we have the subscriber out of sync.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From cscetbon.ext at orange-ftgroup.com  Sun Sep 16 07:06:44 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Sun Sep 16 07:06:56 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46ED1EBB.706@Yahoo.com>
References: <46E54F8D.5010500@orange-ftgroup.com>	<46E559F3.60602@Yahoo.com>	<46E55D8B.3050003@orange-ftgroup.com>	<92869e660709160119h413e7a5exc901e1f66189e9eb@mail.gmail.com>	<46ECE905.80506@orange-ftgroup.com>
	<46ED1EBB.706@Yahoo.com>
Message-ID: <46ED3874.7000303@orange-ftgroup.com>



Jan Wieck wrote:
> On 9/16/2007 4:27 AM, Cyril SCETBON wrote:
>>
>> Filip Rembia?kowski wrote:
>>> Guys, this discussion went quite offtopic, but maybe you missed one
>>> fact that Cyril may no know about.
>>>
>>> In postgres, setting N columns to NULL is just N bits of physical 
>>> writes.
>>>
>>> So the overhead of
>>>
>>> INSERT INTO t1 ( id, data1, data2, data3, ..., data100 )
>>> VALUES( 12345, 'the only non-null data', NULL,NULL, ..., NULL )
>>>
>>> is not so terrible.
>>>   
>> Thanks filip, but I didn't talk about the performance when applying 
>> this request, but the fact that storing a longer request than a 
>> simple insert into t1(col1,col2) values(valcol1,valcol2) causes slony 
>> tables to grow faster, and needs more network bandwidth, that's all :-)
>
> And we can't do that because imagine you have a schema
>
>     create table t1 (
>         a int primary key,
>         b text default 'foo'
>     );
>
> and then do
>
>     insert into t1 (a, b) values (1, NULL);
>
> the resulting row, that make it into the masters table, will be
>
>     (1, NULL)
>
> Yeah, another one of those little things where MySQL behaves different 
> and where Postgres is right according to ANSI. If we omit that NULL 
> column now from the INSERT on the subscriber, the default will be used 
> there, resulting in
>
>     (1, 'foo')
>
> and we have the subscriber out of sync.
>
>
> Jan
>
The suggestion was to catch the request entered so here (a,b) (1, NULL) 
would be stored. but if user enter insert into t1(b) values('b') , then 
(b) ('b') would be stored, and as every subscribe has the same schema 
the default value would be used on them. 

-- 
Cyril SCETBON
From honza at jyxo.com  Sun Sep 16 07:44:30 2007
From: honza at jyxo.com (Jan Matousek)
Date: Sun Sep 16 07:44:41 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46ED3874.7000303@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>
	<46E55D8B.3050003@orange-ftgroup.com>
	<92869e660709160119h413e7a5exc901e1f66189e9eb@mail.gmail.com>
	<46ECE905.80506@orange-ftgroup.com> <46ED1EBB.706@Yahoo.com>
	<46ED3874.7000303@orange-ftgroup.com>
Message-ID: <c14eaebb0709160744h2ea1ef3cl6661cb82e347a044@mail.gmail.com>

T24gOS8xNi8wNywgQ3lyaWwgU0NFVEJPTiA8Y3NjZXRib24uZXh0QG9yYW5nZS1mdGdyb3VwLmNv
bT4gd3JvdGU6Cj4KPiBUaGUgc3VnZ2VzdGlvbiB3YXMgdG8gY2F0Y2ggdGhlIHJlcXVlc3QgZW50
ZXJlZCBzbyBoZXJlIChhLGIpICgxLCBOVUxMKQo+IHdvdWxkIGJlIHN0b3JlZC4gYnV0IGlmIHVz
ZXIgZW50ZXIgaW5zZXJ0IGludG8gdDEoYikgdmFsdWVzKCdiJykgLCB0aGVuCj4gKGIpICgnYicp
IHdvdWxkIGJlIHN0b3JlZCwgYW5kIGFzIGV2ZXJ5IHN1YnNjcmliZSBoYXMgdGhlIHNhbWUgc2No
ZW1hCj4gdGhlIGRlZmF1bHQgdmFsdWUgd291bGQgYmUgdXNlZCBvbiB0aGVtLgoKClNsb255IHRy
aWdnZXJzIGRvZXMgbm90IGtub3cgd2hpY2ggY29sdW1ucyB3ZXJlIHByZXNlbnQgaW4gaW5zZXJ0
IHN0YXRlbWVudCwKdGhleSBqdXN0IGtub3cgdGhlIHZhbHVlcyBpbiBuZXcgcm93LgpGb3IgZWFj
aCBjb2x1bW4sIHRoZSB2YWx1ZSBtYXkgYmUgY29tcGFyZWQgd2l0aCBkZWZhdWx0IHZhbHVlIChp
biBjYXNlCmRlZmF1bHQgdmFsdWUgaXMgcHJlZGljdGFibGUpLCBhbmQgaWYgc2FtZSwgSSB0aGlu
ayB0aGUgY29sdW1uIGNhbiBiZQpvbWl0dGVkIGZyb20gbG9nIGFuZCBpdCBjYW4gbm90IGJyZWFr
IHJlcGxpY2F0aW9uICh3aXRoIGFzc3VtcHRpb24gdGhhdApyZXBsaWNhdGVkIGRhdGFiYXNlIGhh
cyBzYW1lIHNjaGVtYSkuCgpCdXQgSSBhbSBuZXcgdG8gc2xvbnkgYW5kIEkgY2FuIG5vdCBpbWFn
aW5lIGhvdyBjb21wbGljYXRlZCB3b3VsZCBiZSBwYXRjaApmb3IgdGhpcy4KCmouCi0tLS0tLS0t
LS0tLS0tIG5leHQgcGFydCAtLS0tLS0tLS0tLS0tLQpBbiBIVE1MIGF0dGFjaG1lbnQgd2FzIHNj
cnViYmVkLi4uClVSTDogaHR0cDovL2xpc3RzLnNsb255LmluZm8vcGlwZXJtYWlsL3Nsb255MS1n
ZW5lcmFsL2F0dGFjaG1lbnRzLzIwMDcwOTE2LzVhMzUzN2NkL2F0dGFjaG1lbnQuaHRtCg==
From Gregory.Williamson at digitalglobe.com  Sun Sep 16 16:32:19 2007
From: Gregory.Williamson at digitalglobe.com (Gregory Williamson)
Date: Sun Sep 16 16:32:53 2007
Subject: [Slony1-general] Slony and log shipping
Message-ID: <8B319E5A30FF4A48BE7EEAAF609DB233015E2BB5@COMAIL01.digitalglobe.com>

Dear list,

I've been studying Slony for replicating a small OLTP database and feel fai=
rly comfortable with using it in this scenario.

My real question relates to log shipping and its use in the following set u=
p.

We have a number of large spatial databases; they are replicated to allow u=
s to cope with sudden increases in traffic, loss of servers, etc. Let say w=
e have 5 runtime databases with 3 of them in use during the day. =


Updating them all is something of a flail and likely to get worse as we exp=
and.

So I am wondering if log shipping would help. My idea would be to have two =
spatial databases, call them dev and QA, linked by Slony. Content does what=
ever until they are satisfied. The two dbs are in sync and now we go to upd=
ate runtime.

Would it feasable to use log shipping to update the runtimes, first the 2 o=
ut of service and then, probably in the evening when traffic drops, put tho=
se two into production and then use log shipping to update the other now qu=
iet runtimes once we rotate them out of production ?

My thinking is that we could automate almost all of this and save engineers=
 and ops people from ever more manual work, and because of the need to not =
do updates to live databases (slows them down, thrashes cache, etc.) I can'=
t seeing using Slony per se (since updates would need to be asyncronous). U=
pdates tend to be sporadic, at lest once a week but sometimes a lot more of=
ten (daily) and vary in size from small to fairly large (several hundred th=
ousand rows changing in many different tables).

Catcalls, questions, caveats all welcome,

Thanks,

Greg Williamson
Senior DBA
GlobeXplorer LLC, a DigitalGlobe company

Confidentiality Notice: This e-mail message, including any attachments, is =
for the sole use of the intended recipient(s) and may contain confidential =
and privileged information and must be protected in accordance with those p=
rovisions. Any unauthorized review, use, disclosure or distribution is proh=
ibited. If you are not the intended recipient, please contact the sender by=
 reply e-mail and destroy all copies of the original message.

(My corporate masters made me say this.)

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070916/=
56dae23c/attachment.htm
From JanWieck at Yahoo.com  Sun Sep 16 17:04:06 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Sun Sep 16 17:04:53 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46ED3874.7000303@orange-ftgroup.com>
References: <46E54F8D.5010500@orange-ftgroup.com>	<46E559F3.60602@Yahoo.com>	<46E55D8B.3050003@orange-ftgroup.com>	<92869e660709160119h413e7a5exc901e1f66189e9eb@mail.gmail.com>	<46ECE905.80506@orange-ftgroup.com>
	<46ED1EBB.706@Yahoo.com> <46ED3874.7000303@orange-ftgroup.com>
Message-ID: <46EDC476.4060503@Yahoo.com>

On 9/16/2007 10:06 AM, Cyril SCETBON wrote:
> 
> Jan Wieck wrote:
>> On 9/16/2007 4:27 AM, Cyril SCETBON wrote:
>>>
>>> Filip Rembia?kowski wrote:
>>>> Guys, this discussion went quite offtopic, but maybe you missed one
>>>> fact that Cyril may no know about.
>>>>
>>>> In postgres, setting N columns to NULL is just N bits of physical 
>>>> writes.
>>>>
>>>> So the overhead of
>>>>
>>>> INSERT INTO t1 ( id, data1, data2, data3, ..., data100 )
>>>> VALUES( 12345, 'the only non-null data', NULL,NULL, ..., NULL )
>>>>
>>>> is not so terrible.
>>>>   
>>> Thanks filip, but I didn't talk about the performance when applying 
>>> this request, but the fact that storing a longer request than a 
>>> simple insert into t1(col1,col2) values(valcol1,valcol2) causes slony 
>>> tables to grow faster, and needs more network bandwidth, that's all :-)
>>
>> And we can't do that because imagine you have a schema
>>
>>     create table t1 (
>>         a int primary key,
>>         b text default 'foo'
>>     );
>>
>> and then do
>>
>>     insert into t1 (a, b) values (1, NULL);
>>
>> the resulting row, that make it into the masters table, will be
>>
>>     (1, NULL)
>>
>> Yeah, another one of those little things where MySQL behaves different 
>> and where Postgres is right according to ANSI. If we omit that NULL 
>> column now from the INSERT on the subscriber, the default will be used 
>> there, resulting in
>>
>>     (1, 'foo')
>>
>> and we have the subscriber out of sync.
>>
>>
>> Jan
>>
> The suggestion was to catch the request entered so here (a,b) (1, NULL) 
> would be stored. but if user enter insert into t1(b) values('b') , then 
> (b) ('b') would be stored, and as every subscribe has the same schema 
> the default value would be used on them. 

And what exactly do you capture as "request entered" if the original 
query was "insert into foo (a, b, c) select x, y, z from temp_bar;" ?

There certainly is some optimization possible. No doubt. But it isn't 
achievable as cheap as you think. One would first have to agree that all 
nodes in the whole cluster have to have tables containing the same 
columns. Then, the column names can be mapped to short integers in a new 
slony configuration table. Finally, the sl_log tables query field has to 
be split up into a short integer array specifying the table column order 
in the second field, containing all the values.

The question is, are you willing to develop such a patch, or at least 
willing to sponsor development of such a patch?


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From jason at buberel.org  Sun Sep 16 20:45:54 2007
From: jason at buberel.org (Jason L. Buberel)
Date: Sun Sep 16 20:46:43 2007
Subject: [Slony1-general] Re: conflict beween slony and pg_bulkload causing
	postmaster crash
In-Reply-To: <60k5qs90e3.fsf@dba2.int.libertyrms.com>
References: <46EB17D7.4050701@buberel.org>
	<60k5qs90e3.fsf@dba2.int.libertyrms.com>
Message-ID: <46EDF872.7070601@buberel.org>

To follow up on this:

The problem appears to have been caused by the presence of 
'pg_bulkload'. There seems to be some essential conflict between that 
utility and slony. Although I cannot be 100% sure, these are the steps I 
went through prior to reaching that conclusion:

1. On the three nodes in the cluster, leaving pg_bulkload installed on 
all nodes, I completely removed slony from each node by stopping the 
slon daemons and doing a 'drop schema _ar_primary cascade' on each node.

2. I then recreated the cluster using the original slonik configuration 
scripts. At this point, I did NOT start the slon daemons.

3. I ran several queries against each node in the cluster. Everything 
worked fine.

4. I then started the slon daemons. Within a few minutes after the first 
attempts at synchronization, postmaster processes starting dying. The 
syslog showed the telltale fatal messages:

Sep 15 17:28:12 srv3 slon[31511]: [2407-1] DEBUG2 remoteListenThread_2: 
LISTEN
Sep 15 17:28:17 srv3 slon[31511]: [2408-1] DEBUG2 syncThread: new 
sl_action_seq 23036 - SYNC 1019078
Sep 15 17:28:21 srv3 slon[31511]: [2409-1] DEBUG2 localListenThread: 
Received event 3,1019078 SYNC
Sep 15 17:28:22 srv3 slon[31511]: [2411-1] WARN   cleanupThread: "select 
"_ar_primary".logswitch_weekly(); " - server closed the connection 
unexpectedly
Sep 15 17:28:22 srv3 slon[31511]: [2411-2]      This probably means the 
server terminated abnormally
Sep 15 17:28:22 srv3 slon[31511]: [2411-3]      before or while 
processing the request.
Sep 15 17:28:22 srv3 slon[31511]: [2412-1] FATAL  cleanupThread: "delete 
from "_ar_primary".sl_log_1 where log_origin = '2' and log_xid < 
'151888804'; delete from
Sep 15 17:28:22 srv3 slon[31511]: [2412-2]  "_ar_primary".sl_log_2 where 
log_origin = '2' and log_xid < '151888804'; delete from 
"_ar_primary".sl_seqlog where seql_origin
Sep 15 17:28:22 srv3 slon[31511]: [2412-3]  = '2' and seql_ev_seqno < 
'1687734'; select "_ar_primary".logswitch_finish(); " -
Sep 15 17:28:22 srv3 slon[31511]: [2413-1] DEBUG2 slon_retry() from 
pid=31511
Sep 15 17:28:22 srv3 slon[31440]: [6-1] DEBUG2 slon: notify worker 
process to shutdown
Sep 15 17:28:22 srv3 slon[31511]: [2414-1] INFO   remoteListenThread_2: 
disconnecting from 'dbname=altos_research host=srv2 user=postgres 
port=54824'
Sep 15 17:28:22 srv3 postgres-8.2[30743]: [4-1] LOG:  00000: server 
process (PID 31525) was terminated by signal 11
Sep 15 17:28:23 srv3 slon[31511]: [2418-1] INFO   remoteListenThread_1: 
disconnecting from 'dbname=altos_research host=srv1 user=postgres port=5433'
Sep 15 17:28:23 srv3 postgres-8.2[30743]: [4-2] LOCATION:  LogChildExit, 
postmaster.c:2430
Sep 15 17:28:23 srv3 postgres-8.2[30743]: [5-1] LOG:  00000: terminating 
any other active server processes
Sep 15 17:28:23 srv3 postgres-8.2[30743]: [5-2] LOCATION:  
HandleChildCrash, postmaster.c:2315
Sep 15 17:28:23 srv3 slon[31511]: [2421-1] DEBUG2 main: wait for remote 
threads
Sep 15 17:28:23 srv3 postgres-8.2[31510]: [4-1] WARNING:  57P02: 
terminating connection because of crash of another server process
Sep 15 17:28:23 srv3 postgres-8.2[31510]: [4-2] DETAIL:  The postmaster 
has commanded this server process to roll back the current transaction 
and exit, because another server
Sep 15 17:28:23 srv3 postgres-8.2[31510]: [4-3]  process exited 
abnormally and possibly corrupted shared memory.


5. I then stopped the slon daemons, and restarted each of the 
postmasters. I executed a few queries, and everything worked well.

6. Next, I fully uninstalled pg_bulklod (executing the two uninstall.sql 
scripts, removing the .so file, and removing references to the pg_ctl 
wrapper script 'postgresql'.

7. I restarted all of the postmaster daemons. I then restarted all of 
the slon daemons. I executed several queries, and everything is once 
again working normally. Replication is fine.

So let that be a warning to everyone :)

-jason

Christopher Browne wrote:
> logswitch_weekly() doesn't invoke any "wacky C stuff" that I'd expect
> to be at all sensitive that way.  Indeed, it doesn't do much.
>
> - It checks what the date is, to see if it's time to switch logs yet.
>
> - It saves that time.
>
> - It fiddles with the value of the sequence sl_log_status.
>
> - And... nothing else.
>
> This doesn't smell at all like a plausible cause for a sig11.
>
> And the log doesn't tell us that it caused the problem - rather it
> tells us that the problem terminated it.  The cleanup thread work was
> being done on process 13841, terminated due to what was up with 13861.
>
> I think you need to look, if you can, at what backend process 13861
> was doing.  That, I believe, is the thing that's responsible for the
> problem.
>   
From cbbrowne at ca.afilias.info  Sun Sep 16 22:11:27 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Sun Sep 16 22:12:22 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46EDC476.4060503@Yahoo.com> (Jan Wieck's message of "Sun,
	16 Sep 2007 20:04:06 -0400")
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>
	<46E55D8B.3050003@orange-ftgroup.com>
	<92869e660709160119h413e7a5exc901e1f66189e9eb@mail.gmail.com>
	<46ECE905.80506@orange-ftgroup.com> <46ED1EBB.706@Yahoo.com>
	<46ED3874.7000303@orange-ftgroup.com> <46EDC476.4060503@Yahoo.com>
Message-ID: <604pht7u68.fsf@dba2.int.libertyrms.com>

Jan Wieck <JanWieck@Yahoo.com> writes:
> On 9/16/2007 10:06 AM, Cyril SCETBON wrote:
>> Jan Wieck wrote:
>>> On 9/16/2007 4:27 AM, Cyril SCETBON wrote:
>>>>
>>>> Filip Rembia?kowski wrote:
>>>>> Guys, this discussion went quite offtopic, but maybe you missed one
>>>>> fact that Cyril may no know about.
>>>>>
>>>>> In postgres, setting N columns to NULL is just N bits of physical
>>>>> writes.
>>>>>
>>>>> So the overhead of
>>>>>
>>>>> INSERT INTO t1 ( id, data1, data2, data3, ..., data100 )
>>>>> VALUES( 12345, 'the only non-null data', NULL,NULL, ..., NULL )
>>>>>
>>>>> is not so terrible.
>>>>>
>>>> Thanks filip, but I didn't talk about the performance when
>>>> applying this request, but the fact that storing a longer request
>>>> than a simple insert into t1(col1,col2) values(valcol1,valcol2)
>>>> causes slony tables to grow faster, and needs more network
>>>> bandwidth, that's all :-)
>>>
>>> And we can't do that because imagine you have a schema
>>>
>>>     create table t1 (
>>>         a int primary key,
>>>         b text default 'foo'
>>>     );
>>>
>>> and then do
>>>
>>>     insert into t1 (a, b) values (1, NULL);
>>>
>>> the resulting row, that make it into the masters table, will be
>>>
>>>     (1, NULL)
>>>
>>> Yeah, another one of those little things where MySQL behaves
>>> different and where Postgres is right according to ANSI. If we omit
>>> that NULL column now from the INSERT on the subscriber, the default
>>> will be used there, resulting in
>>>
>>>     (1, 'foo')
>>>
>>> and we have the subscriber out of sync.
>>>
>>>
>>> Jan
>>>
>> The suggestion was to catch the request entered so here (a,b) (1,
>> NULL) would be stored. but if user enter insert into t1(b)
>> values('b') , then (b) ('b') would be stored, and as every subscribe
>> has the same schema the default value would be used on them.
>
> And what exactly do you capture as "request entered" if the original
> query was "insert into foo (a, b, c) select x, y, z from temp_bar;" ?
>
> There certainly is some optimization possible. No doubt. But it isn't
> achievable as cheap as you think. One would first have to agree that
> all nodes in the whole cluster have to have tables containing the same
> columns. Then, the column names can be mapped to short integers in a
> new slony configuration table. Finally, the sl_log tables query field
> has to be split up into a short integer array specifying the table
> column order in the second field, containing all the values.

I would question what benefit this would really provide, and at what
cost?

This looks like an optimization for the case where tables are badly
normalized, at the cost of:
a) Adding a lot of complexity, generally, and
b) Probably making it *more* expensive to replicate tables that are
   well normalized.

And I don't see the "win" in this, either.  If there are 40 columns in
a table, there need to be 40 elements in the array for each tuple,
which will be plenty expensive.  I don't see it being cheaper in any
material way than the present representation.

You mentioned to me an idea that seemed pretty sound as to optimizing
things; it would be a slick, slick, idea for SYNCs to use COPY to
quickly get data out of sl_log_* from the provider and into sl_log_*
on the subscriber, and then process application to tables inside a
stored procedure on the subscriber.  *That* strikes me as potentially
a pretty big win.

But this seems like grasping for ways to try to make it sound like
we're optimizing things which would be quite likely to worsen
behaviour for well-designed OLTP apps.
-- 
output = ("cbbrowne" "@" "linuxfinances.info")
http://linuxfinances.info/info/x.html
"I once went  to a shrink.  He  told me to speak freely.   I did.  The
damn fool tried to charge me $90 an hour."
-- jimjr@qis.net (Jim Moore Jr)
From cscetbon.ext at orange-ftgroup.com  Mon Sep 17 01:46:29 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Mon Sep 17 01:47:40 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46EDC476.4060503@Yahoo.com>
References: <46E54F8D.5010500@orange-ftgroup.com>	<46E559F3.60602@Yahoo.com>	<46E55D8B.3050003@orange-ftgroup.com>	<92869e660709160119h413e7a5exc901e1f66189e9eb@mail.gmail.com>	<46ECE905.80506@orange-ftgroup.com>	<46ED1EBB.706@Yahoo.com>
	<46ED3874.7000303@orange-ftgroup.com> <46EDC476.4060503@Yahoo.com>
Message-ID: <46EE3EE5.5040907@orange-ftgroup.com>



Jan Wieck wrote:
> On 9/16/2007 10:06 AM, Cyril SCETBON wrote:
>>
>> Jan Wieck wrote:
>>> On 9/16/2007 4:27 AM, Cyril SCETBON wrote:
>>>>
>>>> Filip Rembia?kowski wrote:
>>>>> Guys, this discussion went quite offtopic, but maybe you missed one
>>>>> fact that Cyril may no know about.
>>>>>
>>>>> In postgres, setting N columns to NULL is just N bits of physical 
>>>>> writes.
>>>>>
>>>>> So the overhead of
>>>>>
>>>>> INSERT INTO t1 ( id, data1, data2, data3, ..., data100 )
>>>>> VALUES( 12345, 'the only non-null data', NULL,NULL, ..., NULL )
>>>>>
>>>>> is not so terrible.
>>>>>   
>>>> Thanks filip, but I didn't talk about the performance when applying 
>>>> this request, but the fact that storing a longer request than a 
>>>> simple insert into t1(col1,col2) values(valcol1,valcol2) causes 
>>>> slony tables to grow faster, and needs more network bandwidth, 
>>>> that's all :-)
>>>
>>> And we can't do that because imagine you have a schema
>>>
>>>     create table t1 (
>>>         a int primary key,
>>>         b text default 'foo'
>>>     );
>>>
>>> and then do
>>>
>>>     insert into t1 (a, b) values (1, NULL);
>>>
>>> the resulting row, that make it into the masters table, will be
>>>
>>>     (1, NULL)
>>>
>>> Yeah, another one of those little things where MySQL behaves 
>>> different and where Postgres is right according to ANSI. If we omit 
>>> that NULL column now from the INSERT on the subscriber, the default 
>>> will be used there, resulting in
>>>
>>>     (1, 'foo')
>>>
>>> and we have the subscriber out of sync.
>>>
>>>
>>> Jan
>>>
>> The suggestion was to catch the request entered so here (a,b) (1, 
>> NULL) would be stored. but if user enter insert into t1(b) 
>> values('b') , then (b) ('b') would be stored, and as every subscribe 
>> has the same schema the default value would be used on them. 
>
> And what exactly do you capture as "request entered" if the original 
> query was "insert into foo (a, b, c) select x, y, z from temp_bar;" ?
>
> There certainly is some optimization possible. No doubt. But it isn't 
> achievable as cheap as you think. 
I agree.
> One would first have to agree that all nodes in the whole cluster have 
> to have tables containing the same columns. Then, the column names can 
> be mapped to short integers in a new slony configuration table. 
> Finally, the sl_log tables query field has to be split up into a short 
> integer array specifying the table column order in the second field, 
> containing all the values.
>
> The question is, are you willing to develop such a patch, 
I've got no experience with postgresql internals or slony to do it :-(
> or at least willing to sponsor development of such a patch?
I may ask this question to the firm where I'm working.
>
>
> Jan
>

-- 
Cyril SCETBON
From dmitry at koterov.ru  Mon Sep 17 03:23:27 2007
From: dmitry at koterov.ru (Dmitry Koterov)
Date: Mon Sep 17 03:24:45 2007
Subject: [Slony1-general] EXECUTE SCRIPT error causes subscribers not to
	get DDL commands
In-Reply-To: <46ED19B6.6080405@Yahoo.com>
References: <1F6A6204-C556-424E-A6F3-9B31A506F8B9@richyen.com>
	<60k5qt9f6x.fsf@dba2.int.libertyrms.com>
	<5a0a9d6f0709141453t1618fc09tf0e26f272ec7b97d@mail.gmail.com>
	<d7df81620709160219w138ef543wb8a2786262b71731@mail.gmail.com>
	<46ED19B6.6080405@Yahoo.com>
Message-ID: <d7df81620709170323t1ff46976x93ccf1ddeb7de9bb@mail.gmail.com>

It's quite easy to reject BEGIN, COMMIT etc., because slonik splits its
input by ";".

The only complex part is SQL comments detection (/* ... */ and --), but
seems it could be done in scan_for_statements() - return NOT the first
position after a ";", but the first position after "; /* comment */ ", so
all next statements are always contain NO comments before them. So it's easy
to detect "BEGIN" etc. in the first position of a string.


On 9/16/07, Jan Wieck <JanWieck@yahoo.com> wrote:
>
> On 9/16/2007 5:19 AM, Dmitry Koterov wrote:
> > Could you please add a protection of submitting these commands in slonik
> > in future Slony versions?
> > I suppose ideally there should be no DDL script which causes the
> > replication to be broken via slonik...
>
> In an ideal world, one would have a chance to create foolproof software.
> Then again, would it be an ideal world if there still would be fools?
>
> I agree that we should reject those scripts that we can easily detect as
> broken. However, with the evolving grammar of Postgres' SQL dialect and
> the explicit requirement of Slony to support cross DB version
> replication, I don't see how that could ever become foolproof.
>
>
> Jan
>
>
> >
> > On 9/15/07, *Andrew Hammond* <andrew.george.hammond@gmail.com
> > <mailto:andrew.george.hammond@gmail.com>> wrote:
> >
> >     On 9/14/07, *Christopher Browne* < cbbrowne@ca.afilias.info
> >     <mailto:cbbrowne@ca.afilias.info>> wrote:
> >
> >         Richard Yen <dba@richyen.com <mailto:dba@richyen.com>> writes:
> >         >  Hi All,
> >         >
> >         >  Ran an EXECUTE SCRIPT command, but somewhere, the script
> >         failed.  The
> >         >  DDL statements were successfully executed on the provider,
> but
> >         for
> >         >  the two subscribers, naturally, nothing happened.
> >         >
> >         >  Now, I'm wondering what I need to do?  Manually add the
> >         columns in on
> >         >  the subscribers?  Attempt to drop the columns from the
> >         provider?  Do
> >         >  something else?
> >         >
> >         >  Here is the output of my slonik command:
> >         > > perform a single schema change
> >         > > DDL script consisting of 4 SQL statements
> >         > > DDL Statement 0: (0,6) [BEGIN;]
> >         > > <stdin>:6: WARNING:  there is already a transaction in
> progress
> >         > > DDL Statement 1: (6,57) [
> >         > > ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;]
> >         > > DDL Statement 2: (57,109) [
> >         > > ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;]
> >         > > DDL Statement 3: (109,117) [
> >         > > COMMIT;]
> >         > > Complete DDL Event...
> >         > > Event submission for DDL failed - PGRES_FATAL_ERROR
> >         > > <stdin>:6: WARNING:  there is no transaction in progress
> >         >
> >         >  Not sure if it helps much.  I'm still scouring around my logs
> >         for the
> >         >  statement that failed, but I don't think I can uncover it...
> >         >
> >         >  Any suggestions/little known facts about what I can do?
> >
> >         <http://slony.info/documentation/ddlchanges.html
> >         <http://slony.info/documentation/ddlchanges.html>>
> >
> >         I can point to where the problem lies:
> >
> >            "The script must not contain transaction BEGIN or END
> statements,
> >             as the script is already executed inside a transaction."
> >
> >         I see a BEGIN and a COMMIT, which *guarantees* that the
> submission
> >         works wrongly.
> >
> >         If you submit a DDL script consisting of:
> >
> >         BEGIN;
> >         ALTER TABLE DROP COLUMN CRAWL_HOST;
> >         ALTER TABLE DROP COLUMN CRAWL_PORT;
> >         COMMIT;
> >
> >         (which re-commits, in the opposite fashion, the same sin that
> >         the first script did)
> >
> >         That should put the "master" back into the appropriate form.
> >
> >         You could then resubmit a slonik DDL script consisting of
> >         ALTER TABLE m_nodes ADD COLUMN crawl_host VARCHAR;
> >         ALTER TABLE m_nodes ADD COLUMN crawl_port SMALLINT;
> >         WITH NEITHER A BEGIN NOR A COMMIT IN IT...
> >
> >         If you're lucky, then you have not submitted any updates that
> would
> >         have tried to add new tuples to table m_nodes, and this DDL
> script
> >         should be able to propagate.
> >
> >         If there are tuples queued up with
> >         m_nodes.crawl_port/m_nodes.crawl_host, sitting in sl_log_1, then
> I'm
> >         not quite sure offhand what to suggest.
> >
> >
> >     You mean aside from reading the manual before using an admittedly
> >     bare-metal tool? :)
> >
> >     Actually, I think this points out a potential new feature in slonik:
> >     detect and refuse to run EXECUTE DDL commands which include
> >     transaction management statements (BEGIN, COMMIT, ROLLBACK,
> >     SAVEPOINT and RELEASE).
> >
> >     Oh, and we probably need to update the documentation to talk about
> >     savepoints too. I can't think of any legitimate way to use them, but
> >     then again, it is a Friday afternoon so maybe I'm just being dense.
> >
> >     Andrew
> >
> >
> >     _______________________________________________
> >     Slony1-general mailing list
> >     Slony1-general@lists.slony.info <mailto:
> Slony1-general@lists.slony.info>
> >     http://lists.slony.info/mailman/listinfo/slony1-general
> >
> >
> >
> > ------------------------------------------------------------------------
> >
> > _______________________________________________
> > Slony1-general mailing list
> > Slony1-general@lists.slony.info
> > http://lists.slony.info/mailman/listinfo/slony1-general
>
>
> --
> #=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D#
> # It's easier to get forgiveness for being wrong than for being right. #
> # Let's break this rule - forgive me.                                  #
> #=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D JanWieck@Yahoo.com #
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070917/=
8bb28388/attachment-0001.htm
From ajs at crankycanuck.ca  Mon Sep 17 07:23:52 2007
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Mon Sep 17 07:24:13 2007
Subject: [Slony1-general] Re: conflict beween slony and pg_bulkload
	causing postmaster crash
In-Reply-To: <46EDF872.7070601@buberel.org>
References: <46EB17D7.4050701@buberel.org>
	<60k5qs90e3.fsf@dba2.int.libertyrms.com>
	<46EDF872.7070601@buberel.org>
Message-ID: <20070917142352.GA582@crankycanuck.ca>

On Sun, Sep 16, 2007 at 08:45:54PM -0700, Jason L. Buberel wrote:
> The problem appears to have been caused by the presence of 
> 'pg_bulkload'. There seems to be some essential conflict between that 

What is pg_bulkload?  In any case. . .

> utility and slony. Although I cannot be 100% sure, these are the steps I 

I should think so, since Slony doesn't allow you to do that sort of
thing on a replica.  I sent a Perl script to the list some time ago
that provides a Slony-compatible bulk loader.  Check the archives.

A

-- 
Andrew Sullivan  | ajs@crankycanuck.ca
This work was visionary and imaginative, and goes to show that visionary
and imaginative work need not end up well. 
		--Dennis Ritchie
From ajs at crankycanuck.ca  Mon Sep 17 07:29:44 2007
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Mon Sep 17 07:29:58 2007
Subject: [Slony1-general] size of requests stored in sl_log_x
In-Reply-To: <46EDC476.4060503@Yahoo.com>
References: <46E54F8D.5010500@orange-ftgroup.com> <46E559F3.60602@Yahoo.com>
	<46E55D8B.3050003@orange-ftgroup.com>
	<92869e660709160119h413e7a5exc901e1f66189e9eb@mail.gmail.com>
	<46ECE905.80506@orange-ftgroup.com> <46ED1EBB.706@Yahoo.com>
	<46ED3874.7000303@orange-ftgroup.com> <46EDC476.4060503@Yahoo.com>
Message-ID: <20070917142944.GB582@crankycanuck.ca>

On Sun, Sep 16, 2007 at 08:04:06PM -0400, Jan Wieck wrote:

> achievable as cheap as you think. One would first have to agree that all 
> nodes in the whole cluster have to have tables containing the same 
> columns. Then, the column names can be mapped to short integers in a new 
> slony configuration table. 

So, let's stop there, please, because this seems to me like a
regression.  The current arrangement may allow us flexibility that we
would lose under such a proposal.

The goal of the OP seems to be "optimization" in exactly the way that
MySQL construes it: for some subset of database-like operations, it
is fast.  But we are working on a general purpose tool.  You have to
weigh the costs of losing generality, too.  If you want a bespoke
tool that replicates perfectly in a way that is ideal for your
particular use pattern of the database, then you'd best hire some
developers for your own development, rather than ask the wider world
to optimise for your own application.

A

-- 
Andrew Sullivan  | ajs@crankycanuck.ca
The plural of anecdote is not data.
		--Roger Brinner
From jason at buberel.org  Mon Sep 17 08:33:39 2007
From: jason at buberel.org (Jason L. Buberel)
Date: Mon Sep 17 08:33:51 2007
Subject: [Slony1-general] Re: conflict beween slony and pg_bulkload	causing
	postmaster crash
In-Reply-To: <20070917142352.GA582@crankycanuck.ca>
References: <46EB17D7.4050701@buberel.org>
	<60k5qs90e3.fsf@dba2.int.libertyrms.com>	<46EDF872.7070601@buberel.org>
	<20070917142352.GA582@crankycanuck.ca>
Message-ID: <46EE9E53.40106@buberel.org>

It is actually a PG project:

http://pgbulkload.projects.postgresql.org/

I'll troll the archives for your script. Thanks for the pointer.

-jason

Andrew Sullivan wrote:
> On Sun, Sep 16, 2007 at 08:45:54PM -0700, Jason L. Buberel wrote:
>   =

>> The problem appears to have been caused by the presence of =

>> 'pg_bulkload'. There seems to be some essential conflict between that =

>>     =

>
> What is pg_bulkload?  In any case. . .
>
>   =

>> utility and slony. Although I cannot be 100% sure, these are the steps I =

>>     =

>
> I should think so, since Slony doesn't allow you to do that sort of
> thing on a replica.  I sent a Perl script to the list some time ago
> that provides a Slony-compatible bulk loader.  Check the archives.
>
> A
>
>   =

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070917/=
650bc836/attachment.htm
From ajs at crankycanuck.ca  Mon Sep 17 08:54:01 2007
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Mon Sep 17 08:54:29 2007
Subject: [Slony1-general] Re: conflict beween slony and
	pg_bulkload	causing postmaster crash
In-Reply-To: <46EE9E53.40106@buberel.org>
References: <46EB17D7.4050701@buberel.org>
	<60k5qs90e3.fsf@dba2.int.libertyrms.com>
	<46EDF872.7070601@buberel.org>
	<20070917142352.GA582@crankycanuck.ca> <46EE9E53.40106@buberel.org>
Message-ID: <20070917155401.GZ582@crankycanuck.ca>

On Mon, Sep 17, 2007 at 08:33:39AM -0700, Jason L. Buberel wrote:
> It is actually a PG project:
> 
> http://pgbulkload.projects.postgresql.org/

Aha.  I think you're going to run into trouble with it and Slony,
though.  I'm not surprised they conflict.
 
> I'll troll the archives for your script. Thanks for the pointer.

I just had a look at it after sending my mail.  There may be a
missing =back after the Perldoc section.

A

-- 
Andrew Sullivan  | ajs@crankycanuck.ca
Users never remark, "Wow, this software may be buggy and hard 
to use, but at least there is a lot of code underneath."
		--Damien Katz
From cbbrowne at ca.afilias.info  Mon Sep 17 10:46:22 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Sep 17 10:46:46 2007
Subject: [Slony1-general] Re: conflict beween slony and
	pg_bulkload	causing postmaster crash
In-Reply-To: <20070917155401.GZ582@crankycanuck.ca> (Andrew Sullivan's message
	of "Mon, 17 Sep 2007 11:54:01 -0400")
References: <46EB17D7.4050701@buberel.org>
	<60k5qs90e3.fsf@dba2.int.libertyrms.com>
	<46EDF872.7070601@buberel.org> <20070917142352.GA582@crankycanuck.ca>
	<46EE9E53.40106@buberel.org> <20070917155401.GZ582@crankycanuck.ca>
Message-ID: <60vea95gnl.fsf@dba2.int.libertyrms.com>

Andrew Sullivan <ajs@crankycanuck.ca> writes:
> On Mon, Sep 17, 2007 at 08:33:39AM -0700, Jason L. Buberel wrote:
>> It is actually a PG project:
>> 
>> http://pgbulkload.projects.postgresql.org/
>
> Aha.  I think you're going to run into trouble with it and Slony,
> though.  I'm not surprised they conflict.

I was surprised until I looked at the code; yes, indeed, it seems
quite plausible that it and Slony-I might conflict, as they do similar
sorts of trickery to eliminate validation of R/I constraints.
-- 
output = ("cbbrowne" "@" "linuxdatabases.info")
http://cbbrowne.com/info/sgml.html
Rules of the Evil Overlord #52. "I will hire a team of board-certified
architects and  surveyors to  examine my castle  and inform me  of any
secret passages  and abandoned tunnels  that I might not  know about."
<http://www.eviloverlord.com/>
From jason at buberel.org  Mon Sep 17 10:58:56 2007
From: jason at buberel.org (Jason L. Buberel)
Date: Mon Sep 17 10:59:15 2007
Subject: [Slony1-general] Re: conflict beween slony and pg_bulkload	causing
	postmaster crash
In-Reply-To: <20070917142352.GA582@crankycanuck.ca>
References: <46EB17D7.4050701@buberel.org>
	<60k5qs90e3.fsf@dba2.int.libertyrms.com>	<46EDF872.7070601@buberel.org>
	<20070917142352.GA582@crankycanuck.ca>
Message-ID: <46EEC060.5050404@buberel.org>

Found the archive entry, and I think you did a very good job of =

convincing me to NOT use your script :)


To quote:

PLEASE READ THE DOCS before you use this.  This thing is _dangerous_. =

It's intended to solve a specific problem.  It is _really really not_
intended to solve generic load-and-replace issues.  Even more, there
are plenty of places where it can completely break replication in
your Slony cluster on a table.  I strongly suggest you use this on a
table that is isolated in its own set.  Even there, things might
break.

Given that introduction, would any sane person even consider it?

Cheers,
jason


Andrew Sullivan wrote:
> On Sun, Sep 16, 2007 at 08:45:54PM -0700, Jason L. Buberel wrote:
>   =

>> The problem appears to have been caused by the presence of =

>> 'pg_bulkload'. There seems to be some essential conflict between that =

>>     =

>
> What is pg_bulkload?  In any case. . .
>
>   =

>> utility and slony. Although I cannot be 100% sure, these are the steps I =

>>     =

>
> I should think so, since Slony doesn't allow you to do that sort of
> thing on a replica.  I sent a Perl script to the list some time ago
> that provides a Slony-compatible bulk loader.  Check the archives.
>
> A
>
>   =

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070917/=
a39c5e55/attachment.htm
From ajs at crankycanuck.ca  Mon Sep 17 11:32:11 2007
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Mon Sep 17 11:32:51 2007
Subject: [Slony1-general] Re: conflict beween slony and
	pg_bulkload	causing postmaster crash
In-Reply-To: <46EEC060.5050404@buberel.org>
References: <46EB17D7.4050701@buberel.org>
	<60k5qs90e3.fsf@dba2.int.libertyrms.com>
	<46EDF872.7070601@buberel.org>
	<20070917142352.GA582@crankycanuck.ca>
	<46EEC060.5050404@buberel.org>
Message-ID: <20070917183211.GG582@crankycanuck.ca>

On Mon, Sep 17, 2007 at 10:58:56AM -0700, Jason L. Buberel wrote:
> Found the archive entry, and I think you did a very good job of 
> convincing me to NOT use your script :)

Well, the point of all that was to emphasise what the docs also say,
which is that you basically can't do bulk loading coherently on a
table that is being replicated and is active. 

If you can be sure that you can re-load the table everywhere (i.e.
you can remove all the data everywhere, fix whatever the problem was,
and then reload everywhere), then it's a suitable tool (in principle
-- no warranty, &c.). 

This general caution is true for any bulk loading on an asynchronous
replication system like Slony -- if the goal is (1) not to send all
the data across the wire "retail" and (2) not to lock the entire
cluster at one time, then you're going to run a risk that node
members will be out of sync with one another.  The script as is
attempts to make that as safe as possible, but it's never going to be
a risk-free operation.

> Given that introduction, would any sane person even consider it?

Given that I wrote it in order to facilitate bulk loading in our
production systems for a particularly sensitive set of data (i.e. if
I was wrong, up to 10% of the Internet could have gone dark), I
am quite sure that it will solve the subset of problems it identifies
as its target.  I just wanted to make sure that others think really
hard before using it.  In particular, it is very important to
emphasise that this cannot be used _regularly_ on active tables. 
This is not the solution for a daily bulk load into an active table,
is all.  The perhaps alarmist disclaimers are there partly because
we've had plenty of people on this list already saying, "Slony breaks
when I do X; that's a bug," in the face of a manual which explicitly
says, "Never do X."  I didn't want to add another vector for such
complaints.

I will note, too, that our DBAs concluded that a more conventional
"load; add to replication and subscribe" sequence worked well enough
for them.  While I was working on this problem, apparently someone
found the cause of a bottleneck in the network, and fixed it.  It was
that bottleneck I was coding around.  Therefore, I have no evidence
that this script has ever been used in production.  It worked
repeatedly in our QA environment, however.

A
-- 
Andrew Sullivan  | ajs@crankycanuck.ca
I remember when computers were frustrating because they *did* exactly what 
you told them to.  That actually seems sort of quaint now.
		--J.D. Baldwin
From cbbrowne at ca.afilias.info  Mon Sep 17 12:41:22 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Sep 17 12:41:51 2007
Subject: [Slony1-general] 4 Problems found with log shipper...
Message-ID: <60ejgx5bbx.fsf@dba2.int.libertyrms.com>

1...  The filenames contain the node number, which is
anti-functional...

 slony1_log_2_00000000000000000115.sql  slony1_log_3_00000000000000000185.sql

2...  There is a race condition where we can get the same file number
generated multiple times (with different node numbers).

slony1_log_1_00000000000000000003.sql slony1_log_2_00000000000000000003.sql
slony1_log_1_00000000000000000005.sql slony1_log_2_00000000000000000005.sql
slony1_log_1_00000000000000000009.sql slony1_log_3_00000000000000000009.sql
slony1_log_1_00000000000000000010.sql slony1_log_3_00000000000000000010.sql
slony1_log_1_00000000000000000011.sql slony1_log_3_00000000000000000011.sql
slony1_log_1_00000000000000000012.sql slony1_log_2_00000000000000000012.sql
slony1_log_1_00000000000000000015.sql slony1_log_2_00000000000000000015.sql
slony1_log_1_00000000000000000017.sql slony1_log_3_00000000000000000017.sql
slony1_log_2_00000000000000000018.sql slony1_log_3_00000000000000000018.sql
slony1_log_1_00000000000000000019.sql slony1_log_3_00000000000000000019.sql

3...  There appears to be some perhaps-deeper race condition...

cbbrowne@dba2:/tmp/slony-regress.d29690/archive_logs_2> grep "'950'" *sql                                                                 
slony1_log_1_00000000000000000064.sql:insert into "public"."table1" (id,data) values ('950','hRfO[?a4Yl@xmyKvFtGxG?<tUf^`VW@=6M_dIFGsV0jobhYB5E44xCO^Rpkofp9qJ7W8Hy3]P`_SS - Gross C format string: %d%05d%s%s%f%l%-72.52LG');
slony1_log_1_00000000000000000064.sql:insert into "public"."table4" (id,numcol,realcol,ptcol,pathcol,polycol,circcol,ipcol,maccol,bitcol,newcol,newint) values ('950','77.7000','7.77','(7,7)','((7,7),(7,7),(7,7),(7,7))','((7,7),(7,7),(7,7),(7,7))','<(7,7),7>','192.168.7.77','08:00:2d:07:07:07','011101110111','2007-09-17 17:34:37.940536+00',NULL);
slony1_log_1_00000000000000000067.sql:insert into "public"."table1" (id,data) values ('950','hRfO[?a4Yl@xmyKvFtGxG?<tUf^`VW@=6M_dIFGsV0jobhYB5E44xCO^Rpkofp9qJ7W8Hy3]P`_SS - Gross C format string: %d%05d%s%s%f%l%-72.52LG');
slony1_log_1_00000000000000000067.sql:insert into "public"."table4" (id,numcol,realcol,ptcol,pathcol,polycol,circcol,ipcol,maccol,bitcol,newcol,newint) values ('950','77.7000','7.77','(7,7)','((7,7),(7,7),(7,7),(7,7))','((7,7),(7,7),(7,7),(7,7))','<(7,7),7>','192.168.7.77','08:00:2d:07:07:07','011101110111','2007-09-17 17:34:37.940536+00',NULL);

Note that the two insert statements occur once in each file (#64 and #67).

What is "triple odd" (hence this fits nicely as item #3) is that there
was no problem on the subscriber node that was writing data locally; I
had 4 nodes, one being a log shipper, and *only* the log shipped node
broke like this.

4...  The log shipper falls over a bit too easily

The race condition of #2 also implies that it is possible that file #7
could get "commited" earlier than file #6.

Consider the case where file #6 is being generated by a pretty big
SYNC from node 1...  Node 3 then generates a SYNC (which does not
mandate replicating any data as it is not an origin node); that can
become file #7, which, since the event involves so little work, means
that it can get submitted to the log shipper before file #6.

Unfortunately, in that case, that makes slony_logshipper decide to
fall over :-(.

Evidently testing is a useful thing to do...  We can probably look
forward to 1.2.12 involving *more* change than was expected :-(.
-- 
(reverse (concatenate 'string "moc.enworbbc" "@" "enworbbc"))
http://cbbrowne.com/info/wp.html
Bushydo, the way of the shrub -- BONSAI!
From wmoran at collaborativefusion.com  Mon Sep 17 13:56:00 2007
From: wmoran at collaborativefusion.com (Bill Moran)
Date: Mon Sep 17 13:56:37 2007
Subject: [Slony1-general] 4 Problems found with log shipper...
In-Reply-To: <60ejgx5bbx.fsf@dba2.int.libertyrms.com>
References: <60ejgx5bbx.fsf@dba2.int.libertyrms.com>
Message-ID: <20070917165600.58c8bb08.wmoran@collaborativefusion.com>

In response to Christopher Browne <cbbrowne@ca.afilias.info>:

> 1...  The filenames contain the node number, which is
> anti-functional...
> 
>  slony1_log_2_00000000000000000115.sql  slony1_log_3_00000000000000000185.sql

By anti-functional, do you mean that it causes confusion when handling the
log files after they've been created?

I don't think having the node # in the name is bad, I just think that's
a bad place for it.  I would recommend:

slony1_log_00000000000000000115_node_2.sql

Which keeps the node information in the name, makes it more apparent
what it is, and allows shell tools to sort the files correctly.

Good?  Bad?  Better ideas?

-- 
Bill Moran
Collaborative Fusion Inc.
http://people.collaborativefusion.com/~wmoran/

wmoran@collaborativefusion.com
Phone: 412-422-3463x4023
From cbbrowne at ca.afilias.info  Mon Sep 17 15:22:40 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Sep 17 15:23:20 2007
Subject: [Slony1-general] 4 Problems found with log shipper...
In-Reply-To: <20070917165600.58c8bb08.wmoran@collaborativefusion.com> (Bill
	Moran's message of "Mon, 17 Sep 2007 16:56:00 -0400")
References: <60ejgx5bbx.fsf@dba2.int.libertyrms.com>
	<20070917165600.58c8bb08.wmoran@collaborativefusion.com>
Message-ID: <60abrl53v3.fsf@dba2.int.libertyrms.com>

Bill Moran <wmoran@collaborativefusion.com> writes:
> In response to Christopher Browne <cbbrowne@ca.afilias.info>:
>
>> 1...  The filenames contain the node number, which is
>> anti-functional...
>> 
>>  slony1_log_2_00000000000000000115.sql  slony1_log_3_00000000000000000185.sql
>
> By anti-functional, do you mean that it causes confusion when handling the
> log files after they've been created?
>
> I don't think having the node # in the name is bad, I just think that's
> a bad place for it.  I would recommend:
>
> slony1_log_00000000000000000115_node_2.sql
>
> Which keeps the node information in the name, makes it more apparent
> what it is, and allows shell tools to sort the files correctly.
>
> Good?  Bad?  Better ideas?

Perhaps I spake too strongly ;-).

Yeah, having it *after* the ID number would make it a lot less
inconvenient.
-- 
"cbbrowne","@","linuxfinances.info"
http://linuxfinances.info/info/lsf.html
:FATAL ERROR -- ATTEMPT TO USE CANADIAN COINS
From jason at buberel.org  Mon Sep 17 22:17:00 2007
From: jason at buberel.org (Jason L. Buberel)
Date: Mon Sep 17 22:17:57 2007
Subject: [Slony1-general] Re: conflict beween slony and pg_bulkload	causing
	postmaster crash
In-Reply-To: <20070917183211.GG582@crankycanuck.ca>
References: <46EB17D7.4050701@buberel.org>
	<60k5qs90e3.fsf@dba2.int.libertyrms.com> <46EDF872.7070601@buberel.org>
	<20070917142352.GA582@crankycanuck.ca> <46EEC060.5050404@buberel.org>
	<20070917183211.GG582@crankycanuck.ca>
Message-ID: <46EF5F4C.4050900@buberel.org>

Andrew,

Thank you very much for the detailed response. In my case, the table is 
not even part of a replication set, but I do need to bulk-load data into 
the table in question on a regular basis...or at least I think I do. 
We're that to fail, my little startup (http://www.altosresearch.com/) 
would go bye-bye in a hurry ;)

This leads me to believe that I've been looking at my problem from the 
wrong direction. The primary product we sell are PDF reports of real 
estate market analytics. Part of what we do is gather data on real 
estate listings from a variety of sources. This data collection work is 
spread across several servers, all of which populate a non-replicated 
tabled (listing_entry). Upon completion, I export the data collected on 
each server and import that into the other two servers. Once completed, 
each of the three servers then has a complete set of listing_entry rows 
for that week.

What would instead be ideal (and more automated/less manual work) would 
be a system in which the data in this 'listing_entry' table was 
automatically dispersed to each of the other nodes in the cluster:

collection-server-1
collection-server-2
    .
    .
    .
collection-server-n

For example, a new listing_entry row inserted on collection-server-1 
would then be replicated to the listing_entry tables on 
collection-server-2 through collection-server-n. This calls for more of 
a multi-master/multi-slave approach, unlike the 
single-master-multi-slave design that slony supports.

I have resisted implementing this at the application level, hoping to 
come across a tool that would allow me to do this bi-directional 
synchronization. Does any such beast exist, or is this ulimately a 
do-it-yourself job?

-jason

Andrew Sullivan wrote:
> emphasise that this cannot be used _regularly_ on active tables. 
> This is not the solution for a daily bulk load into an active table,
> is all.  The perhaps alarmist disclaimers are there partly because
From ajs at crankycanuck.ca  Tue Sep 18 06:22:00 2007
From: ajs at crankycanuck.ca (Andrew Sullivan)
Date: Tue Sep 18 06:22:18 2007
Subject: [Slony1-general] Re: conflict beween slony and
	pg_bulkload	causing postmaster crash
In-Reply-To: <46EF5F4C.4050900@buberel.org>
References: <46EB17D7.4050701@buberel.org>
	<60k5qs90e3.fsf@dba2.int.libertyrms.com>
	<46EDF872.7070601@buberel.org>
	<20070917142352.GA582@crankycanuck.ca>
	<46EEC060.5050404@buberel.org>
	<20070917183211.GG582@crankycanuck.ca>
	<46EF5F4C.4050900@buberel.org>
Message-ID: <20070918132200.GE4754@crankycanuck.ca>

On Mon, Sep 17, 2007 at 10:17:00PM -0700, Jason L. Buberel wrote:
> Thank you very much for the detailed response. In my case, the table is 
> not even part of a replication set, but I do need to bulk-load data into 
> the table in question on a regular basis...or at least I think I do. 

Well, one way to do this, I think, is to use a view of the underlying
tables.  You have more than one table involved at a time.  When you
perform your bulk load, you pull it into an empty table.  When you're
done, you change the view on all nodes, and presto! your new data
appears everywhere.

This is most useful in cases where you can also purge off old data,
so that you have some set of "rotor" tables, only one of which you're
loading at any one time.

> I have resisted implementing this at the application level, hoping to 
> come across a tool that would allow me to do this bi-directional 
> synchronization. Does any such beast exist, or is this ulimately a 
> do-it-yourself job?

It's do it yourself, but this sort of multimaster approach (with no
conflict resolution) is something people have proposed extending
Slony to solve.  You'd do something similar as the view approach
above.  The underlying tables would still need to be replicated,
however, which is different from the way you're doing it now.

A

-- 
Andrew Sullivan  | ajs@crankycanuck.ca
In the future this spectacle of the middle classes shocking the avant-
garde will probably become the textbook definition of Postmodernism. 
                --Brad Holland
From jeff at frostconsultingllc.com  Tue Sep 18 13:49:28 2007
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Tue Sep 18 13:49:53 2007
Subject: [Slony1-general] bug in deadlock handling?
Message-ID: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>

Hi guys, I've got an interesting situation on a slony 1.2.10 3 node cluster. 
Both slaves get their data direct from the master.  Everything has been 
running well up to a few days ago.  Now every time we try to add a new table 
to the cluster, we end up with the following error:

2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select 
"_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR ERROR: 
Slony-I: alterTableRestore(): Table "public"."carts" is not in altered state
CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore( $1 )"
PL/pgSQL function "ddlscript_prepare_int" line 46 at perform

It looks like the problem is being caused by a deadlock:

15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR 
remoteWorkerThread_1: "select "_nerdcluster".ddlScript
_complete_int(1, -1); " PGRES_FATAL_ERROR
Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263 waits for 
AccessExclusiveLock on relation 121589880 of databas
e 121589046; blocked by process 12096.
Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for 
AccessShareLock on relation 121589817 of database 121589046;
blocked by process 12263.

So, my theory is that the execute script alters the tables back to their 
normal states, doesn't get all the locks it wants and bails out without 
putting them back to their previously altered state, thus breaking 
replication.

So, is there a reasonable way to fix this without droppping/resubscribing the 
node?

---
Jeff Frost, Owner 	 <jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From jeff at frostconsultingllc.com  Tue Sep 18 16:05:52 2007
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Tue Sep 18 16:06:22 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
Message-ID: <Pine.LNX.4.64.0709181604570.4701@discord.home.frostconsultingllc.com>

On Tue, 18 Sep 2007, Jeff Frost wrote:

> Hi guys, I've got an interesting situation on a slony 1.2.10 3 node cluster. 
> Both slaves get their data direct from the master.  Everything has been 
> running well up to a few days ago.  Now every time we try to add a new table 
> to the cluster, we end up with the following error:
>
> 2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select 
> "_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR ERROR: 
> Slony-I: alterTableRestore(): Table "public"."carts" is not in altered state
> CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore( $1 )"
> PL/pgSQL function "ddlscript_prepare_int" line 46 at perform
>
> It looks like the problem is being caused by a deadlock:
>
> 15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR 
> remoteWorkerThread_1: "select "_nerdcluster".ddlScript
> _complete_int(1, -1); " PGRES_FATAL_ERROR
> Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
> Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263 waits for 
> AccessExclusiveLock on relation 121589880 of databas
> e 121589046; blocked by process 12096.
> Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for 
> AccessShareLock on relation 121589817 of database 121589046;
> blocked by process 12263.
>
> So, my theory is that the execute script alters the tables back to their 
> normal states, doesn't get all the locks it wants and bails out without 
> putting them back to their previously altered state, thus breaking 
> replication.
>
> So, is there a reasonable way to fix this without droppping/resubscribing the 
> node?

BTW, this is a quiet error...i.e. slonik does not indicate anything untoward 
happened.  Also, the problem only occurs on node 2 and not on node 3.  This 
isn't surprising as there's no activity on node 3 it's just a warm standby, 
but node 2 is actively processing queries.

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From stephane.schildknecht at postgresqlfr.org  Wed Sep 19 01:39:24 2007
From: stephane.schildknecht at postgresqlfr.org (=?ISO-8859-1?Q?St=E9phane_Schildknecht?=)
Date: Wed Sep 19 01:40:22 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <Pine.LNX.4.64.0709181604570.4701@discord.home.frostconsultingllc.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<Pine.LNX.4.64.0709181604570.4701@discord.home.frostconsultingllc.com>
Message-ID: <46F0E03C.7020500@postgresqlfr.org>

Jeff Frost a ?crit :
> On Tue, 18 Sep 2007, Jeff Frost wrote:
>
>> Hi guys, I've got an interesting situation on a slony 1.2.10 3 node
>> cluster. Both slaves get their data direct from the master. 
>> Everything has been running well up to a few days ago.  Now every
>> time we try to add a new table to the cluster, we end up with the
>> following error:
>>
>> 2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select
>> "_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR
>> ERROR: Slony-I: alterTableRestore(): Table "public"."carts" is not in
>> altered state
>> CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore( $1 )"
>> PL/pgSQL function "ddlscript_prepare_int" line 46 at perform
>>
>> It looks like the problem is being caused by a deadlock:
>>
>> 15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR
>> remoteWorkerThread_1: "select "_nerdcluster".ddlScript
>> _complete_int(1, -1); " PGRES_FATAL_ERROR
>> Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
>> Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263 waits
>> for AccessExclusiveLock on relation 121589880 of databas
>> e 121589046; blocked by process 12096.
>> Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for
>> AccessShareLock on relation 121589817 of database 121589046;
>> blocked by process 12263.
>>
>> So, my theory is that the execute script alters the tables back to
>> their normal states, doesn't get all the locks it wants and bails out
>> without putting them back to their previously altered state, thus
>> breaking replication.
>>
>> So, is there a reasonable way to fix this without
>> droppping/resubscribing the node?
>
> BTW, this is a quiet error...i.e. slonik does not indicate anything
> untoward happened.  Also, the problem only occurs on node 2 and not on
> node 3.  This isn't surprising as there's no activity on node 3 it's
> just a warm standby, but node 2 is actively processing queries.
>
Hi,

I encoutered the same problem and came to the conclusion pgpool was the
cause of that problem.

I do have 5 nodes in the replication. The databases on two of them are
accessed through pgpool. One of the two is a spare one, not accessed
under normal conditions, the other one is hugely accessed.

When trying to propagate a ddl script through a slonik "EXECUTE SCRIPT"
command, master and spare slave are correctly modified, the production
one falls into error producing the same messages about altered state.

The only way I found to repair that node was then to drop all slony
things in it (uninstall it) and then reinitialize it. As full
subscription is a more-than-three-hour process, I now stop pgpool before
I do the execute script. The last "execute script" I ran did not fall
into error.

I wonder how I could stop pgpool without preventing application to
connect to the database, and it seemed a good procedure to access the
pgpool or the database by tunneling the access.

I mean pg listens on 5432, pgpool on 5433, and the application connects
through 5434. I then juste have to modify the tunnel to bypass pgpool.
It seems to work, that way. I just wonder if it really a good solution.
Do you have any clue on such a way of processing ?

Best regards,

-- 
St?phane SCHILDKNECHT
Pr?sident de PostgreSQLFr
http://www.postgresqlfr.org

From cscetbon.ext at orange-ftgroup.com  Wed Sep 19 10:36:31 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Wed Sep 19 10:36:49 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <46E70F78.8060603@Yahoo.com>
References: <46E153D1.4060903@orange-ftgroup.com>	<46E1A7A0.30401@Yahoo.com>		<46E305D8.3090502@orange-ftgroup.com>	<46E5AA0D.1060708@orange-ftgroup.com	>
	<46E5C957.7020003@Yahoo.com> <46E63A8D.3020607@orange-ftgroup.com>
	<46E70F78.8060603@Yahoo.com>
Message-ID: <46F15E1F.8080306@orange-ftgroup.com>



Jan Wieck wrote:
> On 9/11/2007 2:49 AM, Cyril SCETBON wrote:
>>
>> Jan Wieck wrote:
>>> On 9/10/2007 4:33 PM, Cyril SCETBON wrote:
>>>>
>>>> Cyril SCETBON wrote:
>>>>>
>>>>>
>>>>> Jan Wieck wrote:
>>>>>> On 9/7/2007 9:36 AM, Cyril SCETBON wrote:
>>>>>>> Hi,
>>>>>>>
>>>>>>> I got this configuration                Node1 --> Node2 (5 
>>>>>>> seconds late)
>>>>>>>                                                           |
>>>>>>>                                                           --> 
>>>>>>> Node3 (2 hours late)
>>>>>>>
>>>>>>> Node2 is processing each SYNC from Node3 and Node2, but Node3 is 
>>>>>>> processing each SYNC from Node2 but not from Node1 which is the 
>>>>>>> origin of the sets :
>>>>>>>
>>>>>>> On Node3 we see  `grep processing 
>>>>>>> /var/log/slony1/node3-pns_profiles_preprod.log|awk '{print 
>>>>>>> $5}'|sort|uniq -c`
>>>>>>>      19 remoteWorkerThread_1:
>>>>>>>     963 remoteWorkerThread_2:
>>>>>>>
>>>>>>> On Node2 we see `grep processing 
>>>>>>> /var/log/slony1/node2-pns_profiles_preprod.log |awk '{print 
>>>>>>> $5}'|sort|uniq -c`
>>>>>>>    1570 remoteWorkerThread_1:
>>>>>>>     865 remoteWorkerThread_3:
>>>>>>>
>>>>>>> Why is there so many SYNC not processed on Node3 ???
>>>>>>>
>>>>>>> Node3 got 22440 queue event and 25 Received event from 
>>>>>>> remoteWorkerThread_1, while Node2 got 4467 queue event and 1578 
>>>>>>> Received event from the same worker.
>>>>>>>
>>>>>>> Is there something to do ?
>>>>>>
>>>>>> How about looking for some error messages?
>>>>> None.
>>>> I've put slon in debug level 2
>>>>>>
>>>>>> What comes to mind would be that sl_event is grossly out of shape 
>>>>>> and that the event selection times out.
>>>>> Seems vacuuming sl_log_1 takes too much time cause of 
>>>>> vacuum_cost_delay and that selecting from this table use a seq 
>>>>> scan. I'm investiguating.
>>>> I forced vacuum to go faster and checked slon logs of subscribers. 
>>>> They got similar disks capabilities which seems to be the 
>>>> bottleneck on all node (wait io ~=50% in vmstat).
>>>>
>>>> I found replication tasks time are different :
>>>>
>>>> On node 3 :
>>>>                      delay in seconds = 585.974ms
>>>>                      cleanupEvent in seconds = 9.25167s
>>>>
>>>> On node 2 :
>>>>                      delay in seconds = 37.6463ms
>>>>                      cleanupEvent in seconds = 0.203265s
>>>>
>>>> May these times explain why node 3 is late compared to node 2 ? 
>>>> What do you think I have to investiguate now ?
>>>
>>> Considering that node 2 can pretty well keep up but node 3 is 
>>> falling way behind, the problem cannot be caused by node 1. Neither 
>>> can it be caused by the event selection of node 3, so that leaves us 
>>> with either the log selection done by node 3 against the data 
>>> provider node 2, or the actual speed of node 3 itself.
>>>
>>> In debug level 2, what does node 3's slon usually report as "delay 
>>> for first row" when processing SYNC events?
>> that's what I gave as 'delay in seconds' above
>
> OK, so the origin can provide log rows almost instantaneously, while 
> node 2 has apparently some issues with the same. Although half a 
> second isn't a catastrophe, it indicates that there are some 
> performance issues handling the overall workload already on that system.
>
> Now when in comes to node 3, this means that it is not doing any 
> actual replication work for 500ms per sync group. Which should not 
> pose a real problem. So my guess is that node 3 is simply too slow to 
> keep up with the write load of the origin, or that the network 
> connection is too slow to actually deliver the log data fast enough. 
> If this is a WAN connection (which by itself can explain 500ms for the 
> first FETCH of 100 log rows), you might want to try using an ssh 
> tunnel with compression.
Although I use SSH compression, it's not better. On The Provider there 
are 400 write/s, do you think it should be worth to increase 
SLON_DATA_FETCH_SIZE to 500 or 1000 in the remote_worker to improve my 
performance ? Network latency (18ms for a ping to another geographical 
site vs 0.2 ms on the same geographical site)
I got 1024 tables that are spread in 64 sets, I was thinking too that 
maybe spreading this 64 sets into 2 databases on the same host would 
improve performance by using 2 differents slony clusters on the same 
machine. So, smaller sl_log_? and 2 differents slon daemons (1 by 
cluster) to take care of the replication.

>
> The other thing to check is to make sure all databases are tuned.
both hosts can serve more than 500 w/s

-- 
Cyril SCETBON
From andrew.george.hammond at gmail.com  Wed Sep 19 11:37:50 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Wed Sep 19 11:38:08 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
Message-ID: <5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>

On 9/18/07, Jeff Frost <jeff@frostconsultingllc.com> wrote:
>
> Hi guys, I've got an interesting situation on a slony 1.2.10 3 node
> cluster.
> Both slaves get their data direct from the master.  Everything has been
> running well up to a few days ago.  Now every time we try to add a new
> table
> to the cluster, we end up with the following error:
>

"Every time"? You have tried more than once?

What I don't see in your problem report is a detailed description, starting
with the cluster in a known good state, of exactly what you have done.
Without knowing exactly what you have done (typescripts or copies of the
shell scripts you used), it's hard to figure out what went wrong.

2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select
> "_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR ERROR:
> Slony-I: alterTableRestore(): Table "public"."carts" is not in altered
> state
> CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore( $1 )"
> PL/pgSQL function "ddlscript_prepare_int" line 46 at perform
>
> It looks like the problem is being caused by a deadlock:
>
> 15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR
> remoteWorkerThread_1: "select "_nerdcluster".ddlScript
> _complete_int(1, -1); " PGRES_FATAL_ERROR
> Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
> Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263 waits for
> AccessExclusiveLock on relation 121589880 of databas
> e 121589046; blocked by process 12096.
> Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for
> AccessShareLock on relation 121589817 of database 121589046;
> blocked by process 12263.
>
> So, my theory is that the execute script alters the tables back to their
> normal states, doesn't get all the locks it wants and bails out without
> putting them back to their previously altered state, thus breaking
> replication.


Bails out is the wrong description. Clobbered by the pgsql deadlock
detection system, leaving the cluster in an unstable state would be more
accurate, if that's what happened. I don't know that there's a way to catch
that clobberage and run a "finally" type thing.

So, is there a reasonable way to fix this without droppping/resubscribing
> the
> node?
>

Well, to start with, you might want to figure out why your application is
taking such aggressive locks. And make sure in the future that it doesn't
happen again (not much point fixing it if it's just gonna re-occur). If you
are using a separate superuser account to connect to your database and run
your slons (generally the "slony" user) then this is really easy to do:
tweak your pg_hba to only allow connections from slony and then kick all
active non-slony connections. Revert your pg_hba at the end of the
maintenance.

If you're willing to experiment with using slony internal functions, you
could put the table in question into altered state. Something like this on
the offending node might work.

SELECT alterTableForReplication((SELECT tab_id FROM sl_table WHERE
tab_reloid =3D (SELECT oid FROM pg_class WHERE relname=3D'cart')));

Or of course it might mess things up even more. :)

Andrew
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070919/=
bf798f16/attachment-0001.htm
From cbbrowne at ca.afilias.info  Wed Sep 19 12:22:52 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Sep 19 12:23:13 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>
Message-ID: <46F1770C.8010201@ca.afilias.info>

Andrew Hammond wrote:
> On 9/18/07, *Jeff Frost* <jeff@frostconsultingllc.com 
> <mailto:jeff@frostconsultingllc.com>> wrote:
>
>     Hi guys, I've got an interesting situation on a slony 1.2.10 3
>     node cluster.
>     Both slaves get their data direct from the master.  Everything has
>     been
>     running well up to a few days ago.  Now every time we try to add a
>     new table
>     to the cluster, we end up with the following error:
>
>
> "Every time"? You have tried more than once?
>
> What I don't see in your problem report is a detailed description, 
> starting with the cluster in a known good state, of exactly what you 
> have done. Without knowing exactly what you have done (typescripts or 
> copies of the shell scripts you used), it's hard to figure out what 
> went wrong.
>
>     2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select
>     "_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR
>     ERROR:
>     Slony-I: alterTableRestore(): Table "public"."carts" is not in
>     altered state
>     CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore(
>     $1 )"
>     PL/pgSQL function "ddlscript_prepare_int" line 46 at perform
>
>     It looks like the problem is being caused by a deadlock:
>
>     15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR
>     remoteWorkerThread_1: "select "_nerdcluster".ddlScript
>     _complete_int(1, -1); " PGRES_FATAL_ERROR
>     Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
>     Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263
>     waits for
>     AccessExclusiveLock on relation 121589880 of databas
>     e 121589046; blocked by process 12096.
>     Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for
>     AccessShareLock on relation 121589817 of database 121589046;
>     blocked by process 12263.
>
>     So, my theory is that the execute script alters the tables back to
>     their
>     normal states, doesn't get all the locks it wants and bails out
>     without
>     putting them back to their previously altered state, thus breaking
>     replication.
>
>
> Bails out is the wrong description. Clobbered by the pgsql deadlock 
> detection system, leaving the cluster in an unstable state would be 
> more accurate, if that's what happened. I don't know that there's a 
> way to catch that clobberage and run a "finally" type thing.
The thing is, that's not what happens.

Unless there's a COMMIT somewhere in the DDL script, in which case all 
bets are off, everywhere, the deadlock should lead to one of two things 
happening:

1. The other process that was holding onto the tables might fail and 
roll back, and the DDL script would complete, or

2.  The DDL script will fail and roll back, leading to the state of the 
tables falling back to what it was before DDL script processing began.

In either case, the results should leave the node in a consistent state, 
either:
a) With the DDL request having gone in, or
b) With the DDL request *not* having gone in.

Unless there's an extra COMMIT in the code (and I just looked at the 
code, and Did Not See One), the failure resulting from a deadlock should 
be benign, restoring the tables to the "previously altered state."
>
>     So, is there a reasonable way to fix this without
>     droppping/resubscribing the
>     node?
>
>
> Well, to start with, you might want to figure out why your application 
> is taking such aggressive locks. And make sure in the future that it 
> doesn't happen again (not much point fixing it if it's just gonna 
> re-occur). If you are using a separate superuser account to connect to 
> your database and run your slons (generally the "slony" user) then 
> this is really easy to do: tweak your pg_hba to only allow connections 
> from slony and then kick all active non-slony connections. Revert your 
> pg_hba at the end of the maintenance.
>
> If you're willing to experiment with using slony internal functions, 
> you could put the table in question into altered state. Something like 
> this on the offending node might work.
>
> SELECT alterTableForReplication((SELECT tab_id FROM sl_table WHERE 
> tab_reloid = (SELECT oid FROM pg_class WHERE relname='cart')));
>
> Or of course it might mess things up even more. :)
The one change to suggest that comes to *my* mind is that we perhaps 
ought to change Slony-I to aggressively lock the replicated tables ASAP 
at the start of the DDL script event.

That will either immediately succeed, and eliminate any possibility of 
future deadlock, or immediately fail, before we even try to alter anything.

This same change was made to the SUBSCRIBE SET process (well, 
"COPY_SET", strictly speaking, but that's not at all user visible...), 
as we saw cases where gradually escalating locks on tables led to 
deadlocks that could waste hours worth of subscription work.

But it seems likely to me that there's more to the problem than we're 
hearing, because deadlock shouldn't cause any corruption of anything - 
to the contrary, it may be expected to prevent it.
From jpfletch at ca.afilias.info  Wed Sep 19 12:53:04 2007
From: jpfletch at ca.afilias.info (JP Fletcher)
Date: Wed Sep 19 12:54:32 2007
Subject: [Slony1-general] cluster broken
In-Reply-To: <60y7fa2qem.fsf@dba2.int.libertyrms.com>
References: <46E9A192.2010906@ca.afilias.info>
	<60y7fa2qem.fsf@dba2.int.libertyrms.com>
Message-ID: <46F17E20.3020605@ca.afilias.info>

Hi,


I'm able to reproduce this condition repeatedly.  The scenario is as 
follows:

Set1 has origin on node8143, which is data provider to node8141, which 
in turn is provider to node8194 :

8143 --> 8141 --> 8194


I add set2, which has origin on node8143.  I then subscribe node8194 to 
node8143 directly.
                                  
This breaks node8194 immediately.  The slon logs for node 8194 show:

2007-09-19 19:42:01 UTC ERROR  remoteWorkerThread_8143: "declare LOG 
cursor for select     log_origin, log_xid, log_tableid,     
log_actionseq, log_cmdtype,     octet_length(log_cmddata),     case when 
octet_length(log_cmddata) <= 8192         then log_cmddata         else 
null end from "_cluster".sl_log_1 where log_origin = 8143 and (  order 
by log_actionseq; " PGRES_FATAL_ERROR ERROR:  syntax error at or near 
"order" at character 283
2007-09-19 19:42:01 UTC ERROR  remoteWorkerThread_8143: "close LOG; " 
PGRES_FATAL_ERROR ERROR:  current transaction is aborted, commands 
ignored until end of transaction block



JP

Christopher Browne wrote:
> JP Fletcher <jpfletch@ca.afilias.info> writes:
>
>   
>> Hi,
>>
>> My 1.2.11 cluster abruptly stopped working, with the following error
>> message present in the pg logs of the origin:
>>
>> 2007-09-13 20:29:06.358 UTC [1679750] cluster slony 10.1.2.133 ERROR:
>> syntax error at or near "order" at character 283
>> 2007-09-13 20:29:06.358 UTC [1679750] cluster slony 10.1.2.133
>> STATEMENT:  declare LOG cursor for select     log_origin, log_xid,
>> log_tableid,     log_actionseq, log_cmdtype,
>> octet_length(log_cmddata),     case when octet_length(log_cmddata) <=
>> 8192         then log_cmddata         else null end from
>> "_cluster".sl_log_1 where log_origin = 8143 and (  order by
>> log_actionseq;
>>
>>
>> I had been changing some subscriptions around,  with no evidence of
>> failure.  Apart from that, the cluster wasn't doing anything...
>>     
>
> Hmm.  This sounds a whole lot like:
>
> <http://gborg.postgresql.org/project/slony1/bugs/bugupdate.php?1226>
>
> That was supposedly fixed about two years ago.
>   


-- 
JP Fletcher
Database Administrator
Afilias Canada
voice: 416.646.3304 ext. 4123
fax: 416.646.3305
mobile: 416.561.4763
jpfletch@ca.afilias.info


From jeff at frostconsultingllc.com  Wed Sep 19 14:56:50 2007
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Wed Sep 19 14:57:18 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <46F1770C.8010201@ca.afilias.info>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>
	<46F1770C.8010201@ca.afilias.info>
Message-ID: <Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>

On Wed, 19 Sep 2007, Christopher Browne wrote:

>> Bails out is the wrong description. Clobbered by the pgsql deadlock 
>> detection system, leaving the cluster in an unstable state would be more 
>> accurate, if that's what happened. I don't know that there's a way to catch 
>> that clobberage and run a "finally" type thing.
> The thing is, that's not what happens.
>
> Unless there's a COMMIT somewhere in the DDL script, in which case all bets 
> are off, everywhere, the deadlock should lead to one of two things happening:
>
> 1. The other process that was holding onto the tables might fail and roll 
> back, and the DDL script would complete, or
>
> 2.  The DDL script will fail and roll back, leading to the state of the 
> tables falling back to what it was before DDL script processing began.
>
> In either case, the results should leave the node in a consistent state, 
> either:
> a) With the DDL request having gone in, or
> b) With the DDL request *not* having gone in.
>
> Unless there's an extra COMMIT in the code (and I just looked at the code, 
> and Did Not See One), the failure resulting from a deadlock should be benign, 
> restoring the tables to the "previously altered state."
>>
>>     So, is there a reasonable way to fix this without
>>     droppping/resubscribing the
>>     node?
>> 
>> 
>> Well, to start with, you might want to figure out why your application is 
>> taking such aggressive locks. And make sure in the future that it doesn't 
>> happen again (not much point fixing it if it's just gonna re-occur). If you 
>> are using a separate superuser account to connect to your database and run 
>> your slons (generally the "slony" user) then this is really easy to do: 
>> tweak your pg_hba to only allow connections from slony and then kick all 
>> active non-slony connections. Revert your pg_hba at the end of the 
>> maintenance.
>> 
>> If you're willing to experiment with using slony internal functions, you 
>> could put the table in question into altered state. Something like this on 
>> the offending node might work.
>> 
>> SELECT alterTableForReplication((SELECT tab_id FROM sl_table WHERE 
>> tab_reloid = (SELECT oid FROM pg_class WHERE relname='cart')));
>> 
>> Or of course it might mess things up even more. :)
> The one change to suggest that comes to *my* mind is that we perhaps ought to 
> change Slony-I to aggressively lock the replicated tables ASAP at the start 
> of the DDL script event.
>
> That will either immediately succeed, and eliminate any possibility of future 
> deadlock, or immediately fail, before we even try to alter anything.
>
> This same change was made to the SUBSCRIBE SET process (well, "COPY_SET", 
> strictly speaking, but that's not at all user visible...), as we saw cases 
> where gradually escalating locks on tables led to deadlocks that could waste 
> hours worth of subscription work.
>
> But it seems likely to me that there's more to the problem than we're 
> hearing, because deadlock shouldn't cause any corruption of anything - to the 
> contrary, it may be expected to prevent it.

this is the latest SQL that caused the problem (note there is not a COMMIT in 
the sql):

--------
CREATE TABLE orders.amazon_items
(
   id serial NOT NULL,
   order_id integer NOT NULL,
   item_id integer NOT NULL,
   amazon_item_id character varying(14) NOT NULL,
   CONSTRAINT amazon_items_pkey PRIMARY KEY (id),
   CONSTRAINT amazon_items_order_id_fkey FOREIGN KEY (order_id)
       REFERENCES orders.orders (id) MATCH SIMPLE
       ON UPDATE NO ACTION ON DELETE NO ACTION,
   CONSTRAINT amazon_items_item_id_fkey FOREIGN KEY (item_id)
       REFERENCES orders.items (id) MATCH SIMPLE
       ON UPDATE NO ACTION ON DELETE NO ACTION
)
WITH OIDS;
ALTER TABLE orders.amazon_items OWNER TO thenerds;
--------

It was called by the following slonik script:

--------
#!/usr/bin/slonik
include </nerds/preamble.slonik>;

         EXECUTE SCRIPT (
                 SET ID = 1,
                 FILENAME = '/nerds/thenerds.sql',
                 EVENT NODE = 1
         );
--------

and caused the following deadlock to occur:

15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR
remoteWorkerThread_1: "select "_nerdcluster".ddlScript
_complete_int(1, -1); " PGRES_FATAL_ERROR
Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263 waits for
AccessExclusiveLock on relation 121589880 of databas
e 121589046; blocked by process 12096.
Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for
AccessShareLock on relation 121589817 of database 121589046;
blocked by process 12263.

Which then left the some of the tables on that slave in a bad state breaking 
replication:

2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select
"_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR ERROR:
Slony-I: alterTableRestore(): Table "public"."carts" is not in altered state
CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore( $1 )"
PL/pgSQL function "ddlscript_prepare_int" line 46 at perform

Note that it's just an AccessShareLock that's killing us.  Looks like that's 
caused by a select query which does searches.  Our application does not 
produce any extraneous locking, it simply does SELECTS on that server.

Interestingly, before we started using the slave for queries, we would have 
the deadlocks happen on the master when doing DDL changes, but this never 
caused the tables on the master to get into a bad state.  You could just 
re-run your EXECUTE SCRIPT and it would usually work fine the second time.

What other info can I provide?

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From stephane.schildknecht at postgresqlfr.org  Thu Sep 20 00:17:33 2007
From: stephane.schildknecht at postgresqlfr.org (=?ISO-8859-1?Q?St=E9phane_Schildknecht?=)
Date: Thu Sep 20 00:18:35 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>	<46F1770C.8010201@ca.afilias.info>
	<Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
Message-ID: <46F21E8D.8050606@postgresqlfr.org>

Jeff Frost a ?crit :
> On Wed, 19 Sep 2007, Christopher Browne wrote:
>
>>> Bails out is the wrong description. Clobbered by the pgsql deadlock
>>> detection system, leaving the cluster in an unstable state would be
>>> more accurate, if that's what happened. I don't know that there's a
>>> way to catch that clobberage and run a "finally" type thing.
>> The thing is, that's not what happens.
>>
>> Unless there's a COMMIT somewhere in the DDL script, in which case
>> all bets are off, everywhere, the deadlock should lead to one of two
>> things happening:
>>
>> 1. The other process that was holding onto the tables might fail and
>> roll back, and the DDL script would complete, or
>>
>> 2.  The DDL script will fail and roll back, leading to the state of
>> the tables falling back to what it was before DDL script processing
>> began.
>>
>> In either case, the results should leave the node in a consistent
>> state, either:
>> a) With the DDL request having gone in, or
>> b) With the DDL request *not* having gone in.
>>
>> Unless there's an extra COMMIT in the code (and I just looked at the
>> code, and Did Not See One), the failure resulting from a deadlock
>> should be benign, restoring the tables to the "previously altered
>> state."
>>>
>>>     So, is there a reasonable way to fix this without
>>>     droppping/resubscribing the
>>>     node?
>>>
>>>
>>> Well, to start with, you might want to figure out why your
>>> application is taking such aggressive locks. And make sure in the
>>> future that it doesn't happen again (not much point fixing it if
>>> it's just gonna re-occur). If you are using a separate superuser
>>> account to connect to your database and run your slons (generally
>>> the "slony" user) then this is really easy to do: tweak your pg_hba
>>> to only allow connections from slony and then kick all active
>>> non-slony connections. Revert your pg_hba at the end of the
>>> maintenance.
>>>
>>> If you're willing to experiment with using slony internal functions,
>>> you could put the table in question into altered state. Something
>>> like this on the offending node might work.
>>>
>>> SELECT alterTableForReplication((SELECT tab_id FROM sl_table WHERE
>>> tab_reloid = (SELECT oid FROM pg_class WHERE relname='cart')));
>>>
>>> Or of course it might mess things up even more. :)
>> The one change to suggest that comes to *my* mind is that we perhaps
>> ought to change Slony-I to aggressively lock the replicated tables
>> ASAP at the start of the DDL script event.
>>
>> That will either immediately succeed, and eliminate any possibility
>> of future deadlock, or immediately fail, before we even try to alter
>> anything.
>>
>> This same change was made to the SUBSCRIBE SET process (well,
>> "COPY_SET", strictly speaking, but that's not at all user
>> visible...), as we saw cases where gradually escalating locks on
>> tables led to deadlocks that could waste hours worth of subscription
>> work.
>>
>> But it seems likely to me that there's more to the problem than we're
>> hearing, because deadlock shouldn't cause any corruption of anything
>> - to the contrary, it may be expected to prevent it.
>
> this is the latest SQL that caused the problem (note there is not a
> COMMIT in the sql):
>
> --------
> CREATE TABLE orders.amazon_items
> (
>   id serial NOT NULL,
>   order_id integer NOT NULL,
>   item_id integer NOT NULL,
>   amazon_item_id character varying(14) NOT NULL,
>   CONSTRAINT amazon_items_pkey PRIMARY KEY (id),
>   CONSTRAINT amazon_items_order_id_fkey FOREIGN KEY (order_id)
>       REFERENCES orders.orders (id) MATCH SIMPLE
>       ON UPDATE NO ACTION ON DELETE NO ACTION,
>   CONSTRAINT amazon_items_item_id_fkey FOREIGN KEY (item_id)
>       REFERENCES orders.items (id) MATCH SIMPLE
>       ON UPDATE NO ACTION ON DELETE NO ACTION
> )
> WITH OIDS;
> ALTER TABLE orders.amazon_items OWNER TO thenerds;
> --------
>
> It was called by the following slonik script:
>
> --------
> #!/usr/bin/slonik
> include </nerds/preamble.slonik>;
>
>         EXECUTE SCRIPT (
>                 SET ID = 1,
>                 FILENAME = '/nerds/thenerds.sql',
>                 EVENT NODE = 1
>         );
> --------
>
> and caused the following deadlock to occur:
>
> 15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR
> remoteWorkerThread_1: "select "_nerdcluster".ddlScript
> _complete_int(1, -1); " PGRES_FATAL_ERROR
> Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
> Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263 waits for
> AccessExclusiveLock on relation 121589880 of databas
> e 121589046; blocked by process 12096.
> Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for
> AccessShareLock on relation 121589817 of database 121589046;
> blocked by process 12263.
>
> Which then left the some of the tables on that slave in a bad state
> breaking replication:
>
> 2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select
> "_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR ERROR:
> Slony-I: alterTableRestore(): Table "public"."carts" is not in altered
> state
> CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore( $1 )"
> PL/pgSQL function "ddlscript_prepare_int" line 46 at perform
>
> Note that it's just an AccessShareLock that's killing us.  Looks like
> that's caused by a select query which does searches.  Our application
> does not produce any extraneous locking, it simply does SELECTS on
> that server.
>
> Interestingly, before we started using the slave for queries, we would
> have the deadlocks happen on the master when doing DDL changes, but
> this never caused the tables on the master to get into a bad state. 
> You could just re-run your EXECUTE SCRIPT and it would usually work
> fine the second time.
>
> What other info can I provide?
>
First, I don't think you have to use the execute script command to
create a new table.

I'd also like to know if you use pgpool, on slave, master, both ?

Does the re-executing of the script offer any solution ?

Cheers,
SAS
From jeff at frostconsultingllc.com  Thu Sep 20 08:04:23 2007
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Thu Sep 20 08:04:37 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <46F21E8D.8050606@postgresqlfr.org>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>
	<46F1770C.8010201@ca.afilias.info>
	<Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
	<46F21E8D.8050606@postgresqlfr.org>
Message-ID: <Pine.LNX.4.64.0709200801470.20452@discord.home.frostconsultingllc.com>

On Thu, 20 Sep 2007, St=E9phane Schildknecht wrote:

>> --------
>> CREATE TABLE orders.amazon_items
>> (
>>   id serial NOT NULL,
>>   order_id integer NOT NULL,
>>   item_id integer NOT NULL,
>>   amazon_item_id character varying(14) NOT NULL,
>>   CONSTRAINT amazon_items_pkey PRIMARY KEY (id),
>>   CONSTRAINT amazon_items_order_id_fkey FOREIGN KEY (order_id)
>>       REFERENCES orders.orders (id) MATCH SIMPLE
>>       ON UPDATE NO ACTION ON DELETE NO ACTION,
>>   CONSTRAINT amazon_items_item_id_fkey FOREIGN KEY (item_id)
>>       REFERENCES orders.items (id) MATCH SIMPLE
>>       ON UPDATE NO ACTION ON DELETE NO ACTION
>> )
>> WITH OIDS;
>> ALTER TABLE orders.amazon_items OWNER TO thenerds;
>> --------
>>
>> It was called by the following slonik script:
>>
>> --------
>> #!/usr/bin/slonik
>> include </nerds/preamble.slonik>;
>>
>>         EXECUTE SCRIPT (
>>                 SET ID =3D 1,
>>                 FILENAME =3D '/nerds/thenerds.sql',
>>                 EVENT NODE =3D 1
>>         );
>> --------
>>
>> and caused the following deadlock to occur:
>>
>> 15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR
>> remoteWorkerThread_1: "select "_nerdcluster".ddlScript
>> _complete_int(1, -1); " PGRES_FATAL_ERROR
>> Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
>> Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263 waits for
>> AccessExclusiveLock on relation 121589880 of databas
>> e 121589046; blocked by process 12096.
>> Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for
>> AccessShareLock on relation 121589817 of database 121589046;
>> blocked by process 12263.
>>
>> Which then left the some of the tables on that slave in a bad state
>> breaking replication:
>>
>> 2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select
>> "_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR ERROR:
>> Slony-I: alterTableRestore(): Table "public"."carts" is not in altered
>> state
>> CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore( $1 )"
>> PL/pgSQL function "ddlscript_prepare_int" line 46 at perform
>>
>> Note that it's just an AccessShareLock that's killing us.  Looks like
>> that's caused by a select query which does searches.  Our application
>> does not produce any extraneous locking, it simply does SELECTS on
>> that server.
>>
>> Interestingly, before we started using the slave for queries, we would
>> have the deadlocks happen on the master when doing DDL changes, but
>> this never caused the tables on the master to get into a bad state.
>> You could just re-run your EXECUTE SCRIPT and it would usually work
>> fine the second time.
>>
>> What other info can I provide?
>>
> First, I don't think you have to use the execute script command to
> create a new table.
>
> I'd also like to know if you use pgpool, on slave, master, both ?
>
> Does the re-executing of the script offer any solution ?

You're quite right and I think we'll start just executing the create tables=
 on =

all nodes independently without execute script, but the same problem happen=
s =

with ALTER TABLE as well, this just happened to be the latest example that =

caused a problem.

We are using pgpool in master/slave mode.  So, pgpool is load balancing =

between node 1 and node 2.  Node 3 is not in the pgpool cluster.

Unfortunately, since the first run of the script leaves node 2 in a bad sta=
te =

and breaks replication, running the script again doesn't help.  So far I've =

had to node 2 from replication and re-subscribe to fix the problem.

-- =

Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From stephane.schildknecht at postgresqlfr.org  Thu Sep 20 09:52:49 2007
From: stephane.schildknecht at postgresqlfr.org (=?ISO-8859-1?Q?St=E9phane_Schildknecht?=)
Date: Thu Sep 20 09:53:17 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <Pine.LNX.4.64.0709200801470.20452@discord.home.frostconsultingllc.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>
	<46F1770C.8010201@ca.afilias.info>
	<Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
	<46F21E8D.8050606@postgresqlfr.org>
	<Pine.LNX.4.64.0709200801470.20452@discord.home.frostconsultingllc.com>
Message-ID: <46F2A561.8060500@postgresqlfr.org>

Jeff Frost a ?crit :
> On Thu, 20 Sep 2007, St?phane Schildknecht wrote:
>
>>> --------
>>> CREATE TABLE orders.amazon_items
>>> (
>>>   id serial NOT NULL,
>>>   order_id integer NOT NULL,
>>>   item_id integer NOT NULL,
>>>   amazon_item_id character varying(14) NOT NULL,
>>>   CONSTRAINT amazon_items_pkey PRIMARY KEY (id),
>>>   CONSTRAINT amazon_items_order_id_fkey FOREIGN KEY (order_id)
>>>       REFERENCES orders.orders (id) MATCH SIMPLE
>>>       ON UPDATE NO ACTION ON DELETE NO ACTION,
>>>   CONSTRAINT amazon_items_item_id_fkey FOREIGN KEY (item_id)
>>>       REFERENCES orders.items (id) MATCH SIMPLE
>>>       ON UPDATE NO ACTION ON DELETE NO ACTION
>>> )
>>> WITH OIDS;
>>> ALTER TABLE orders.amazon_items OWNER TO thenerds;
>>> --------
>>>
>>> It was called by the following slonik script:
>>>
>>> --------
>>> #!/usr/bin/slonik
>>> include </nerds/preamble.slonik>;
>>>
>>>         EXECUTE SCRIPT (
>>>                 SET ID = 1,
>>>                 FILENAME = '/nerds/thenerds.sql',
>>>                 EVENT NODE = 1
>>>         );
>>> --------
>>>
>>> and caused the following deadlock to occur:
>>>
>>> 15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR
>>> remoteWorkerThread_1: "select "_nerdcluster".ddlScript
>>> _complete_int(1, -1); " PGRES_FATAL_ERROR
>>> Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
>>> Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263
>>> waits for
>>> AccessExclusiveLock on relation 121589880 of databas
>>> e 121589046; blocked by process 12096.
>>> Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for
>>> AccessShareLock on relation 121589817 of database 121589046;
>>> blocked by process 12263.
>>>
>>> Which then left the some of the tables on that slave in a bad state
>>> breaking replication:
>>>
>>> 2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select
>>> "_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR ERROR:
>>> Slony-I: alterTableRestore(): Table "public"."carts" is not in altered
>>> state
>>> CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore(
>>> $1 )"
>>> PL/pgSQL function "ddlscript_prepare_int" line 46 at perform
>>>
>>> Note that it's just an AccessShareLock that's killing us.  Looks like
>>> that's caused by a select query which does searches.  Our application
>>> does not produce any extraneous locking, it simply does SELECTS on
>>> that server.
>>>
>>> Interestingly, before we started using the slave for queries, we would
>>> have the deadlocks happen on the master when doing DDL changes, but
>>> this never caused the tables on the master to get into a bad state.
>>> You could just re-run your EXECUTE SCRIPT and it would usually work
>>> fine the second time.
>>>
>>> What other info can I provide?
>>>
>> First, I don't think you have to use the execute script command to
>> create a new table.
>>
>> I'd also like to know if you use pgpool, on slave, master, both ?
>>
>> Does the re-executing of the script offer any solution ?
>
> You're quite right and I think we'll start just executing the create
> tables on all nodes independently without execute script, but the same
> problem happens with ALTER TABLE as well, this just happened to be the
> latest example that caused a problem.

I guess no matter what the script contains, using pgpool will break the
replication.
>
> We are using pgpool in master/slave mode.  So, pgpool is load
> balancing between node 1 and node 2.  Node 3 is not in the pgpool
> cluster.
>
> Unfortunately, since the first run of the script leaves node 2 in a
> bad state and breaks replication, running the script again doesn't
> help.  So far I've had to node 2 from replication and re-subscribe to
> fix the problem.
>

So did I.

Cheers,

SAS
From jeff at frostconsultingllc.com  Thu Sep 20 09:56:04 2007
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Thu Sep 20 09:56:25 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <46F2A561.8060500@postgresqlfr.org>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>
	<46F1770C.8010201@ca.afilias.info>
	<Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
	<46F21E8D.8050606@postgresqlfr.org>
	<Pine.LNX.4.64.0709200801470.20452@discord.home.frostconsultingllc.com>
	<46F2A561.8060500@postgresqlfr.org>
Message-ID: <Pine.LNX.4.64.0709200954370.399@glacier.frostconsultingllc.com>

On Thu, 20 Sep 2007, St=E9phane Schildknecht wrote:

>> You're quite right and I think we'll start just executing the create
>> tables on all nodes independently without execute script, but the same
>> problem happens with ALTER TABLE as well, this just happened to be the
>> latest example that caused a problem.
>
> I guess no matter what the script contains, using pgpool will break the
> replication.

Why is that?  I tcpdump'd the pgpool session and did not see any extra lock=
s =

being used.  And to note, the slonik commands do not go through pgpool, the=
se =

go straight to the master.

I thought pgpool was supposed to be slony aware?


-- =

Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From ahodgson at simkin.ca  Thu Sep 20 10:05:59 2007
From: ahodgson at simkin.ca (Alan Hodgson)
Date: Thu Sep 20 10:06:34 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <46F2A561.8060500@postgresqlfr.org>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<Pine.LNX.4.64.0709200801470.20452@discord.home.frostconsultingllc.com>
	<46F2A561.8060500@postgresqlfr.org>
Message-ID: <200709201005.59925@hal.medialogik.com>

On Thursday 20 September 2007, St?phane Schildknecht 
<stephane.schildknecht@postgresqlfr.org> wrote:
> > You're quite right and I think we'll start just executing the create
> > tables on all nodes independently without execute script, but the same
> > problem happens with ALTER TABLE as well, this just happened to be the
> > latest example that caused a problem.

Be aware that if the new table has any sort of foreign key relationship with 
an existing, replicated table, that you will need to use EXECUTE SCRIPT to 
create it.


-- 
`"Gun-wielding recluse gunned down by local police" isn't the epitaph
I want. I am hoping for "Witnesses reported the sound up to two hundred
kilometers away" or "Last body part finally located".' --- James Nicoll

From andrew.george.hammond at gmail.com  Thu Sep 20 14:51:48 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Thu Sep 20 14:52:26 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <Pine.LNX.4.64.0709200801470.20452@discord.home.frostconsultingllc.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>
	<46F1770C.8010201@ca.afilias.info>
	<Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
	<46F21E8D.8050606@postgresqlfr.org>
	<Pine.LNX.4.64.0709200801470.20452@discord.home.frostconsultingllc.com>
Message-ID: <5a0a9d6f0709201451ub730582x67a2f0b83ba1076c@mail.gmail.com>

On 9/20/07, Jeff Frost <jeff@frostconsultingllc.com> wrote:
>
> On Thu, 20 Sep 2007, St=E9phane Schildknecht wrote:
>
> >> --------
> >> CREATE TABLE orders.amazon_items
> >> (
> >>   id serial NOT NULL,
> >>   order_id integer NOT NULL,
> >>   item_id integer NOT NULL,
> >>   amazon_item_id character varying(14) NOT NULL,
> >>   CONSTRAINT amazon_items_pkey PRIMARY KEY (id),
> >>   CONSTRAINT amazon_items_order_id_fkey FOREIGN KEY (order_id)
> >>       REFERENCES orders.orders (id) MATCH SIMPLE
> >>       ON UPDATE NO ACTION ON DELETE NO ACTION,
> >>   CONSTRAINT amazon_items_item_id_fkey FOREIGN KEY (item_id)
> >>       REFERENCES orders.items (id) MATCH SIMPLE
> >>       ON UPDATE NO ACTION ON DELETE NO ACTION
> >> )
> >> WITH OIDS;
> >> ALTER TABLE orders.amazon_items OWNER TO thenerds;
> >> --------
> >>
> >> It was called by the following slonik script:
> >>
> >> --------
> >> #!/usr/bin/slonik
> >> include </nerds/preamble.slonik>;
> >>
> >>         EXECUTE SCRIPT (
> >>                 SET ID =3D 1,
> >>                 FILENAME =3D '/nerds/thenerds.sql',
> >>                 EVENT NODE =3D 1
> >>         );
> >> --------
> >>
> >> and caused the following deadlock to occur:
> >>
> >> 15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR
> >> remoteWorkerThread_1: "select "_nerdcluster".ddlScript
> >> _complete_int(1, -1); " PGRES_FATAL_ERROR
> >> Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
> >> Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263 waits
> for
> >> AccessExclusiveLock on relation 121589880 of databas
> >> e 121589046; blocked by process 12096.
> >> Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for
> >> AccessShareLock on relation 121589817 of database 121589046;
> >> blocked by process 12263.
> >>
> >> Which then left the some of the tables on that slave in a bad state
> >> breaking replication:
> >>
> >> 2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select
> >> "_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR ERROR:
> >> Slony-I: alterTableRestore(): Table "public"."carts" is not in altered
> >> state
> >> CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore( $1
> )"
> >> PL/pgSQL function "ddlscript_prepare_int" line 46 at perform
> >>
> >> Note that it's just an AccessShareLock that's killing us.  Looks like
> >> that's caused by a select query which does searches.  Our application
> >> does not produce any extraneous locking, it simply does SELECTS on
> >> that server.
> >>
> >> Interestingly, before we started using the slave for queries, we would
> >> have the deadlocks happen on the master when doing DDL changes, but
> >> this never caused the tables on the master to get into a bad state.
> >> You could just re-run your EXECUTE SCRIPT and it would usually work
> >> fine the second time.
> >>
> >> What other info can I provide?
> >>
> > First, I don't think you have to use the execute script command to
> > create a new table.
> >
> > I'd also like to know if you use pgpool, on slave, master, both ?
> >
> > Does the re-executing of the script offer any solution ?
>
> You're quite right and I think we'll start just executing the create
> tables on
> all nodes independently without execute script, but the same problem
> happens
> with ALTER TABLE as well, this just happened to be the latest example that
> caused a problem.



He is quite wrong if the tables you're referencing are replicated. If that
is the case then you can create the tables without RI constraints and add
them via ALTER TABLE slonik scripts. I suspect that you already know this
based on your comment about ALTER TABLE problems, but want to make sure it's
clear in the archives.


We are using pgpool in master/slave mode.  So, pgpool is load balancing
> between node 1 and node 2.  Node 3 is not in the pgpool cluster.
>
> Unfortunately, since the first run of the script leaves node 2 in a bad
> state
> and breaks replication, running the script again doesn't help.  So far
> I've
> had to node 2 from replication and re-subscribe to fix the problem.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070920/=
9542a85d/attachment.htm
From andrew.george.hammond at gmail.com  Thu Sep 20 14:58:10 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Thu Sep 20 14:58:48 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <Pine.LNX.4.64.0709200954370.399@glacier.frostconsultingllc.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>
	<46F1770C.8010201@ca.afilias.info>
	<Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
	<46F21E8D.8050606@postgresqlfr.org>
	<Pine.LNX.4.64.0709200801470.20452@discord.home.frostconsultingllc.com>
	<46F2A561.8060500@postgresqlfr.org>
	<Pine.LNX.4.64.0709200954370.399@glacier.frostconsultingllc.com>
Message-ID: <5a0a9d6f0709201458h64c358cbl72f69b337bc7e635@mail.gmail.com>

On 9/20/07, Jeff Frost <jeff@frostconsultingllc.com> wrote:
>
> On Thu, 20 Sep 2007, St=E9phane Schildknecht wrote:
>
> >> You're quite right and I think we'll start just executing the create
> >> tables on all nodes independently without execute script, but the same
> >> problem happens with ALTER TABLE as well, this just happened to be the
> >> latest example that caused a problem.
> >
> > I guess no matter what the script contains, using pgpool will break the
> > replication.
>
> Why is that?  I tcpdump'd the pgpool session and did not see any extra
> locks
> being used.  And to note, the slonik commands do not go through pgpool,
> these
> go straight to the master.
>
> I thought pgpool was supposed to be slony aware?
>

Really? I know that a lot of people, including myself, have _wanted_ a slony
aware pgpool and for quite some time now. I'm not aware of any such code
actually being written. But that's for client software anyway, certainly not
the slons. Why on earth would anyone even _want_ connect a slon through
pgpool?

Andrew
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070920/=
e3883101/attachment.htm
From jeff at frostconsultingllc.com  Thu Sep 20 15:03:50 2007
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Thu Sep 20 15:04:32 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <5a0a9d6f0709201458h64c358cbl72f69b337bc7e635@mail.gmail.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com> 
	<46F1770C.8010201@ca.afilias.info>
	<Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
	<46F21E8D.8050606@postgresqlfr.org>
	<Pine.LNX.4.64.0709200801470.20452@discord.home.frostconsultingllc.com>
	<46F2A561.8060500@postgresqlfr.org>
	<Pine.LNX.4.64.0709200954370.399@glacier.frostconsultingllc.com>
	<5a0a9d6f0709201458h64c358cbl72f69b337bc7e635@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709201500220.399@glacier.frostconsultingllc.com>
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From cscetbon.ext at orange-ftgroup.com  Fri Sep 21 00:41:33 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Fri Sep 21 00:42:28 2007
Subject: [Slony1-general] How far is a receiver from the provider
Message-ID: <46F375AD.3030704@orange-ftgroup.com>

Hi,

What is the best way to see how far is a receiver ?
Until now I used sl_status.st_lag_time but due to the precision it seems 
not really usable.

Thanks.
-- 
Cyril SCETBON
From trinaths at intoto.com  Fri Sep 21 04:16:49 2007
From: trinaths at intoto.com (Trinath Somanchi)
Date: Fri Sep 21 04:17:58 2007
Subject: [Slony1-general] ERROR cannot get sl_local_node_id - ERROR: schema
 "_public" does not exist
Message-ID: <46F3A821.7090700@intoto.com>

Hi all,

I have installed 1.2.11 version of slony-1 with perl scripts enabled .

I have initialized the database . and modified the slony_tools.conf to =

fit my specifications ,

Then I executed  ./perltools/slonik_init_cluster   and  =

./perltools/slonik_store_node --config =

/home/mss_user/masterdb/etc/slon_tools.conf  node1  =


and after thes two executions , I executed ./perltools/slon_start 1

But Slony did not start .

I get the following error :

2007-09-21 16:28:53 IST CONFIG main: slon version 1.2.11 starting up
2007-09-21 16:28:53 IST DEBUG2 slon: watchdog process started
2007-09-21 16:28:53 IST DEBUG2 slon: watchdog ready - pid =3D 25083
2007-09-21 16:28:53 IST DEBUG2 slon: worker process created - pid =3D 25122
2007-09-21 16:28:53 IST ERROR  cannot get sl_local_node_id - ERROR:  =

schema "_public" does not exist
2007-09-21 16:28:53 IST FATAL  main: Node is not initialized properly - =

sleep 10s


How can I troubleshoot this error . I have searched google for the same =

,, in some of the forms they said to execute "slonik_init_cluster " and =

"slonik_store_node" and then star the slon ..

I have done the same as described the google searched form but then also =

, I get the same error .

Please help me in this regard,

Thanks in advance,

Best Regards,
-- =

Trinath Somanchi.


***************************************************************************=
*****
This email message (including any attachments) is for the sole use of the i=
ntended recipient(s) =

and may contain confidential, proprietary and privileged information. Any u=
nauthorized review, =

use, disclosure or distribution is prohibited. If you are not the intended =
recipient, =

please immediately notify the sender by reply email and destroy all copies =
of the original message. =

Thank you.
 =

Intoto Inc. =


-------------- next part --------------
A non-text attachment was scrubbed...
Name: trinaths.vcf
Type: text/x-vcard
Size: 316 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20070921=
/fdb2638e/trinaths.vcf
From jeff at frostconsultingllc.com  Fri Sep 21 08:37:33 2007
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Fri Sep 21 08:37:42 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>
	<46F1770C.8010201@ca.afilias.info>
	<Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
Message-ID: <Pine.LNX.4.64.0709210836140.20452@discord.home.frostconsultingllc.com>

On Wed, 19 Sep 2007, Jeff Frost wrote:

> On Wed, 19 Sep 2007, Christopher Browne wrote:
>
>>> Bails out is the wrong description. Clobbered by the pgsql deadlock 
>>> detection system, leaving the cluster in an unstable state would be more 
>>> accurate, if that's what happened. I don't know that there's a way to 
>>> catch that clobberage and run a "finally" type thing.
>> The thing is, that's not what happens.
>> 
>> Unless there's a COMMIT somewhere in the DDL script, in which case all bets 
>> are off, everywhere, the deadlock should lead to one of two things 
>> happening:
>> 
>> 1. The other process that was holding onto the tables might fail and roll 
>> back, and the DDL script would complete, or
>> 
>> 2.  The DDL script will fail and roll back, leading to the state of the 
>> tables falling back to what it was before DDL script processing began.
>> 
>> In either case, the results should leave the node in a consistent state, 
>> either:
>> a) With the DDL request having gone in, or
>> b) With the DDL request *not* having gone in.
>> 
>> Unless there's an extra COMMIT in the code (and I just looked at the code, 
>> and Did Not See One), the failure resulting from a deadlock should be 
>> benign, restoring the tables to the "previously altered state."
>>>
>>>     So, is there a reasonable way to fix this without
>>>     droppping/resubscribing the
>>>     node?
>>> 
>>> 
>>> Well, to start with, you might want to figure out why your application is 
>>> taking such aggressive locks. And make sure in the future that it doesn't 
>>> happen again (not much point fixing it if it's just gonna re-occur). If 
>>> you are using a separate superuser account to connect to your database and 
>>> run your slons (generally the "slony" user) then this is really easy to 
>>> do: tweak your pg_hba to only allow connections from slony and then kick 
>>> all active non-slony connections. Revert your pg_hba at the end of the 
>>> maintenance.
>>> 
>>> If you're willing to experiment with using slony internal functions, you 
>>> could put the table in question into altered state. Something like this on 
>>> the offending node might work.
>>> 
>>> SELECT alterTableForReplication((SELECT tab_id FROM sl_table WHERE 
>>> tab_reloid = (SELECT oid FROM pg_class WHERE relname='cart')));
>>> 
>>> Or of course it might mess things up even more. :)
>> The one change to suggest that comes to *my* mind is that we perhaps ought 
>> to change Slony-I to aggressively lock the replicated tables ASAP at the 
>> start of the DDL script event.
>> 
>> That will either immediately succeed, and eliminate any possibility of 
>> future deadlock, or immediately fail, before we even try to alter anything.
>> 
>> This same change was made to the SUBSCRIBE SET process (well, "COPY_SET", 
>> strictly speaking, but that's not at all user visible...), as we saw cases 
>> where gradually escalating locks on tables led to deadlocks that could 
>> waste hours worth of subscription work.
>> 
>> But it seems likely to me that there's more to the problem than we're 
>> hearing, because deadlock shouldn't cause any corruption of anything - to 
>> the contrary, it may be expected to prevent it.
>
> this is the latest SQL that caused the problem (note there is not a COMMIT in 
> the sql):
>
> --------
> CREATE TABLE orders.amazon_items
> (
>  id serial NOT NULL,
>  order_id integer NOT NULL,
>  item_id integer NOT NULL,
>  amazon_item_id character varying(14) NOT NULL,
>  CONSTRAINT amazon_items_pkey PRIMARY KEY (id),
>  CONSTRAINT amazon_items_order_id_fkey FOREIGN KEY (order_id)
>      REFERENCES orders.orders (id) MATCH SIMPLE
>      ON UPDATE NO ACTION ON DELETE NO ACTION,
>  CONSTRAINT amazon_items_item_id_fkey FOREIGN KEY (item_id)
>      REFERENCES orders.items (id) MATCH SIMPLE
>      ON UPDATE NO ACTION ON DELETE NO ACTION
> )
> WITH OIDS;
> ALTER TABLE orders.amazon_items OWNER TO thenerds;
> --------
>
> It was called by the following slonik script:
>
> --------
> #!/usr/bin/slonik
> include </nerds/preamble.slonik>;
>
>        EXECUTE SCRIPT (
>                SET ID = 1,
>                FILENAME = '/nerds/thenerds.sql',
>                EVENT NODE = 1
>        );
> --------
>
> and caused the following deadlock to occur:
>
> 15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR
> remoteWorkerThread_1: "select "_nerdcluster".ddlScript
> _complete_int(1, -1); " PGRES_FATAL_ERROR
> Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
> Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263 waits for
> AccessExclusiveLock on relation 121589880 of databas
> e 121589046; blocked by process 12096.
> Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for
> AccessShareLock on relation 121589817 of database 121589046;
> blocked by process 12263.
>
> Which then left the some of the tables on that slave in a bad state breaking 
> replication:
>
> 2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select
> "_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR ERROR:
> Slony-I: alterTableRestore(): Table "public"."carts" is not in altered state
> CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore( $1 )"
> PL/pgSQL function "ddlscript_prepare_int" line 46 at perform
>
> Note that it's just an AccessShareLock that's killing us.  Looks like that's 
> caused by a select query which does searches.  Our application does not 
> produce any extraneous locking, it simply does SELECTS on that server.
>
> Interestingly, before we started using the slave for queries, we would have 
> the deadlocks happen on the master when doing DDL changes, but this never 
> caused the tables on the master to get into a bad state.  You could just 
> re-run your EXECUTE SCRIPT and it would usually work fine the second time.
>
> What other info can I provide?

So, what I'm getting from all this is that while the deadlocks can occur, 
slony should gracefully error out and return the tables to their previously 
altered state, but that doesn't seem to happen on these nodes.  Note that it's 
only a problem when there's a deadlock on the slave, not on the master. 
Should I file this as a bug?  If so, do I just need to send an email to 
slony1-bugs?

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From andrew.george.hammond at gmail.com  Fri Sep 21 10:41:53 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Fri Sep 21 10:42:01 2007
Subject: [Slony1-general] How far is a receiver from the provider
In-Reply-To: <46F375AD.3030704@orange-ftgroup.com>
References: <46F375AD.3030704@orange-ftgroup.com>
Message-ID: <5a0a9d6f0709211041k3d22d92ey6a09934f5c20e7cd@mail.gmail.com>

If it's "not really usable", then you're probably trying to get slony to do
something that it can not reasonably be expected to do. This conversation
has already been had on this mailing list. Please search the archives for
"lag" and "asynchronous". You should find plenty of discussion. I believe
the most recent was only about a month ago.

Andrew


On 9/21/07, Cyril SCETBON <cscetbon.ext@orange-ftgroup.com> wrote:
>
> Hi,
>
> What is the best way to see how far is a receiver ?
> Until now I used sl_status.st_lag_time but due to the precision it seems
> not really usable.
>
> Thanks.
> --
> Cyril SCETBON
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070921/=
5df68cb9/attachment.htm
From david at fetter.org  Fri Sep 21 11:50:41 2007
From: david at fetter.org (David Fetter)
Date: Fri Sep 21 11:50:50 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is everyone
	on the replica-hooks-discuss mailing list?
In-Reply-To: <e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>
	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>
Message-ID: <20070921185040.GF17506@fetter.org>

On Fri, Sep 21, 2007 at 09:44:59PM +0300, Marko Kreen wrote:
> On 9/20/07, Decibel! <decibel@decibel.org> wrote:
> > Seeing the complete duplication of txid.sql between Slony and
> > londiste bugs me, so I'm hoping we can come up with a replacement
> > for that in core, and the replica-hooks list seems the logical way
> > to discuss that...
> 
> You forgot to give link to list:
> 
>  http://pgfoundry.org/mailman/listinfo/replica-hooks-discuss
> 
> 
> Compared of to rest of replica-hooks discussion, this is pretty
> straightforward affair, not much to discuss here.
> 
> Only question is - Are Slony-I devs interested in common module?
> And do they want some changes in it?

What say we ask the rest of the Slony-I people, whom I'm CC'ing here :)

Cheers,
D
> Actually, I planned to submit the module to 8.4 contrib, and we can
> have the discussion then.  But if you could review it beforehand, it
> would be even better as I can then do the changes before submitting.
> Please look at the CVS/2.1.5-rc1 version, there are several cleanups
> done compared to 2.1.4.

> 
> -- 
> marko
> _______________________________________________
> Skytools-users mailing list
> Skytools-users@pgfoundry.org
> http://pgfoundry.org/mailman/listinfo/skytools-users

-- 
David Fetter <david@fetter.org> http://fetter.org/
phone: +1 415 235 3778        AIM: dfetter666
                              Skype: davidfetter

Remember to vote!
Consider donating to PostgreSQL: http://www.postgresql.org/about/donate
From dant at cdkkt.com  Fri Sep 21 12:25:50 2007
From: dant at cdkkt.com (Daniel B. Thurman)
Date: Fri Sep 21 12:25:58 2007
Subject: [Slony1-general] Problems connecting via slon service
Message-ID: <021126B987E43D44A860139823C079110E2B74@orion.cdkkt.com>


I am having problems trying to get the slon service to run with password:

On the Master Server, the service startup message I received shows:
CONFIG storePath: pa_server=2 pa_client=1 pa_conninfo="host=raider.cdkkt.com dbname=MyTest user=postgres" pa_connretry=10

And what is missing is, the password=*** entry.  I thought the connection info was to be taken from the slon configuration file,

On the Master server, The error message I have received is:
ERROR  slon_connectdb: PQconnectdb("host=raider.cdkkt.com dbname=MyTest user=postgres") failed - fe_sendauth: no password supplied

But my slon configuration file for the master server shows:
# Set the cluster name that this instance of slon is running against
# default is to read it off the command line
cluster_name='MasterCluster'

# Set slon's connection info, default is to read it off the command line
conn_info='host=copper.cdkkt.com port=5432 dbname=MyTest user=postgres password=***'

========================
On the Slave Server, the service startup message I received shows:
CONFIG storePath: pa_server=2 pa_client=1 pa_conninfo="host=copper.cdkkt.com dbname=MyTest user=postgres" pa_connretry=10

And what is missing is, the password=*** entry.  I thought the connection info was to be taken from the slon configuration file,

On the Slave server, The error message I have received is:
ERROR  slon_connectdb: PQconnectdb("host=copper.cdkkt.com dbname=MyTest user=postgres") failed - fe_sendauth: no password supplied

But my slon configuration file for the slave server shows:
# Set the cluster name that this instance of slon is running against
# default is to read it off the command line
cluster_name='MasterCluster'

# Set slon's connection info, default is to read it off the command line
conn_info='host=raider.cdkkt.com port=5432 dbname=MyTest user=postgres password=***'

So what do I need to do to repair this?

Thanks!
Dan

No virus found in this outgoing message.
Checked by AVG Free Edition. 
Version: 7.5.487 / Virus Database: 269.13.27/1020 - Release Date: 9/20/2007 12:07 PM
 
From dant at cdkkt.com  Fri Sep 21 13:15:07 2007
From: dant at cdkkt.com (Daniel B. Thurman)
Date: Fri Sep 21 13:15:16 2007
Subject: [Slony1-general] Problems with replication
Message-ID: <021126B987E43D44A860139823C079110E2B75@orion.cdkkt.com>


On the master server, I have an error reported:
ERROR  remoteWorkerThread_2: "select "_MasterCluster".setAddTable_int(1, 1, '"public"."cars"', 'cars_pkey', ''); " PGRES_FATAL_ERROR ERROR:  Slony-I: setAddTable_int: table id 1 has already been assigned!

On the slave server, I have an error reported:
ERROR  remoteWorkerThread_1: "select "_MasterCluster".setAddTable_int(1, 1, '"public"."cars"', 'cars_pkey', ''); " PGRES_FATAL_ERROR ERROR:  Slony-I: setAddTable_int: table id 1 has already been assigned!

What does this mean, and what do I need to do to fix this?

Thanks!
Dan

No virus found in this outgoing message.
Checked by AVG Free Edition. 
Version: 7.5.487 / Virus Database: 269.13.27/1020 - Release Date: 9/20/2007 12:07 PM
 
From dant at cdkkt.com  Fri Sep 21 13:17:37 2007
From: dant at cdkkt.com (Daniel B. Thurman)
Date: Fri Sep 21 13:17:46 2007
Subject: [Slony1-general] [SOLVED] Problems connecting via slon service
Message-ID: <021126B987E43D44A860139823C079110E2B76@orion.cdkkt.com>

>I am having problems trying to get the slon service to run 
>with password:
>
>On the Master Server, the service startup message I received shows:
>CONFIG storePath: pa_server=2 pa_client=1 
>pa_conninfo="host=raider.cdkkt.com dbname=MyTest 
>user=postgres" pa_connretry=10
>
>And what is missing is, the password=*** entry.  I thought the 
>connection info was to be taken from the slon configuration file,
>
>On the Master server, The error message I have received is:
>ERROR  slon_connectdb: PQconnectdb("host=raider.cdkkt.com 
>dbname=MyTest user=postgres") failed - fe_sendauth: no 
>password supplied
>
>But my slon configuration file for the master server shows:
># Set the cluster name that this instance of slon is running against
># default is to read it off the command line
>cluster_name='MasterCluster'
>
># Set slon's connection info, default is to read it off the 
>command line
>conn_info='host=copper.cdkkt.com port=5432 dbname=MyTest 
>user=postgres password=***'
>
>========================
>On the Slave Server, the service startup message I received shows:
>CONFIG storePath: pa_server=2 pa_client=1 
>pa_conninfo="host=copper.cdkkt.com dbname=MyTest 
>user=postgres" pa_connretry=10
>
>And what is missing is, the password=*** entry.  I thought the 
>connection info was to be taken from the slon configuration file,
>
>On the Slave server, The error message I have received is:
>ERROR  slon_connectdb: PQconnectdb("host=copper.cdkkt.com 
>dbname=MyTest user=postgres") failed - fe_sendauth: no 
>password supplied
>
>But my slon configuration file for the slave server shows:
># Set the cluster name that this instance of slon is running against
># default is to read it off the command line
>cluster_name='MasterCluster'
>
># Set slon's connection info, default is to read it off the 
>command line
>conn_info='host=raider.cdkkt.com port=5432 dbname=MyTest 
>user=postgres password=***'
>
>So what do I need to do to repair this?
>
>Thanks!
>Dan
>

Ok, I figured this out already.  I updated the _Cluster.sl_path table with
the correct connect strings and all is good for this problem.

Dan

No virus found in this outgoing message.
Checked by AVG Free Edition. 
Version: 7.5.487 / Virus Database: 269.13.27/1020 - Release Date: 9/20/2007 12:07 PM
 
From cbbrowne at ca.afilias.info  Fri Sep 21 15:14:21 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Fri Sep 21 15:14:32 2007
Subject: [Slony1-general] More Tests for NG testbed
Message-ID: <60tzpnzmwy.fsf@dba2.int.libertyrms.com>

I have been drawing some of the tests not frequently getting run from
the "ducttape" area and generating tests that can be easily run in
automated fashion in the /tests/ area.  They've been getting mouldy;
by having them on the "automatic" list, that should make it *way*
easier to keep the issues monitored.

Next week, I plan to add in:
 - Torture testing MERGE SET (which has been problematic at times)
 - A subtransaction test
 - Duplicating test #6 (with 6 nodes)
 - Some usage of pgbench

Can anyone suggest any notable patterns I should see about adding?
-- 
let name="cbbrowne" and tld="acm.org" in String.concat "@" [name;tld];;
http://www3.sympatico.ca/cbbrowne/advocacy.html
"What did we agree about a leader??"
"We agreed we wouldn't have one."
"Good.  Now shut up and do as I say..."
From decibel at decibel.org  Fri Sep 21 15:40:01 2007
From: decibel at decibel.org (Decibel!)
Date: Fri Sep 21 15:40:19 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is everyone
	on the replica-hooks-discuss mailing list?
In-Reply-To: <20070921185040.GF17506@fetter.org>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>
	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>
	<20070921185040.GF17506@fetter.org>
Message-ID: <20070921224001.GB95343@decibel.org>

On Fri, Sep 21, 2007 at 11:50:41AM -0700, David Fetter wrote:
> On Fri, Sep 21, 2007 at 09:44:59PM +0300, Marko Kreen wrote:
> > On 9/20/07, Decibel! <decibel@decibel.org> wrote:
> > > Seeing the complete duplication of txid.sql between Slony and
> > > londiste bugs me, so I'm hoping we can come up with a replacement
> > > for that in core, and the replica-hooks list seems the logical way
> > > to discuss that...
> > 
> > You forgot to give link to list:
> > 
> >  http://pgfoundry.org/mailman/listinfo/replica-hooks-discuss
> > 
> > 
> > Compared of to rest of replica-hooks discussion, this is pretty
> > straightforward affair, not much to discuss here.

Actually, what I'm really wondering is if a "commit ID" analogous to a
transaction ID but set at commit time (and in order of commits) would
vastly simplify things...

> > Only question is - Are Slony-I devs interested in common module?
> > And do they want some changes in it?
> 
> What say we ask the rest of the Slony-I people, whom I'm CC'ing here :)

We want to have the discussion across 3 lists? :)
-- 
Decibel!, aka Jim C. Nasby, Database Architect  decibel@decibel.org 
Give your computer some brain candy! www.distributed.net Team #1828
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 187 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20070921/35e8343f/attachment.pgp
From david at fetter.org  Fri Sep 21 16:05:59 2007
From: david at fetter.org (David Fetter)
Date: Fri Sep 21 16:06:11 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is everyone
	on the replica-hooks-discuss mailing list?
In-Reply-To: <20070921224001.GB95343@decibel.org>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>
	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>
	<20070921185040.GF17506@fetter.org>
	<20070921224001.GB95343@decibel.org>
Message-ID: <20070921230559.GI17506@fetter.org>

On Fri, Sep 21, 2007 at 05:40:01PM -0500, Decibel! wrote:
> On Fri, Sep 21, 2007 at 11:50:41AM -0700, David Fetter wrote:
> > On Fri, Sep 21, 2007 at 09:44:59PM +0300, Marko Kreen wrote:
> > > On 9/20/07, Decibel! <decibel@decibel.org> wrote:
> > > > Seeing the complete duplication of txid.sql between Slony and
> > > > londiste bugs me, so I'm hoping we can come up with a replacement
> > > > for that in core, and the replica-hooks list seems the logical way
> > > > to discuss that...
> > > 
> > > You forgot to give link to list:
> > > 
> > >  http://pgfoundry.org/mailman/listinfo/replica-hooks-discuss
> > > 
> > > 
> > > Compared of to rest of replica-hooks discussion, this is pretty
> > > straightforward affair, not much to discuss here.
> 
> Actually, what I'm really wondering is if a "commit ID" analogous to a
> transaction ID but set at commit time (and in order of commits) would
> vastly simplify things...
> 
> > > Only question is - Are Slony-I devs interested in common module?
> > > And do they want some changes in it?
> > 
> > What say we ask the rest of the Slony-I people, whom I'm CC'ing here :)
> 
> We want to have the discussion across 3 lists? :)

Better all at once now than a giant mess later :)

Cheers,
D
-- 
David Fetter <david@fetter.org> http://fetter.org/
phone: +1 415 235 3778        AIM: dfetter666
                              Skype: davidfetter

Remember to vote!
Consider donating to PostgreSQL: http://www.postgresql.org/about/donate
From decibel at decibel.org  Fri Sep 21 16:08:03 2007
From: decibel at decibel.org (Decibel!)
Date: Fri Sep 21 16:08:21 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is everyone
	on the replica-hooks-discuss mailing list?
In-Reply-To: <20070921230559.GI17506@fetter.org>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>
	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>
	<20070921185040.GF17506@fetter.org>
	<20070921224001.GB95343@decibel.org>
	<20070921230559.GI17506@fetter.org>
Message-ID: <20070921230803.GC95343@decibel.org>

On Fri, Sep 21, 2007 at 04:05:59PM -0700, David Fetter wrote:
> On Fri, Sep 21, 2007 at 05:40:01PM -0500, Decibel! wrote:
> > On Fri, Sep 21, 2007 at 11:50:41AM -0700, David Fetter wrote:
> > > On Fri, Sep 21, 2007 at 09:44:59PM +0300, Marko Kreen wrote:
> > > > On 9/20/07, Decibel! <decibel@decibel.org> wrote:
> > > > > Seeing the complete duplication of txid.sql between Slony and
> > > > > londiste bugs me, so I'm hoping we can come up with a replacement
> > > > > for that in core, and the replica-hooks list seems the logical way
> > > > > to discuss that...
> > > > 
> > > > You forgot to give link to list:
> > > > 
> > > >  http://pgfoundry.org/mailman/listinfo/replica-hooks-discuss
> > > > 
> > > > 
> > > > Compared of to rest of replica-hooks discussion, this is pretty
> > > > straightforward affair, not much to discuss here.
> > 
> > Actually, what I'm really wondering is if a "commit ID" analogous to a
> > transaction ID but set at commit time (and in order of commits) would
> > vastly simplify things...
> > 
> > > > Only question is - Are Slony-I devs interested in common module?
> > > > And do they want some changes in it?
> > > 
> > > What say we ask the rest of the Slony-I people, whom I'm CC'ing here :)
> > 
> > We want to have the discussion across 3 lists? :)
> 
> Better all at once now than a giant mess later :)

Well, I figured it'd be better to discuss it on replica-hooks, but if
people'd rather crosspost to 3 lists I'm fine with that...
-- 
Decibel!, aka Jim C. Nasby, Database Architect  decibel@decibel.org 
Give your computer some brain candy! www.distributed.net Team #1828
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 187 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20070921/0f8f2845/attachment.pgp
From dant at cdkkt.com  Fri Sep 21 16:25:55 2007
From: dant at cdkkt.com (Daniel B. Thurman)
Date: Fri Sep 21 16:26:06 2007
Subject: [Slony1-general] Slony reported error..
Message-ID: <021126B987E43D44A860139823C079110E2B78@orion.cdkkt.com>


Slony Log reported an error on the Master server:
ERROR  remoteWorkerThread_2: sl_setsync entry for set 1 not found on provider

What does this mean?

Thanks!
Dan

No virus found in this outgoing message.
Checked by AVG Free Edition. 
Version: 7.5.487 / Virus Database: 269.13.27/1020 - Release Date: 9/20/2007 12:07 PM
 
From mpartio at gmail.com  Fri Sep 21 23:09:14 2007
From: mpartio at gmail.com (Mikko Partio)
Date: Fri Sep 21 23:09:31 2007
Subject: [Slony1-general] Problems with replication
In-Reply-To: <021126B987E43D44A860139823C079110E2B75@orion.cdkkt.com>
References: <021126B987E43D44A860139823C079110E2B75@orion.cdkkt.com>
Message-ID: <2ca799770709212309k37cb1480m99afe080006deef3@mail.gmail.com>

On 9/21/07, Daniel B. Thurman <dant@cdkkt.com> wrote:
>
>
> On the master server, I have an error reported:
> ERROR  remoteWorkerThread_2: "select "_MasterCluster".setAddTable_int(1,
> 1, '"public"."cars"', 'cars_pkey', ''); " PGRES_FATAL_ERROR ERROR:  Slony=
-I:
> setAddTable_int: table id 1 has already been assigned!
>
> On the slave server, I have an error reported:
> ERROR  remoteWorkerThread_1: "select "_MasterCluster".setAddTable_int(1,
> 1, '"public"."cars"', 'cars_pkey', ''); " PGRES_FATAL_ERROR ERROR:  Slony=
-I:
> setAddTable_int: table id 1 has already been assigned!
>
> What does this mean, and what do I need to do to fix this?
>
> Thanks!
> Dan


Well I'd decipher this mystical error report so that you already have a
table in replication with id 1 and now you're trying to add another one with
the same id and obviously that won't work. Table id's have to unique in a
replication cluster (if I remember correctly), so just use id=3D2 for examp=
le.

Regards

MP
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070922/=
bf8b7e59/attachment-0001.htm
From markokr at gmail.com  Sat Sep 22 00:07:54 2007
From: markokr at gmail.com (Marko Kreen)
Date: Sat Sep 22 00:08:14 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is everyone
	on the replica-hooks-discuss mailing list?
In-Reply-To: <20070921230803.GC95343@decibel.org>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>
	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>
	<20070921185040.GF17506@fetter.org>
	<20070921224001.GB95343@decibel.org>
	<20070921230559.GI17506@fetter.org>
	<20070921230803.GC95343@decibel.org>
Message-ID: <e51f66da0709220007g7f817525pf840064132f54581@mail.gmail.com>

On 9/22/07, Decibel! <decibel@decibel.org> wrote:
> Well, I figured it'd be better to discuss it on replica-hooks, but if
> people'd rather crosspost to 3 lists I'm fine with that...

I'm already discussing it in slony-hackers, and I think the discussion
belongs to there rather than replica-hooks as it is pretty concrete
near-term affair that mostly affects slony and nobody else as other
replication solutions use other event transport mechanisms.

But thanks for bringing the topic up!

-- 
marko
From trinaths at intoto.com  Sat Sep 22 04:45:05 2007
From: trinaths at intoto.com (Trinath Somanchi)
Date: Sat Sep 22 04:45:29 2007
Subject: [Slony1-general] ERROR cannot get sl_local_node_id - ERROR: schema
 "_public" does not exist
Message-ID: <58973.117.97.48.235.1190461505.squirrel@mail.intoto.com>

Hi all,

I have installed 1.2.11 version of slony-1 with perl scripts enabled .

I have initialized the database . and modified the slony_tools.conf to =

fit my specifications ,

Then I executed  ./perltools/slonik_init_cluster   and
/perltools/slonik_store_node --config =

/home/mss_user/masterdb/etc/slon_tools.conf  node1  =


and after these two executions , I executed ./perltools/slon_start 1

But Slony did not start .

I get the following error :

2007-09-21 16:28:53 IST CONFIG main: slon version 1.2.11 starting up
2007-09-21 16:28:53 IST DEBUG2 slon: watchdog process started
2007-09-21 16:28:53 IST DEBUG2 slon: watchdog ready - pid =3D 25083
2007-09-21 16:28:53 IST DEBUG2 slon: worker process created - pid =3D 25122
2007-09-21 16:28:53 IST ERROR  cannot get sl_local_node_id - ERROR:  =

schema "_public" does not exist
2007-09-21 16:28:53 IST FATAL  main: Node is not initialized properly - =

sleep 10s


How can I troubleshoot this error . I have searched google for the same =

,, in some of the forms they said to execute "slonik_init_cluster " and =

"slonik_store_node" and then start the slon ..

I have done the same as described in the google search , but =

, I get the same error .

Please help me in this regard,

Thanks in advance,

Best Regards,
-- =

Trinath Somanchi.



********************************************************************************
This email message (including any attachments) is for the sole use of the intended recipient(s) 
and may contain confidential, proprietary and privileged information. Any unauthorized review, 
use, disclosure or distribution is prohibited. If you are not the intended recipient, 
please immediately notify the sender by reply email and destroy all copies of the original message. 
Thank you.
 
Intoto Inc. 

From dant at cdkkt.com  Sat Sep 22 05:39:21 2007
From: dant at cdkkt.com (Daniel B. Thurman)
Date: Sat Sep 22 05:39:24 2007
Subject: [Slony1-general] Problems with replication
Message-ID: <021126B987E43D44A860139823C079110E2B7B@orion.cdkkt.com>

Ah!, thanks,  that was the problem.  I was not using unique ids.

-----Original Message-----
From: Mikko Partio [mailto:mpartio@gmail.com]
Sent: Friday, September 21, 2007 11:09 PM
To: Daniel B. Thurman
Cc: Slony-I (E-mail)
Subject: Re: [Slony1-general] Problems with replication




On 9/21/07, Daniel B. Thurman < HYPERLINK "mailto:dant@cdkkt.com"dant@cdkkt=
.com> wrote: =



On the master server, I have an error reported:
ERROR  remoteWorkerThread_2: "select "_MasterCluster".setAddTable_int(1, 1,=
 '"public"."cars"', 'cars_pkey', ''); " PGRES_FATAL_ERROR ERROR:  Slony-I: =
setAddTable_int: table id 1 has already been assigned! =


On the slave server, I have an error reported:
ERROR  remoteWorkerThread_1: "select "_MasterCluster".setAddTable_int(1, 1,=
 '"public"."cars"', 'cars_pkey', ''); " PGRES_FATAL_ERROR ERROR:  Slony-I: =
setAddTable_int: table id 1 has already been assigned! =


What does this mean, and what do I need to do to fix this?

Thanks!
Dan


Well I'd decipher this mystical error report so that you already have a tab=
le in replication with id 1 and now you're trying to add another one with t=
he same id and obviously that won't work. Table id's have to unique in a re=
plication cluster (if I remember correctly), so just use id=3D2 for example=
. =


Regards

MP =






No virus found in this incoming message.
Checked by AVG Free Edition.
Version: 7.5.487 / Virus Database: 269.13.27/1020 - Release Date: 9/20/2007=
 12:07 PM



No virus found in this outgoing message.
Checked by AVG Free Edition. =

Version: 7.5.487 / Virus Database: 269.13.27/1020 - Release Date: 9/20/2007=
 12:07 PM
 =

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070922/=
86b3ffa3/attachment.htm
From cbbrowne at ca.afilias.info  Sun Sep 23 21:01:22 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Sun Sep 23 21:01:43 2007
Subject: [Slony1-general] ERROR cannot get sl_local_node_id - ERROR:
	schema "_public" does not exist
In-Reply-To: <58973.117.97.48.235.1190461505.squirrel@mail.intoto.com>
	(Trinath Somanchi's message of "Sat,
	22 Sep 2007 17:15:05 +0530 (IST)")
References: <58973.117.97.48.235.1190461505.squirrel@mail.intoto.com>
Message-ID: <60r6koogod.fsf@dba2.int.libertyrms.com>

"Trinath Somanchi" <trinaths@intoto.com> writes:
> I have installed 1.2.11 version of slony-1 with perl scripts enabled .
>
> I have initialized the database . and modified the slony_tools.conf to =
>
> fit my specifications ,
>
> Then I executed  ./perltools/slonik_init_cluster   and
> /perltools/slonik_store_node --config =
>
> /home/mss_user/masterdb/etc/slon_tools.conf  node1  =
>
>
> and after these two executions , I executed ./perltools/slon_start 1
>
> But Slony did not start .
>
> I get the following error :
>
> 2007-09-21 16:28:53 IST CONFIG main: slon version 1.2.11 starting up
> 2007-09-21 16:28:53 IST DEBUG2 slon: watchdog process started
> 2007-09-21 16:28:53 IST DEBUG2 slon: watchdog ready - pid =3D 25083
> 2007-09-21 16:28:53 IST DEBUG2 slon: worker process created - pid =3D 25122
> 2007-09-21 16:28:53 IST ERROR  cannot get sl_local_node_id - ERROR:  =
>
> schema "_public" does not exist
> 2007-09-21 16:28:53 IST FATAL  main: Node is not initialized properly - =
>
> sleep 10s
>
>
> How can I troubleshoot this error . I have searched google for the same =
>
> ,, in some of the forms they said to execute "slonik_init_cluster " and =
>
> "slonik_store_node" and then start the slon ..
>
> I have done the same as described in the google search , but =
>
> , I get the same error .

Well, it appears that that one or the other of the nodes did not get
initialized.  And as long as that is the case, none of the things that
depend on the node being properly initialized will work.

Usually, it's a useful sort of thing to simplify things until you can
identify exactly which step didn't work.

The simplest thing would be to run minimal slonik scripts to perform
the actions, step by step, and see when one of those scripts fails,
which presumably some step did.  At that point, the error messages
ought to give some clue as to what failure caused your problem, and
perhaps clues as to how to fix it...
-- 
let name="cbbrowne" and tld="cbbrowne.com" in name ^ "@" ^ tld;;
http://cbbrowne.com/info/linuxxian.html
If you add a couple of i's to Microsoft's stock ticker symbol, you get
'misfit'.  This is, of course, not a coincidence.
From stephane.schildknecht at postgresqlfr.org  Sun Sep 23 23:31:12 2007
From: stephane.schildknecht at postgresqlfr.org (=?ISO-8859-1?Q?St=E9phane_Schildknecht?=)
Date: Sun Sep 23 23:31:40 2007
Subject: [Slony1-general] Problems connecting via slon service
In-Reply-To: <021126B987E43D44A860139823C079110E2B74@orion.cdkkt.com>
References: <021126B987E43D44A860139823C079110E2B74@orion.cdkkt.com>
Message-ID: <46F759B0.1000408@postgresqlfr.org>

Daniel B. Thurman a ?crit :
> I am having problems trying to get the slon service to run with password:
>
> On the Master Server, the service startup message I received shows:
> CONFIG storePath: pa_server=2 pa_client=1 pa_conninfo="host=raider.cdkkt.com dbname=MyTest user=postgres" pa_connretry=10
>
> And what is missing is, the password=*** entry.  I thought the connection info was to be taken from the slon configuration file,
>
> On the Master server, The error message I have received is:
> ERROR  slon_connectdb: PQconnectdb("host=raider.cdkkt.com dbname=MyTest user=postgres") failed - fe_sendauth: no password supplied
>
> But my slon configuration file for the master server shows:
> # Set the cluster name that this instance of slon is running against
> # default is to read it off the command line
> cluster_name='MasterCluster'
>
> # Set slon's connection info, default is to read it off the command line
> conn_info='host=copper.cdkkt.com port=5432 dbname=MyTest user=postgres password=***'
>
> ========================
> On the Slave Server, the service startup message I received shows:
> CONFIG storePath: pa_server=2 pa_client=1 pa_conninfo="host=copper.cdkkt.com dbname=MyTest user=postgres" pa_connretry=10
>
> And what is missing is, the password=*** entry.  I thought the connection info was to be taken from the slon configuration file,
>
> On the Slave server, The error message I have received is:
> ERROR  slon_connectdb: PQconnectdb("host=copper.cdkkt.com dbname=MyTest user=postgres") failed - fe_sendauth: no password supplied
>
> But my slon configuration file for the slave server shows:
> # Set the cluster name that this instance of slon is running against
> # default is to read it off the command line
> cluster_name='MasterCluster'
>
> # Set slon's connection info, default is to read it off the command line
> conn_info='host=raider.cdkkt.com port=5432 dbname=MyTest user=postgres password=***'
>
> So what do I need to do to repair this?
>
> Thanks!
> Dan
>
>   
Hi,

It seems to me there's a mess between master and slave, either in
configuration file or on the command line.

Could you tell us how you launched the slon daemons ?

Regards,
SAS
From cscetbon.ext at orange-ftgroup.com  Mon Sep 24 08:06:46 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Mon Sep 24 08:06:54 2007
Subject: [Slony1-general] How far is a receiver from the provider
In-Reply-To: <5a0a9d6f0709211041k3d22d92ey6a09934f5c20e7cd@mail.gmail.com>
References: <46F375AD.3030704@orange-ftgroup.com>
	<5a0a9d6f0709211041k3d22d92ey6a09934f5c20e7cd@mail.gmail.com>
Message-ID: <46F7D286.8040105@orange-ftgroup.com>



Andrew Hammond wrote:
> If it's "not really usable", then you're probably trying to get slony 
> to do something that it can not reasonably be expected to do. 
hmm
> This conversation has already been had on this mailing list. Please 
> search the archives for "lag" and "asynchronous". You should find 
> plenty of discussion. I believe the most recent was only about a month 
> ago.
OK.
thanks.
>
> Andrew
>
>
> On 9/21/07, *Cyril SCETBON* <cscetbon.ext@orange-ftgroup.com 
> <mailto:cscetbon.ext@orange-ftgroup.com>> wrote:
>
>     Hi,
>
>     What is the best way to see how far is a receiver ?
>     Until now I used sl_status.st_lag_time but due to the precision it
>     seems
>     not really usable.
>
>     Thanks.
>     --
>     Cyril SCETBON
>     _______________________________________________
>     Slony1-general mailing list
>     Slony1-general@lists.slony.info
>     <mailto:Slony1-general@lists.slony.info>
>     http://lists.slony.info/mailman/listinfo/slony1-general
>
>

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From JanWieck at Yahoo.com  Mon Sep 24 08:22:42 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Mon Sep 24 08:22:58 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is everyone
	on the replica-hooks-discuss mailing list?
In-Reply-To: <20070921224001.GB95343@decibel.org>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>	<20070921185040.GF17506@fetter.org>
	<20070921224001.GB95343@decibel.org>
Message-ID: <46F7D642.9@Yahoo.com>

On 9/21/2007 6:40 PM, Decibel! wrote:
> On Fri, Sep 21, 2007 at 11:50:41AM -0700, David Fetter wrote:
>> On Fri, Sep 21, 2007 at 09:44:59PM +0300, Marko Kreen wrote:
>> > On 9/20/07, Decibel! <decibel@decibel.org> wrote:
>> > > Seeing the complete duplication of txid.sql between Slony and
>> > > londiste bugs me, so I'm hoping we can come up with a replacement
>> > > for that in core, and the replica-hooks list seems the logical way
>> > > to discuss that...
>> > 
>> > You forgot to give link to list:
>> > 
>> >  http://pgfoundry.org/mailman/listinfo/replica-hooks-discuss
>> > 
>> > 
>> > Compared of to rest of replica-hooks discussion, this is pretty
>> > straightforward affair, not much to discuss here.
> 
> Actually, what I'm really wondering is if a "commit ID" analogous to a
> transaction ID but set at commit time (and in order of commits) would
> vastly simplify things...

It would simplify things for a single master, multiple slaves system. 
But a pure ID won't help a multimaster system at all. If you are 
proposing that this "ID" does make use of a clock value in addition to 
methods that ensure global uniqueness of ID's in order to provide the 
base for time line based conflict resolution in a multimaster system 
(which is what I last proposed together with the pg_trigger and 
pg_rewrite changes), then I'm all ears.

But be careful! Do not use words like "timestamp" or "clock" when you 
describe your mechanism. Everyone with some half knowledge gained from 
reading IT-World will jump down your throat if you do.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From decibel at decibel.org  Mon Sep 24 09:18:57 2007
From: decibel at decibel.org (Decibel!)
Date: Mon Sep 24 09:19:13 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is
	everyone on the replica-hooks-discuss mailing list?
In-Reply-To: <46F7D642.9@Yahoo.com>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>
	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>
	<20070921185040.GF17506@fetter.org>
	<20070921224001.GB95343@decibel.org> <46F7D642.9@Yahoo.com>
Message-ID: <20070924161855.GJ95343@decibel.org>

On Mon, Sep 24, 2007 at 11:22:42AM -0400, Jan Wieck wrote:
> On 9/21/2007 6:40 PM, Decibel! wrote:
> >On Fri, Sep 21, 2007 at 11:50:41AM -0700, David Fetter wrote:
> >>On Fri, Sep 21, 2007 at 09:44:59PM +0300, Marko Kreen wrote:
> >>> On 9/20/07, Decibel! <decibel@decibel.org> wrote:
> >>> > Seeing the complete duplication of txid.sql between Slony and
> >>> > londiste bugs me, so I'm hoping we can come up with a replacement
> >>> > for that in core, and the replica-hooks list seems the logical way
> >>> > to discuss that...
> >>> 
> >>> You forgot to give link to list:
> >>> 
> >>>  http://pgfoundry.org/mailman/listinfo/replica-hooks-discuss
> >>> 
> >>> 
> >>> Compared of to rest of replica-hooks discussion, this is pretty
> >>> straightforward affair, not much to discuss here.
> >
> >Actually, what I'm really wondering is if a "commit ID" analogous to a
> >transaction ID but set at commit time (and in order of commits) would
> >vastly simplify things...
> 
> It would simplify things for a single master, multiple slaves system. 
> But a pure ID won't help a multimaster system at all. If you are 

Well, we currently don't have any multi-master systems that aren't
statement-based, so I'd be happy for just having a commit ID right
now... I suspect that a future multi-master system could still make use
of a plain commit ID as well (though it'd obviously need something more
than that).
-- 
Decibel!, aka Jim C. Nasby, Database Architect  decibel@decibel.org 
Give your computer some brain candy! www.distributed.net Team #1828
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 187 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20070924/03e266d7/attachment.pgp
From dant at cdkkt.com  Mon Sep 24 10:00:48 2007
From: dant at cdkkt.com (Daniel B. Thurman)
Date: Mon Sep 24 10:00:55 2007
Subject: [Slony1-general] Problems connecting via slon service
Message-ID: <021126B987E43D44A860139823C079110E2B81@orion.cdkkt.com>

>Daniel B. Thurman a ?crit :
>> I am having problems trying to get the slon service to run 
>with password:
>>
>> <snip>
>>
>> Thanks!
>> Dan
>>
>>   
>Hi,
>
>It seems to me there's a mess between master and slave, either in
>configuration file or on the command line.
>
>Could you tell us how you launched the slon daemons ?
>
>Regards,
>SAS
>

I found the problem.  I was using pgAdminIII v8.0-beta-5 to configure
the slons for the master and the slaves, and apparently it adds the
connection strings in certain places but with missing keywords such as
user= password= port= and so on.  I was able to repair this by going
directly into the _Cluster tables and to correct them there.  I was
able to get the slons and replication to work at this time.

Thanks for replying,
Dan

No virus found in this outgoing message.
Checked by AVG Free Edition. 
Version: 7.5.488 / Virus Database: 269.13.30/1025 - Release Date: 9/23/2007 1:53 PM
 
From JanWieck at Yahoo.com  Mon Sep 24 10:10:31 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Mon Sep 24 10:10:41 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is	everyone
	on the replica-hooks-discuss mailing list?
In-Reply-To: <20070924161855.GJ95343@decibel.org>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>	<20070921185040.GF17506@fetter.org>	<20070921224001.GB95343@decibel.org>
	<46F7D642.9@Yahoo.com> <20070924161855.GJ95343@decibel.org>
Message-ID: <46F7EF87.4070900@Yahoo.com>

On 9/24/2007 12:18 PM, Decibel! wrote:
> On Mon, Sep 24, 2007 at 11:22:42AM -0400, Jan Wieck wrote:
>> On 9/21/2007 6:40 PM, Decibel! wrote:
>> >On Fri, Sep 21, 2007 at 11:50:41AM -0700, David Fetter wrote:
>> >>On Fri, Sep 21, 2007 at 09:44:59PM +0300, Marko Kreen wrote:
>> >>> On 9/20/07, Decibel! <decibel@decibel.org> wrote:
>> >>> > Seeing the complete duplication of txid.sql between Slony and
>> >>> > londiste bugs me, so I'm hoping we can come up with a replacement
>> >>> > for that in core, and the replica-hooks list seems the logical way
>> >>> > to discuss that...
>> >>> 
>> >>> You forgot to give link to list:
>> >>> 
>> >>>  http://pgfoundry.org/mailman/listinfo/replica-hooks-discuss
>> >>> 
>> >>> 
>> >>> Compared of to rest of replica-hooks discussion, this is pretty
>> >>> straightforward affair, not much to discuss here.
>> >
>> >Actually, what I'm really wondering is if a "commit ID" analogous to a
>> >transaction ID but set at commit time (and in order of commits) would
>> >vastly simplify things...
>> 
>> It would simplify things for a single master, multiple slaves system. 
>> But a pure ID won't help a multimaster system at all. If you are 
> 
> Well, we currently don't have any multi-master systems that aren't
> statement-based, so I'd be happy for just having a commit ID right
> now... I suspect that a future multi-master system could still make use
> of a plain commit ID as well (though it'd obviously need something more
> than that).

Unless you have a particular use case in mind, I'd be against such plain 
commit ID right now.

The point is that if we have "something" now, we have to support and 
continue having "that something" in the future. Which will be what? A 
thing that theoretically can make life easier for existing replication 
systems, that already have a solution for not having it in the first 
place. But it will also be a thing that is *in the way* of something 
that might be useful for replication systems we don't have yet, like a 
row based multimaster. The argument then being "we already have x, y and 
z that we need to support; how much more things have to be added to core?".

For Slony-I specifically, we are currently developing version 2.0. This 
version will not be backwards compatible to any Postgres version before 
8.3 because it makes use of the pg_trigger and pg_rewrite changes that 
happened there. This is required because the system catalog mucking done 
in earlier Slony versions had caused endless pain. However, the benefits 
of any kind of "commit ID" that might be coming in 8.4 will not warrant 
such backwards incompatibility again. So I doubt that Slony-I would make 
use of such feature any sooner than when we drop support for 8.3 
somewhere in the distant future.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From jpfletch at ca.afilias.info  Mon Sep 24 10:39:58 2007
From: jpfletch at ca.afilias.info (JP Fletcher)
Date: Mon Sep 24 10:41:32 2007
Subject: [Slony1-general] cluster broken
In-Reply-To: <46F17E20.3020605@ca.afilias.info>
References: <46E9A192.2010906@ca.afilias.info>	<60y7fa2qem.fsf@dba2.int.libertyrms.com>
	<46F17E20.3020605@ca.afilias.info>
Message-ID: <46F7F66E.6020809@ca.afilias.info>

Is this something that will be fixed, or is it 'not supported'?



JP Fletcher wrote:
> Hi,
>
>
> I'm able to reproduce this condition repeatedly.  The scenario is as 
> follows:
>
> Set1 has origin on node8143, which is data provider to node8141, which 
> in turn is provider to node8194 :
>
> 8143 --> 8141 --> 8194
>
>
> I add set2, which has origin on node8143.  I then subscribe node8194 
> to node8143 directly.
>                                  This breaks node8194 immediately.  
> The slon logs for node 8194 show:
>
> 2007-09-19 19:42:01 UTC ERROR  remoteWorkerThread_8143: "declare LOG 
> cursor for select     log_origin, log_xid, log_tableid,     
> log_actionseq, log_cmdtype,     octet_length(log_cmddata),     case 
> when octet_length(log_cmddata) <= 8192         then 
> log_cmddata         else null end from "_cluster".sl_log_1 where 
> log_origin = 8143 and (  order by log_actionseq; " PGRES_FATAL_ERROR 
> ERROR:  syntax error at or near "order" at character 283
> 2007-09-19 19:42:01 UTC ERROR  remoteWorkerThread_8143: "close LOG; " 
> PGRES_FATAL_ERROR ERROR:  current transaction is aborted, commands 
> ignored until end of transaction block
>
>
>
> JP
>
> Christopher Browne wrote:
>> JP Fletcher <jpfletch@ca.afilias.info> writes:
>>
>>  
>>> Hi,
>>>
>>> My 1.2.11 cluster abruptly stopped working, with the following error
>>> message present in the pg logs of the origin:
>>>
>>> 2007-09-13 20:29:06.358 UTC [1679750] cluster slony 10.1.2.133 ERROR:
>>> syntax error at or near "order" at character 283
>>> 2007-09-13 20:29:06.358 UTC [1679750] cluster slony 10.1.2.133
>>> STATEMENT:  declare LOG cursor for select     log_origin, log_xid,
>>> log_tableid,     log_actionseq, log_cmdtype,
>>> octet_length(log_cmddata),     case when octet_length(log_cmddata) <=
>>> 8192         then log_cmddata         else null end from
>>> "_cluster".sl_log_1 where log_origin = 8143 and (  order by
>>> log_actionseq;
>>>
>>>
>>> I had been changing some subscriptions around,  with no evidence of
>>> failure.  Apart from that, the cluster wasn't doing anything...
>>>     
>>
>> Hmm.  This sounds a whole lot like:
>>
>> <http://gborg.postgresql.org/project/slony1/bugs/bugupdate.php?1226>
>>
>> That was supposedly fixed about two years ago.
>>   
>
>


-- 
JP Fletcher
Database Administrator
Afilias Canada
voice: 416.646.3304 ext. 4123
fax: 416.646.3305
mobile: 416.561.4763
jpfletch@ca.afilias.info


From cbbrowne at ca.afilias.info  Mon Sep 24 12:09:28 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Sep 24 12:09:48 2007
Subject: [Slony1-general] cluster broken
In-Reply-To: <46F7F66E.6020809@ca.afilias.info>
References: <46E9A192.2010906@ca.afilias.info>	<60y7fa2qem.fsf@dba2.int.libertyrms.com>
	<46F17E20.3020605@ca.afilias.info>
	<46F7F66E.6020809@ca.afilias.info>
Message-ID: <46F80B68.2070305@ca.afilias.info>

JP Fletcher wrote:
> Is this something that will be fixed, or is it 'not supported'?
>
I have discussed this one with Jan; he thought it needed to be fixed 
fairly soon.

On my short term "to do" list is to build an example of this as one of 
the regression tests.  Today, in between not seeing things properly (I 
went to the optometrist, so my pupils are wildly dilated!), I have been 
working on a "dupe node" script; after that, I'll get to adding to the 
regression tests.
From cbbrowne at ca.afilias.info  Mon Sep 24 14:29:28 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Mon Sep 24 14:29:40 2007
Subject: [Slony1-general] cluster broken
In-Reply-To: <46F17E20.3020605@ca.afilias.info> (JP Fletcher's message of "Wed,
	19 Sep 2007 15:53:04 -0400")
References: <46E9A192.2010906@ca.afilias.info>
	<60y7fa2qem.fsf@dba2.int.libertyrms.com>
	<46F17E20.3020605@ca.afilias.info>
Message-ID: <608x6voipz.fsf@dba2.int.libertyrms.com>

JP Fletcher <jpfletch@ca.afilias.info> writes:

> Hi,
>
>
> I'm able to reproduce this condition repeatedly.  The scenario is as
> follows:
>
> Set1 has origin on node8143, which is data provider to node8141, which
> in turn is provider to node8194 :
>
> 8143 --> 8141 --> 8194
>
>
> I add set2, which has origin on node8143.  I then subscribe node8194
> to node8143 directly.
>                                  This breaks node8194 immediately.

I have added a test case that exercises this kind of scenario to CVS HEAD:
<http://lists.slony.info/pipermail/slony1-commit/2007-September/002012.html>
<http://lists.slony.info/pipermail/slony1-commit/2007-September/002013.html>

The test is called "testmultipaths."

We'll be able to readily measure when the problem is repaired.

I don't believe that this kind of case has ever worked, but it's
definitely a bad thing that it doesn't.
-- 
select 'cbbrowne' || '@' || 'cbbrowne.com';
http://www3.sympatico.ca/cbbrowne/advocacy.html
Overheard in the mall: "What's with your sister and her spitting fetish?" 
From andrew.george.hammond at gmail.com  Mon Sep 24 16:09:02 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Mon Sep 24 16:09:16 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <Pine.LNX.4.64.0709210836140.20452@discord.home.frostconsultingllc.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>
	<46F1770C.8010201@ca.afilias.info>
	<Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
	<Pine.LNX.4.64.0709210836140.20452@discord.home.frostconsultingllc.com>
Message-ID: <5a0a9d6f0709241609w244ec2ffx5c3409313cc02f0a@mail.gmail.com>

On 9/21/07, Jeff Frost <jeff@frostconsultingllc.com> wrote:
>
> On Wed, 19 Sep 2007, Jeff Frost wrote:
>
> > On Wed, 19 Sep 2007, Christopher Browne wrote:
> >
> >>> Bails out is the wrong description. Clobbered by the pgsql deadlock
> >>> detection system, leaving the cluster in an unstable state would be
> more
> >>> accurate, if that's what happened. I don't know that there's a way to
> >>> catch that clobberage and run a "finally" type thing.
> >> The thing is, that's not what happens.
> >>
> >> Unless there's a COMMIT somewhere in the DDL script, in which case all
> bets
> >> are off, everywhere, the deadlock should lead to one of two things
> >> happening:
> >>
> >> 1. The other process that was holding onto the tables might fail and
> roll
> >> back, and the DDL script would complete, or
> >>
> >> 2.  The DDL script will fail and roll back, leading to the state of the
> >> tables falling back to what it was before DDL script processing began.
> >>
> >> In either case, the results should leave the node in a consistent
> state,
> >> either:
> >> a) With the DDL request having gone in, or
> >> b) With the DDL request *not* having gone in.
> >>
> >> Unless there's an extra COMMIT in the code (and I just looked at the
> code,
> >> and Did Not See One), the failure resulting from a deadlock should be
> >> benign, restoring the tables to the "previously altered state."
> >>>
> >>>     So, is there a reasonable way to fix this without
> >>>     droppping/resubscribing the
> >>>     node?
> >>>
> >>>
> >>> Well, to start with, you might want to figure out why your application
> is
> >>> taking such aggressive locks. And make sure in the future that it
> doesn't
> >>> happen again (not much point fixing it if it's just gonna re-occur).
> If
> >>> you are using a separate superuser account to connect to your database
> and
> >>> run your slons (generally the "slony" user) then this is really easy
> to
> >>> do: tweak your pg_hba to only allow connections from slony and then
> kick
> >>> all active non-slony connections. Revert your pg_hba at the end of the
> >>> maintenance.
> >>>
> >>> If you're willing to experiment with using slony internal functions,
> you
> >>> could put the table in question into altered state. Something like
> this on
> >>> the offending node might work.
> >>>
> >>> SELECT alterTableForReplication((SELECT tab_id FROM sl_table WHERE
> >>> tab_reloid =3D (SELECT oid FROM pg_class WHERE relname=3D'cart')));
> >>>
> >>> Or of course it might mess things up even more. :)
> >> The one change to suggest that comes to *my* mind is that we perhaps
> ought
> >> to change Slony-I to aggressively lock the replicated tables ASAP at
> the
> >> start of the DDL script event.
> >>
> >> That will either immediately succeed, and eliminate any possibility of
> >> future deadlock, or immediately fail, before we even try to alter
> anything.
> >>
> >> This same change was made to the SUBSCRIBE SET process (well,
> "COPY_SET",
> >> strictly speaking, but that's not at all user visible...), as we saw
> cases
> >> where gradually escalating locks on tables led to deadlocks that could
> >> waste hours worth of subscription work.
> >>
> >> But it seems likely to me that there's more to the problem than we're
> >> hearing, because deadlock shouldn't cause any corruption of anything -
> to
> >> the contrary, it may be expected to prevent it.
> >
> > this is the latest SQL that caused the problem (note there is not a
> COMMIT in
> > the sql):
> >
> > --------
> > CREATE TABLE orders.amazon_items
> > (
> >  id serial NOT NULL,
> >  order_id integer NOT NULL,
> >  item_id integer NOT NULL,
> >  amazon_item_id character varying(14) NOT NULL,
> >  CONSTRAINT amazon_items_pkey PRIMARY KEY (id),
> >  CONSTRAINT amazon_items_order_id_fkey FOREIGN KEY (order_id)
> >      REFERENCES orders.orders (id) MATCH SIMPLE
> >      ON UPDATE NO ACTION ON DELETE NO ACTION,
> >  CONSTRAINT amazon_items_item_id_fkey FOREIGN KEY (item_id)
> >      REFERENCES orders.items (id) MATCH SIMPLE
> >      ON UPDATE NO ACTION ON DELETE NO ACTION
> > )
> > WITH OIDS;
> > ALTER TABLE orders.amazon_items OWNER TO thenerds;
> > --------
> >
> > It was called by the following slonik script:
> >
> > --------
> > #!/usr/bin/slonik
> > include </nerds/preamble.slonik>;
> >
> >        EXECUTE SCRIPT (
> >                SET ID =3D 1,
> >                FILENAME =3D '/nerds/thenerds.sql',
> >                EVENT NODE =3D 1
> >        );
> > --------
> >
> > and caused the following deadlock to occur:
> >
> > 15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR
> > remoteWorkerThread_1: "select "_nerdcluster".ddlScript
> > _complete_int(1, -1); " PGRES_FATAL_ERROR
> > Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
> > Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263 waits
> for
> > AccessExclusiveLock on relation 121589880 of databas
> > e 121589046; blocked by process 12096.
> > Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for
> > AccessShareLock on relation 121589817 of database 121589046;
> > blocked by process 12263.
> >
> > Which then left the some of the tables on that slave in a bad state
> breaking
> > replication:
> >
> > 2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select
> > "_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR ERROR:
> > Slony-I: alterTableRestore(): Table "public"."carts" is not in altered
> state
> > CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore( $1 )"
> > PL/pgSQL function "ddlscript_prepare_int" line 46 at perform
> >
> > Note that it's just an AccessShareLock that's killing us.  Looks like
> that's
> > caused by a select query which does searches.  Our application does not
> > produce any extraneous locking, it simply does SELECTS on that server.
> >
> > Interestingly, before we started using the slave for queries, we would
> have
> > the deadlocks happen on the master when doing DDL changes, but this
> never
> > caused the tables on the master to get into a bad state.  You could just
> > re-run your EXECUTE SCRIPT and it would usually work fine the second
> time.
> >
> > What other info can I provide?
>
> So, what I'm getting from all this is that while the deadlocks can occur,
> slony should gracefully error out and return the tables to their
> previously
> altered state, but that doesn't seem to happen on these nodes.  Note that
> it's
> only a problem when there's a deadlock on the slave, not on the master.
> Should I file this as a bug?  If so, do I just need to send an email to
> slony1-bugs?
>

If you can reproduce the problem then yes, absolutely. Ideally, write a new
test-case that demonstrates it.


Andrew
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070924/=
aa67f8fc/attachment.htm
From andrew.george.hammond at gmail.com  Mon Sep 24 16:17:05 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Mon Sep 24 16:17:17 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <Pine.LNX.4.64.0709201500220.399@glacier.frostconsultingllc.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com>
	<46F1770C.8010201@ca.afilias.info>
	<Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
	<46F21E8D.8050606@postgresqlfr.org>
	<Pine.LNX.4.64.0709200801470.20452@discord.home.frostconsultingllc.com>
	<46F2A561.8060500@postgresqlfr.org>
	<Pine.LNX.4.64.0709200954370.399@glacier.frostconsultingllc.com>
	<5a0a9d6f0709201458h64c358cbl72f69b337bc7e635@mail.gmail.com>
	<Pine.LNX.4.64.0709201500220.399@glacier.frostconsultingllc.com>
Message-ID: <5a0a9d6f0709241617k3d71f56au4bf75191274d41b4@mail.gmail.com>

On 9/20/07, Jeff Frost <jeff@frostconsultingllc.com> wrote:
>
> On Thu, 20 Sep 2007, Andrew Hammond wrote:
> > Really? I know that a lot of people, including myself, have _wanted_ a
> slony
> > aware pgpool and for quite some time now. I'm not aware of any such code
> > actually being written. But that's for client software anyway, certainly
> not
> > the slons. Why on earth would anyone even _want_ connect a slon through
> > pgpool?
>
> Sorry, you must be reading serially through your mail.  I believe in a
> later
> email I specified that the slons do not connect through pgpool nor does
> slonik.  pgpool is only being used to load balance read-only search
> queries.
>
> Perhaps by 'slony aware' I should have said 'slony friendly'?  I.e. it
> sends
> SELECTS to both nodes and other queries to the master only.  (Other
> queries
> being defined as non-selects and anything wrapped in a transaction block.)
>

With apologies to H.L. Mencken, that sounds like a simple, direct, plausible
and wrong solution to a complex problem. If pgpool can be configured to send
_transactions_ which have been SET TRANSACTION READ ONLY; to a subscriber
then this might be clever. Otherwise it's not only a stunningly obvious race
condition but total failure to understand locking and mvcc.

Andrew
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070924/=
173caa31/attachment-0001.htm
From andrew.george.hammond at gmail.com  Mon Sep 24 16:20:21 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Mon Sep 24 16:20:33 2007
Subject: [Slony1-general] Problems connecting via slon service
In-Reply-To: <021126B987E43D44A860139823C079110E2B81@orion.cdkkt.com>
References: <021126B987E43D44A860139823C079110E2B81@orion.cdkkt.com>
Message-ID: <5a0a9d6f0709241620t2f1ac6e8uad8a57927b85accf@mail.gmail.com>

On 9/24/07, Daniel B. Thurman <dant@cdkkt.com> wrote:
>
> >Daniel B. Thurman a =E9crit :
> >> I am having problems trying to get the slon service to run
> >with password:
> >>
> >> <snip>
> >>
> >> Thanks!
> >> Dan
> >>
> >>
> >Hi,
> >
> >It seems to me there's a mess between master and slave, either in
> >configuration file or on the command line.
> >
> >Could you tell us how you launched the slon daemons ?
> >
> >Regards,
> >SAS
> >
>
> I found the problem.  I was using pgAdminIII v8.0-beta-5 to configure
> the slons for the master and the slaves, and apparently it adds the
> connection strings in certain places but with missing keywords such as
> user=3D password=3D port=3D and so on.  I was able to repair this by going
> directly into the _Cluster tables and to correct them there.  I was
> able to get the slons and replication to work at this time.
>


That's one way to do it. A better way is to use .pgpass files. See the
postgresql documentation on this.

Andrew
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070924/=
27d5caa0/attachment.htm
From andrew.george.hammond at gmail.com  Mon Sep 24 17:37:59 2007
From: andrew.george.hammond at gmail.com (Andrew Hammond)
Date: Mon Sep 24 17:38:13 2007
Subject: [Slony1-general] Bucardo (postgresql 8.0+ async row based
	multi-master replication with conflict resolution) released
Message-ID: <5a0a9d6f0709241737k543d3a09w3e11bed7976d7004@mail.gmail.com>

http://people.planetpostgresql.org/greg/index.php?/archives/109-guid.html

Congratulations to Greg on his release! It's always good to see new and
interesting work.

Andrew
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070924/=
395e744c/attachment.htm
From markokr at gmail.com  Tue Sep 25 01:21:46 2007
From: markokr at gmail.com (Marko Kreen)
Date: Tue Sep 25 01:22:07 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is everyone
	on the replica-hooks-discuss mailing list?
In-Reply-To: <20070921224001.GB95343@decibel.org>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>
	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>
	<20070921185040.GF17506@fetter.org>
	<20070921224001.GB95343@decibel.org>
Message-ID: <e51f66da0709250121i4123b46of503601bb793fc2c@mail.gmail.com>

On 9/22/07, Decibel! <decibel@decibel.org> wrote:
> Actually, what I'm really wondering is if a "commit ID" analogous to a
> transaction ID but set at commit time (and in order of commits) would
> vastly simplify things...

Could you clarify?  I don't get it.  Assuming we keep the trigger
based event logging, the event storage happens at the time of
insert/update/delete statement, how can anything determined at
commit time be useful?

The xxid/txid usage may be slightly unobvious, but it is direct
1:1 mapping to PostgreSQL internal MVCC logic, so you can be
certain that if postgres works then this also works.

I see no need to replace it with something else.

-- 
marko
From markokr at gmail.com  Tue Sep 25 01:43:28 2007
From: markokr at gmail.com (Marko Kreen)
Date: Tue Sep 25 01:43:50 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is
	everyone on the replica-hooks-discuss mailing list?
In-Reply-To: <46F7EF87.4070900@Yahoo.com>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>
	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>
	<20070921185040.GF17506@fetter.org>
	<20070921224001.GB95343@decibel.org> <46F7D642.9@Yahoo.com>
	<20070924161855.GJ95343@decibel.org> <46F7EF87.4070900@Yahoo.com>
Message-ID: <e51f66da0709250143l84383f4r59053979fa254916@mail.gmail.com>

On 9/24/07, Jan Wieck <JanWieck@yahoo.com> wrote:
> For Slony-I specifically, we are currently developing version 2.0. This
> version will not be backwards compatible to any Postgres version before
> 8.3 because it makes use of the pg_trigger and pg_rewrite changes that
> happened there. This is required because the system catalog mucking done
> in earlier Slony versions had caused endless pain. However, the benefits
> of any kind of "commit ID" that might be coming in 8.4 will not warrant
> such backwards incompatibility again. So I doubt that Slony-I would make
> use of such feature any sooner than when we drop support for 8.3
> somewhere in the distant future.

To clarify the topic - the txid module in Skytools is 8byte,
non-wrapping version of xxid module in SlonyI.  Upper 4 bytes
are filled with the 'wraparound epoch' which is already in core.

First question - Are you interested in common module for this?
Eg, if it would be available in core, would you convert SlonyI 3.0
over to it?  Or, if it had been included in 8.3, would you convert
Slony 2.0 over to it?

Basically I ask this because if you say "no, never", the code
quite likely won't get accepted into core.


Secondly, if you _are_ interested, maybe we can agree what the
common module will look like and ship with both SlonyI 2.0 and
Skytools?  Then the Slony 2.0 could come prepared for it? You
can then drop it whenever you drop support for 8.3.

Ofcourse this depends on schedules you have set for yourselves
and there is no problem if you say no to that idea.

-- 
marko
From jeff at frostconsultingllc.com  Tue Sep 25 07:33:26 2007
From: jeff at frostconsultingllc.com (Jeff Frost)
Date: Tue Sep 25 07:33:33 2007
Subject: [Slony1-general] bug in deadlock handling?
In-Reply-To: <5a0a9d6f0709241609w244ec2ffx5c3409313cc02f0a@mail.gmail.com>
References: <Pine.LNX.4.64.0709181317310.4701@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709191137u4ef64662hae65e974003e7ae6@mail.gmail.com> 
	<46F1770C.8010201@ca.afilias.info>
	<Pine.LNX.4.64.0709191446530.4701@discord.home.frostconsultingllc.com>
	<Pine.LNX.4.64.0709210836140.20452@discord.home.frostconsultingllc.com>
	<5a0a9d6f0709241609w244ec2ffx5c3409313cc02f0a@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709250727190.20452@discord.home.frostconsultingllc.com>

On Mon, 24 Sep 2007, Andrew Hammond wrote:

>>>>> SELECT alterTableForReplication((SELECT tab_id FROM sl_table WHERE
>>>>> tab_reloid = (SELECT oid FROM pg_class WHERE relname='cart')));
>>>>>
>>>>> Or of course it might mess things up even more. :)
>>>> The one change to suggest that comes to *my* mind is that we perhaps
>> ought
>>>> to change Slony-I to aggressively lock the replicated tables ASAP at
>> the
>>>> start of the DDL script event.
>>>>
>>>> That will either immediately succeed, and eliminate any possibility of
>>>> future deadlock, or immediately fail, before we even try to alter
>> anything.
>>>>
>>>> This same change was made to the SUBSCRIBE SET process (well,
>> "COPY_SET",
>>>> strictly speaking, but that's not at all user visible...), as we saw
>> cases
>>>> where gradually escalating locks on tables led to deadlocks that could
>>>> waste hours worth of subscription work.
>>>>
>>>> But it seems likely to me that there's more to the problem than we're
>>>> hearing, because deadlock shouldn't cause any corruption of anything -
>> to
>>>> the contrary, it may be expected to prevent it.
>>>
>>> this is the latest SQL that caused the problem (note there is not a
>> COMMIT in
>>> the sql):
>>>
>>> --------
>>> CREATE TABLE orders.amazon_items
>>> (
>>>  id serial NOT NULL,
>>>  order_id integer NOT NULL,
>>>  item_id integer NOT NULL,
>>>  amazon_item_id character varying(14) NOT NULL,
>>>  CONSTRAINT amazon_items_pkey PRIMARY KEY (id),
>>>  CONSTRAINT amazon_items_order_id_fkey FOREIGN KEY (order_id)
>>>      REFERENCES orders.orders (id) MATCH SIMPLE
>>>      ON UPDATE NO ACTION ON DELETE NO ACTION,
>>>  CONSTRAINT amazon_items_item_id_fkey FOREIGN KEY (item_id)
>>>      REFERENCES orders.items (id) MATCH SIMPLE
>>>      ON UPDATE NO ACTION ON DELETE NO ACTION
>>> )
>>> WITH OIDS;
>>> ALTER TABLE orders.amazon_items OWNER TO thenerds;
>>> --------
>>>
>>> It was called by the following slonik script:
>>>
>>> --------
>>> #!/usr/bin/slonik
>>> include </nerds/preamble.slonik>;
>>>
>>>        EXECUTE SCRIPT (
>>>                SET ID = 1,
>>>                FILENAME = '/nerds/thenerds.sql',
>>>                EVENT NODE = 1
>>>        );
>>> --------
>>>
>>> and caused the following deadlock to occur:
>>>
>>> 15:27:54 sql1 slon[12252]: [39-1] 2007-09-18 15:27:54 EDT ERROR
>>> remoteWorkerThread_1: "select "_nerdcluster".ddlScript
>>> _complete_int(1, -1); " PGRES_FATAL_ERROR
>>> Sep 18 15:27:54 sql1 slon[12252]: [39-2]  ERROR:  deadlock detected
>>> Sep 18 15:27:54 sql1 slon[12252]: [39-3] DETAIL:  Process 12263 waits
>> for
>>> AccessExclusiveLock on relation 121589880 of databas
>>> e 121589046; blocked by process 12096.
>>> Sep 18 15:27:54 sql1 slon[12252]: [39-4] Process 12096 waits for
>>> AccessShareLock on relation 121589817 of database 121589046;
>>> blocked by process 12263.
>>>
>>> Which then left the some of the tables on that slave in a bad state
>> breaking
>>> replication:
>>>
>>> 2007-09-18 15:56:06 EDT ERROR  remoteWorkerThread_1: "select
>>> "_nerdcluster".ddlScript_prepare_int(1, -1); " PGRES_FATAL_ERROR ERROR:
>>> Slony-I: alterTableRestore(): Table "public"."carts" is not in altered
>> state
>>> CONTEXT:  SQL statement "SELECT  "_nerdcluster".alterTableRestore( $1 )"
>>> PL/pgSQL function "ddlscript_prepare_int" line 46 at perform
>>>
>>> Note that it's just an AccessShareLock that's killing us.  Looks like
>> that's
>>> caused by a select query which does searches.  Our application does not
>>> produce any extraneous locking, it simply does SELECTS on that server.
>>>
>>> Interestingly, before we started using the slave for queries, we would
>> have
>>> the deadlocks happen on the master when doing DDL changes, but this
>> never
>>> caused the tables on the master to get into a bad state.  You could just
>>> re-run your EXECUTE SCRIPT and it would usually work fine the second
>> time.
>>>
>>> What other info can I provide?
>>
>> So, what I'm getting from all this is that while the deadlocks can occur,
>> slony should gracefully error out and return the tables to their
>> previously
>> altered state, but that doesn't seem to happen on these nodes.  Note that
>> it's
>> only a problem when there's a deadlock on the slave, not on the master.
>> Should I file this as a bug?  If so, do I just need to send an email to
>> slony1-bugs?
>>
>
> If you can reproduce the problem then yes, absolutely. Ideally, write a new
> test-case that demonstrates it.

It seems quite reproducible on this particular setup.  Basically, run any 
slonik command which uses EXECUTE SCRIPT and if you get a deadlock on node2, 
it will leave some of node2's tables in the non modified state (i.e. the 
triggers are missing).

Problem is, I'm not sure how to write a test case which would guarantee a 
deadlock on node2 only.  I'll write this up and send it to 
slony1-bugs@lists.slony.info.

-- 
Jeff Frost, Owner 	<jeff@frostconsultingllc.com>
Frost Consulting, LLC 	http://www.frostconsultingllc.com/
Phone: 650-780-7908	FAX: 650-649-1954
From JanWieck at Yahoo.com  Tue Sep 25 07:33:46 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Tue Sep 25 07:33:58 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is everyone
	on the replica-hooks-discuss mailing list?
In-Reply-To: <e51f66da0709250121i4123b46of503601bb793fc2c@mail.gmail.com>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>	<20070921185040.GF17506@fetter.org>	<20070921224001.GB95343@decibel.org>
	<e51f66da0709250121i4123b46of503601bb793fc2c@mail.gmail.com>
Message-ID: <46F91C4A.9090601@Yahoo.com>

On 9/25/2007 4:21 AM, Marko Kreen wrote:
> On 9/22/07, Decibel! <decibel@decibel.org> wrote:
>> Actually, what I'm really wondering is if a "commit ID" analogous to a
>> transaction ID but set at commit time (and in order of commits) would
>> vastly simplify things...
> 
> Could you clarify?  I don't get it.  Assuming we keep the trigger
> based event logging, the event storage happens at the time of
> insert/update/delete statement, how can anything determined at
> commit time be useful?

I think his theory is about a replication protocol that applies changes 
on slaves in the commit order of the master. Using such protocol would 
certainly simplify things, since all the slave has to do is to remember 
the last commit ID applied, then select all changes with a higher commit 
ID next time.

The flaw in that theory is that such protocol would assume an index over 
the commit ID. Without that index, the entire log would have to be 
sequentially scanned and sorted each round, so there would not be any 
benefit to that. But such index cannot be maintained easily because the 
commit ID isn't known at insert time, so the tuples would have to be 
revisited after the transaction committed.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From JanWieck at Yahoo.com  Tue Sep 25 07:45:15 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Tue Sep 25 07:45:27 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is	everyone
	on the replica-hooks-discuss mailing list?
In-Reply-To: <e51f66da0709250143l84383f4r59053979fa254916@mail.gmail.com>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>	<20070921185040.GF17506@fetter.org>	<20070921224001.GB95343@decibel.org>
	<46F7D642.9@Yahoo.com>	<20070924161855.GJ95343@decibel.org>
	<46F7EF87.4070900@Yahoo.com>
	<e51f66da0709250143l84383f4r59053979fa254916@mail.gmail.com>
Message-ID: <46F91EFB.6080409@Yahoo.com>

On 9/25/2007 4:43 AM, Marko Kreen wrote:
> On 9/24/07, Jan Wieck <JanWieck@yahoo.com> wrote:
>> For Slony-I specifically, we are currently developing version 2.0. This
>> version will not be backwards compatible to any Postgres version before
>> 8.3 because it makes use of the pg_trigger and pg_rewrite changes that
>> happened there. This is required because the system catalog mucking done
>> in earlier Slony versions had caused endless pain. However, the benefits
>> of any kind of "commit ID" that might be coming in 8.4 will not warrant
>> such backwards incompatibility again. So I doubt that Slony-I would make
>> use of such feature any sooner than when we drop support for 8.3
>> somewhere in the distant future.
> 
> To clarify the topic - the txid module in Skytools is 8byte,
> non-wrapping version of xxid module in SlonyI.  Upper 4 bytes
> are filled with the 'wraparound epoch' which is already in core.

The above was in response to Jim's "commit ID".

> 
> First question - Are you interested in common module for this?
> Eg, if it would be available in core, would you convert SlonyI 3.0
> over to it?  Or, if it had been included in 8.3, would you convert
> Slony 2.0 over to it?
> 
> Basically I ask this because if you say "no, never", the code
> quite likely won't get accepted into core.
> 
> 
> Secondly, if you _are_ interested, maybe we can agree what the
> common module will look like and ship with both SlonyI 2.0 and
> Skytools?  Then the Slony 2.0 could come prepared for it? You
> can then drop it whenever you drop support for 8.3.

Does that module also provide support for the xxid_snapshot type and 
associated functions like xxid_lt_snapshot()? If that is the case then 
there would be value in using and shipping it with Slony-I 2.0, assuming 
that widespread use of a common module makes adoption into core more likely.

> 
> Ofcourse this depends on schedules you have set for yourselves
> and there is no problem if you say no to that idea.
> 

Slony-I 2.0 is supposed to be available very close to the 8.3 release.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From decibel at decibel.org  Tue Sep 25 08:06:55 2007
From: decibel at decibel.org (Decibel!)
Date: Tue Sep 25 08:07:09 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is
	everyone on the replica-hooks-discuss mailing list?
In-Reply-To: <46F91C4A.9090601@Yahoo.com>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>
	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>
	<20070921185040.GF17506@fetter.org>
	<20070921224001.GB95343@decibel.org>
	<e51f66da0709250121i4123b46of503601bb793fc2c@mail.gmail.com>
	<46F91C4A.9090601@Yahoo.com>
Message-ID: <20070925150654.GK95343@decibel.org>

On Tue, Sep 25, 2007 at 10:33:46AM -0400, Jan Wieck wrote:
> On 9/25/2007 4:21 AM, Marko Kreen wrote:
> >On 9/22/07, Decibel! <decibel@decibel.org> wrote:
> >>Actually, what I'm really wondering is if a "commit ID" analogous to a
> >>transaction ID but set at commit time (and in order of commits) would
> >>vastly simplify things...
> >
> >Could you clarify?  I don't get it.  Assuming we keep the trigger
> >based event logging, the event storage happens at the time of
> >insert/update/delete statement, how can anything determined at
> >commit time be useful?
> 
> I think his theory is about a replication protocol that applies changes 
> on slaves in the commit order of the master. Using such protocol would 
> certainly simplify things, since all the slave has to do is to remember 
> the last commit ID applied, then select all changes with a higher commit 
> ID next time.
> 
> The flaw in that theory is that such protocol would assume an index over 
> the commit ID. Without that index, the entire log would have to be 
> sequentially scanned and sorted each round, so there would not be any 
> benefit to that. But such index cannot be maintained easily because the 
> commit ID isn't known at insert time, so the tuples would have to be 
> revisited after the transaction committed.

Yes, my vision was to have a separate table that tracked what a
transaction's commit ID was; it wouldn't make any sense to go screwing
around in the log table once you got the CID. While not as easy as if
you could just grab a range of XIDs out of the log, it'd still be much
simpler than how syncs currently work.

Another thought occurs to me... I know that folks have asked for commit
triggers in the past for other purposes; if we had that it would be easy
to build your own commit ID with a sequence.
-- 
Decibel!, aka Jim C. Nasby, Database Architect  decibel@decibel.org 
Give your computer some brain candy! www.distributed.net Team #1828
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 187 bytes
Desc: not available
Url : http://lists.slony.info/pipermail/slony1-general/attachments/20070925/11c5eed0/attachment.pgp
From markokr at gmail.com  Tue Sep 25 08:15:02 2007
From: markokr at gmail.com (Marko Kreen)
Date: Tue Sep 25 08:15:10 2007
Subject: [Slony1-general] Re: [Skytools-users] [Slony1-hackers] Is
	everyone on the replica-hooks-discuss mailing list?
In-Reply-To: <46F91EFB.6080409@Yahoo.com>
References: <F0296FDB-72BA-46FD-B921-EA622DF1C89C@decibel.org>
	<e51f66da0709211144l47f02402j35092d0ef58cd44b@mail.gmail.com>
	<20070921185040.GF17506@fetter.org>
	<20070921224001.GB95343@decibel.org> <46F7D642.9@Yahoo.com>
	<20070924161855.GJ95343@decibel.org> <46F7EF87.4070900@Yahoo.com>
	<e51f66da0709250143l84383f4r59053979fa254916@mail.gmail.com>
	<46F91EFB.6080409@Yahoo.com>
Message-ID: <e51f66da0709250815p21e4365ao9ea5fe5e93ab5bc3@mail.gmail.com>

On 9/25/07, Jan Wieck <JanWieck@yahoo.com> wrote:
> On 9/25/2007 4:43 AM, Marko Kreen wrote:
> > Secondly, if you _are_ interested, maybe we can agree what the
> > common module will look like and ship with both SlonyI 2.0 and
> > Skytools?  Then the Slony 2.0 could come prepared for it? You
> > can then drop it whenever you drop support for 8.3.
>
> Does that module also provide support for the xxid_snapshot type and
> associated functions like xxid_lt_snapshot()? If that is the case then
> there would be value in using and shipping it with Slony-I 2.0, assuming
> that widespread use of a common module makes adoption into core more likely.

yes, both type and "lt" is supported.  I sent a mail about the
module API to slony1-hackers where you can get the overview:

 http://lists.slony.info/pipermail/slony1-hackers/2007-September/000069.html

I think it would be really good if we could settle on single
module.  That makes getting it into core quite likely, especially
considering that it's useful not only for replication, but for
anybody who wants to implement queue-like things in database.

> > Ofcourse this depends on schedules you have set for yourselves
> > and there is no problem if you say no to that idea.
>
> Slony-I 2.0 is supposed to be available very close to the 8.3 release.

Not too soon but not too far off too.

Main change would be to replace the 4-byte xxid with 8-byte bigint
type.  Does not sound very bad, but I'm not familiar with SlonyI
code, you need to decide for yourself.

-- 
marko
From cscetbon.ext at orange-ftgroup.com  Tue Sep 25 08:47:21 2007
From: cscetbon.ext at orange-ftgroup.com (Cyril SCETBON)
Date: Tue Sep 25 08:47:28 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <5a0a9d6f0709101544h41da1a6pa7375579aab463ff@mail.gmail.com>
References: <46E153D1.4060903@orange-ftgroup.com> <46E1A7A0.30401@Yahoo.com>	
	<46E305D8.3090502@orange-ftgroup.com>
	<46E5AA0D.1060708@orange-ftgroup.com>
	<5a0a9d6f0709101544h41da1a6pa7375579aab463ff@mail.gmail.com>
Message-ID: <46F92D89.4010803@orange-ftgroup.com>



Andrew Hammond wrote:
> On 9/10/07, *Cyril SCETBON* <cscetbon.ext@orange-ftgroup.com 
> <mailto:cscetbon.ext@orange-ftgroup.com>> wrote:
>
>
>     Cyril SCETBON wrote:
>     >
>     >
>     > Jan Wieck wrote:
>     >> On 9/7/2007 9:36 AM, Cyril SCETBON wrote:
>     >>> Hi,
>     >>>
>     >>> I got this configuration                Node1 --> Node2 (5
>     seconds
>     >>> late)
>     >>>                                                           |
>     >>>                                                           -->
>     Node3
>     >>> (2 hours late)
>     >>>
>     >>> Node2 is processing each SYNC from Node3 and Node2, but Node3 is
>     >>> processing each SYNC from Node2 but not from Node1 which is the
>     >>> origin of the sets :
>     >>>
>     >>> On Node3 we see  `grep processing
>     >>> /var/log/slony1/node3-pns_profiles_preprod.log|awk '{print
>     >>> $5}'|sort|uniq -c`
>     >>>      19 remoteWorkerThread_1:
>     >>>     963 remoteWorkerThread_2:
>     >>>
>     >>> On Node2 we see `grep processing
>     >>> /var/log/slony1/node2-pns_profiles_preprod.log |awk '{print
>     >>> $5}'|sort|uniq -c`
>     >>>    1570 remoteWorkerThread_1:
>     >>>     865 remoteWorkerThread_3:
>     >>>
>     >>> Why is there so many SYNC not processed on Node3 ???
>     >>>
>     >>> Node3 got 22440 queue event and 25 Received event from
>     >>> remoteWorkerThread_1, while Node2 got 4467 queue event and 1578
>     >>> Received event from the same worker.
>     >>>
>     >>> Is there something to do ?
>     >>
>     >> How about looking for some error messages?
>     > None.
>     I've put slon in debug level 2
>     >>
>     >> What comes to mind would be that sl_event is grossly out of
>     shape and
>     >> that the event selection times out.
>     > Seems vacuuming sl_log_1 takes too much time cause of
>     > vacuum_cost_delay and that selecting from this table use a seq
>     scan.
>     > I'm investiguating.
>     I forced vacuum to go faster and checked slon logs of subscribers.
>     They
>     got similar disks capabilities which seems to be the bottleneck on all
>     node (wait io ~=50% in vmstat).
>
>     I found replication tasks time are different :
>
>     On node 3 :
>                          delay in seconds = 585.974ms
>                          cleanupEvent in seconds = 9.25167s
>
>     On node 2 :
>                          delay in seconds = 37.6463ms
>                          cleanupEvent in seconds = 0.203265s
>
>     May these times explain why node 3 is late compared to node 2 ?
>     What do
>     you think I have to investiguate now ?
>
>     PS: hosts consume the same processor load but node 2 is a biprocessor
>     2.6Ghz and node 3 is a biprocessor dual core 1.8Ghz (4 processors seen
>     by Linux kernel SMP)
>
>
> So... the computer with the slower processor is slower?
> What delay are you referring too? If it's from 
> _foo.sl_status.st_lag_time then you should be aware that it's actual

> precision is about +/-5 seconds.
where the value 5 seconds comes from ?
> While the cleanup is disk intensive, it also does a good chunk of 
> number crunching. I'm surprised to see an order of magnitude in 
> difference, but... not shocked.
>
> Andrew

-- 
Cyril SCETBON - Ing?nieur bases de donn?es
AUSY pour France T?l?com - SCR/HDI/DOP/HEBEX

T?l : +33 (0)4 97 12 87 60
Jabber : cscetbon@jabber.org
France Telecom - Orange
790 Avenue du Docteur Maurice Donat 
B?timent Marco Polo C2 
06250 Mougins
France

***********************************
Ce message et toutes les pieces jointes (ci-apres le 'message') sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite.
Tout message electronique est susceptible d'alteration. Le Groupe France
Telecom decline toute responsabilite au titre de ce message s'il a ete
altere, deforme ou falsifie.
Si vous n'etes pas destinataire de ce message, merci de le detruire
immediatement et d'avertir l'expediteur.
***********************************
This message and any attachments (the 'message') are confidential and
intended solely for the addressees.
Any unauthorised use or dissemination is prohibited.
Messages are susceptible to alteration. France Telecom Group shall not be
liable for the message if altered, changed or falsified.
If you are not recipient of this message, please cancel it immediately and
inform the sender.
************************************

From cbbrowne at ca.afilias.info  Tue Sep 25 09:39:53 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Sep 25 09:40:02 2007
Subject: [Slony1-general] Processing of SYNC from origin node
In-Reply-To: <46F92D89.4010803@orange-ftgroup.com> (Cyril SCETBON's message of
	"Tue, 25 Sep 2007 17:47:21 +0200")
References: <46E153D1.4060903@orange-ftgroup.com> <46E1A7A0.30401@Yahoo.com>
	<46E305D8.3090502@orange-ftgroup.com>
	<46E5AA0D.1060708@orange-ftgroup.com>
	<5a0a9d6f0709101544h41da1a6pa7375579aab463ff@mail.gmail.com>
	<46F92D89.4010803@orange-ftgroup.com>
Message-ID: <604phiog12.fsf@dba2.int.libertyrms.com>

Cyril SCETBON <cscetbon.ext@orange-ftgroup.com> writes:
> Andrew Hammond wrote:
>> So... the computer with the slower processor is slower?
>> What delay are you referring too? If it's from
>> _foo.sl_status.st_lag_time then you should be aware that it's actual
>
>> precision is about +/-5 seconds.
> where the value 5 seconds comes from ?

Updates to sl_confirm take place as SYNCs are processed, and the
granularity is never terribly exact.

- If the system is pretty busy (e.g. - regular updates to tables),
  SYNCs will be processed fairly frequently (often with default
  behaviour of either every 1s or every 10s), but with some lag
  due to how long the SYNC takes to process.

- If the system is NOT busy (e.g. - quiet times when updates to tables
  are infrequent), the default sync_interval_timeout is 10s, and hence
  on average, confirmations will be behind by 5s (1/2 of 10s).
-- 
(reverse (concatenate 'string "ofni.sesabatadxunil" "@" "enworbbc"))
http://www3.sympatico.ca/cbbrowne/linuxxian.html
Rules of the  Evil Overlord #22. "No matter how tempted  I am with the
prospect  of unlimited  power, I  will  not consume  any energy  field
bigger than my head. <http://www.eviloverlord.com/>
From cbbrowne at ca.afilias.info  Tue Sep 25 11:52:54 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Tue Sep 25 11:53:03 2007
Subject: [Slony1-general] Backport of "listen path generator"
Message-ID: <60zlzamvax.fsf@dba2.int.libertyrms.com>

I have backport the automatic listen path generator from CVS HEAD...

The generating of listen paths has something of a sordid history:

- In v1.0, it had to be handled by hand by users, which was fine for
  simple clusters, but nasty for bigger clusters with many nodes.

- For v1.1, I wrote an automagic listen path generator which Jan
  rewrote, which seemed nice, but which had some problems.

- For v1.2, Florian Pflug rewrote it, fixing the problems then seen.

Unfortunately, we then saw some further problems.  So...

- For v2.0, Jan rewrote it again.

Our folk were, internally, running into problems with v1.2 for some of
our test cases, so I tried a backport of the new v2.0 code.

  Tests done thus far:
  - I added a "testlistenpath" test to the set of tests, which is working
    fine

   - JP Fletcher did some testing of cases where he saw things break,
     and this change addressed those cases, and examination of sl_listen
     showed that the paths did indeed look apropos...

With this having worked well, I have committed the backport to the 1.2
branch, so it will be in v1.2.12.

<http://lists.slony.info/pipermail/slony1-commit/2007-September/002016.html>

If we encounter further issues with listen path generation, it seems
pretty likely that it's easier to fix the new code than to worry about
trying to roll back to elder code...

If people have any test cases that tend to exercise this, it's worth
testing this.
-- 
(format nil "~S@~S" "cbbrowne" "acm.org")
http://www3.sympatico.ca/cbbrowne/finances.html
Rules of  the Evil  Overlord #6.  "I will not  gloat over  my enemies'
predicament before killing them." <http://www.eviloverlord.com/>
From bnichols at ca.afilias.info  Wed Sep 26 07:35:15 2007
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Wed Sep 26 07:35:22 2007
Subject: [Slony1-general] Problem Building 1.2.11 with PG 8.1.10
Message-ID: <1190817315.2654.4.camel@bnicholson-desktop>

I've just built PG 8.1.10 on AIX 5.3, and encountered the following
error when trying to configure slony.

pg_config says pg_includeserverdir
is /opt/dbs/pgsql8110-slony115-AIX5300-05-00-64bit-2007-09-26/include/server/
checking for correct version of PostgreSQL... 8.1
checking PostgreSQL for enable-thread-safety as required on
aix5.3.0.0... yes
checking for PQunescapeBytea in -lpq... no
configure: error: Your version of libpq doesn't have PQunescapeBytea
     this means that your version of PostgreSQL is lower than 7.3
     and thus not supported by Slony-I.


-- 
Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.


From rod at iol.ie  Wed Sep 26 07:43:44 2007
From: rod at iol.ie (Raymond O'Donnell)
Date: Wed Sep 26 07:43:56 2007
Subject: [Slony1-general] Problem Building 1.2.11 with PG 8.1.10
In-Reply-To: <1190817315.2654.4.camel@bnicholson-desktop>
References: <1190817315.2654.4.camel@bnicholson-desktop>
Message-ID: <46FA7020.9020201@iol.ie>

On 26/09/2007 15:35, Brad Nicholson wrote:
> I've just built PG 8.1.10 on AIX 5.3, and encountered the following
> error when trying to configure slony.
> 
> pg_config says pg_includeserverdir
> is /opt/dbs/pgsql8110-slony115-AIX5300-05-00-64bit-2007-09-26/include/server/
> checking for correct version of PostgreSQL... 8.1
> checking PostgreSQL for enable-thread-safety as required on
> aix5.3.0.0... yes
> checking for PQunescapeBytea in -lpq... no
> configure: error: Your version of libpq doesn't have PQunescapeBytea
>      this means that your version of PostgreSQL is lower than 7.3
>      and thus not supported by Slony-I.

That's funny - I got the same error about 10 minutes ago, and had an 
email half-written to this list before I realised what was wrong - it 
turned out I was mistakenly pointing --with-pgconfigdir at the source 
tree, instead of at the actual installation.

HTH

Ray.

---------------------------------------------------------------
Raymond O'Donnell, Director of Music, Galway Cathedral, Ireland
rod@iol.ie
---------------------------------------------------------------
From darcy at dbitech.ca  Wed Sep 26 07:39:46 2007
From: darcy at dbitech.ca (Darcy Buskermolen)
Date: Wed Sep 26 07:44:15 2007
Subject: [Slony1-general] Problem Building 1.2.11 with PG 8.1.10
In-Reply-To: <1190817315.2654.4.camel@bnicholson-desktop>
References: <1190817315.2654.4.camel@bnicholson-desktop>
Message-ID: <200709260739.47323.darcy@dbitech.ca>

On Wednesday 26 September 2007 07:35:15 Brad Nicholson wrote:
> I've just built PG 8.1.10 on AIX 5.3, and encountered the following
> error when trying to configure slony.
>
> pg_config says pg_includeserverdir
> is
> /opt/dbs/pgsql8110-slony115-AIX5300-05-00-64bit-2007-09-26/include/server/
> checking for correct version of PostgreSQL... 8.1
> checking PostgreSQL for enable-thread-safety as required on
> aix5.3.0.0... yes
> checking for PQunescapeBytea in -lpq... no
> configure: error: Your version of libpq doesn't have PQunescapeBytea
>      this means that your version of PostgreSQL is lower than 7.3
>      and thus not supported by Slony-I.

Wild guess, but do you have more than one libpq on the system?

From bnichols at ca.afilias.info  Wed Sep 26 08:00:48 2007
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Wed Sep 26 08:00:58 2007
Subject: [Slony1-general] Problem Building 1.2.11 with PG 8.1.10
In-Reply-To: <200709260739.47323.darcy@dbitech.ca>
References: <1190817315.2654.4.camel@bnicholson-desktop>
	<200709260739.47323.darcy@dbitech.ca>
Message-ID: <1190818849.2654.11.camel@bnicholson-desktop>

On Wed, 2007-09-26 at 07:39 -0700, Darcy Buskermolen wrote:
> On Wednesday 26 September 2007 07:35:15 Brad Nicholson wrote:
> > I've just built PG 8.1.10 on AIX 5.3, and encountered the following
> > error when trying to configure slony.
> >
> > pg_config says pg_includeserverdir
> > is
> > /opt/dbs/pgsql8110-slony115-AIX5300-05-00-64bit-2007-09-26/include/server/
> > checking for correct version of PostgreSQL... 8.1
> > checking PostgreSQL for enable-thread-safety as required on
> > aix5.3.0.0... yes
> > checking for PQunescapeBytea in -lpq... no
> > configure: error: Your version of libpq doesn't have PQunescapeBytea
> >      this means that your version of PostgreSQL is lower than 7.3
> >      and thus not supported by Slony-I.
> 
> Wild guess, but do you have more than one libpq on the system?

Yes, but nothing that old, and with this being the configure for slony,
it really shouldn't be finding anything else

export PREFIX=/opt/dbs/pgsql8110-slony115-AIX5300-05-00-64bit-2007-09-26
LDFLAGS="-Wl,-bbigtoc" CC="gcc -maix64" ./configure \
       --prefix=$PREFIX \
       --bindir=$PREFIX/bin \
       --datadir=$PREFIX/share \
       --libdir=$PREFIX/lib \
       --with-pgconfigdir=$PREFIX/bin \
       --with-pgbindir=$PREFIX/bin \
       --with-pgincludedir=$PREFIX/include \
       --with-pglibdir=$PREFIX/lib \
       --with-pgsharedir=$PREFIX/share

-- 
Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.

From cbbrowne at ca.afilias.info  Wed Sep 26 08:03:11 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Sep 26 08:03:17 2007
Subject: [Slony1-general] Problem Building 1.2.11 with PG 8.1.10
In-Reply-To: <1190817315.2654.4.camel@bnicholson-desktop> (Brad Nicholson's
	message of "Wed, 26 Sep 2007 10:35:15 -0400")
References: <1190817315.2654.4.camel@bnicholson-desktop>
Message-ID: <60d4w5mpu8.fsf@dba2.int.libertyrms.com>

Brad Nicholson <bnichols@ca.afilias.info> writes:
> I've just built PG 8.1.10 on AIX 5.3, and encountered the following
> error when trying to configure slony.
>
> pg_config says pg_includeserverdir
> is /opt/dbs/pgsql8110-slony115-AIX5300-05-00-64bit-2007-09-26/include/server/
> checking for correct version of PostgreSQL... 8.1
> checking PostgreSQL for enable-thread-safety as required on
> aix5.3.0.0... yes
> checking for PQunescapeBytea in -lpq... no
> configure: error: Your version of libpq doesn't have PQunescapeBytea
>      this means that your version of PostgreSQL is lower than 7.3
>      and thus not supported by Slony-I.

I have seen this happen (in possibly a Somewhat Similar Environment
;-)) due to there being some compiler failure that was not related to
the version of PostgreSQL.

You might take a look in the file "config.log", heading to the end,
and then walking backwards until you reach the error.

Things to watch out for:
- On AIX, in 64 bit mode, you need "export OBJECT_MODE=64"
- For GCC, I seem to recall CC having to be (more or less) "export CC='gcc -maix_64'"
- If compiling with GCC, on AIX you need to make sure that you're NOT building
  archives using GNU ar.  "which ar" should answer the question...

It's more than likely one of these things that's breaking.
-- 
output = ("cbbrowne" "@" "linuxfinances.info")
http://linuxdatabases.info/info/lsf.html
"The  primary  difference  between  computer  salesmen  and  used  car
salesmen is that used car salesmen know when they're lying to you."
From bnichols at ca.afilias.info  Wed Sep 26 08:03:21 2007
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Wed Sep 26 08:03:27 2007
Subject: [Slony1-general] Problem Building 1.2.11 with PG 8.1.10
In-Reply-To: <46FA7020.9020201@iol.ie>
References: <1190817315.2654.4.camel@bnicholson-desktop>
	<46FA7020.9020201@iol.ie>
Message-ID: <1190819001.2654.15.camel@bnicholson-desktop>

On Wed, 2007-09-26 at 15:43 +0100, Raymond O'Donnell wrote:
> On 26/09/2007 15:35, Brad Nicholson wrote:
> > I've just built PG 8.1.10 on AIX 5.3, and encountered the following
> > error when trying to configure slony.
> > 
> > pg_config says pg_includeserverdir
> > is /opt/dbs/pgsql8110-slony115-AIX5300-05-00-64bit-2007-09-26/include/server/
> > checking for correct version of PostgreSQL... 8.1
> > checking PostgreSQL for enable-thread-safety as required on
> > aix5.3.0.0... yes
> > checking for PQunescapeBytea in -lpq... no
> > configure: error: Your version of libpq doesn't have PQunescapeBytea
> >      this means that your version of PostgreSQL is lower than 7.3
> >      and thus not supported by Slony-I.
> 
> That's funny - I got the same error about 10 minutes ago, and had an 
> email half-written to this list before I realised what was wrong - it 
> turned out I was mistakenly pointing --with-pgconfigdir at the source 
> tree, instead of at the actual installation.

I got this error while using our standard, documented build procedures
that we have used to successfully build several version of
Postgres/Slony, with the only difference being that I've built pg 8.1.10
vs. 8.1.8 and I've build openssl with PG.

-- 
Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.

From cbbrowne at ca.afilias.info  Wed Sep 26 08:09:07 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Sep 26 08:09:13 2007
Subject: [Slony1-general] Problem Building 1.2.11 with PG 8.1.10
In-Reply-To: <1190818849.2654.11.camel@bnicholson-desktop> (Brad Nicholson's
	message of "Wed, 26 Sep 2007 11:00:48 -0400")
References: <1190817315.2654.4.camel@bnicholson-desktop>
	<200709260739.47323.darcy@dbitech.ca>
	<1190818849.2654.11.camel@bnicholson-desktop>
Message-ID: <608x6tmpkc.fsf@dba2.int.libertyrms.com>

Brad Nicholson <bnichols@ca.afilias.info> writes:
> On Wed, 2007-09-26 at 07:39 -0700, Darcy Buskermolen wrote:
>> On Wednesday 26 September 2007 07:35:15 Brad Nicholson wrote:
>> > I've just built PG 8.1.10 on AIX 5.3, and encountered the following
>> > error when trying to configure slony.
>> >
>> > pg_config says pg_includeserverdir
>> > is
>> > /opt/dbs/pgsql8110-slony115-AIX5300-05-00-64bit-2007-09-26/include/server/
>> > checking for correct version of PostgreSQL... 8.1
>> > checking PostgreSQL for enable-thread-safety as required on
>> > aix5.3.0.0... yes
>> > checking for PQunescapeBytea in -lpq... no
>> > configure: error: Your version of libpq doesn't have PQunescapeBytea
>> >      this means that your version of PostgreSQL is lower than 7.3
>> >      and thus not supported by Slony-I.
>> 
>> Wild guess, but do you have more than one libpq on the system?
>
> Yes, but nothing that old, and with this being the configure for slony,
> it really shouldn't be finding anything else
>
> export PREFIX=/opt/dbs/pgsql8110-slony115-AIX5300-05-00-64bit-2007-09-26
> LDFLAGS="-Wl,-bbigtoc" CC="gcc -maix64" ./configure \
>        --prefix=$PREFIX \
>        --bindir=$PREFIX/bin \
>        --datadir=$PREFIX/share \
>        --libdir=$PREFIX/lib \
>        --with-pgconfigdir=$PREFIX/bin \
>        --with-pgbindir=$PREFIX/bin \
>        --with-pgincludedir=$PREFIX/include \
>        --with-pglibdir=$PREFIX/lib \
>        --with-pgsharedir=$PREFIX/share

Suggestion:
  Remove all of those -- options except for "--with-pgconfigdir=$PREFIX/bin"

There was a *lot* of cleanup done in version 1.2 so that you should
only need to specify the other values individually if:

 a) You have some really peculiar setup where they vary from a
    'standard' PostgreSQL directory layout, and

 b) Also, simultaneously, you are building against a PostgreSQL build
    that was hacked around so that its "pg_config" doesn't know the
    proper shape of that directory layout.

I *know* that neither a) nor b) is the case, for your installs, so I'm
quite confident you have no need to set other than
--with-pgconfigdir...
-- 
let name="cbbrowne" and tld="linuxdatabases.info" in String.concat "@" [name;tld];;
http://www3.sympatico.ca/cbbrowne/sap.html
OS/2: Why marketing matters more than technology...
From bnichols at ca.afilias.info  Wed Sep 26 08:13:48 2007
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Wed Sep 26 08:13:59 2007
Subject: [Slony1-general] Problem Building 1.2.11 with PG 8.1.10
In-Reply-To: <60d4w5mpu8.fsf@dba2.int.libertyrms.com>
References: <1190817315.2654.4.camel@bnicholson-desktop>
	<60d4w5mpu8.fsf@dba2.int.libertyrms.com>
Message-ID: <1190819631.2654.22.camel@bnicholson-desktop>

On Wed, 2007-09-26 at 15:03 +0000, Christopher Browne wrote:

> Things to watch out for:
> - On AIX, in 64 bit mode, you need "export OBJECT_MODE=64"

echo $OBJECT_MODE
64

> - For GCC, I seem to recall CC having to be (more or less) "export CC='gcc -maix_64'"

It is set at the config line

> - If compiling with GCC, on AIX you need to make sure that you're NOT building
>   archives using GNU ar.  "which ar" should answer the question...

which ar
/usr/bin/ar

> It's more than likely one of these things that's breaking.

Doesn't look that way.
-- 
Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.

From bnichols at ca.afilias.info  Wed Sep 26 08:14:06 2007
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Wed Sep 26 08:14:29 2007
Subject: [Slony1-general] Problem Building 1.2.11 with PG 8.1.10
In-Reply-To: <608x6tmpkc.fsf@dba2.int.libertyrms.com>
References: <1190817315.2654.4.camel@bnicholson-desktop>
	<200709260739.47323.darcy@dbitech.ca>
	<1190818849.2654.11.camel@bnicholson-desktop>
	<608x6tmpkc.fsf@dba2.int.libertyrms.com>
Message-ID: <1190819651.2654.24.camel@bnicholson-desktop>

On Wed, 2007-09-26 at 15:09 +0000, Christopher Browne wrote:
> I *know* that neither a) nor b) is the case, for your installs, so I'm
> quite confident you have no need to set other than
> --with-pgconfigdir...

But I do need to get to the bottom of what is actually failing, as it
also fails with 1.1.5, which I also have need to build.
-- 
Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.

From bnichols at ca.afilias.info  Wed Sep 26 08:19:21 2007
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Wed Sep 26 08:19:28 2007
Subject: [Slony1-general] Problem Building 1.2.11 with PG 8.1.10
In-Reply-To: <1190819651.2654.24.camel@bnicholson-desktop>
References: <1190817315.2654.4.camel@bnicholson-desktop>
	<200709260739.47323.darcy@dbitech.ca>
	<1190818849.2654.11.camel@bnicholson-desktop>
	<608x6tmpkc.fsf@dba2.int.libertyrms.com>
	<1190819651.2654.24.camel@bnicholson-desktop>
Message-ID: <1190819961.2654.27.camel@bnicholson-desktop>

On Wed, 2007-09-26 at 11:14 -0400, Brad Nicholson wrote:
> On Wed, 2007-09-26 at 15:09 +0000, Christopher Browne wrote:
> > I *know* that neither a) nor b) is the case, for your installs, so I'm
> > quite confident you have no need to set other than
> > --with-pgconfigdir...
> 
> But I do need to get to the bottom of what is actually failing, as it
> also fails with 1.1.5, which I also have need to build.

But, for arguments sake, trying 1.2 with 

export PREFIX=/opt/dbs/pgsql8110-slony115-AIX5300-05-00-64bit-2007-09-26
 LDFLAGS="-Wl,-bbigtoc" CC="gcc -maix64" ./configure --with-pgconfigdir=
$PREFIX/bin        
 
Results in the same error.

-- 
Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.

From bnichols at ca.afilias.info  Wed Sep 26 08:28:40 2007
From: bnichols at ca.afilias.info (Brad Nicholson)
Date: Wed Sep 26 08:28:50 2007
Subject: [Slony1-general] Problem Building 1.2.11 with PG 8.1.10
In-Reply-To: <60d4w5mpu8.fsf@dba2.int.libertyrms.com>
References: <1190817315.2654.4.camel@bnicholson-desktop>
	<60d4w5mpu8.fsf@dba2.int.libertyrms.com>
Message-ID: <1190820522.2654.33.camel@bnicholson-desktop>

On Wed, 2007-09-26 at 15:03 +0000, Christopher Browne wrote:

> You might take a look in the file "config.log", heading to the end,
> and then walking backwards until you reach the error.

Forgot about this part:

configure:6889: checking for PQunescapeBytea in -lpq
configure:6924: gcc -maix64 -o conftest -g -O2  -Wl,-bbigtoc
-L/opt/dbs/pgsql8110-slony115-AIX5300-05-00-64bit-2007-09-26/lib/
conftest.c -lpq
    -lpthreads >&5
ld: 0711-317 ERROR: Undefined symbol: .SSL_pending
ld: 0711-317 ERROR: Undefined symbol: .PEM_read_DHparams
ld: 0711-317 ERROR: Undefined symbol: .DH_size
ld: 0711-317 ERROR: Undefined symbol: .DH_check
ld: 0711-317 ERROR: Undefined symbol: .BIO_new_mem_buf
ld: 0711-317 ERROR: Undefined symbol: .PEM_read_bio_DHparams
ld: 0711-317 ERROR: Undefined symbol: .BIO_free
ld: 0711-317 ERROR: Undefined symbol: .DH_generate_parameters
ld: 0711-317 ERROR: Undefined symbol: .SSL_CTX_free
ld: 0711-317 ERROR: Undefined symbol: .SSL_shutdown
ld: 0711-317 ERROR: Undefined symbol: .SSL_free
ld: 0711-317 ERROR: Undefined symbol: .X509_free
ld: 0711-317 ERROR: Undefined symbol: .ERR_get_error
ld: 0711-317 ERROR: Undefined symbol: .ERR_reason_error_string
ld: 0711-317 ERROR: Undefined symbol: .SSL_read
ld: 0711-317 ERROR: Undefined symbol: .SSL_get_error
ld: 0711-317 ERROR: Undefined symbol: .SSL_connect
ld: 0711-317 ERROR: Undefined symbol: .SSL_get_peer_certificate
ld: 0711-317 ERROR: Undefined symbol: .X509_get_subject_name
ld: 0711-317 ERROR: Undefined symbol: .X509_NAME_oneline
ld: 0711-317 ERROR: Undefined symbol: .X509_NAME_get_text_by_NID
ld: 0711-317 ERROR: Undefined symbol: .SSL_new
ld: 0711-317 ERROR: Undefined symbol: .SSL_set_ex_data
ld: 0711-317 ERROR: Undefined symbol: .SSL_set_fd
ld: 0711-317 ERROR: Undefined symbol: .SSL_CTX_set_tmp_dh_callback
ld: 0711-317 ERROR: Undefined symbol: .SSL_CTX_ctrl
ld: 0711-317 ERROR: Undefined symbol: .SSL_CTX_load_verify_locations
ld: 0711-317 ERROR: Undefined symbol: .SSL_CTX_set_verify
ld: 0711-317 ERROR: Undefined symbol: .TLSv1_method
ld: 0711-317 ERROR: Undefined symbol: .SSL_CTX_new
ld: 0711-317 ERROR: Undefined symbol: .SSL_library_init
ld: 0711-317 ERROR: Undefined symbol: .SSL_load_error_strings
ld: 0711-317 ERROR: Undefined symbol: .CRYPTO_set_id_callback
ld: 0711-317 ERROR: Undefined symbol: .CRYPTO_num_locks
ld: 0711-317 ERROR: Undefined symbol: .CRYPTO_set_locking_callback
ld: 0711-317 ERROR: Undefined symbol: .SSL_get_ex_data
ld: 0711-317 ERROR: Undefined symbol: .PEM_read_X509
ld: 0711-317 ERROR: Undefined symbol: .PEM_read_PrivateKey
ld: 0711-317 ERROR: Undefined symbol: .X509_check_private_key
ld: 0711-317 ERROR: Undefined symbol: .SSL_write
ld: 0711-345 Use the -bloadmap or -bnoquiet option to obtain more
information.
collect2: ld returned 8 exit status
configure:6930: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "postgresql-slony1-engine"
| #define PACKAGE_TARNAME "postgresql-slony1-engine"
| #define PACKAGE_VERSION "1.2.11"
| #define PACKAGE_STRING "postgresql-slony1-engine 1.2.11"
| #define PACKAGE_BUGREPORT ""
| #define HAVE_PTHREAD 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_FCNTL_H 1
| #define HAVE_LIMITS_H 1
| #define HAVE_STDDEF_H 1
| #define HAVE_SYS_SOCKET_H 1
| #define HAVE_SYS_TIME_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_GETTIMEOFDAY 1
| #define HAVE_DUP2 1
| #define HAVE_ALARM 1
| #define HAVE_MEMSET 1
| #define HAVE_SELECT 1
| #define HAVE_STRDUP 1
| #define HAVE_STRERROR 1
| #define HAVE_STRTOL 1
| #define HAVE_STRTOUL 1
| #define HAVE_INT32_T 1
| #define HAVE_UINT32_T 1
| #define HAVE_U_INT32_T 1
| #define HAVE_INT64_T 1
| #define HAVE_UINT64_T 1
| #define HAVE_U_INT64_T 1
| #define HAVE_SSIZE_T 1
| #define HAVE_POSIX_SIGNALS
| #define PG_VERSION_OK 1
| #define PG_VERSION_MAJOR 8
| #define PG_VERSION_MINOR 1
| /* end confdefs.h.  */
|
| /* Override any GCC internal prototype to avoid an error.
|    Use char because int might match the return type of a GCC
|    builtin and then its argument prototype would still apply.  */
| #ifdef __cplusplus
| extern "C"
| #endif
| char PQunescapeBytea ();
| int
| main ()
| {
| return PQunescapeBytea ();
|   ;
|   return 0;
| }
configure:6948: result: no
configure:6961: error: Your version of libpq doesn't have
PQunescapeBytea
     this means that your version of PostgreSQL is lower than 7.3
     and thus not supported by Slony-I.




-- 
Brad Nicholson  416-673-4106
Database Administrator, Afilias Canada Corp.

From cbbrowne at ca.afilias.info  Wed Sep 26 08:34:25 2007
From: cbbrowne at ca.afilias.info (Christopher Browne)
Date: Wed Sep 26 08:34:31 2007
Subject: [Slony1-general] Problem Building 1.2.11 with PG 8.1.10
In-Reply-To: <1190820522.2654.33.camel@bnicholson-desktop> (Brad Nicholson's
	message of "Wed, 26 Sep 2007 11:28:40 -0400")
References: <1190817315.2654.4.camel@bnicholson-desktop>
	<60d4w5mpu8.fsf@dba2.int.libertyrms.com>
	<1190820522.2654.33.camel@bnicholson-desktop>
Message-ID: <60ps05l9tq.fsf@dba2.int.libertyrms.com>

Brad Nicholson <bnichols@ca.afilias.info> writes:

> On Wed, 2007-09-26 at 15:03 +0000, Christopher Browne wrote:
>
>> You might take a look in the file "config.log", heading to the end,
>> and then walking backwards until you reach the error.
>
> Forgot about this part:
>
> configure:6889: checking for PQunescapeBytea in -lpq
> configure:6924: gcc -maix64 -o conftest -g -O2  -Wl,-bbigtoc
> -L/opt/dbs/pgsql8110-slony115-AIX5300-05-00-64bit-2007-09-26/lib/
> conftest.c -lpq
>     -lpthreads >&5
> ld: 0711-317 ERROR: Undefined symbol: .SSL_pending
> ld: 0711-317 ERROR: Undefined symbol: .PEM_read_DHparams
> ld: 0711-317 ERROR: Undefined symbol: .DH_size
> ld: 0711-317 ERROR: Undefined symbol: .DH_check

Actually, that helps!

The problem is that libpq expects to have SSL libraries available, and
you don't have them specified in the Slony-I configuration.

Try adding in "LIBS=/opt/freeware/lib" and that may help.

e.g.
   CC="gcc -maix64" LIBS=/opt/freeware/lib ./configure --lots-of-parms
-- 
output = reverse("ofni.sailifa.ac" "@" "enworbbc")
<http://dba2.int.libertyrms.com/>
Christopher Browne
(416) 673-4124 (land)
From craig_james at emolecules.com  Wed Sep 26 09:55:34 2007
From: craig_james at emolecules.com (Craig James)
Date: Wed Sep 26 09:53:35 2007
Subject: [Slony1-general] Scheduled updates: Part-time slony?
Message-ID: <46FA8F06.4090901@emolecules.com>

We maintain a database that is only updated once per week on a scheduled basis, and it has a backup copy running on a separate server.  I'd like to use Slony to keep these two in sync.

Question 1: Since the updates are scheduled, is there any reason to run slon the rest of the week?  I'd like to start slon, do the update, wait for the slaves to be updated, and then shut off slon.

Question 2: How do I know for certain that the slaves are 100% synchronized with the master, so that I can shut off slon?

Question 3: Can I do the update on the master, wait for it to finish, THEN start the slon daemons to sync the slave database?

Thanks,
Craig
From mpartio at gmail.com  Wed Sep 26 21:15:31 2007
From: mpartio at gmail.com (Mikko Partio)
Date: Wed Sep 26 21:15:48 2007
Subject: [Slony1-general] Scheduled updates: Part-time slony?
In-Reply-To: <46FA8F06.4090901@emolecules.com>
References: <46FA8F06.4090901@emolecules.com>
Message-ID: <2ca799770709262115w4215bc83r4d6701ee1e04d28d@mail.gmail.com>

On 9/26/07, Craig James <craig_james@emolecules.com> wrote:
>
> We maintain a database that is only updated once per week on a scheduled
> basis, and it has a backup copy running on a separate server.  I'd like to
> use Slony to keep these two in sync.
>
> Question 1: Since the updates are scheduled, is there any reason to run
> slon the rest of the week?  I'd like to start slon, do the update, wait f=
or
> the slaves to be updated, and then shut off slon.



Sure.


Question 2: How do I know for certain that the slaves are 100% synchronized
> with the master, so that I can shut off slon?



Check view sl_status, if st_lag_num_events is close to zero you are probably
synchronized.


Question 3: Can I do the update on the master, wait for it to finish, THEN
> start the slon daemons to sync the slave database?



Sure but why? It seems to me that if you have only one large update per week
it would be easier just to pg_dump the database to the standby location
after the update. Unless your database is very large?

Regards

Mikko
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070927/=
f0a11bb2/attachment.htm
From craig_james at emolecules.com  Thu Sep 27 07:13:41 2007
From: craig_james at emolecules.com (Craig James)
Date: Thu Sep 27 07:11:36 2007
Subject: [Slony1-general] Copying data from a non-Slony table
In-Reply-To: <2ca799770709262115w4215bc83r4d6701ee1e04d28d@mail.gmail.com>
References: <46FA8F06.4090901@emolecules.com>
	<2ca799770709262115w4215bc83r4d6701ee1e04d28d@mail.gmail.com>
Message-ID: <46FBBA95.2070606@emolecules.com>

Suppose I have two tables, SOURCE and DESTINATION, and only DESTINATION is under Slony replication.  Does the following work?

   insert into DESTINATION(a,b,c) (select a,b,c from SOURCE);

Since the slave database doesn't have the SOURCE table, how will Slony get the data?  Does it convert it into a series of one-line inserts?  Does it just fail in this case?

Thanks,
Craig
From darcy at dbitech.ca  Thu Sep 27 07:17:07 2007
From: darcy at dbitech.ca (Darcy Buskermolen)
Date: Thu Sep 27 07:21:24 2007
Subject: [Slony1-general] Copying data from a non-Slony table
In-Reply-To: <46FBBA95.2070606@emolecules.com>
References: <46FA8F06.4090901@emolecules.com>
	<2ca799770709262115w4215bc83r4d6701ee1e04d28d@mail.gmail.com>
	<46FBBA95.2070606@emolecules.com>
Message-ID: <200709270717.07797.darcy@dbitech.ca>

On Thursday 27 September 2007 07:13:41 Craig James wrote:
> Suppose I have two tables, SOURCE and DESTINATION, and only DESTINATION is
> under Slony replication.  Does the following work?
>
>    insert into DESTINATION(a,b,c) (select a,b,c from SOURCE);
>
> Since the slave database doesn't have the SOURCE table, how will Slony get
> the data?  Does it convert it into a series of one-line inserts?  Does it
> just fail in this case?

Slony is not statement replication so yes this will work fine, internaly it 
will be converted to a series of one line inserts, which will all be applied 
to the subscriber in a single transaction.


>
> Thanks,
> Craig
> _______________________________________________
> Slony1-general mailing list
> Slony1-general@lists.slony.info
> http://lists.slony.info/mailman/listinfo/slony1-general


From JanWieck at Yahoo.com  Thu Sep 27 08:53:58 2007
From: JanWieck at Yahoo.com (Jan Wieck)
Date: Thu Sep 27 08:54:15 2007
Subject: [Slony1-general] Slony reported error..
In-Reply-To: <021126B987E43D44A860139823C079110E2B78@orion.cdkkt.com>
References: <021126B987E43D44A860139823C079110E2B78@orion.cdkkt.com>
Message-ID: <46FBD216.1000402@Yahoo.com>

On 9/21/2007 7:25 PM, Daniel B. Thurman wrote:
> Slony Log reported an error on the Master server:
> ERROR  remoteWorkerThread_2: sl_setsync entry for set 1 not found on provider
> 
> What does this mean?

It means that the current sync status for the set you try to subscribe 
cascaded from a node other than the origin does not exist. I guess you 
tried to create a cascaded node without waiting for the data provider to 
have completed its own subscription process.


Jan

-- 
#======================================================================#
# It's easier to get forgiveness for being wrong than for being right. #
# Let's break this rule - forgive me.                                  #
#================================================== JanWieck@Yahoo.com #
From lavalamp at spiritual-machines.org  Tue Sep 25 20:19:43 2007
From: lavalamp at spiritual-machines.org (Brian A. Seklecki)
Date: Thu Sep 27 15:21:34 2007
Subject: [Slony1-general] Replication System via VPN
In-Reply-To: <601wfx88on.fsf@dba2.int.libertyrms.com>
References: <a68bc3110706261912y6ac88d75u1b4b09cce29ba676@mail.gmail.com>
	<20070627192014.GA27069@phlogiston.dyndns.org>
	<601wfx88on.fsf@dba2.int.libertyrms.com>
Message-ID: <1190776784.3425.13.camel@new-host>

Slony uses the pgsql protocol for inter-node communication.  I can
attest to success with IPSec VPN compatibility from a Major Vendor.  You
just need to plan your WAN bandwidth needs accordingly.  Check out
"Metro Ethernet" technology for metro-area networks.
 

On Wed, 2007-06-27 at 16:05 -0400, Christopher Browne wrote:
> Andrew Sullivan <ajs@crankycanuck.ca> writes:
> > On Wed, Jun 27, 2007 at 10:12:31AM +0800, Dewi Andriyanti wrote:
> >> I intend to build a replication system via VPN using Slony but I need more
> >> reference. Is Slony good in data integrity, consistency, reliability and
> >> response time? Is Slony better than PGCluster? What is drawbacks of Slony?
> >> Would anybody help me to share stable configuration for replication system
> >> via VPN using Slony?
> >
> > What's the bandwidth available inside the VPN?  You need to make sure
> > you can propagate the changes fast enough.  I don't believe PGCluster
> > can work over wide areas -- I think it has to be local.
> 
> I haven't seen any discussion of PGCluster in a while; the thing that
> has been discussed a lot more of late has been PGCluster-2.
> 
> That's a system which shares parts of PostgreSQL shared memory across
> the network; I would expect that to perform extraordinarily badly
> across a WAN.  If PGCluster uses a similar architecture, then the same
> would presumably be true.  I'm not sure they are identical that way,
> though...

From unfies at gmail.com  Fri Sep 28 17:00:26 2007
From: unfies at gmail.com (Will Langford)
Date: Fri Sep 28 17:00:39 2007
Subject: [Slony1-general] slony-i + drbd
Message-ID: <2b17483b0709281700o2c9af247x33b4249e0ae17d4d@mail.gmail.com>

Hi,

I work for a company that installs network services in many locations, each
are completely isolated/localized.  These services include moderate to heavy
postgresql traffic, with either a balanced select/update ratio, or slightly
leaning towards more updates.

Due to the nature of our products, we typically only need a single mid to
low range server to handle our loads.  Times are changing, our products are
becoming more demanding, and needs are changing as well.

We've always had a heartbeat/drbd fail over system on location so that if
our system goes down, a backup takes over.  We've had insanely great success
with this setup.  The low amount of down time is acceptable, although our
system is generally a 24/7 grinder.

If we keep our current setup where the two primary nodes have the database
live in DRBD, and there's a third report crunching box, how tolerant is
slony-1 to heartbeat/drbd switch over to a new system ? Or is there some
kind of multi-master replication system that's effective for a 2 or 3 system
setup ?

Lately, I've been looking at several bottle necks in our system.  I've had
good results with moving to a newer version of postgres, and also with
changing out the underlying filesystem from ext3 to reiser.  I've done about
all I can to tweak configuration file stuffs relating to
wal/fsm/buffers/etc.  I've also done what I can to get proper columns
indexed in the myriad of tables used.  The last couple things left for
optimization attempts would be to generate diagrammed output of query
patterns of our software and possibly also to move as many software queries
to function calls rather than just strings passed to the c lib back end (ie:
to avoid constant tokenizing).

Given that we typically have only two servers on location, it seems that
many of the multi-master replication/clustering addons would end up with a
negative speed benefit, especially given the 'bad' update/select ratio.  As
such, we do have some client softwares that do only some mean ole huge nasty
selects explicitly (no updates), and there are daily report crunchings on
nonvolatile (ie: previous day's) data.

We're a small software house, and many of the enterprise solutions are
beyond our budget... so... make do with what ya got, etc.  We could
probabily easily justify an additional low end server to handle the
read-only client softwares, as long as they were executed soley on this box.


So..... if the non-volatile read only queries are being executed on the
slave system.... I can see this as being a fairly decent performance boon
during peak report generation etc.  Anything that would need write access
would either connect to the master system, or generate some .sql files to be
copied over and ran on the master system.

Our current DRBD/failover system is for the database files and all other
our-software specific files to live on the DRBD replicated mount point.
We've not had any problems with a crashed / tripped-over-power-chord fail
over issues with postgres firing up on the backup server after discovering
the first node is dead.  And, I actually kind of prefer this system compared
to application level replication, because any kind of lock/stall caused by
the application replication subsystem is detrimental, and our client
software is a bit volatile at times (a 5 year old work in progress....
feature creep etc). So... my question becomes (just to copy/paste) :

If we keep our current setup where the two primary nodes have the database
live in DRBD, and there's a third report crunching box, how tolerant is
slony-1 to heartbeat/drbd switch over to a new system ? Or is there some
kind of multi-master replication system that's effective for a 2 or 3 system
setup ?

-Will
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.slony.info/pipermail/slony1-general/attachments/20070928/=
1d1d0341/attachment.htm
